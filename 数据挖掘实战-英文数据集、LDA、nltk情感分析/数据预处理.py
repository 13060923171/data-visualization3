import pandas as pd
# æ•°æ®å¤„ç†åº“
import matplotlib
import matplotlib.pyplot as plt
import numpy as np
import re

from tqdm import tqdm

from collections import Counter
import itertools

from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.decomposition import LatentDirichletAllocation

from nltk.sentiment.vader import SentimentIntensityAnalyzer
from nltk.stem import WordNetLemmatizer
import nltk

list_number = [i for i in range(1,61)]
list_df = []

for i in list_number:
    try:
        data = pd.read_excel('./åŸå§‹æ•°æ®/{}.xlsx'.format(i))
        data['è§†é¢‘ç¼–å·'] = i
        list_df.append(data)
    except:
        pass

df = pd.concat(list_df,axis=0)
lemmatizer = WordNetLemmatizer()
#è®¾ç½®æƒ…æ„Ÿæ¨¡å‹åº“
sid = SentimentIntensityAnalyzer()

stop_words = []
with open('å¸¸ç”¨è‹±æ–‡åœç”¨è¯(NLPå¤„ç†è‹±æ–‡å¿…å¤‡)stopwords.txt','r',encoding='utf-8')as f:
    lines = f.readlines()
    for line in lines:
        stop_words.append(line.strip().replace("'",""))


#å»æ‰æ ‡ç‚¹ç¬¦å·ï¼Œä»¥åŠæœºæ¢°å‹ç¼©
def preprocess_word(word):
    # Remove punctuation
    word = word.strip('\'"?!,.():;')
    # Convert more than 2 letter repetitions to 2 letter
    # funnnnny --> funny
    word = re.sub(r'(.)\1+', r'\1\1', word)
    # Remove - & '
    word = re.sub(r'(-|\')', '', word)
    return word


#å†æ¬¡å»æ‰æ ‡ç‚¹ç¬¦å·
def gettext(x):
    import string
    punc = string.punctuation
    for ch in punc:
        txt = str(x).replace(ch,"")
    return txt


# #æ›¿æ¢è¡¨æƒ…åŒ…
# def handle_emojis(text):
#     # Smile -- :), : ), :-), (:, ( :, (-:, :')
#     text = re.sub(r'(:\s?\)|:-\)|\(\s?:|\(-:|:\'\))', ' ', text)
#     # Laugh -- :D, : D, :-D, xD, x-D, XD, X-D
#     text = re.sub(r'(:\s?D|:-D|x-?D|X-?D)', ' ', text)
#     # Love -- <3, :*
#     text = re.sub(r'(<3|:\*)', ' ', text)
#     # Wink -- ;-), ;), ;-D, ;D, (;,  (-;
#     text = re.sub(r'(;-?\)|;-?D|\(-?;)', ' ', text)
#     # Sad -- :-(, : (, :(, ):, )-:
#     text = re.sub(r'(:\s?\(|:-\(|\)\s?:|\)-:)', ' ', text)
#     # Cry -- :,(, :'(, :"(
#     text = re.sub(r'(:,\(|:\'\(|:"\()', ' ', text)
#     # Angry -- >:(, >:-(, :'(
#     text = re.sub(r'(>:\(|>:-\(|:\'\()', ' ', text)
#     # Surprised -- :O, :o, :-O, :-o, :0, 8-0
#     text = re.sub(r'(:\s?[oO]|:-[oO]|:0|8-0)', ' ', text)
#     # Confused -- :/, :\, :-/, :-\
#     text = re.sub(r'(:\\|:/|:-\\\\|:-/)', ' ', text)
#     # Embarrassed -- :$, :-$
#     text = re.sub(r'(:\\$|:-\\$)', ' ', text)
#     # Other emoticons
#     emoticons = re.findall(r'(?::|;|=)(?:-)?(?:\)|\(|D|P)', text)
#     for emoticon in emoticons:
#         text = text.replace(emoticon, " ")
#     return text

#æ›¿æ¢è¡¨æƒ…åŒ…
def handle_emojis(text):
    text = re.sub(r'ğŸ‘', 'nice ', text)
    text = re.sub(r'ğŸ¤¤', 'delicious ', text)
    text = re.sub(r'â¤', 'favorite ', text)
    text = re.sub(r'ğŸ˜‹', 'fond ', text)
    text = re.sub(r'ğŸ˜€', 'glad ', text)
    text = re.sub(r'ğŸ˜', 'endearment ', text)
    text = re.sub(r'ğŸ‘', 'great ', text)
    text = re.sub(r'ğŸŒ', 'like ', text)
    text = re.sub(r'ğŸ˜ƒ', 'favorite ', text)
    text = re.sub(r'ğŸ˜˜', 'love ', text)
    text = re.sub(r'ğŸ˜¡', 'angry ', text)
    text = re.sub(r'ğŸ’”', 'upset ', text)
    text = re.sub(r'ğŸ¤¢', 'sad ', text)
    text = re.sub(r'ğŸ˜­', 'sorrowing ', text)
    text = re.sub(r'ğŸ‘‡', 'poorly ', text)
    text = re.sub(r'ğŸ˜–', 'sick ', text)
    text = re.sub(r'ğŸ˜…', 'Speechless ', text)
    text = re.sub(r'ğŸ’©', 'lousy ', text)
    return text


def clean_text(text):
    # Replaces URLs with the word URL
    text = re.sub(r'((www\.[\S]+)|(https?://[\S]+))', ' ', text)
    # Replace @username with the word USER_MENTION
    text = re.sub(r'@[\S]+', ' ', text)
    # Replace #hashtag with the word HASHTAG
    text = re.sub(r'#(\S+)', ' ', text)
    text = re.sub(r'#\w+', ' ', text)
    # Remove RT (retext)
    text = re.sub(r'\brt\b', ' ', text)
    # Replace 2+ dots with space
    text = re.sub(r'\.{2,}', ' ', text)
    # Strip space, " and ' from text
    text = text.strip(' "\'')
    # Handle emojis
    text = handle_emojis(text)
    # Replace multiple spaces with a single space
    text = re.sub(r'\s+', ' ', text)

    # Remove numbers
    text = re.sub(r'\d+', ' ', text)
    # Remove punctuation
    text = re.sub(r'[^A-Za-z0-9\s]+', ' ', text)
    # Lowercase and split into words
    words = text.lower().split()
    words = [w for w in words if w not in stop_words]
    words = [lemmatizer.lemmatize(w) for w in words]
    words = [preprocess_word(w) for w in words]
    if len(words) != 0:
        return ' '.join(words)
    else:
        return np.NAN

#æƒ…æ„Ÿåˆ¤æ–­
def emotional_judgment(x):
    compound = x['compound']
    if compound >= 0.05:
        return 'positive'
    elif compound <= -0.05:
        return 'negative'
    else:
        return 'neutral'


df = df.drop_duplicates(subset=['textDisplay'])
df['textDisplay'] = df['textDisplay'].astype('str')
df = df.dropna(subset=['textDisplay'],axis=0)
df['clearn_text'] = df['textDisplay'].apply(gettext)
df = df.dropna(subset=['clearn_text'],axis=0)
df['clearn_text'] = df['clearn_text'].apply(clean_text)
df.dropna(subset=['clearn_text'],axis=0,inplace=True)
#å¼€å§‹æƒ…æ„Ÿåˆ¤æ–­
df['scores'] = df['clearn_text'].apply(lambda commentText: sid.polarity_scores(commentText))
#è¡¨ç¤ºæ–‡æœ¬æƒ…æ„Ÿçš„ç»¼åˆå¾—åˆ†ï¼ˆ-1åˆ°1ä¹‹é—´çš„æµ®ç‚¹æ•°ï¼‰
df['compound'] = df['scores'].apply(lambda score_dict: score_dict['compound'])
#è¯»å–è´Ÿé¢
df['Negtive'] = df['scores'].apply(lambda score_dict: score_dict['neg'])
#è¯»å–æ­£é¢
df['Postive'] = df['scores'].apply(lambda score_dict: score_dict['pos'])
#è¯»å–ä¸­ç«‹
df['Neutral'] = df['scores'].apply(lambda score_dict: score_dict['neu'])
#è¯»å–å¤æ‚åº¦
df['sentiment_class'] = df['scores'].apply(emotional_judgment)
#ä¿å­˜æœ€æ–°æ–‡æ¡£
df.to_excel('data.xlsx',encoding="utf-8-sig",index=None)

