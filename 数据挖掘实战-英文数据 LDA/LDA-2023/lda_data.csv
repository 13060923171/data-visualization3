id,杂志名称,页码,日期,标题,子标题,内容,分词,主题概率,主题类型
632854,Main,12,31/12/2023,An eye  on  AI,"Regulating the use of artificial intelligence against potential abuse is a crucial endeavour, experts say.","THERE is no denying that artificial intelligence (AI) is taking the modern world by storm.
 Following the launch of the popular AI chatbot ChatGPT in late 2022, AI has dominated headlines and conversations in 2023, leading Collins Dictionary lexicographers to name it the word of the year.
 Fears of the effect AI could have on society and humanity at large prompted an open letter signed by thousands of public figures and headed by tech mogul Elon Musk and Apple cofounder and tech entrepreneur Steve Wozniak, calling for an immediate pause of giant AI experiments like ChatGPT until proper guidelines are established.
 Of course, the rise of AI has not gone unnoticed by the Malaysian government either, with Science, Technology and Innovation Minister Chang Lih Kang saying his ministry is looking into the possibility of regulating AI use in the country.
 However, before formulating any laws to govern AI, Chang’s ministry is looking into drafting an AI code of ethics.
 “The plan to come up with AI regulations is the end goal, and it starts with the establishment of AI governance and a code of ethics, which are expected to be ready by next year,” Chang says.
 Given that AI is still a burgeoning field, there remains much to learn and understand about its capabilities and potential risks. So developing effective regulations for this nascent technology presents a unique challenge for all stakeholders.
 Chang has already identified an obstacle on the road to AI regulation: the possibility that such regulations and monitoring will slow down technology innovation.
 “This is because an innovation process that is governed by strict regulations will discourage innovators or businesses from taking risks,” he says.
 Immediate foundation
 But an AI code of ethics could prove crucial as an immediate foundation for stakeholders, says International Islamic University Malaysia computer science and AI expert, Prof Emeritus Datuk Tengku Mohd Tengku Sembok.
 “The professional computing community and the users of any digital systems should welcome the initiative taken by the Mosti minister to come up with an AI code of ethics and AI laws,” he said, referring to the Science, Technology and Innovation Minister.
 “The code of AI ethics will serve as a good immediate foundation for organisations to practise and prepare for the enactment of AI laws in the future.
 “The code of ethics is not legally mandatory and is intended to set ethical standards, but the law will be legally mandatory,” he explains.
 Tengku Mohd points out that the process of enacting an AI law will take time as it needs to go through the legislative process in Parliament first. Thus it is prudent for the government to craft a code of ethics before going straight to enacting a law.
 However, Tengku Mohd wants to go one step further to strengthen the governance of digital systems and proposes the establishment of a Board of Computer Professionals.
 “I am of the opinion that the government should have the code of ethics, followed by law, for digital systems in general, with or without the use of AI technology.”
 He points out that any engineering project must be endorsed by engineering consultants under the purview of the Board of Engineers because such projects involve safety; similarly, because digital systems are encroaching into the safety and security of every user in all daily activities, there should be the same type of oversight.
 Looking abroad
 For now, the immediate concern is the upcoming AI code of ethics, and Tengku Mohd has some suggestions on what the code should strive to achieve.
 Firstly, he says the code of  ethics should provide a guideline for individuals and organisations on how to design, develop, deploy, and use AI technology.
 This must be done in a way that is trustworthy and prioritises human dignity, equality, preservation of the environment, respect for cultural diversity, and data responsibility.
 A standard operating procedure must be developed, and certified AI experts must be recruited to certify and secure AI applications in any system, he adds.
 Tengku Mohd also says the code must address the principles recommended by the United Nations, which are to not harm, to have a defined purpose,  necessity and proportionality, safety and security, fairness  and nondiscrimination, sustainability, right to privacy, data  protection and data governance, human autonomy and oversight, transparency and explainability, responsibility and accountability, and, lastly, inclusion and participation. 
 The government is well  aware of the developments of  AI regulations worldwide, says Chang, pointing to the European Union’s AI Act which was recently provisionally agreed upon.
 Taking time
 Aside from the EU’s AI Act, many other countries have also started the process of developing ethical guidelines or laws related to AI, says Tengku Mohd.
 In the United States, for example, there may not be federal AI regulations yet but individual states like California have implemented laws such as the Cali-fornia Consumer Privacy Act giving consumers the right to opt out of any business’s AI or automation programmes. The United Kingdom is exploring AI ethics while bodies such as the Information Commissioner’s Office guide responsible AI use in the country.
 In China, authorities have already released guidelines for the ethical use of AI and the government is actively working on AI-related regulations. And right next door in neighbouring Singapore, there is already an AI governance framework which helps organisations validate the performance of their AI systems through standardised tests against 11 principles.",artificial intelligence modern storm launch popular chatbot chatgpt late headline conversation collins dictionary lexicographer word society humanity letter thousand public figure tech mogul elon musk apple cofounder tech entrepreneur wozniak pause giant experiment proper guideline rise unnoticed malaysian government science technology innovation minister chang lih ministry possibility country law govern chang ministry code ethic regulation goal establishment governance code ethic ready chang field learn understand capability potential risk effective regulation nascent technology unique challenge stakeholder obstacle road regulation possibility regulation slow technology innovation innovation process strict regulation innovator business risk foundation code ethic crucial foundation stakeholder international islamic university malaysia computer science expert prof emeritus datuk tengku mohd tengku sembok professional community user digital system initiative mosti minister code ethic law science technology innovation minister code ethic foundation organisation prepare enactment law future code ethic mandatory ethical standard law mandatory explains mohd process law time legislative process parliament prudent government craft code ethic law tengku mohd step governance digital system establishment board computer professional opinion government code ethic law digital system technology engineering project engineering consultant board engineer project safety digital system safety security user daily activity oversight concern upcoming code ethic mohd suggestion strive code ethic guideline individual organisation design deploy technology trustworthy prioritises human dignity equality preservation environment respect cultural diversity data responsibility standard procedure expert certify secure application system tengku mohd code address principle united nation harm purpose necessity proportionality safety security fairness nondiscrimination sustainability privacy data protection data governance human autonomy oversight transparency explainability responsibility accountability inclusion participation government aware development regulation chang european union time country process ethical guideline law tengku mohd united federal regulation individual california law fornia consumer privacy consumer business automation programme united kingdom ethic body office guide responsible country china authority guideline ethical government regulation singapore governance framework organisation validate performance system test principle,"[(3, 0.119881965), (4, 0.8780311)]",4
632852,Main,13,31/12/2023,Why doctors should get to know AI  as well as they know their spouses,,"CHATGPT has made artificial intelligence (AI) widely available, including for doctors. Other types of medical AI and algorithms are getting smarter. And with new US Food and Drug Administration efforts underway to evaluate many algorithms, higher quality ones will increasingly enter routine clinical use, aiding in every-thing from the detection of heart attacks to treatment decisions for cancer.
 In theory, these advances are great news. But they won’t lead to better diagnostic ability and patient treatment unless doctors change how they approach clinical care. Even worse, using algorithms and AI in the wrong way can harm patients, yet most US medical students currently learn little to nothing about these technologies.
 We recently proposed curricula in the New England Journal of Medicine to prepare physicians for these coming changes. To benefit from AI while keeping patients safe, doctors must know these technologies intimately – how they “think”, what they’re good at and where they’re limited – as you might understand a trusted colleague or even a spouse.
 In other words, doctors should view these technologies as partners, not programs.
 How do we build strong doctor- AI partnerships? Communication is critical. But right now, doctors and AI don’t speak the same language. When doctors think and talk about disease, their language is physiological: which bodily systems are involved, and how those systems relate to patient symptoms or laboratory findings.
 But when algorithms and AI analyse large swathes of patient data to predict outcomes or find relational patterns, they do so in a purely quantitative way. Their “language” is one of numerical probabilities – a 10% probability that a woman with abdominal pain is having a heart attack, a 70% probability that a patient with a lung mass on a CT scan has cancer.
 Having real-world probabilities supports doctors making better diagnoses, prognoses and treatment recommendations. For example, a doctor may conclude that a patient has “all the signs” of a particular diagnosis, yet may benefit from an algorithmic reminder that the probability of that diagnosis is under 50%, meaning the patient could easily have something else and the doctor should continue investigating (and AI may even suggest alternative diagnoses).
 However, these benefits only materialize if doctors are comfortable using and thinking in terms of probabilities – and currently, many doctors struggle with this.
 How can doctors think more in terms of probabilities? For one, many medical students arrive at American medical schools having never taken statistics, and we agree with others that statistics and epidemiology matter more than the typical premedical calculus course to practising medicine. Once in medical school, students should practice using probabilities to make decisions, not simply memorising formulas. 
 At the University of Maryland School of Medicine, we have developed online visualisation tools (testingwisely.com) to make thinking in terms of probabilities more intuitive, reflecting recent advances in the psychology of decision-making and risk assessment.
 Second, doctors must understand the limitations of their AI partners and set realistic expectations. For example, imagine an algorithm flags a patient as low risk for developing heart disease because their yearly blood work is normal and they don’t have diabetes or high blood pressure. If the patient’s siblings have had heart attacks but the algorithm didn’t “know” this information when it made its prediction, that’s important for a physician to understand and could mean the algorithm underestimated the patient’s true risk. Better, more transparent algorithms will reduce, but cannot fully prevent, these scenarios. Therefore, doctors’ judgement – and some healthy scepticism – remain essential.
 Finally, it’s an unwritten rule that partnerships often divide tasks by skill sets (in our respective households, we’re usually on dish duty). A doctor-AI partnership will be similar. Eventually, algorithms may routinely scan patients’ medical records, linking their symptoms to potentially overlooked diagnoses or providing tailored risk predictions for development of conditions like cancer.
 Due to the sheer volume of today’s medical records, this is something machines will always do better than physicians. But deciding how to act on this information is something only doctors and patients can do. It requires weighing potential harms and benefits and patient preferences. Doing this well requires critical thinking and clear communication with patients to support joint decision-making.
 These skills aren’t always intuitive, and we must teach them to physicians.
 Today, thousands of students across the United States are in their first months of medical school. What students learn now, and how medicine adapts to algorithms and AI, will matter to patient care. These technologies are more than mere programs but far from replacing physicians. They’re partners, and there is an art and science to combining their skills well.
 At the end of the day, we are all patients – and should care that medicine gets this relationship right. –  The Baltimore Sun/Tribune News Service
 Katherine Goodman is an epidemiologist, an assistant professor of epidemiology and public health at the University of Maryland School of Medicine, and an investigator at the University of Maryland Institute for Health Computing. Daniel Morgan is a physician; a professor of epidemiology, public health and infectious diseases; and director of the Center for Innovation in Diagnosis at the University of Maryland School of Medicine.",chatgpt artificial intelligence doctor medical algorithm food drug administration effort algorithm quality enter routine clinical detection heart treatment decision cancer theory advance news diagnostic ability patient treatment doctor clinical care algorithm wrong harm patient medical student learn technology curriculum journal medicine prepare coming benefit patient safe doctor technology limited understand colleague spouse doctor technology partner program strong doctor partnership communication critical doctor speak language doctor disease language physiological system system patient symptom laboratory finding analyse swathe patient data outcome relational pattern quantitative language numerical probability probability woman abdominal pain heart attack probability patient lung mass scan cancer real probability doctor prognosis treatment recommendation conclude patient sign diagnosis algorithmic reminder probability diagnosis patient doctor alternative benefit materialize doctor comfortable term probability doctor doctor term probability medical student arrive american medical school statistic statistic typical premedical calculus medicine medical school student practice probability decision formula university school medicine online visualisation tool term probability advance psychology decision risk assessment doctor limitation partner realistic expectation algorithm flag low risk heart disease blood normal blood pressure patient sibling heart algorithm prediction physician understand algorithm underestimated patient true risk transparent algorithm prevent scenario doctor healthy scepticism essential unwritten rule partnership task skill set respective household dish duty doctor partnership scan patient medical record symptom diagnosis risk prediction development condition cancer sheer volume medical record machine physician doctor patient potential harm benefit patient preference critical communication patient joint decision skill intuitive teach physician thousand student united month medical school student medicine adapts matter patient care technology program physician partner science combining skill day patient medicine relationship sun tribune news service katherine goodman epidemiologist assistant professor public health university school medicine investigator university institute health daniel morgan physician professor public health infectious disease director center innovation diagnosis university school medicine,"[(2, 0.9971609)]",2
632856,Main,13,31/12/2023,NYT has an edge  in suit againstOpenAI,,"THE lawsuit filed by The New York Times against OpenAI and Microsoft for copyright infringement pits one of the great establishment media institutions against the purveyor of a transformative new technology. Symbolically, the case promises a clash of the titans: labour-intensive human newsgathering against pushbutton information produced by artificial intelligence (AI). But legally, the case represents something different: a classic instance of the lag between established law and emerging technology.
 Copyright law, a set of rules that date back to the invention of the printing press, was not designed to cover large language models (LLMs) like ChatGPT. It will have to be consciously evolved by the courts to fit our current circumstances.
 The key legal issue in the case will be the doctrine known as fair use. Codified in the United States in the Copyright Act of 1976, fair use tells you when it’s acceptable to use text copyrighted by someone else. The fair use test has four factors. Educational and nonprofit uses are more likely to be found to be fair use. Creative work gets more copyright protection than technical writing or news. The amount of the work that has been copied matters, as does the centrality to the copied work of the material that’s been copied. And perhaps most important for The Times’ lawsuit, courts also consider whether the copying will harm the present or future market for the work copied.
 Once you know the law, you can guess roughly how the legal arguments in the case are going to go. The Times will point to examples where a user asks a question of ChatGPT and it replies with something substantially like a New York Times article. The newspaper will observe that ChatGPT is part of a business and charges fees for access to its latest versions, and that Bing, which uses the AI programme, is a core part of Microsoft’s business. The Times will emphasise the creative aspects of journalism. Above all, it will argue that if you can ask an LLM-powered search engine for the day’s news, and get content drawn directly from The New York Times, that will harm and maybe even kill its business model.
 Most of these points are plausible legal arguments. But OpenAI and Microsoft will be prepared for them. They’ll likely respond by saying that their LLM doesn’t copy; rather, it learns and makes statistical predictions to produce new answers. If I read an article in The New York Times and then write a Bloomberg opinion column on the same topic, that isn’t copyright infringement, even though I may have learned a great deal from The Times piece and relied on that information to form my own opinion. For this reason, many copyright experts have been theorising that it cannot be a copyright violation for an LLM to learn from existing online material, even if it’s under copyright. The defendants can also be expected to argue that news consists of facts and should therefore be treated more permissively than creative material.
 But Microsoft and OpenAI will have a hard time refuting the final point – that their product, which relies on newsgathering businesses like The Times, will harm those businesses. ChatGPT and other LLMs cannot go out into the world to gather and vet new facts. They are restricted, for the foreseeable future, to “learning” from information that has already been published. It follows that for LLMs to provide useful information, someone else – that is, a human – must first gather the information, ascertain that it is accurate, and publish it. This is the essence of newsgathering. It’s costly to get it right.
 What’s more, to know that we can rely on news, we need it to come from an institution that we can trust – one with a track record and a reputation it has a business interest in upholding. Otherwise, we would not have news. We would have an iterative echo chamber untethered from reality.
 Here is where the fundamental public interest in the maintenance of the free press becomes relevant to the fair use question. If you can get information more cheaply from an LLM than from The New York Times, you might drop your subscription. But if everyone did that, there would be no New York Times at all. Put another way, OpenAI and Microsoft need The New York Times and other news organisations to exist if they are to provide reliable news as part of their service. Rationally and economically, therefore, they ought to be obligated to pay for the information they are using.
 Fitting this powerful public interest into copyright law won’t be simple for the courts. Literal copying is the easiest form of infringement to punish. In ordinary legal circumstances, if LLMs change words sufficiently to be summarising rather than copying, that weakens The Times’ case. Yet summaries in different words would still be sufficient to kill The Times and similar organisations – and leave us newsless.
 The courts will need to be attuned to all this. If they don’t get it right, Congress will have to act. The news infrastructure is already tottering. If we destroy it altogether, democracy will be the loser. – Bloomberg
 Noah Feldman is a professor of law at Harvard University and also an author, most recently, of The Broken Constitution: Lincoln, Slavery and the Refounding of America.",lawsuit york time microsoft copyright infringement establishment medium institution transformative technology clash titan intensive human pushbutton artificial intelligence classic instance lag law technology copyright law rule press cover language model chatgpt court fit current circumstance key legal issue doctrine fair united copyright fair acceptable text fair test factor educational nonprofit fair creative copyright protection technical news amount matter centrality material time lawsuit court harm future market law guess legal argument time example user question chatgpt york time article newspaper observe chatgpt business charge fee access version programme core microsoft business time creative aspect journalism llm search engine day news content york time harm kill business model plausible legal argument prepared respond llm copy statistical prediction answer article york time write bloomberg opinion column topic infringement deal time relied form opinion reason copyright expert copyright violation llm online material copyright defendant argue news creative material microsoft hard time final product relies business time harm business gather vet foreseeable future llm human gather ascertain accurate publish essence costly news institution trust track record reputation business news iterative echo chamber untethered reality fundamental public maintenance free press relevant fair question cheaply llm york drop subscription york time openai microsoft york time news organisation reliable news service obligated pay powerful public copyright law simple court literal easiest form infringement punish ordinary legal circumstance change copying time summary time organisation newsless court congress news infrastructure destroy democracy bloomberg noah feldman professor law harvard university author broken constitution lincoln slavery refounding america,"[(3, 0.9964478)]",3
632640,StarBiz 7,7,30/12/2023,Indonesia braces  for AI revolution,,"AUTOMATION and artificial intelligence (AI) represent a profound socio-technical transformation for Indonesia, which can transform occupational structures and notions of social mobility. As intelligent algorithms and robots integrate across arenas pivotal for the country’s growing middle class, including banking, factories, logistics firms and customer-service providers, the potential for new inequalities emerges if the nation is unprepared.
 As a serious task, the new government elected in the upcoming election should prioritise proactive governance and encourage adaptive strategies to safeguard the inclusive prosperity of Indonesia’s 100 million-strong consumer class through the AI transition.
 A wave of automation is already palpable in the archipelago today. Machine-learning algorithms enhance the profitability of Indonesian eCommerce by more accurately predicting purchasing patterns than specialised marketers. Robotic process automation eliminates repetitive administrative tasks in IT services and business-process outsourcing offices across Java at a low cost.
 Government projections indicate that 90% of companies will adopt such technologies by 2030. Further exponential leaps in natural language processing, computer vision, predictive analytics and cloud robotics foreshadow unprecedented white-collar disruption ahead.
 Experts like McAfee and Brynjolfsson foresee the emergence of AI capabilities rapidly outpacing human proficiency across various domains, including data analysis, financial trading, legal review, inventory management, equipment monitoring, journalism and medical diagnosis within the next decade. As artificial general intelligence matures further, even roles traditionally deemed irreplaceable will not withstand machine competition.
 Thus, a question emerges: How can Indonesia support the millions of middle-income urban office workers, managers and small-business owners vulnerable to unemployment from automation, while harnessing AI-driven growth equitably?
 The middle class rose as Indonesia embraced manufacturing and digital connectivity since the early 2000s with burgeoning consumer activity driving gross domestic product growth in major cities. However, the continuing trend of automation poses a threat as it replaces middle-skill jobs faster than new ones appear. This situation will lead to a rise in status anxiety as the stability of white-collar jobs disappears, particularly for families who have recently escaped historical hardships and achieved stability.
 Market research firm McKinsey estimates that over 70% of current occupations in Indonesia have at least a 30% probability of automation in the next 10-15 years aligned with global shifts associated with intelligent algorithms. 
 Prolonged job displacement could deplete savings and negatively impact the mental health of vulnerable workers, especially as social safety nets remain underdeveloped compared with those in neighbouring countries. Loss of economic independence will also strain gender roles and household dynamics traditionally tied to male breadwinning status.
 To counter possible despair, some people who are optimistic about automation imagine that high-tech tools can produce lots of goods and services without relying on human work. This could help society shift toward more recreational lifestyles.
 However, for this idea to generate widespread prosperity, the benefits need to be shared fairly. We should be careful that job losses from technology do not just create a middle strata without much substance, while the plutocrats profit more from automated businesses through tactics like buying back shares and lay-offs.
 Avoiding this unequal trajectory requires comprehensive policy reforms with deep socio-cultural sensitivity.
 Educational institutions will play a crucial role in the workforce transition by aligning skills training with specialisations that complement machine intelligence, which is less susceptible to redundancy, while supporting vulnerable demographics. Providing students and educators with guidance that frames automation as an empowering tool rather than a threat is essential. This helps prevent anxiety from solidifying into technophobia.
 Tailoring higher vocational programmes to focus on maintaining AI systems could elevate engineers, programmers, data analysts, social researchers and creative designers into a new middle class to contribute to the growth of machine-learning applications. We must also emphasise the enduring value of soft skills such as relationship intelligence, creativity, human empathy, political acumen and ethics – qualities even the most advanced AI struggles to replicate. These skills will continue to be valuable in newly hybridised jobs.
 For those pursuing their careers, reskilling options through online microcredentials, specially designed for women managing domestic responsibilities, provide avenues to repurpose existing expertise into emerging fields. User-experience design, human-computer interaction, data visualisation, predictive-model oversight, intelligent-sensor engineering, trusted-dataset curation and AI-safety analysis hold promise as resilient career pathways.
 Nevertheless, the pace of reskilling efforts lags the rapid adoption of automation by the private sector and leaves workers to grapple with at least temporary challenges due to occupational changes. To address this, a comprehensive approach involves overhauling Indonesia’s underdeveloped social security systems.
 This reform could provide crucial support for affordable transitional health care, improved housing accessibility, retraining opportunities and job search assistance – funded through corporate productivity taxes. Such a strategy aims to maintain overall demand without compelling citizens to sell off assets. The consideration of small, non-permanent basic-income pilots emerges as an option to offer cash-based relief, particularly during periods of redundancy resulting from automation. This approach recognises the need for alternative policy thinking in the algorithmic age.
 Many believe redirecting productivity dividends directly into healthcare, education and housing is an effective strategy, as it prevents inflation that could diminish the utility of basic income for the vulnerable.
 In ensuring citizens have access to support resources, it is important to improve Internet infrastructure. This expansion is crucial for making skills-retraining opportunities accessible to rural migrants who have played a significant role in fuelling the expansion of the urban middle class.
 Lastly, Indonesia should establish a dedicated policy task force to consistently model and evaluate the varied occupational and regional impacts stemming from the adoption of AI through extensive datasets. This approach enables adaptive policy responses that are responsive to the diverse experiences within communities, particularly for those facing challenges in navigating opportunities and potential exclusion. — The Jakarta Post/ANN
 Wida Ayu Puspitosari is a lecturer at the Department of Sociology, Brawijaya University, Malang, East Java. The views expressed here are the writer’s own.",automation artificial intelligence represent profound technical transformation indonesia transform occupational structure notion social mobility intelligent algorithm robot arena pivotal country middle class factory logistics firm customer service provider potential inequality nation unprepared task government upcoming election prioritise proactive governance encourage adaptive strategy inclusive prosperity indonesia strong consumer class transition automation palpable machine algorithm enhance profitability indonesian ecommerce pattern marketer robotic process automation repetitive administrative task service business process office low cost government projection company technology exponential leap natural language processing computer vision predictive analytics robotics unprecedented white collar disruption expert brynjolfsson foresee emergence capability human proficiency domain data analysis financial trading legal review inventory management equipment journalism medical diagnosis decade artificial intelligence matures irreplaceable withstand machine competition question indonesia support million middle income urban office worker manager business owner vulnerable unemployment automation driven growth middle class indonesia digital connectivity consumer activity gross domestic product growth major city trend automation threat replaces skill job situation rise status anxiety stability white collar job family historical hardship stability market firm mckinsey estimate current occupation probability automation global shift intelligent algorithm job displacement deplete saving impact mental health vulnerable worker social safety net underdeveloped neighbouring country loss economic independence strain gender role dynamic male status counter despair people optimistic automation imagine tech tool lot service human society shift recreational lifestyle idea widespread prosperity benefit careful job loss technology middle stratum substance plutocrat automated business tactic share unequal trajectory comprehensive policy reform socio cultural sensitivity educational institution crucial role workforce transition skill specialisation complement machine intelligence susceptible redundancy vulnerable demographic student educator guidance frame tool threat essential anxiety technophobia vocational programme system engineer programmer analyst social researcher creative designer middle class contribute growth machine learning application soft skill relationship intelligence creativity human empathy political acumen ethic quality struggle skill valuable job career option microcredentials woman domestic responsibility avenue expertise field user experience design human computer interaction data visualisation predictive model sensor engineering dataset curation safety analysis promise resilient career pathway pace effort rapid adoption automation private sector worker grapple temporary challenge occupational address comprehensive approach indonesia underdeveloped social security system reform crucial support affordable transitional health care housing accessibility opportunity job search assistance corporate productivity tax strategy maintain demand citizen asset permanent basic income pilot option offer cash relief period redundancy automation approach alternative policy algorithmic age productivity dividend education housing effective strategy prevents inflation diminish utility basic income vulnerable citizen access support resource internet infrastructure expansion crucial skill opportunity accessible rural migrant role expansion urban middle class indonesia dedicated policy task force evaluate varied occupational regional impact adoption extensive datasets enables adaptive policy response diverse experience community challenge opportunity potential exclusion jakarta post ann wida ayu puspitosari lecturer department sociology brawijaya university malang east java view writer,"[(0, 0.99814737)]",0
631290,StarBiz,8,27/12/2023,Reality check on AI as it affects politics more than business,,"SINGAPORE: Generative artificial intelligence (AI) was the biggest thing to happen in the world of work in 2023, until it was not.
 The year is ending with a reality check for many bosses, who are realising that they have not figured out what to use AI for, how to use it, and if they are ready for it.
 Meanwhile, more workers plodded back to the office, trailed by new coffee chains betting big on their caffeine breaks.
 The ugly word “bleisure” resurged after the pandemic, as more workers returned to business travelling, with four in 10 tagging private vacations to their work trips.
 What will happen in 2024?
 Lay-offs caused by AI adoption will be held off in 2024, said tech consultancy Access Partnership’s Bensen Koh. But workers will continue to be under pressure.
 Programmers, financial analysts, customer service providers and graphic designers will be among professions most affected, while others such as plumbers, gardeners, counsellors and healthcare practitioners would less likely be so.
 “The impact on workers will be uneven,” he said.
 Workers already planning how to get ahead will find themselves more desirable when Gen AI goes mainstream.
 “One way might be to be an early adopter, to become an AI practitioner and be the one providing advice on how best to adopt AI in your field,” said  Koh.
 Another route would be to pick up complementary skills, he said. 
 “For example, a graphic designer could also develop expertise in marketing and progress to design and lead campaigns.”
 With elections coming up in the United States, Europe, India and Taiwan, analyst Laveena Iyer from the Economist Intelligence Unit expects Gen AI to impact politics more than business.
 “Generative AI, and the fake content that it can produce, will drive misinformation and erode confidence in the political process, undermining its legitimacy,” she said.
 “Any substantial election interference this time around would impact broader trust in AI.”
 Gloria Arlini, chief operating officer of Generation Singapore, a non-profit for retraining and job placement, believes more bosses will coach workers for specific roles and skills.
 So, goodbye to old methods of training for training’s sake, such as doling out training credits or hitting a number of training hours.
 There will be more apprenticeship and traineeship programmes, she added, offering smoother transitions for workers taking up skills-based jobs.
 She expects more firms to formally recognise diverse skills, education qualifications and mental health differences in hiring. The workplace fairness legislation to be passed in 2024 will be an impetus.
 “Singapore’s workforce is set to become more adaptable, inclusive and in tune with the demands of the new economy,” she said.
 Over three in 10 small and medium-sized firms here use employer of record (EOR) services to manage remote teams, and most of them plan to do more of it in 2024, said EOR firm Remote, citing an IDC survey it commissioned.
 An EOR is an entity that legally employs workers on behalf of another business, handling all aspects of employment including compliance, payroll and taxes. 
 “We see international organisations wanting to hire Singaporeans, as well as Singaporean businesses looking to expand internationally and leverage talent beyond borders,” said the firm’s chief executive Job van der Voort.
 Jobs are expected to turn more global. —The Straits Times/ANN",generative artificial intelligence biggest happen reality check boss ready worker office coffee chain caffeine break word bleisure pandemic worker business private vacation trip lay offs adoption tech consultancy access partnership koh worker pressure programmer financial analyst customer service provider graphic designer profession plumber gardener counsellor practitioner impact worker uneven worker desirable gen mainstream adopter practitioner advice adopt field route pick complementary skill graphic designer expertise marketing progress design lead campaign election united europe india taiwan analyst iyer economist intelligence unit gen impact politics business generative content drive misinformation confidence political process legitimacy substantial election interference time impact trust gloria arlini chief officer generation singapore profit job placement boss coach worker specific role skill method sake credit training hour traineeship programme smoother transition worker skill job firm diverse skill education qualification health difference workplace fairness legislation impetus singapore workforce adaptable inclusive tune demand economy sized firm record eor service remote team eor firm remote idc survey eor entity worker behalf business aspect employment compliance payroll tax international organisation singaporean singaporean business leverage talent border firm chief executive job van der voort job global strait time,"[(0, 0.9046692), (4, 0.091728)]",0
630926,StarBiz,12,25/12/2023,OpenAI to              raise US$100bil                  in new funding,,"NEW YORK: OpenAI is in early discussions to raise a fresh round of funding at a valuation at or above US$100bil, people with knowledge of the matter say, a deal that would cement the ChatGPT maker as one of the world’s most valuable startups.
 Investors potentially involved in the fundraising round have been included in preliminary discussions, according to the people, who asked not to be identified to discuss private matters. 
 Details like the terms, valuation and timing of the funding round haven’t yet been finalised and could still change, the people said.
 If the funding round happens as planned, it would make the artificial intelligence (AI) darling the second-most valuable startup in the United States, behind only Elon Musk’s Space Exploration Technologies Corp, according to data from CBInsights. 
 The company is set to complete a separate tender offer in early January, which would allow employees to sell their shares at a valuation of US$86bil, Bloomberg previously reported.
 That is being led by Thrive Capital and saw more demand from investors than there was availability, people familiar with the matter have said.
 OpenAI’s rocketing valuation mirrors the AI frenzy it kicked off one year ago after releasing ChatGPT, a chatbot capable of composing eerily human sentences and even poetry in response to simple prompts. 
 The company became Silicon Valley’s hottest startup, raising US$13bil to date from Microsoft Corp, and spurred a new appreciation for the promise of AI that changed the tech industry landscape within a few months. 
 Amazon.com Inc and Alphabet Inc have since poured billions into OpenAI-rival Anthropic. 
 Salesforce Inc led an investment into Hugging Face that valued it at US$4.5bil, and Nvidia Corp, which makes many of the semiconductors that power AI tasks, said earlier this month it made more than two dozen investments in 2023. — Bloomberg",york penai discussion fresh round funding valuation people matter deal cement chatgpt maker valuable startup investor round preliminary discussion people identified private matter detail term valuation funding round change people round artificial intelligence valuable startup elon musk space exploration technology data cbinsights company complete separate tender offer january employee share valuation bloomberg led thrive capital demand investor availability people familiar matter valuation mirror frenzy chatgpt chatbot capable human sentence response simple prompt company silicon valley hottest startup bil microsoft corp appreciation promise tech industry month alphabet billion rival anthropic salesforce investment hugging bil corp semiconductor power task month dozen investment,"[(1, 0.99166447)]",1
630146,Main,5,22/12/2023,PLUS urges vehicle owners to use new AI chatbot for help,,"PETALING JAYA: Assistance and information on PLUS highways can now be obtained through the PLUS Texting Realtime Interface (PUTRI) Chatbot on WhatsApp via 019-356 9802.
 According to PLUS, communication with PUTRI Chatbot will allow highway users to request for emergency assistance through the SOS button as well as obtain information about PLUS Highway services without having to contact the PLUSLine via 1-800-88-0000.
 These include traffic information, toll rates, frequently asked questions, products and facilities, promotions and events, feedback and incident reporting, among others.
 “The PUTRI Chatbot is the first chatbot of the expressway industry that was introduced by PLUS in September 2020.
 “It leverages on Artificial Intelligence (AI) and Machine Learning (ML) to engage with users in online text-based interactions using natural language processing.
 “Since its introduction, the PUTRI Chatbot has successfully handled approximately 220,000 responses and complete conversations with highway users regarding PLUS Highway services in digital form,” PLUS said in a statement.
 It added that PUTRI Chatbot provides various responses on PLUS Highway services quicker.
 “With the help of PUTRI Chatbot, PLUS’ Traffic Monitoring Centre personnel will be able to focus on emergency calls and streamline the coordination of assistance for highway users facing emergencies on the highway.
 “The PUTRI Chatbot initiative was recently selected as the champion in the Private Sector category at the Innovative Creative Convention (ICC) 2023.
 “The recognition demonstrated PLUS’ commitment to innovation and excellence in providing efficient services to highway users,” added the statement.
 Highway users may engage with PUTRI Chatbot through WhatsApp at 019-356 9802 or through PLUS App, PLUS website at www.plus.com.my, X Applica­tion @PLUS2U, PLUSMiles portal at www.plusmiles.com.my, and through PLUS Malaysia Facebook page.",jaya assistance highway realtime interface putri chatbot whatsapp communication putri highway user emergency assistance button highway service plusline traffic toll rate question product facility promotion event incident reporting putri chatbot industry september leverage artificial intelligence machine learning engage user text interaction natural language processing introduction putri chatbot response complete conversation highway user service digital form statement putri chatbot highway service quicker chatbot traffic centre personnel emergency streamline coordination assistance highway user emergency chatbot initiative champion private sector category innovative creative convention icc recognition commitment innovation excellence efficient service highway user statement highway user putri chatbot whatsapp website applica tion plusmiles portal malaysia facebook,"[(2, 0.99204016)]",2
629652,StarBiz,11,21/12/2023,Lenovo’s 60% rally may extend as AI adds to optimism,,"HONG KONG: A three-month rally in Lenovo Group Ltd shares may have legs, thanks to signs of a global demand recovery for personal computers and enthusiasm about the Chinese firm’s products tied to artificial intelligence (AI).
 The world’s top PC maker’s stock in Hong Kong has risen over 30% from a mid-October low, making it the best performer in the Hang Seng Tech Index during the period. 
 Its 60% jump this year also puts it on track for the strongest annual performance since 2009.
 Lenovo’s surge was part of a broader rally among its peers amid signs that a post-pandemic industry slump may have finally ended, helped by cyclical demand for PC replacement and upgrades. 
 High hopes for new products that may benefit from the ongoing AI investment frenzy also are fuelling optimism that the stock’s bull run can last well into 2024. 
 “The strong sentiment, in my opinion, was mainly driven by the impending recovery of PC demand starting likely from late 2023, and the rising fervour surrounding the concept of ‘AI PC’,” said Steven Tseng, a Bloomberg Intelligence analyst. 
 Lenovo said last month that it is targeting PC revenue growth this quarter after signs of a long-awaited recovery helped it report a smaller-than-feared profit decline. 
 The company continues to see single-digit global PC shipment growth next year and remains confident in outpacing rivals given its leading market position and higher exposure to commercial models, Goldman Sachs Group Inc analysts including Verena Jeng wrote in a recent note after a meeting with Lenovo’s management. 
 Global PC makers have been grappling with a downturn that emerged after the Covid era, but the downward spiral slowed in the third quarter, according to research firm International Data Corp. 
 With over 75% of its revenue from overseas, Lenovo also is less exposed to China’s slowing economy.
 Another major boost to the stock’s momentum lies in investor excitement about its first AI server project that started this month and more products in the pipeline for next year. 
 “We are ‘buy’ rated on Lenovo as we believe it is well positioned to ride on AI technology enhancement,” Goldman’s Jeng wrote. 
 “We expect AI’s higher requirements of computing power and new AI functions will support demand for Lenovo’s end devices.”
 Goldman’s price target of HK$11.79 implies a 15% upside from the stock’s last close. 
 Traders also are expressing their bullishness in the options market, where the right to buy Lenovo shares in three months is now at a significant premium above its cost a month ago. 
 Meantime, put options, which offer investors the right to sell the stock, have become cheaper.
 To be sure, Lenovo no longer looks cheap. The stock now trades at 11 times forward earnings, compared with an average of nine times over the past five years.
 “The expectation is indeed very high,” said Xiadong Bao, a fund manager at Edmond de Rothschild Asset Management.
 “But if the management can deliver what they guided so far, and if the early market feedback is positive on the local AI applications on the high-spec AI PC and its associated 10% to 15% average selling price bump, the outperformance may continue.” — Bloomberg",kong month lenovo share sign global demand recovery personal computer chinese firm product artificial intelligence top maker stock hong kong mid low performer hang seng tech period jump track strongest annual performance lenovo surge rally peer sign pandemic industry slump cyclical demand replacement upgrade product benefit ongoing investment frenzy optimism stock bull strong sentiment opinion impending recovery demand late fervour concept steven tseng bloomberg intelligence analyst lenovo month revenue growth quarter sign recovery report profit decline company single digit global shipment growth confident rival market position exposure commercial model sachs analyst verena jeng note meeting lenovo management global maker downturn covid era downward spiral quarter firm international data corp revenue lenovo china economy major boost stock momentum investor excitement server project month product pipeline buy lenovo ride technology enhancement goldman jeng requirement power function demand lenovo device goldman price target implies stock close trader bullishness option market lenovo share month premium cost month option investor stock cheaper lenovo cheap stock trade forward earnings average time xiadong bao fund manager edmond asset management management market positive local application average selling price bump outperformance bloomberg,"[(4, 0.9954296)]",4
629098,Main,28,19/12/2023,Jailed ex-PM  using AI-crafted speech to call for votes,,"ISLAMABAD: Former prime minister Imran Khan is using an audio clip generated by artificial intelligence (AI) to address supporters in the first event of its kind in the politics of the South Asian nation, though marred by internet disruptions.
 The audio, played over a photograph of Imran during an internet rally of his Pakistan Tehreek-e-Insaf party, drew more than 1.4 million views on YouTube and other social media platforms.
 He is currently serving a three-year sentence in jail.
 “Our party is not allowed to hold public rallies,” he said in the speech, urging supporters to turn out in large numbers at general elections set for Feb 8. 
 “Our people are being kidnapped and their families are being harassed.”
 The disruptions to livestreaming fuelled transparency concerns with users nationwide complaining of slow internet speeds and throttling, a technique telecoms regulators use to choke streaming on apps.
 Pakistan’s telecoms regulator said the interruptions were being investigated, but added that internet accessibility overall appeared to be normal.
 Imran’s speech was generated from a written version he had approved from prison, said officials of his party, which staged the event because it faces a state-backed crackdown on physical gatherings, while its leader is blacked out of media.
 Murtaza Solangi, information minister in Pakistan’s caretaker government assigned to supervise the elections which has been suspected of favouring Imran’s opponents, did not respond to a Reuters request for a comment.
 Jailed since he was convicted and sentenced to three years on graft charges on Aug 5, Imran is embroiled in dozens of court cases, with some trials held in prison behind closed doors, which legal experts say infringes the right to fair proceedings.
 A political crisis has swirled around the 71-year-old former cricket star since his ouster last year in a vote of confidence in parliament. — Reuters",islamabad prime minister imran khan clip artificial intelligence address supporter event politics south asian nation internet disruption photograph imran internet rally tehreek insaf party view social medium platform sentence jail party hold public rally supporter election feb people family disruption fuelled transparency concern user nationwide slow internet speed technique telecom regulator apps pakistan telecom interruption internet accessibility normal imran speech version prison official party event crackdown physical gathering leader medium murtaza minister pakistan caretaker government supervise election imran opponent respond reuters comment graft charge imran dozen court trial prison door legal expert infringes fair proceeding political crisis cricket star ouster vote confidence parliament reuters,"[(1, 0.99213356)]",1
628638,Main,14,18/12/2023,First AI images using brain activity,Scientists have created a technology that enables visualisation of perceptual content,"Japanese scientists have succeeded in creating the world’s first mental images of objects and landscapes from human brain activity  by using artificial intelligence (AI) technology, local media reported.
 The team of scientists from the National Institutes for Quantum Science and Technology (QST) and other organisations was able to produce rough images of a leopard with a recognisable mouth, ears and spotted pattern, as well as objects like an airplane with red lights on its wings, Kyodo News reported on Saturday.
 The technology, dubbed “brain decoding”, enables the visuali­sation of perceptual content based on brain activity and could be applied to the medical and welfare fields, the report said.
 During research, participants were shown 1,200 images of objects and landscapes, with the relationship between their brain signals and the images analysed and quantified using functional magnetic resonance imaging, or fMRI.
 The same images were input into the generative AI to learn their correspondence with the brain activity.
 The technology could be used in the development of communication devices and to gain an understanding of the brain mechanisms of hallucinations and dreams, according to the researchers.
 QST researcher Kei Majima said humans have used microscopes and other devices to view a world that was invisible to the naked eye, but they have not been able to step inside a person’s mind, noting that this is the first time for humans to peer inside another person’s mind.
 The findings were published recently in the online edition of the international scientific journal Neural Networks. — Xinhua",japanese scientist mental image landscape human brain activity artificial intelligence technology local medium team scientist national institute science technology qst organisation rough image recognisable mouth ear pattern object red light wing news saturday technology brain decoding enables sation perceptual content brain activity medical welfare field report participant object landscape relationship brain signal image quantified functional magnetic resonance fmri image generative learn correspondence brain activity technology development communication device understanding brain mechanism hallucination researcher kei majima human microscope device invisible naked eye step person noting time human person mind finding online edition international scientific journal neural network,"[(2, 0.9911466)]",2
628366,Main,29,17/12/2023,A touch of AI on the dearly departed,Chinese mourners use digital edge to resurrect and reconnect with the dead,"At a quiet cemetery in eastern China, bereaved father Seakoo Wu pulls out his phone, places it on a gravestone and plays a recording of his son.
 They are words that the late student never spoke, but brought into being with artificial intelligence (AI).
 “I know you’re in great pain every day because of me, and feel guilty and helpless,” intones Xuanmo in a slightly robotic voice.
 “Even though I can’t be by your side ever again, my soul is still in this world, accompanying you through life.”
 Stricken by grief, Wu and his wife have joined a growing number of Chinese people turning to AI technology to create lifelike avatars of their departed.
 Ultimately, Wu wants to build a fully-realistic replica that behaves just like his dead son but dwells in virtual reality.
 “Once we synchronise reality and the metaverse, I’ll have my son with me again,” Wu said.
 “I can train him so that when he sees me, he knows I’m his father.”
 Some Chinese firms claim to have created thousands of “digital people” from as little as 30 seconds of audiovisual material of the deceased.
 Experts say they can offer much-needed comfort for people devastated by the loss of loved ones.
 But they also evoke an unsettling theme from the British sci-fi series Black Mirror in which people rely on advanced AI for bereave­ment support.
 Needs are growing
 Wu and his wife were devasta­ted when Xuanmo, their only child, died of a sudden stroke last year at the age of 22 while atten­ding Exeter University in Britain.
 The accounting and finance student, keen sportsman and posthumous organ donor “had such a rich and varied life”, said Wu.
 “He always carried in him this desire to help people and a sense of right and wrong,” he said.
 Following a boom in deep lear­ning technologies like ChatGPT in China, Wu began researching ways to resurrect him.
 He gathered photos, videos and audio recordings of his son and spent thousands of dollars hiring AI firms that cloned Xuanmo’s face and voice.
 The results so far are rudimentary, but he has also set up a work team to create a database contai­ning vast amounts of information on his son.
 Wu hopes to feed it into powerful algorithms to create an avatar capable of copying his son’s thin­king and speech patterns with extreme precision.
 Several companies specialising in so-called “ghost bots” have emerged in the United States in recent years.
 But the industry is booming in China, according to Zhang Zewei, the founder of AI firm Super Brain and a former collaborator with Wu.
 “On AI technology, China is in the highest class worldwide,” said Zhang from a workspace in the eastern city of Jingjiang.
 “And there are so many people in China, many with emotional needs, which gives us an advantage when it comes to market demand.”
 Super Brain charges between 10,000 and 20,000 yuan (RM6,570 and RM13,140) to create a basic avatar within about 20 days, said Zhang.
 They range from those who have died to living parents unable to spend time with their children and – controversially – a heartbroken woman’s ex-boyfriend.
 Clients can even hold video calls with a staff member whose face and voice are digitally overlaid with those of the person they have lost.
 “The significance for the whole world is huge,” Zhang said.
 “A digital version of someone (can) exist forever, even after their body has been lost.”
 New humanism
 Sima Huapeng, who founded Nanjing-based Silicon Intelli­gence, said the technology would “bring about a new kind of humanism”.
 He likened it to portraiture and photography, which helped people commemorate the dead in revolutionary ways.
 Tal Morse, a visiting research fellow at the Centre for Death and Society at Britain’s University of Bath, said ghost bots may offer comfort.
 But he cautioned that more research was needed to understand their psychological and ethical implications.
 “A key question here is how ‘loyal’ are the ghost bots to the personality they were designed to mimic,” Morse told AFP.
 “What happens if they do things that will ‘contaminate’ the memory of the person they are supposed to represent?”
 Another quandary arises from the inability of dead people to consent, experts said.
 While permission was probably unnecessary to mimic speech or behaviour, it might be needed to “do certain other things with that simulacrum”, said Nate Sharadin, a philosopher at the University of Hong Kong specialising in AI and its social effects.
 For Zhang, all new technology is “a double-edged sword”.
 “As long as we’re helping those who need it, I see no problem”.
 He doesn’t work with those for whom it could have negative impacts, he said, citing a woman who had attempted suicide after her daughter’s death.
 Bereaved father Wu said Xuanmo “probably would have been willing” to be digitally revived.
 “One day, son, we will all reunite in the metaverse,” he said as his wife dissolved into tears before his grave.
 “The technology is getting better every day... it’s just a matter of time.” — AFP",quiet cemetery eastern china seakoo phone gravestone son late student artificial intelligence day guilty helpless intones xuanmo robotic voice soul life stricken grief wife chinese people technology create avatar build realistic replica behaves dead son dwells virtual reality synchronise reality metaverse son train chinese firm thousand digital people audiovisual material expert comfort people loss unsettling theme british sci series black mirror people ment support wife devasta xuanmo child sudden stroke age exeter university accounting finance student keen posthumous organ rich varied life desire people wrong boom deep lear technology china resurrect photo video audio recording son thousand dollar firm xuanmo voice rudimentary set team create database contai vast amount son hope powerful algorithm create avatar capable son thin king speech extreme precision company ghost bot united industry china zhang zewei founder firm super brain collaborator technology china class worldwide zhang workspace eastern city jingjiang people emotional advantage market demand brain charge create basic avatar day range parent unable spend time child woman client video staff voice person significance huge zhang digital version body humanism sima huapeng silicon intelli gence technology humanism portraiture photography people dead revolutionary tal morse fellow centre death society university bath ghost bot comfort understand psychological ethical implication key question ghost bot personality mimic morse afp contaminate memory person represent quandary arises inability dead people consent expert permission unnecessary mimic speech behaviour simulacrum nate sharadin philosopher university hong kong social effect zhang technology sword negative impact woman suicide daughter death xuanmo day son reunite metaverse wife tear technology day matter time afp,"[(0, 0.9964954)]",0
628008,Main,28,16/12/2023,Pope calls for AI regulation,"Use in warfare, lack of human values among Vatican’s concerns","ROME: Pope Francis called for an international treaty to ensure artificial intelligence is developed and used ethically, arguing that the risks of technology lacking human values of compassion, mercy, morality and forgiveness are too great.
 Francis added his voice to increasing calls for binding, global regulation of AI in his annual message for the World Day of Peace, which the Catholic Church celebrates each Jan 1. The Vatican released the text of the message on Thursday.
 For Francis, the appeal is somewhat personal: Earlier this year, an AI-generated image of him wearing a luxury white puffer jacket went viral, showing just how quickly realistic deepfake imagery can spread online.
 The pope’s message was released just days after European Union negotiators secured provisional approval on the world’s first comprehensive AI rules that are expected to serve as a gold standard for governments considering their own regulation.
 Francis acknowledged the pro­mise AI offers and praised technological advances as a manifestation of the creativity of human intelligence, echoing the message the Vatican delivered at this year’s UN General Assembly where a host of world leaders raised the promise and perils of the technology.
 But his new peace message went further and emphasised the grave, existential concerns that have been raised by ethicists and human rights advocates about the technology that promises to transform everyday life in ways that can disrupt everything from democratic elections to art.
 “Artificial intelligence may well represent the highest-stakes gamble of our future,” said Cardinal Michael Czerny of the Vatican’s development office, who introduced the message at a press conference Thursday.
 “If it turns out badly, humanity is to blame.”
 The document insisted that the technological development and deployment of AI must keep foremost concerns about guaranteeing fundamental human rights, promoting peace and guarding against disinformation, discrimination and distortion.
 Francis’ greatest alarm was devoted to the use of AI in the armaments sector.
 He noted that remote weapons systems had already led to a “distancing from the immense tragedy of war”.
 “The unique capacity for moral judgment and ethical decision-­making is more than a complex collection of algorithms, and that capacity cannot be reduced to programming a machine,” he wrote.
 On a more basic level, he warned about the profound repercussions on humanity of automated systems that rank citizens or categorise them.
 In addition to the threats to jobs around the world that can be done by robots, Francis noted that such technology could determine the reliability of an applicant for a mortgage, the right of a migrant to receive political asylum or the chance of reoffending by someone previously convicted of a crime.
 “Algorithms must not be allowed to determine how we understand human rights, to set aside the essential human values of compassion, mercy and forgiveness, or to eliminate the possibility of an individual changing and leaving his or her past behind,” he wrote. — AP",rome pope francis international treaty artificial intelligence risk technology human value compassion morality forgiveness francis voice call global regulation annual message day peace catholic church jan vatican text message thursday francis appeal personal image luxury white puffer jacket viral realistic deepfake imagery spread pope message day european union negotiator provisional approval comprehensive rule gold standard government regulation pro mise offer technological advance manifestation creativity human intelligence message vatican host leader promise peril technology peace message grave existential concern ethicist human right technology promise everyday life democratic election artificial intelligence represent stake gamble future cardinal michael vatican development office message press conference thursday humanity blame document technological development deployment concern fundamental human right peace disinformation discrimination distortion francis alarm armament sector weapon system immense tragedy war unique capacity moral judgment ethical decision complex collection algorithm capacity machine basic level profound repercussion humanity system rank citizen addition threat job robot technology determine reliability applicant mortgage migrant receive political asylum chance crime algorithm determine understand human right essential human value compassion mercy forgiveness possibility individual,"[(3, 0.4104359), (4, 0.5857714)]",4
628138,StarBiz 7,10,16/12/2023,AI adoption to leap forward,,"THE increasing penetration of artificial intelligence (AI) is one of the megatrends taking the world by storm. 
 From education to businesses, politics and healthcare, AI is changing our world and shaping the future of humanity across nearly every industry.
 This proliferation of this technology is expected to intensify in 2024 and beyond as businesses seek to further improve productivity and efficiency, and reduce costs, while improving the quality of life.
 According to UBS, the increasing adoption of AI is set to create significant broader implications in the global economy, particularly for a growth region like Asia.
 “AI will take technology disruption to the next level – presenting both significant opportunities and risks,” it says.
 It predicts the next 10 years or so would be defined by “AI economy”, which will have a huge impact on jobs, productivity, inflation and geopolitics, while accelerating the shift towards new economy sectors.
 Meanwhile, BlackRock predicts enterprise AI adoption and product integration will leap forward from 2024, and multi-modal AI will move closer to reality. 
 With that, hardware opportunities will grow to expand beyond graphics processing units (GPUs), the investment group says.
 Undoubtedly, the rise of AI is expected to result in further gains for advanced computing players in the future.
 Malaysia stands to gain from this development as it is exposed to the semiconductor supply chain.
 According to BNP Paribas Asset Management, there will likely be stronger deployments of GPUs, field programmable gate arrays and application specific integrated circuits, moving forward.
 “AI will likely be a major driver of semiconductor demand for the remainder of the decade, and logic and memory chip companies, foundries and semiconductor capital equipment and materials providers should benefit,” BNP Paribas says in its Investment Outlook for 2024 note.
 It points out that as AI continues to proliferate into new applications, it expects 2024 to be a crucial year in the development of the investment opportunity that AI offers.
 “We are optimistic about the pervasive adoption of AI and its positive impact on cloud service providers, software companies, owners of large databases, the semiconductor supply chain and companies that are using AI to improve business processes,” BNP Paribas says.
 “We see AI as a key enabler of recommendation engines, automated customer service systems, manufacturing automation, document production and many other systems.
 “With such diverse potential, we believe AI will be a key growth driver in 2024 and beyond,” it adds.",penetration artificial intelligence storm education business politics future humanity industry proliferation technology intensify business productivity efficiency cost quality life ubs adoption create broader implication global economy growth region asia technology disruption level opportunity predicts economy huge impact job productivity inflation geopolitics shift economy sector predicts adoption product integration multi modal move closer reality hardware opportunity graphic unit investment result gain player future malaysia gain development semiconductor supply chain bnp paribas asset management stronger deployment gpus field programmable gate array application specific circuit major driver semiconductor demand remainder decade logic memory chip company foundry capital equipment material provider bnp paribas investment outlook note application crucial development investment opportunity offer optimistic pervasive adoption positive impact cloud service provider software company owner database supply chain company business process paribas key enabler recommendation engine customer service system automation document production system diverse potential key growth driver,"[(4, 0.994047)]",4
627557,StarBiz,11,15/12/2023,Adobe says AI will take longer to boost results,,"NEW YORK: Adobe Inc gave a lukewarm outlook for sales in 2024, disappointing investors who expected new generative artificial intelligence (AI) tools would boost the software company’s results.
 Revenue will be about US$21.4bil in the fiscal year ending in December 2024, the company said Wednesday in a statement. 
 Profit, excluding some items, will be as much as US$18 a share. Analysts, on average, estimated sales of US$21.7bil and adjusted profit of US$18 a share.
 Wall Street expects Adobe to be one of the first software giants to benefit from the excitement over generative AI technology, which responds to prompts by producing unique text or images. 
 In recent months, the company has announced a new version of its AI model, Firefly, raised prices, and focused its October user conference on the technology. 
 The company cited “significant upsell of our new Firefly” with large customers, according to remarks prepared for a conference call after the results.
 However, that enthusiasm was dashed by the annual outlook. Shares declined about 6% in extended trading after closing at US$624.26 in New York. 
 The stock had jumped 85% this year as “investors appear very comfortable with Adobe’s ability to monetise generative AI,” Keith Weiss, an analyst at Morgan Stanley, wrote ahead of the results. — Bloomberg",york adobe lukewarm outlook sale investor generative artificial intelligence tool software company revenue fiscal december company wednesday statement profit item share analyst estimated sale bil profit share wall street software giant excitement generative technology prompt unique text image month company version model firefly price october user conference technology company upsell firefly customer remark conference call enthusiasm annual outlook share extended trading closing york stock investor comfortable adobe ability monetise generative keith wei analyst stanley bloomberg,"[(4, 0.9889983)]",4
627219,Main,14,14/12/2023,AI deciphering devotees’ fortunes in Taiwan,,"A TEMPLE in Taiwan’s Yunlin county is using artificial intelligence (AI) to help decipher devotees’ fortunes due to a manpower shortage, reported Sin Chew Daily. 
 The Beigang Wude temple bought three computers containing an RTX-A6000-48G graphics card, each costing T$180,000 (RM26,800), to perform the task. 
 Rather than going to the temple to seek divine answers through lottery sticks inscribed with text or numerals, people can now have their fortunes told via the temple’s Facebook page. 
 The AI is reportedly trained to decipher fortune based on the lottery stick a devotee ends up getting.
 A temple representative said that with an increasing number of visitors over the years, it unfortunately was unable to retain the staff trained to do the job.
 The temple management then started to employ AI to help ease the workload. 
 One of the most popular in Taiwan, the temple is said to receive some 200,000 visitors a day during the Chinese New Year period.
 > A man in China’s Henan province donated most of his 86.62 million yuan (RM56.5mil) lottery winnings, saying that he could not spend it all, Sin Chew Daily reported.
 According to local reports, a man wearing a mask arrived to collect his winnings but donated 53 million yuan (RM34.6mil) – 61% of his winnings – to the Henan Sports Development Foundation.
 The man surnamed Guo said he bought the ticket at a roadside stall for 100 yuan (RM65).
 Asked if he would retire from his job, Guo said: “Still have to work. Must work!”
 He said he will spend the rest of his fortune to buy a shop and a house.
 > Encouraged by her adoptive parents, a woman in China’s Shandong province located her biological parents through blood bank data and with the help of police, the daily also reported.
 Xiao Zhao (not her real name), 33, travelled 900km south to see them only to find that her mother and sister were nowhere to be found. Only her biological father was present.
 Xiao Zhao, who was adopted from an orphanage and grew up in a loving family, immediately explained that she was there to see how her biological parents were doing.
 The father curtly said: “I know we owe you a lot. I have told them (your mother and sister).”
 Xiao Zhao immediately burst into tears, adding that “no one owes anyone anything”.
 She asked her dad for a hug, adding that she is married to a businessman.
 “Good for you, I am comforted!” came the terse reply.
 The awkward interaction was recorded by the police, who  coordinated the meeting and shared the video on social  media.",temple taiwan yunlin county artificial intelligence decipher devotee fortune manpower shortage sin chew wude temple computer graphic card perform task temple seek divine answer stick text numeral people fortune temple facebook trained decipher fortune lottery stick devotee temple representative visitor unable retain staff job temple management employ ease workload popular taiwan temple receive visitor day chinese period china henan province yuan mil lottery winning sin chew local report mask collect winning yuan mil winning henan sport development foundation guo ticket roadside stall yuan retire job guo rest fortune shop house adoptive parent woman shandong province biological parent bank data police xiao zhao real mother sister biological father xiao zhao orphanage family biological parent lot mother sister xiao zhao burst tear owes dad hug married businessman terse reply awkward interaction police meeting video social medium,"[(4, 0.9934092)]",4
625591,StarBiz,1,12/12/2023,Boom time for Malaysian AI,Local investors have not fully digested the strong upside prospects of the sector,"PETALING JAYA: Artificial intelligence (AI) is set to be the next growth engine for the technology sector.
 Stocks linked to this sub-segment of the tech space have seen strong gains this year.
 Analysts believe the run has further legs to go with companies such as Nvidia Corp, Advanced Micro Devices and their related branded manufacturers in Taiwan such as Asustek Computer Inc gaining strong interest of late. 
 AI requires computing power that is used by graphics processing unit (GPU) in computers and they are the key to the training of neural networks, the enabler of AI.
 Apart from powering computer games and graphics/video-intensive computers, GPUs help quicken the training of neural networks which are a key component of many algorithms enabling AI.
 The two main GPU designers and makers in the world are Nvidia and AMD.
 It appears that tech stocks on Bursa Malaysia have not caught up with the strong rally in the United States as the surge in interest since late last year are limited to makers of GPUs and their related companies.
 There was much buzz last week on the local tech space with Nvidia founder and chief executive officer Jensen Huang dropping by several countries in the region including Malaysia to announce business ventures.
 For Malaysia, Nvidia last Friday announced a data centre partnership and it also announced last Sunday it will set up a manufacturing base in Vietnam.
 YTL Power International Bhd announced a collaboration with Nvidia to deploy AI infrastructure with Nvidia H100 Tensor Core GPUs at its YTL Green Data Centre Park in Kulai, Johor.
 YTL Power’s share price received a boost with this development and saw gains of almost 15% last week alone. The company is now considered an AI-linked firm by market players with this partnership.
 SPI Asset Management managing partner Stephen Innes said the surge in share prices of AI-linked companies is just the beginning and investors have not fully digested the strong upside prospects of this latest development in the tech space.
 “We are only seeing the tip of the iceberg on a decade-long transition to AI. 
 “Right now, most of the focus is on the companies making the tools necessary to power the AI revolution that appears to be fast descending upon businesses and, eventually, the broader economy,” Innes told StarBiz.“In the immediate sense, such a build phase may also benefit the ‘shovel providers’ of this ‘gold rush’ – the companies that provide the computing power and tools necessary to build the models needed to compete. 
 “For this year, at least, Nvidia has stood out as that hardware store on the prospecting hill,” he added.
 Innes expects Nvidia will continue to trend higher and be trading at US$600 per share next year and over US$1000 in the longer term. 
 High-net-worth investor and former  investment banker Ian Yoong Kah Yin said investor interest in the domestic tech sector will be AI-driven, moving forward. 
 “The listed companies in this space are YTL Power, ITMAX System Bhd and Straits Energy Resources Bhd. YTL Corp and YTL Power, its subsidiary, are in data centres. 
 “ITMAX is in video surveillance and analytics. Straits Energy is into oil bunkering, telecommunications solutions and AI-enabling services,” Yoong told StarBiz.YTL, YTL Power, ITMAX and Straits Energy are trading at financial year 2024 price-to-earnings ratio (PER) of 10, 8, 19 and 10 times, respectively, he noted. 
 Meanwhile, Yoong said the wider local tech space on Bursa Malaysia is expected to remain in the doldrums in the first half of 2024, with recovery seen earliest in the second half of next year. 
 “The Bursa Malaysia Technology index currently commands an above-average valuation, with a forward PER multiples of 25 times. The historical average PER is 21 times.
 “The semiconductor-based sub-sector is expected to report weak earnings in the next two to three quarters,” Yoong added.
 Commenting on tech stocks’ performance on Bursa Malaysia, Rakuten Trade head of equity sales Vincent Lau said many Malaysian tech stocks appear to be stuck in a trading range.
 “Fund managers are staying on the sidelines and I think they need to see fourth-quarter numbers first. 
 “Ours are lagging behind and only in the United States it seems to be doing well. Even in Hong Kong the tech sector is struggling,” Lau told StarBiz.However, a tech recovery is still on track and the fourth quarter might be supported by restocking activities.
 He said how strong will the recovery be is still the main question.
 “But in the AI space, it still has some legs to run while for electric vehicles, it continues to be another growth sector,” Lau said.
 “We may be at a short-term bottom now, as I think it will be quite a firm recovery moving into 2024. We may be at an inflection point.”
 On YTL Power-Nvidia partnership, RHB Research said it has a long-term positive view on this development. 
 “The project may also boost its data centre take-up rate in Johor.
 “YTL Power’s earnings growth should strengthen upon the successful delivery of the project delivery in the long run but investors ought to take note that additional capital expenditure requirements ahead could be rather intensive,” it said in a note.",jaya artificial intelligence growth engine technology sector stock segment tech space strong gain analyst company corp micro device manufacturer asustek computer strong late power graphic unit gpu computer key neural network computer game video intensive computer quicken training neural network key component algorithm main gpu designer maker amd tech stock malaysia strong united surge maker gpus company week local tech space nvidia founder chief executive officer jensen country region malaysia business venture data centre partnership sunday manufacturing base vietnam ytl power international bhd collaboration deploy infrastructure nvidia tensor core gpus ytl green data centre park kulai johor ytl power share price boost development gain week company firm market player partnership spi asset management partner stephen innes surge share price company investor strong upside prospect development tech space iceberg decade transition focus company power revolution descending business broader economy innes starbiz sense phase benefit shovel provider rush company power tool model stood hardware store prospecting hill innes nvidia trend trading share term net worth investor investment banker ian kah yin investor domestic tech sector company space power itmax system bhd energy resource corp ytl power subsidiary data centre video surveillance analytics energy oil telecommunication solution service starbiz ytl ytl power itmax energy trading financial price earnings ratio time local tech space bursa malaysia doldrums half recovery earliest half bursa malaysia technology average valuation forward time historical average time semiconductor sector report weak earnings quarter tech stock performance bursa malaysia trade head equity sale vincent lau malaysian tech stock range fund manager sideline fourth quarter united hong kong tech sector lau starbiz tech recovery track fourth quarter activity strong recovery main question space leg electric vehicle growth sector short term bottom firm recovery inflection ytl power partnership rhb term positive view development project boost data centre rate johor power earnings growth successful delivery project delivery investor additional capital expenditure requirement intensive note,"[(4, 0.9971419)]",4
625631,StarBiz,5,12/12/2023,Bosses get reality                check on generation AI,,"IT is like a new relationship – the first year was starry-eyed and full of promise.
 Generative artificial intelligence (gen AI) was going to do your board presentations, write this newspaper column, delight customers and let every lay worker code away his own work problems.
 But past a year of flirting and learning, bosses are discovering the extravagance and shortcomings – both the technology’s and theirs – in bringing home the hottest tech debutant since the Internet four decades ago.
 Despite leading the region in government planning, findings are that just over one in 10 businesses in Singapore are ready.
 Cisco’s inaugural AI Readiness Index compiled around September reported only 13% of firms here are prepared to deploy and leverage AI in general.“Considerable gaps exist across other key business pillars like infrastructure, data, governance, talent and culture,” said its president for Asean Tay Bee Kheng.
 With ease of use arising from its response to common language commands, research firm Forrester expects gen AI to raise workers’ productivity by 50%, boosting them in areas such as self-service analytics, code writing and content creation.
 But will it transform businesses? For only 30% of firms in the Asia-Pacific, said the firm’s senior research director Frederic Giron.
 Even then, that will take place over years, not months, he added.
 That gen AI is the biggest thing after the Internet is beyond dispute.
 Bloomberg Intelligence projects the gen AI market to grow from US$40bil 2022 to US$1.3 trillion by 2032.
 Its share of total information technology spending on hardware, software services, ad spending and gaming market spending will boom from less than 1% to 10% over the same period, the report noted.
 Yet to get bosses to fully commit? That is going to take time.
 Bensen Koh, consultant with tech advisory firm Access Partnership, expects firms to focus on areas with the “widest potential appeal, lowest perceived risk, and lowest need for human resources upskilling”.
 For example, it could be used to help manage customer relationships and sales, accounting and finance, and for internal collaboration.
 “These are functions that most companies have and would like to improve on,” he said. 
 “As they are internal facing, risk is perceived to be lower. So long as the AI tools are relatively simple to use, not much upskilling is required.”
 Gavin Barfield, Salesforce’s chief technology officer for solutions in the region, said: “As  many Asean organisations still have untapped data, it is projected that more companies will lay the groundwork for AI by 2024.”
 Clear policies
 Just getting companies AI-ready requires data governance frameworks, clear policies for data collection, storage and use, and constant monitoring and auditing of training data, he added.
 For most back-office workers in human resources, finance and supply chain work, much more needs to happen before gen AI could support real-time analytics, flagging bottlenecks and inventory shortages.
 Enosix, an integration provider for enterprise software giant SAP, blogged: Resources are stretched, data silos are killing productivity (and the customer experience), and AI is stuck in the starting gates without trusted data.
 “But those aren’t SAP trends, that’s the state of the industry.”
 When ChatGPT went mainstream in November 2022, it immediately seduced leaders’ imagination.
 Announcements followed almost daily from businesses on new gen AI capabilities for customers and employees. 
 Some were embellished. Most were not meaningful.
 Then, bosses became alarmed when they found workers privately engaging ChatGPT and handing over company secrets like source code.
 Bot workers
 They also began to realise the business risks of employing these bot workers that not only make things up, but also spew racist, sexist and other eyebrow-raising remarks.
 At its 2024 tech trends presentation on Dec 5, Forrester senior analyst Liu Meng offered a teaser to his audience, predicting that in the coming year, “at least one insurer will offer an AI hallucination-risks policy. And it will be profitable”.
 After July, when enterprise gen AI-embedded software such as Salesforce’s Einstein GPT, Adobe’s Firefly and Microsoft’s Copilot made pricing plans public, another concern arose: costs.
 The risks and staggering investment sums ploughed into their partners, such as OpenAI and Cohere, that are building and running the large language models underlying the technology have been cited.
 The joke about town is that these costs are about to give bosses another shock treatment, not unlike the one they got not long ago from cloud subscription charges.
 Microsoft Copilot, for instance, sets a firm back US$30 per user per month.
 But to even be able to use it, the worker must already be on the E3 or E5 versions of Microsoft 365, priced at US$36 and US$57 respectively, per user per month.
 Commitment must be for at least a year.
 So what shall one do if technology gets overtaken six months from now? And after shelling out for the technology, will workers put it to good use?
 Forrester’s Giron suggests that firms start with pilots.
 “There are ways for you to test and try with gen AI pilots which are low risk and low cost to go. And then you can double down,” he said.
 “These things (like Copilot) are now going to become massively commoditised, embedded in software applications, which means that the case for justifying US$30 per user per month drops,” he added. — The Straits Times/ANN
 Krist Boo is a senior correspondent with The Straits Times Singapore. The views expressed are the writer’s own.",relationship starry promise generative artificial intelligence gen board presentation newspaper column delight customer worker code learning boss extravagance shortcoming technology hottest tech debutant internet decade region government finding business ready cisco inaugural readiness reported firm deploy leverage considerable gap key business pillar infrastructure data governance talent culture president asean tay bee kheng ease response common language command firm forrester gen worker productivity service analytics content creation transform business firm pacific firm senior director frederic giron month gen biggest internet dispute bloomberg intelligence project market grow bil share total technology spending hardware software service spending market spending boom period report commit time koh consultant tech advisory firm access partnership firm widest potential appeal lowest risk lowest human resource upskilling manage customer relationship sale finance internal collaboration function company internal facing risk lower tool simple upskilling gavin barfield salesforce chief technology officer solution region asean organisation data company groundwork policy company ready data governance framework policy data collection storage constant monitoring data office worker human resource finance supply chain gen support real time analytics bottleneck inventory shortage integration provider enterprise software giant sap resource data silo productivity customer experience gate data sap trend industry mainstream november leader imagination announcement daily business gen capability customer employee meaningful boss worker chatgpt company secret source code worker business risk bot worker spew sexist eyebrow remark tech trend presentation forrester senior analyst liu meng teaser audience insurer offer hallucination risk policy profitable july enterprise gen software salesforce einstein gpt adobe firefly microsoft copilot pricing plan public concern arose cost staggering investment sum partner cohere language model technology joke town cost shock treatment cloud subscription charge copilot instance set firm month worker version user month commitment technology overtaken month technology worker firm pilot gen pilot low risk low cost double copilot software application user month strait time ann krist boo senior correspondent strait time view writer,"[(3, 0.99714345)]",3
625947,Main,8,12/12/2023,The danger of AI-powered scams,"Deepfakes, voice cloning and phishing emails on the rise, warns CSM","PETALING JAYA: Scammers are increasingly using artificial intelligence (AI) to make their scams more believable and effective, says CyberSecurity Malaysia (CSM).
 Its chief executive officer Datuk Dr Amirudin Abdul Wahab said AI-powered scams are getting smarter by the day, making them harder to spot.
 He said it is crucial to stay updated on the latest scam tactics and take the necessary safeguards.
 Some common AI-driven scam techniques include deepfakes, voice cloning, phishing emails and text messages as well as social media manipulation, said Amirudin.
 “Deepfakes are videos or audio recordings that have been mani­pulated to make it look or sound like someone else is saying or doing something they never did.
 “Scammers can use deepfakes to impersonate trusted indivi­duals, such as a friend or family member, in order to trick victims into giving them money or personal information.
 “Voice cloning is a technique that allows scammers to create a synthetic voice that sounds exactly like someone else’s voice.
 “Scammers can then use this voice to make phone calls to victims, pretending to be someone they trust. AI could be used to generate emails that appear to be from a victim’s bank or credit card company, asking them to verify their account information,” he told The Star.
 Social media manipulation is another common technique, whereby scammers use AI to target specific individuals or groups on social media with personalised ads or messages.
 For example, an AI could be used to identify people who are recently divorced or unemployed, and then target them with ads for scams that promise to help them get rich quickly, he said.
 The Star on Dec 6 published an interview with Federal Com­mercial Crime Investigation Department (CCID) director Comm Datuk Seri Ramli Mohamed Yoosuf who warned how deepfakes, voice spoofing and financial market manipulation could all become the future of crime when syndicates start using AI in their operations.
 Comm Ramli had said AI could be used by syndicates in their illicit activities against Malaysians by as early as the middle of 2024.
 Meanwhile, Amirudin said the best defence against scams is vigilance and education.
 He said the public must remain cautious and sceptical of any suspicious communications. 
 “If an offer seems too good to be true, it warrants a closer look and further questioning,” he said.
 He added that when contacted by any individual or organisation, it is crucial to verify their identity first.
 “This could involve independently verifying contact details and directly reaching out to the organisation for confirmation. For example, if you receive a call from the Inland Revenue Board (LHDN) claiming that you have unpaid taxes, you should contact the LHDN directly to confirm the claim,” he said.
 Amirudin said when it comes to AI-generated communications, watch for red flags such as unusual phrasing, inconsistencies in tone or factual inaccuracies.
 “With deepfakes, be alert for anomalies in voice tones or facial geometry, such as odd lighting or pixelation in video images.
 “Above all, never divulge personal or financial information to unverified parties.
 “Stay informed about potential scams by following verified news and updates from trusted ­sources, including law enforcement agencies,” he said.
 Amirudin added that CSM is aware of the potential for AI technologies like deepfakes to spread misinformation and the effectiveness of AI phishing, or malicious Generative Pre-trained Trans­formers (GPT), of gathering dangerous information.
 Generative AI could potentially be used to disseminate false information, create deceptions and modify malicious code to evade cyber defences, said Amirudin.
 “The consequences of these actions could be dire, leading to national instability, damage to digital infrastructure and breaches of sensitive data,” he said.
 On the other hand, the cyber­security industry has been leveraging AI to combat these crimes and overcome several challenges, he said.
 He added that AI provides the opportunity to enhance existing standards by using such tools to monitor, identify and counter AI threats and attacks.
 “As such, AI functions as a double-edged sword, bringing benefits to both cybersecurity efforts and potential criminals alike,” he said.Amirudin also said CSM is proactively monitoring and investigating fraudulent activities facilitated by AI technologies.
 “We collaborate with technology experts to remain at the forefront of AI developments and employ advanced detection tools to identify potential threats.
 “Furthermore, we maintain close cooperation with other agencies, both domestically and internationally, to combat these crimes effectively,” he said.
 Amirudin added that education and awareness campaigns have been a crucial component of CSM’s efforts to inform the public about the risks associated with AI-powered scams.
 It has also been collaborating with other organisations to raise awareness about the risks of AI-powered technologies and deepfakes, he said.
 Programmes such as Jelajah Anti-Scam Kebangsaan 2023, CyberSAFE Program (Cyber Security Awareness For Everyone) and the Cyber Security Awareness Talk (CSAT) have been launched to combat various AI-focused crimes, said Amirudin.",jaya scammer artificial intelligence scam believable effective cybersecurity malaysia csm chief executive officer datuk amirudin abdul wahab scam smarter day spot crucial stay scam tactic safeguard common driven scam technique deepfakes email text message social medium manipulation amirudin deepfakes audio recording sound scammer impersonate indivi duals family trick victim money personal voice technique scammer synthetic voice sound voice scammer phone call victim trust generate email bank credit card company verify account star social medium manipulation common technique scammer target specific individual social medium ad message identify people unemployed target ad rich star dec interview federal mercial crime investigation department ccid director comm datuk seri ramli deepfakes voice financial market manipulation future crime operation ramli illicit activity malaysian amirudin defence scam vigilance education public cautious sceptical suspicious communication true warrant individual organisation crucial verify identity contact detail organisation confirmation call inland revenue board unpaid tax contact claim amirudin communication red flag unusual phrasing inconsistency factual inaccuracy alert anomaly voice tone facial geometry odd pixelation video image personal financial unverified party potential scam news update source law enforcement agency csm aware potential technology spread misinformation effectiveness malicious generative pre trans former dangerous generative disseminate false create deception malicious code cyber defence amirudin consequence action leading national instability damage digital infrastructure breach sensitive data hand security industry combat crime challenge opportunity enhance standard tool identify counter threat function sword benefit cybersecurity effort potential criminal csm fraudulent activity technology technology expert forefront development advanced detection tool potential threat close cooperation agency combat crime amirudin education awareness campaign crucial component csm effort public risk scam organisation awareness risk powered technology programme jelajah anti scam kebangsaan cybersafe program cyber security awareness security awareness talk csat combat crime,"[(4, 0.99694633)]",4
625075,StarBiz,12,11/12/2023,Regulators look into Microsoft’s OpenAI stake,Software giant claims it doesn’t control AI company,"Washington: With global regulators examining Microsoft Corp’s US$13bil investment in OpenAI, the software giant has a simple argument it hopes will resonate with antitrust officials: It doesn’t own a traditional stake in the buzzy startup so can’t be said to control it.
 When Microsoft negotiated an additional US$10bil investment in OpenAI in January, it opted for an unusual arrangement, people familiar with the matter said at the time. Rather than buy a chunk of the cutting-edge artificial intelligence (AI) lab, it cut a deal to receive almost half of OpenAI’s financial returns until the investment is repaid up to a pre-determined cap, one of the people said. The unorthodox structure was concocted because OpenAI is a capped for-profit company housed inside a non-profit organisation.
 It’s not clear regulators see a distinction, however. Last Friday the British Competition and Markets Authority said it was gathering information from stakeholders to determine whether the collaboration between the two firms threatens competition in Britain, home of Google’s AI research lab Deepmind. 
 The US Federal Trade Commission is also examining the nature of Microsoft’s investment in OpenAI and whether it may violate antitrust laws, according to a person familiar with the matter.
 The inquiries are preliminary and the agency hasn’t opened a formal investigation, according to the person, who asked not to be named discussing a confidential matter. 
 Microsoft didn’t report the transaction to the agency because the investment in OpenAI doesn’t amount to control of the company under US law, the person said. OpenAI is a non-profit and acquisitions of non-corporate entities aren’t reported under US merger law, regardless of value. Agency officials are analysing the situation and assessing what its options are.
 “While details of our agreement remain confidential, it is important to note that Microsoft does not own any portion of OpenAI and is simply entitled to a share of profit distributions,” a Microsoft spokesperson said in a statement. 
 last Friday, Microsoft president Brad Smith said “the only thing that has changed is that Microsoft will now have a non-voting observer on OpenAI’s board.” He described its relationship with OpenAI as “very different” from Google’s outright acquisition of DeepMind in Britain.
 “Our partnership with Microsoft empowers us to pursue our research and develop safe and beneficial AI tools for everyone, while remaining independent and operating competitively. Their non-voting board observer does not provide them with governing authority or control over OpenAI’s operations,” said an OpenAI spokesperson in a statement.
 From the beginning, Microsoft and OpenAI took pains to telegraph the two companies’ independence. Microsoft hoped to reassure investors and customers that it’s not overly reliant on one partner. OpenAI didn’t want employees, customers and other investors thinking it was merely an outpost of Redmond, Washington-based Microsoft. That careful positioning was upended last month with the firing of OpenAI chief executive officer (CEO) Sam Altman and the startup’s near implosion. 
 The Altman imbroglio demonstrated both Microsoft’s lack of control and its influence. Microsoft received just minutes notice that the OpenAI board planned to announce Altman’s ouster, and its executives were not consulted in the decision. Still Microsoft CEO Satya Nadella played a key role, along with other investors, in forcing the board to reverse its decision. At one point Microsoft said it would hire Altman and his OpenAI colleagues to form a new Microsoft AI unit.
 Once Altman was restored as CEO, Microsoft executives debated the wisdom of taking a seat on the OpenAI board, people familiar with the matter said at the time. On the one hand, executives feared that a board seat or observer slot might draw the attention of regulators. 
 On the other hand, Microsoft wanted to keep a closer eye on its partner and protect its investment – an imperative that carried the day, despite the risks.
 Ultimately, Microsoft could face a world of regulatory headaches. Regulators in Europe are also paying attention, according to a spokesperson for the European Commission. 
 In order for a transaction to be notifiable to the Commission under the EU Merger Regulation, it has to involve a change of control on a lasting basis. While this transaction has not been formally notified, the Commission had been following the situation even before the management turmoil, the spokesperson said.
 Last month, Germany’s competition authority said it wasn’t subjecting Microsoft’s OpenAI investment to a merger review. But the regulator said they would hold off only because OpenAI didn’t have substantial business in Germany. 
 After reviewing the transaction and talking the companies, the regulator found the investment would give Microsoft a “material competitive influence” over the AI company that might warrant scrutiny in the future if OpenAI increases its activities in Germany.
 The partnership raises competition issues if Microsoft cuts back on its own AI research and development or if the investment keeps OpenAI from partnering with the tech giant’s rivals, said Bloomberg Intelligence antitrust analyst Jennifer Rie. 
 Antitrust enforcers may also have concerns about Microsoft’s board observer since it would give Microsoft additional information on OpenAI’s plans even if it doesn’t have rights to influence the decisions. — Bloomberg",washington global regulator microsoft corp bil investment openai software giant simple argument hope antitrust official traditional stake buzzy startup control additional bil investment january unusual arrangement people familiar matter time chunk edge artificial intelligence lab cut deal receive half openai financial return investment pre cap people unorthodox structure openai capped profit company inside profit organisation regulator friday british competition market stakeholder determine collaboration firm competition britain google lab deepmind federal trade commission nature microsoft investment openai violate antitrust law person familiar matter inquiry preliminary agency formal investigation person confidential matter microsoft report transaction agency investment openai amount control company law person openai profit acquisition corporate entity merger law agency official situation option detail agreement confidential note microsoft portion openai share profit distribution spokesperson statement friday microsoft president brad smith microsoft voting observer board relationship google outright acquisition deepmind britain partnership microsoft empowers safe beneficial tool independent board observer authority control openai operation spokesperson statement microsoft openai pain telegraph company microsoft reassure investor customer reliant partner employee customer investor outpost redmond washington careful positioning upended month openai chief executive officer ceo sam altman startup implosion altman imbroglio microsoft lack control influence minute board ouster executive decision ceo satya nadella key role investor board reverse decision microsoft hire altman colleague microsoft unit altman ceo microsoft executive wisdom seat board people familiar matter time hand executive board seat slot draw attention regulator hand eye partner protect investment imperative day risk microsoft regulatory headache regulator attention spokesperson european commission transaction notifiable commission merger regulation change control lasting basis transaction notified commission situation management turmoil spokesperson month germany competition authority microsoft openai investment merger review regulator openai substantial business germany transaction company regulator investment microsoft material competitive influence company warrant scrutiny future openai increase activity partnership competition issue cut development investment openai tech giant rival intelligence antitrust analyst jennifer rie antitrust enforcer concern board observer additional openai plan right influence decision,"[(1, 0.99725705)]",1
625289,Lifestyle,4,11/12/2023,Inside the Pentagon’s AI battlefield,The US military’s advancements raise questions about the role of autonomous lethal weapons and the challenges of responsible artificial intelligence deployment.,"ARTIFICIAL intelligence (AI) employed by the US military has piloted pint-sized surveillance drones in special operations forces’ missions and helped Ukraine in its war against Russia.
 It tracks soldiers’ fitness, predicts when Air Force planes need maintenance, and helps keep tabs on rivals in space.
 Now, the Pentagon is intent on fielding multiple thousands of relatively inexpensive, expendable AI-enabled autonomous vehicles by 2026 to keep pace with China.
 The ambitious initiative, dubbed Replicator, seeks to “galvanise progress in the too-slow shift of US military innovation to leverage platforms that are small, smart, cheap, and many”, deputy secretary of defence Kathleen Hicks said in August.
 While its funding is uncertain and details vague, Replicator is expected to accelerate hard decisions on what AI tech is mature and trustworthy enough to deploy, including weaponised systems.There is little dispute among scientists, industry experts and Pentagon officials that the United States will, within the next few years, have fully autonomous lethal weapons.
 And though officials insist humans will always be in control, experts say advances in data- processing speed and machine-to-machine communications will inevitably relegate people to supervisory roles.
 That’s especially true if, as expected, lethal weapons are deployed en masse in drone swarms.
 Many countries are working on them, and neither China, Russia, Iran, India, nor Pakistan have signed a US-initiated pledge to use military AI responsibly.
 It’s unclear if the Pentagon is currently formally assessing any fully autonomous lethal weapons system for deployment, as required by a 2012 directive. A Pentagon spokeswoman would not say.
 Replicator highlights immense technological and personnel challenges for Pentagon procurement and development as the AI revolution promises to transform how wars are fought.
 “The Department of Defense is struggling to adopt the AI developments from the last machine- learning breakthrough,” said Gregory Allen, a former top Pentagon AI official now at the Center for Strategic and International Studies think tank.
 The Pentagon’s portfolio boasts more than 800 AI-related unclassified projects, much of which is still in testing. Typically, machine learning and neural networks are helping humans gain insights and create efficiencies.
 “The AI that we’ve got in the Department of Defense right now is heavily leveraged and augments people,” said Missy Cummings, director of George Mason University’s robotics centre and a former Navy fighter pilot.
 “There’s no AI running around on its own. People are using it to try to understand the fog of war better.”
 One domain where AI-assisted tools are tracking potential threats is space, the latest frontier in military competition.
 China envisions using AI, including on satellites, to “make decisions on who is and isn’t an adversary”, US Space Force chief technology and innovation officer Lisa Costa told an online conference recently.The US aims to keep pace.
 An operational prototype called Machina used by the Space Force keeps tabs autonomously on more than 40,000 objects in space, orchestrating thousands of data collections nightly with a global telescope network.
 Machina’s algorithms marshal telescope sensors. Computer vision and large language models tell them what objects to track. And AI choreographs drawing instantly on astrodynamics and physics datasets, Col Wallace ‘Rhet’ Turnbull of Space Systems Command told a conference in August.
 Another AI project at the Space Force analyses radar data to detect imminent adversary missile launches, he said.
 Elsewhere, AI’s predictive powers help the Air Force keep its fleet aloft, anticipating the maintenance needs of more than 2,600 aircraft, including B-1 bombers and Blackhawk helicopters.
 Machine-learning models identify possible failures dozens of hours before they happen, said Tom Siebel, CEO of Silicon Valley-based C3 AI, which has the contract.
 C3’s tech also models the trajectories of missiles for the US Missile Defense Agency and identifies insider threats in the federal workforce for the Defense Counterintelligence and Security Agency.Among health-related efforts is a pilot project tracking the fitness of the Army’s entire Third Infantry Division – more than 13,000 soldiers. Predictive modelling and AI help reduce injuries and increase performance, said Maj Matt Visser.
 In Ukraine, AI provided by the Pentagon and its Nato allies helps thwart Russian aggression.
 Nato allies share intelligence from data gathered by satellites, drones and humans, some aggregated with software from US contractor Palantir.
 Some data comes from Maven, the Pentagon’s pathfinding AI project now mostly managed by the National Geospatial-Intelligence Agency, say officials, including retired Air Force Gen Jack Shanahan, the inaugural Pentagon AI director. 
 Maven began in 2017 as an effort to process video from drones in the Middle East – spurred by US Special Operations forces fighting ISIS and al-Qaeda – and now aggregates and analyses a wide array of sensors and human-derived data.
 AI has also helped the US-  created Security Assistance Group for Ukraine organise logistics for military assistance from a coalition of 40 countries, Pentagon officials say.To survive on the battlefield these days, military units must be small, mostly invisible and move quickly because exponentially growing networks of sensors let anyone “see anywhere on the globe at any moment”, then-joint chiefs chairman Gen Mark Milley observed in a June speech. “And what you can see, you can shoot.”
 To more quickly connect combatants, the Pentagon has prioritised the development of intertwined battle networks, called Joint All-Domain Command and Control, to automate the processing of optical, infrared, radar and other data across the armed services.
 But the challenge is huge and fraught with bureaucracy.
 Christian Brose, a former Senate Armed Services Committee staff director now at the defence tech firm Anduril, is among the military reform advocates who nevertheless believe they “may be winning here to a certain extent”.
 “The argument may be less about whether this is the right thing to do and increasingly more about how do we actually do it – and on the rapid timelines required,” he said. 
 Brose’s 2020 book, The Kill Chain, argues for urgent retooling to match China in the race to develop smarter and cheaper networked weapons systems.
 To that end, the US military is hard at work on “human- machine teaming”.
 Dozens of uncrewed air and sea vehicles currently keep tabs on Iranian activity. US Marines and Special Forces also use Anduril’s autonomous Ghost mini-copter, sensor towers and counter-drone tech to protect American forces.
 Industry advances in computer vision have been essential. Shield AI lets drones operate without GPS, communications or even remote pilots.
 It’s the key to its Nova, a quadcopter, which US special operations units have used in conflict areas to scout buildings.
 On the horizon: The Air Force’s “loyal wingman” programme intends to pair piloted aircraft with autonomous ones.
 An F-16 pilot might, for instance, send out drones to scout, draw enemy fire or attack targets. Air Force leaders are aiming for a debut later this decade.The loyal wingman timeline doesn’t quite mesh with Replicator’s, which many consider overly ambitious. In the meantime, the Pentagon’s vagueness on Replicator may partly intend to keep rivals guessing, though planners may also still be feeling their way on feature and mission goals, said Paul Scharre, a military AI expert and author of Four Battlegrounds.
 Anduril and Shield AI, each backed by hundreds of millions in venture capital funding, are among the companies vying for contracts.
 Nathan Michael, chief technology officer at Shield AI, estimates they will have an autonomous swarm of at least three uncrewed aircraft ready in a year using its V-BAT aerial drone. 
 The US military currently uses the V-BAT – without an AI mind – on Navy ships, on counter-drug missions and in support of Marine Expeditionary Units, the company says.It will take some time before larger swarms can be reliably fielded, Michael said. 
 “Everything is crawl, walk, run – unless you’re setting yourself up for failure.”
 The only weapons systems that Shanahan, the inaugural Pentagon AI chief, currently trusts to operate autonomously are wholly defensive, like Phalanx anti-missile systems on ships. 
 He worries less about autonomous weapons making decisions on their own than about systems that don’t work as advertised or kill non-combatants or friendly forces.
 The department’s current chief digital and AI officer, Craig Martell, is determined not to let that happen.
 “Regardless of the autonomy of the system, there will always be a responsible agent that understands the limitations of the system, has trained well with the system, has justified confidence in when and where it’s deployable, and will always take the responsibility,” said Martell, who previously headed machine- learning at LinkedIn and Lyft. “That will never not be the case.”As to when AI will be reliable enough for lethal autonomy, Martell said it makes no sense to generalise. For example, Martell trusts his car’s adaptive cruise control but not the tech that’s supposed to keep it from changing lanes.
 “As the responsible agent, I would not deploy that except in very constrained situations,” he said. “Now extrapolate that to the military.”
 Martell’s office is evaluating potential generative AI use cases – it has a special task force for that – but focuses more on testing and evaluating AI in development.
 One urgent challenge, says Jane Pinelis, chief AI engineer at Johns Hopkins University’s Applied Physics Lab and former chief of AI assurance in Martell’s office, is recruiting and retaining the talent needed to test AI tech.
 The Pentagon can’t compete on salaries. Computer science PhDs with AI-related skills can earn more than the military’s top- ranking generals and admirals.Testing and evaluation standards are also immature, as a recent National Academy of Sciences report on Air Force AI highlighted.
 Might that mean the US will one day field under duress autonomous weapons that don’t fully pass muster?
 “We are still operating under the assumption that we have time to do this as rigorously and as diligently as possible,” said Pinelis.“I think if we’re less than ready and it’s time to take action, somebody is going to be forced to make a decision.” – AP",artificial intelligence military pint surveillance drone special operation force mission ukraine war russia soldier fitness predicts air force plane maintenance tab rival space pentagon intent multiple thousand inexpensive expendable autonomous vehicle pace ambitious initiative replicator galvanise progress slow shift military innovation leverage platform cheap deputy secretary defence kathleen august funding uncertain detail vague replicator hard decision tech mature trustworthy deploy weaponised system dispute scientist industry expert official autonomous lethal weapon official human control expert advance data speed machine machine communication people supervisory role true lethal weapon drone swarm country russia iran india pakistan pledge military unclear pentagon autonomous lethal weapon system deployment directive pentagon spokeswoman replicator highlight immense technological personnel procurement development revolution transform war department defense adopt development machine gregory allen top pentagon official center strategic international study pentagon portfolio unclassified project machine neural network human insight efficiency department defense leveraged augments people cummings director george mason university robotics navy fighter pilot people fog war domain tool potential threat space military competition china envisions satellite decision adversary space force chief technology innovation officer lisa costa online conference aim pace operational prototype space force tab space thousand data collection global telescope network machina algorithm telescope sensor computer vision language model track choreographs astrodynamics physic datasets wallace rhet turnbull space system conference august project space force radar data imminent adversary missile predictive power force fleet maintenance aircraft bomber blackhawk helicopter machine model failure hour tom siebel ceo silicon valley contract tech model trajectory missile defense agency identifies threat federal workforce defense counterintelligence security agency health effort pilot project fitness army entire infantry division soldier injury performance maj matt visser ukraine pentagon nato ally russian aggression nato ally share intelligence data satellite drone human software contractor palantir data project national geospatial intelligence agency official retired air force gen jack shanahan inaugural pentagon director maven effort process video drone spurred special operation force isi qaeda analysis wide array sensor data security assistance ukraine organise logistics military assistance coalition country official survive battlefield day military unit invisible move network sensor moment joint chief chairman gen mark milley june speech shoot connect combatant development battle network joint domain command control automate processing optical radar data service challenge huge fraught bureaucracy christian brose senate service committee staff director defence tech firm military reform extent argument rapid timeline brose book kill chain urgent match china race smarter cheaper networked weapon system military hard human machine dozen uncrewed air sea vehicle iranian activity marine special force autonomous ghost mini copter sensor tower drone tech american force industry computer vision essential shield drone gps communication pilot key nova quadcopter special operation unit scout building air force loyal wingman programme pair autonomous pilot instance send drone draw enemy fire attack target force leader debut decade loyal wingman timeline mesh replicator ambitious pentagon vagueness replicator rival planner feature mission goal scharre military expert author anduril shield hundred million venture capital funding company contract chief technology officer estimate autonomous swarm aircraft ready bat aerial drone military bat mind navy ship drug mission marine expeditionary unit company time larger swarm michael crawl failure weapon system shanahan inaugural pentagon chief trust defensive phalanx anti missile system ship worry autonomous weapon decision system kill combatant friendly force department current chief digital officer craig martell happen autonomy system responsible agent limitation system trained system confidence deployable responsibility martell machine linkedin lyft reliable lethal autonomy martell sense generalise martell trust car adaptive cruise control tech lane responsible agent deploy situation military martell office potential generative special task force development urgent challenge jane pinelis chief engineer john university physic lab chief assurance martell office talent test tech pentagon compete salary computer science phd skill military top general admiral evaluation standard national academy science air force day field autonomous weapon muster assumption time ready time action decision,"[(1, 0.7237991), (4, 0.27517134)]",1
624691,Main,35,10/12/2023,EU strikes deal to regulate AI tools,Generative systems such as ChatGPT and Bard to come under a set of controls,"BRUSSELS: The European Union reached a hard-fought deal on what is poised to become the most comprehensive regulation of artificial intelligence in the western world. 
 Thierry Breton, the bloc’s internal market chief, said the deal strikes a balance between fostering innovation and protecting the rights of people and companies. 
 “We spent a lot of time on finding the right balance between making the most of AI potential to support law enforcement while protecting our citizens’ fundamental rights,” he said early Saturday in a statement. “We do not want any mass surveillance in Europe.”
 After more than 37 hours of negotiations this week, delegates from the European Commission, the European Parliament and 27 member countries agreed to a set of controls for generative artificial intelligence tools such as OpenAI Inc.’s ChatGPT and Google’s Bard – the kind capable of producing content on command.
 The negotiators agreed to allow some live scanning of faces, but with safeguards and exemptions, Breton said. The deal would prohibit biometric scanning that categorises people by sensitive characteristics, such as political or religious beliefs, sexual orientation or race. Officials said this was one of the most difficult and sensitive issues in the talks.
 The proposed legislation would impose financial penalties on companies that violate the rules, with fines up to €35 million (RM175.84mil), or 7% of global turnover, depending on the infringement and the size of the company. 
 The draft legislation still needs to be formally approved by EU member states and the parliament. But the deal marks a critical step toward landmark AI policy that will – in the absence of any meaningful action by US Congress – set the tone for the regulation of the fast-developing technology. The EU is aiming to enact the first firm guardrails on AI outside of Asia. 
 Policymakers have been working for months to finalise the language in the AI Act and get it passed before European elections in June usher in a new commission and parliament that could force more changes and stall efforts. 
 The decision was hammered out at a session on Friday following a nearly 24 hour marathon that stretched from Wednesday to Thursday. During the first meeting, some negotiators dozed off in the hall as others debated the most sensitive topic of restricting live facial scanning technology in public before finally agreeing to break.The difficult discussions underscore how contentious the debate over regulating AI has become, dividing world leaders and tech executives alike as generative tools continue explode in popularity. 
 The EU – like other governments including the US and UK – has struggled to find a balance between the need to protect its own AI startups, such as France’s Mistral AI and Germany’s Aleph Alpha, against potential societal risks. That proved to be a key sticking point in negotiations, with some countries including France and Germany opposing rules that they said would unnecessarily handicap local companies. — Bloomberg",brussels union fought deal comprehensive regulation artificial intelligence western thierry breton bloc internal market chief deal strike balance innovation right people company lot time balance potential support law enforcement citizen fundamental right saturday statement mass surveillance europe hour negotiation week delegate european commission european parliament country set control generative artificial intelligence tool chatgpt google bard capable content command negotiator live scanning safeguard exemption deal prohibit biometric scanning categorises people sensitive characteristic political religious belief sexual orientation race official difficult sensitive issue talk legislation financial penalty company rule fine mil global turnover infringement size company draft legislation parliament deal critical step landmark policy absence meaningful action congress regulation technology enact firm asia policymakers month language european election usher commission parliament force stall effort decision session hour marathon wednesday thursday meeting negotiator hall sensitive topic live facial technology public break difficult discussion contentious debate regulating leader tech executive generative tool explode popularity government balance protect startup mistral germany aleph potential societal risk key negotiation country france germany rule local company,"[(3, 0.99496883)]",3
624609,StarBiz 7,4,09/12/2023,YTL Power and Nvidia in AI collaboration,Deal to bring fastest supercomputers to M’sia by 2024,"PETALING JAYA: YTL Power International Bhd has joined forces with Nasdaq’s Nvidia Corp to build artificial intelligence (AI) infrastructure that is expected to bring the fastest supercomputers to Malaysia by mid-2024.
 The AI infrastructure will reside at the YTL Green Data Centre Park in Johor – a 500-megawatt facility developed by YTL Power and powered entirely by on-site solar energy.
 Meanwhile, YTL Communications Sdn Bhd, the telecommunications subsidiary of YTL Power, which operates a national mobile network under the “Yes” brand, will own and manage the AI infrastructure and provide AI computing services to the nation.
 In a statement, YTL Power said the AI infrastructure will provide the foundation for scientific research and the development of solutions and applications that will accelerate Malaysia’s progress towards becoming an AI nation. 
 “YTL will not only provide green, energy-efficient AI infrastructure to scientists, developers, and startups across the nation, it will also create AI-specific applications and services for its customers,” it added.
 The group announced plans to deploy graphics processing units (GPUs), particularly the Nvidia H100 Tensor Core, which is known for its capabilities in supporting cutting-edge AI data centres. 
 Nvidia H100 GPUs deliver generative AI and can speed up large language models or LLMs by 30 times compared with the previous-generation GPUs. 
 Additionally, YTL Power will utilise Nvidia’s AI enterprise software to enhance efficiency in AI production. It plans to customise and deploy a Malay language foundation model that will be sensitive to Malaysia’s multicultural heritage.
 Minister of Investment, Trade and Industry Tengku Datuk Seri Zafrul Abdul Aziz, who witnessed the collaboration, said this partnership exemplifies the kind of strategic collaborations targeted by the New Industrial Master Plan 2030.
 “By offering supercomputing cloud services and leveraging AI to power innovations, such partnerships enhance our economic complexity, paving the way for us to become a high technology and high-income nation while further positioning Malaysia as a top investment destination,” he said.
 Nvidia senior vice-president of the Asia-Pacific region Raymond Teh said AI will help enhance jobs, drive competitiveness and supercharge innovation.
 YTL Power managing director Datuk Yeoh Seok Hong said this partnership brings numerous benefits to the nation, especially by leading in AI development.",jaya ytl power international bhd force nasdaq nvidia corp build artificial intelligence infrastructure bring fastest supercomputer mid infrastructure reside ytl green data centre park johor megawatt facility ytl power site solar energy ytl communication bhd telecommunication subsidiary ytl power national mobile network brand manage infrastructure service nation statement ytl power infrastructure foundation scientific development solution application malaysia progress nation ytl green energy efficient infrastructure scientist developer nation create specific application service customer plan graphic unit nvidia tensor core capability edge data centre gpus deliver generative speed language model time previous generation gpus ytl power utilise nvidia enterprise software enhance efficiency production plan deploy malay language foundation sensitive malaysia multicultural heritage minister investment trade industry datuk seri zafrul abdul aziz collaboration partnership strategic collaboration industrial master plan cloud service power innovation partnership economic complexity technology income nation malaysia top investment destination senior vice president pacific region raymond teh enhance job competitiveness supercharge innovation ytl power director datuk yeoh seok hong partnership numerous benefit nation development,"[(1, 0.9945226)]",1
624149,StarBiz,9,08/12/2023,Asia hedge funds avert China turmoil with bets on Japan and AI,,"SINGAPORE: Asia hedge funds are set to post improved performances in 2023 after dodging the China investment minefield with winning bets tied to Japan’s rebound, economic trends and the artificial intelligence or AI-fuelled technology rally.
 About 58% of Asia-focused funds tracked by Preqin Ltd avoided losses in the first 10 months of the year, compared with just 32% in 2022. Among the 2023 winners are funds overseen by Astignes Capital Asia Pte, Keystone Investors Pte, Panview Capital Ltd and Trivest Advisors Ltd. 
 Buoyant stock markets in November – the MSCI Asia-Pacific Index jumped the most since January – may have narrowed or eliminated losses at other funds, with a Eurekahedge Pte index edging up about 1% for the month even before most funds reported numbers.
 Funds were rewarded for navigating choppy waters in China, where the short-lived euphoria over exiting from Covid restrictions gave way to persistent concerns about a housing market crisis, economic slowdown and geopolitical tensions. 
 Those who cut China bets early in favour of Japan and global technology names reaped benefits, even as the investor stampede for Japan stymied bearish wagers.
 About 68% of China-focused hedge funds lost money in the first 10 months of the year, compared with just 18% of peers specialising in Japan, according to Preqin data.
 Former Goldman Sachs Group Inc partner Ryan Thall’s Panview Asian Equity Fund surged nearly 20% in the first 11 months, led by bullish bets on smaller, lesser-known Japanese companies swept up in corporate governance reforms, said a person with knowledge of the matter. 
 Also paying off were bets against Asian duty-free shop operators for not meeting market expectations after China lifted pandemic controls. It also profited from a short position against a US cosmetics maker that has struggled to maintain sales in China.
 Athos Asia Event Driven Fund returned 5.6% through November, said a source. Deals lifted returns, such as those involving Australia’s Origin Energy Ltd and Japanese companies. The fund made money from a bet that the market exaggerated the risk that China would refuse regulatory approval for US chipmaker Broadcom Inc’s merger with cloud company VMWare Inc. 
 Athos, an Asia event-driven shop founded by Matthew Moskey and Fred Schulte-Hillen, also profited from short-term pricing gaps among Chinese companies’ shares traded domestically, in Hong Kong and in the United States. More US-traded Chinese companies have gained listings in Hong Kong in recent years. 
 Investor exodus
 The investor exodus from Chinese equities made for greater arbitrage opportunities as stock prices became more volatile and spreads between different classes of shares widened, said the source. 
 Trivest Advisors’ TAL China Focus Master Fund averted the fate of its peers with a nearly 16% gain in the first 10 months. 
 At the end of September, the firm held more than US$830mil worth of shares of US technology giants Microsoft Corp, Meta Platforms Inc, Nvidia Corp and Alphabet Inc. It also had nearly US$193mil parked in the US shares of PDD Holdings Inc, a rising star among Chinese eCommerce companies, and Luckin Coffee Inc, the Chinese coffee chain that has staged a turnaround after fraud allegations. The two have soared 74% and 37% respectively this year. 
 Good performance
 Keystone Investors returned nearly 24% in the first 11 months, said a source. It dabbled in some of the same names, including Microsoft, Nvidia, Meta and PDD, along with New Oriental Education & Technology Group Inc, whose US shares more than doubled this year. Keystone is led by Liu Xuan, a one-time analyst and portfolio manager at global firms including Point72 Asset Management and Millennium Management. 
 Ovata Equity Strategies Fund rose 9.7% in the first 11 months, said a person familiar with the firm helmed by James Chen, former Asia equities head of BlueCrest Capital Management. More volatile markets favour funds like Ovata that seek to profit from wider pricing disparities between related securities. The fund also made money from Japanese stocks, with the Nikkei 225 up 27% this year.
 Two Asia-focused firms that allocate capital to pods of investors with different strategies proved the benefits of diversification this year. Dymon Asia Multi-Strategy Investment Fund gained an estimated 10% in the first 11 months, while Polymer Asia Fund was up 3.4% through October, according to sources.
 Macro hedge funds
 The biggest winner as a group was macro hedge funds, which trade across stock, bond, commodity and currency markets to tap broad trends.
 Arete Macro Fund of Will Li’s Ocean Arete Ltd gained 9.1% in the first 11 months, according to a source. Lifting returns was a bullish bet on the greenback and bearish wagers on longer-dated US Treasury bonds, on the belief that the US economy would withstand higher interest rates. It also made money buying stocks of large Chinese banks as a proxy for fiscal stimulus, said a source. Further paying off were short positions in European luxury goods, as higher global inflation hurt consumers’ purchasing power. 
 Trades involving Japanese rates and China’s economic slowdown helped Southern Ridges Capital Pte’s newer Summit Macro Fund to an 8.8% gain in the first 10 months, while its older macro fund rose 4.6%, said a source. — Bloomberg",singapore asia hedge fund post improved performance china investment minefield bet japan economic trend artificial intelligence technology rally fund preqin avoided loss month winner fund overseen astignes capital asia pte keystone investor panview capital trivest advisor buoyant stock market msci asia pacific january loss fund month fund fund choppy water short euphoria covid restriction persistent concern housing market crisis economic slowdown geopolitical tension china bet japan global technology name benefit investor japan bearish wager hedge fund money month peer japan preqin data goldman sachs partner thall panview asian equity fund month bullish bet japanese company corporate governance reform person matter bet asian duty free shop operator market expectation pandemic control short position cosmetic maker maintain sale athos asia event fund november source deal return australia origin energy japanese company money bet market risk china refuse regulatory approval chipmaker broadcom merger company vmware athos asia event shop matthew moskey schulte hillen short term pricing gap chinese company share hong kong traded chinese company listing hong kong investor exodus investor exodus chinese equity arbitrage stock price volatile spread share source trivest advisor tal china focus master fund fate peer month firm worth share technology giant corp meta platform corp alphabet mil share holding star chinese ecommerce company coffee chinese coffee chain turnaround fraud allegation performance keystone investor month source name microsoft nvidia meta pdd oriental education technology share keystone liu xuan time analyst portfolio manager global firm asset management millennium management ovata equity strategy month person familiar firm james chen asia equity bluecrest capital management volatile market fund ovata seek profit wider pricing disparity security money japanese stock asia firm capital pod investor strategy benefit diversification dymon asia multi strategy investment fund estimated month asia fund october source hedge fund biggest winner macro hedge fund trade stock bond commodity currency market broad trend arete fund ocean arete month source return bullish greenback bearish wager treasury bond belief economy rate money stock chinese bank proxy fiscal stimulus source short position european luxury global inflation consumer power trade japanese rate economic slowdown southern ridge capital pte summit macro fund gain month fund source bloomberg,"[(3, 0.99757755)]",3
624331,Main,15,08/12/2023,AI belongs to the capitalists now,,"WHAT happened at OpenAI over a few days last month could be described in many ways: a juicy boardroom drama, a tug of war over one of America’s biggest startups, a clash between those who want artificial intelligence to progress faster and those who want to slow it down.
 But it was, most importantly, a fight between two duelling visions of AI.
 In one vision, AI is a transformative new tool, the latest in a line of world-changing innovations that includes the steam engine, electricity and the personal computer, and that, if put to the right uses, could usher in a new era of prosperity and make gobs of money for the businesses that harness its potential.
 In another vision, AI is something closer to an alien life form – a leviathan being summoned from the mathematical depths of neural networks – that must be restrained and deployed with extreme caution in order to prevent it from taking over and killing us all.
 With the return of Sam Altman to OpenAI, the company whose board fired him as CEO a few days earlier, the battle between these two views appears to be over.
 Team Capitalism won. Team Leviathan lost.
 OpenAI’s new board will consist of three people, at least initially: Adam D’Angelo, the CEO of Quora (and the only holdover from the old board); Bret Taylor, a former executive at Facebook and Salesforce; and former US Treasury Secretary Larry Summers. The board is expected to grow from there.
 OpenAI’s largest investor, Microsoft, is also expected to have a larger voice in OpenAI’s governance going forward. That may include a board seat.
 Gone from the board are three of the members who pushed for Altman’s ouster: Ilya Sutskever, OpenAI’s chief scientist (who has since recanted his decision); Helen Toner, a director of strategy at Georgetown University’s Centre for Security and Emerging Technology; and Tasha McCauley, an entrepreneur and researcher at the RAND Corp.
 Sutskever, Toner and McCauley are representative of the kinds of people who were heavily involved in thinking about AI a decade ago – an eclectic mix of academics, Silicon Valley futurists and computer scientists.
 They viewed the technology with a mix of fear and awe, and they worried about theoretical future events like the “singularity,” a point at which AI would outstrip our ability to contain it.
 Many were affiliated with philosophical groups like the Effective Altruists, a movement that uses data and rationality to make moral decisions, and were persuaded to work in AI out of a desire to minimise the technology’s destructive effects.
 This was the vibe around AI in 2015, when OpenAI was formed as a non-profit, and it helps explain why the organisation kept its convoluted governance structure – which gave the non-profit board the ability to control the company’s operations and replace its leadership – even after it started a for-profit arm in 2019.
 At the time, protecting AI from the forces of capitalism was viewed by many in the industry as a top priority, one that needed to be enshrined in corporate bylaws and charter documents.
 But a lot has changed since 2019. Powerful AI is no longer just a thought experiment – it exists inside real products, like ChatGPT, that are used by millions of people every day.
 The world’s biggest tech companies are racing to build even more powerful systems. And billions of dollars are being spent to build and deploy AI inside businesses, with the hope of reducing labour costs and increasing productivity.
 The new board members are the kinds of business leaders you’d expect to oversee such a project.
 Taylor, the new board chair, is a seasoned Silicon Valley deal maker who led the sale of Twitter to Elon Musk last year, when he was the chair of Twitter’s board. And Summers is the Ur-capitalist – a prominent economist who has said that he believes technological change is “net good” for society.
 There may still be voices of caution on the reconstituted OpenAI board, or figures from the AI safety movement. But they won’t have veto power, or the ability to effectively shut down the company in an instant, the way the old board did. And their preferences will be balanced alongside others’, such as those of the company’s executives and investors.
 That’s a good thing if you’re Microsoft, or any of the thousands of other businesses that rely on OpenAI’s technology. More traditional governance means less risk of a sudden explosion, or a change that would force you to switch AI providers in a hurry.
 And perhaps what happened at OpenAI – a triumph of corporate interests over worries about the future – was inevitable, given AI’s increasing importance. A technology potentially capable of ushering in a Fourth Industrial Revolution was unlikely to be governed over the long term by those who wanted to slow it down – not when so much money was at stake.
 There are still a few traces of the old attitudes in the AI industry. Anthropic, a rival company started by a group of former OpenAI employees, has set itself up as a public benefit corporation, a legal structure that is meant to insulate it from market pressures. And an active open-source AI movement has advocated that AI remain free of corporate control.
 But these are best viewed as the last vestiges of the old era of AI, in which the people building AI regarded the technology with both wonder and terror, and sought to restrain its power through organisational governance. Now, the utopians are in the driver’s seat. Full speed ahead. — ©2023 The New York Times Company",openai day month juicy boardroom drama tug war america biggest startup clash artificial intelligence progress fight vision vision transformative tool innovation steam engine electricity personal computer era prosperity money business potential vision closer alien life form leviathan mathematical depth neural network deployed extreme caution prevent return sam altman company board ceo day battle view team capitalism team leviathan board consist people angelo ceo board bret taylor executive facebook salesforce treasury secretary larry summer board grow largest investor microsoft larger voice openai governance board seat board altman ouster ilya sutskever chief scientist decision helen toner director strategy georgetown university security technology tasha mccauley entrepreneur researcher corp sutskever toner representative kind people thinking decade eclectic mix academic valley futurist computer scientist technology mix fear awe theoretical future event singularity outstrip ability philosophical effective altruist movement data rationality moral decision desire minimise technology destructive effect openai profit organisation governance structure profit board ability control company operation leadership started profit arm time force capitalism industry top priority corporate bylaw document powerful experiment exists real product million people day biggest tech company build powerful system billion dollar build deploy business labour cost productivity board business leader oversee project taylor board chair silicon valley deal maker sale twitter elon musk chair board summer capitalist prominent economist technological change net society voice openai board figure safety movement veto power ability company instant board preference company executive investor microsoft thousand business technology traditional governance risk sudden explosion change force switch provider openai triumph corporate worry inevitable technology capable ushering fourth industrial revolution term money stake trace attitude industry anthropic rival company openai employee public benefit corporation legal structure insulate market pressure active source movement free corporate control vestige era people technology terror restrain power organisational governance utopian seat speed york time company,"[(1, 0.74336475), (3, 0.10642079), (4, 0.1487262)]",1
623793,StarBiz,12,07/12/2023,Outperforming Beijing tech fund calls for caution on AI stocks,,"SHANGHAI: A technology-focused China equity fund outperforming 98% of peers this year advises caution over the frenzy in artificial intelligence (AI) themes, saying it might be the biggest under-priced risk.
 “There are huge fundamental risks, especially in terms of public safety, in AI at this current stage,” said Yun Bingwang, an investment officer at Qingdao Luxiu Investment Management Co. 
 “These uncertainties mean that we cannot make investment decisions.” 
 Yun’s Luxiu Lvjing Fund has returned 76% this year, according to fund tracker Shenzhen PaiPaiWang Investment and Management Co, trouncing the benchmark CSI 300 Index by 88 percentage points. That puts the fund, which primarily invests in global tech companies, in the top 2% among 10,308 peer private-fund products.
 The fund owes its outperformance to bets on online retailer PDD Holdings Inc, best known for hit shopping app Temu and domestic bargains trailblazer Pinduoduo, amid the stock’s slump earlier this year. 
 The market misjudged Chinese consumers’ shift back into premium products after the end of Covid controls, said Yun. 
 Dip buying in Apple Inc shares in late 2022 also contributed to returns.
 While Yun is keeping tabs on how AI is disrupting tech giants, he said there’s no rush to buy. 
 He compares missing out on AI this year to side stepping the euphoria in Chinese private tutoring names in early 2021, with some firms losing almost all of their value later that year after a shock overhaul over the sector.
 In China, six out the top 10 performers on the benchmark gauge this year were lifted on AI wagers, with Dawning Information Industry Co’s 73% advance helming the charge. 
 The leading stock-focused mutual funds this year also count software, media and chip shares that benefitted from the trade as their biggest holdings, according to data from financial website East Money Information Co. — Bloomberg",shanghai technology china equity fund peer caution frenzy artificial intelligence theme biggest risk huge fundamental risk term public safety current stage yun bingwang investment officer luxiu investment management uncertainty investment decision luxiu lvjing fund fund tracker shenzhen paipaiwang investment management benchmark csi percentage fund global tech company peer private fund product owes outperformance bet retailer pdd holding app temu domestic bargain pinduoduo stock slump market chinese consumer premium product covid control apple share return tab tech giant compare euphoria chinese private name firm shock overhaul sector top performer gauge wager industry advance charge stock mutual fund count software medium chip share trade biggest holding data financial website east money bloomberg,"[(0, 0.16135925), (1, 0.8326713)]",1
623479,StarBiz,9,06/12/2023,Nvidia                       plans to help build Japan                 AI ecosystem,,"TOKYO: Nvidia Corp plans to help build an artificial intelligence (AI) tech-related ecosystem in Japan to meet demand in a country eager to gain an edge in AI.
 The Santa Clara, California-based company will seek to partner with Japanese research organisations, companies and startups to build factories of AI, chief executive officer Jensen Huang said during opening remarks in a meeting with Japanese Economy Minister Yasutoshi Nishimura.
 Nvidia will set up an AI research laboratory and invest in local startups and educate the public on using AI, Huang said.
 Nvidia’s graphics chips, which process large amounts of data by performing calculations in parallel, have become the leading tool for training AI services.
 Prices for Nvidia chips have surged as companies and governments fight to develop their own AI prowess. 
 Huang, earlier this week, met with Japanese Prime Minister Fumio Kishida and promised to do his best to prioritise Japan, according to local news reports.
 “We will build a network of AI factories here in Japan, so that Japan can process the data of the society and create intelligence for the society and for the industry,” he  said. Tokyo is trying to regain tech leadership by leveraging its expertise in materials science and chipmaking tools and by supplying billions of dollars in subsidies to ramp up domestic production. —  Bloomberg",tokyo nvidia corp plan artificial intelligence tech ecosystem japan meet demand country eager gain edge santa clara california company seek partner japanese organisation company build factory chief executive officer jensen remark japanese economy minister yasutoshi laboratory invest local startup public huang nvidia graphic chip process amount data calculation tool training service price chip company government prowess huang week japanese prime minister fumio kishida japan local news report network factory japan process data society create intelligence society industry tokyo regain tech leadership expertise material science chipmaking tool billion dollar subsidy domestic production bloomberg,"[(4, 0.9912379)]",4
623489,StarBiz,10,06/12/2023,"Singapore to  triple AI experts to 15,000 people",,"SINGAPORE: Singapore plans to triple its pool of artificial intelligence (AI) experts, including machine-learning scientists and engineers, to 15,000, as part of its national AI strategy, deputy prime minister Lawrence Wong says.
 The South-East Asian nation of 5.45 million, which is home to the Asian headquarters of global tech giants, such as Google owner Alphabet and Microsoft, said it would also work to boost its available high-performance computing resources by securing access through partnerships with chipmakers and cloud service providers.
 Nvidia revenue for the quarter that ended in October included US$2.7bil that originated from Singapore, trailing only the United States, China, and Taiwan, according to a company filing to the US Securities and Exchange Commission.
 Singapore also pledged under its AI strategy to increase government incentives for the sector, including by backing accelerator programmes for AI startups and encouraging companies to set up AI “centres of excellence”. — Reuters",singapore plan triple artificial intelligence expert machine learning scientist national strategy deputy prime minister lawrence south east asian nation asian headquarters global tech giant owner alphabet microsoft boost performance resource access partnership chipmakers service provider revenue quarter october bil united china taiwan company security exchange commission strategy increase government incentive sector accelerator programme startup company centre excellence reuters,"[(4, 0.9858582)]",4
623521,Main,5,06/12/2023,HK cops encounter fraud syndicate that used AI-generated images,,"KUALA LUMPUR: Hong Kong police crippled a fraud syndicate that used artificial intelligence (AI) to create doctored images for loan scams targeting banks and money-lenders.
 Superintendent Dicken Ko Tik of the cyber security and techno­logy crime bureau was reported saying on Aug 25 that it was the first time police had discovered scammers employing the so-called deepfake technology to deceive financial institutions.
 “The racket used an AI face- changing programme, commonly known as deepfake technology, to apply for loans online with financial institutions,” he said.
 According to police, the syndicate used eight stolen Hong Kong identity cards and bogus documents, including proof of address and income, to apply for loans online.
 As financial institutions required applicants to scan and upload their identification documents as well as provide real-time selfies during the online application process, Ko said scammers utilised AI-generated ­images to mimic people on the stolen identity cards.
 He said an investigation revea­led that the syndicate made at least 20 online loan applications using the technology in a bid to deceive facial recognition systems used by money-lenders to verify applicant identities.
 He added that one of the 20 applications that was approved involved a loan of HK$70,000 (RM42,050).
 The deepfake scam has promp­ted police to offer recommendations to related financial institutions to upgrade their anti-fraud measures.
 “We will continue to engage with stakeholders from various industries to bring cyber criminals hiding in the digital world to justice,” he was quoted by the South China Morning Post on Aug 25.
 On top of the 20 cases involving AI-generated images, police said the syndicate also used the eight stolen identity cards to apply for 70 other loans and 54 bank accounts with 20 different banks and money-lending companies between September 2022 and July this year.
 Ko said the syndicate also used the stolen identity cards to register for more than 30 prepaid SIM cards.
 In April and May, the fraudsters used the SIM cards to send out more than 7,200 phishing messa­ges, tricking residents into provi­ding credit card information by falsely offering shopping reward points, he said.
 After gathering evidence, police arrested four men and two women in a series of raids in Kowloon Bay, Diamond Hill, Yau Ma Tei, Lai Chi Kok and North Point on Aug 24.
 The suspects, aged 31 to 50, were detained on suspicion of conspiracy to defraud.",kuala hong kong police fraud syndicate artificial intelligence create image loan scam bank money lender dicken tik cyber security techno logy crime bureau aug time police scammer deepfake technology deceive financial institution racket programme technology apply loan financial institution syndicate kong identity card bogus document proof address income apply loan financial institution applicant scan upload identification document real time selfies application process scammer image mimic people identity card investigation revea syndicate online loan application technology bid deceive facial recognition system money lender applicant identity application involved loan deepfake scam promp police recommendation financial institution anti fraud measure engage stakeholder industry cyber criminal digital justice south china morning post aug top image syndicate identity card loan bank account bank money lending company july syndicate identity card register sim card april fraudsters card messa ge resident credit card reward gathering evidence police woman series raid bay diamond hill yau tei lai kok north aug suspect detained suspicion conspiracy defraud,"[(3, 0.9943913)]",3
623525,Main,5,06/12/2023,Police gearing up to combat AI-based crime,,"KUALA LUMPUR: Staying ahead of the game is vital to law enforcement efforts to curb the potential misuse of artificial intelligence (AI).
 Bukit Aman Commercial Crime Investigation Department (CCID) director Comm Datuk Seri Ramli Mohamed Yoosuf said as part of their efforts to gear up to combat AI-based crime, it is important for his personnel to know what they are potentially up against.
 “With AI, the enemy that we are facing is invisible, which makes policing efforts more complex.
 “As such, we are sending  our officers from time to time  for training and international exposure with other law enforcement agencies across the  globe.
 “We are always looking for appropriate courses to enhance their knowledge and skills,” he told The Star recently.
 He said they are working closely with the United Nations Office on Drugs and Crime (UNODC) on the matter.
 “Locally, we are also working together with the Malaysian Communications and Multimedia and Commission and relevant government ministries on ways to synergise resources in tackling AI-related crime in future.
 “We always need to keep ourselves abreast with the latest developments in technology. The situation is such that technology is ever evolving and when ­changes occur, crime syndicates also evolve their modus operandi.
 “We need to ensure we are one step ahead of them so that the use of AI by syndicates does not get out of hand,” he said.
 Comm Ramli said aside from training law enforcement personnel, the public also needs to be fully aware of the danger and potential risks of AI if they want to avoid falling prey to these syndicates.
 “Other countries are already grappling with deepfakes and dark web creations of voices and videos that mimic people in real life.
 “If people are aware of such things, it could help prevent them from becoming the latest victim,” he said.",kuala lumpur game vital law enforcement effort potential misuse artificial intelligence bukit aman commercial crime investigation department ccid director comm datuk seri ramli yoosuf effort combat crime personnel enemy facing invisible policing effort complex officer time time international exposure law enforcement agency course knowledge skill star united nation office drug crime unodc matter malaysian communication commission relevant government ministry resource crime future development technology situation technology occur crime syndicate modus operandi step syndicate hand ramli training law enforcement personnel public aware danger potential risk avoid prey syndicate country deepfakes dark web creation voice mimic people real life people aware prevent victim,"[(0, 0.9915648)]",0
622271,StarEdu,6,03/12/2023,‘Better diagnosis with AI’,,"THE latest healthcare equipment systems at Hospital Canselor Tuanku Muhriz (HCTM) Universiti Kebangsaan Malaysia (UKM) will lead to faster, more efficient, and accurate diagnosis and treatment.
 The two artificial intelligence-based machines, costing RM9.2mil, have already improved the quality of patient care services since they started operating at the varsity on Dec 26 last year (Fluoroscopy System) and Feb 8 this year (Angiography System), said UKM vice-chancellor Prof Datuk Dr Mohd Ekhwan Toriman.
 The biplace angiography and fluoroscopy machines were acquired for the Radiology Department and Endoscopy Centre, respectively, as part of the RM53mil allocation for HCTM under the 12th Malaysia Plan (12MP).
 Higher Education Minister Datuk Seri Mohamed Khaled Nordin said the allocation was to replace obsolete equipment used for radiology, operating room, endoscopy, radiotherapy and oncology services.
 HCTM, he said, is a teaching hospital that has been in operation for 26 years.
 Various amenities, facilities and equipment are in need of upgrading, replacement and refurbishment, he said.
 The quality of the medical education ecosystem and the efficiency of the services that teaching hospitals offer cannot be compromised, he said, adding that the 12MP allocation would facilitate the utilisation of cutting-edge medical equipment, and enhance the standard and quality of treatment services at HCTM.
 His speech was read out by the ministry’s deputy secretary-general (Management and Development) Dr Mohd Zabri Yusoff during the unveiling of the equipment at UKM on Oct 30. 
 Prof Mohd Ekhwan said HCTM has consistently served as a benchmark for the use of cutting-edge laboratory equipment, such as the Total Laboratory Automation (TLA) for biochemical testing.
 HCTM has also been recognised as the country’s first teaching hospital to employ the Robotic Surgical Assistant (ROSA), specifically for arthroplasty knee joint replacement surgery, he said.“With the availability of the latest high-performance medical equipment and facilities, UKM is committed to providing health care to patients more effectively,” he said.",healthcare equipment system hospital canselor tuanku muhriz hctm universiti kebangsaan malaysia ukm lead efficient accurate diagnosis treatment artificial intelligence machine mil quality patient care service varsity dec fluoroscopy system feb angiography system ukm vice chancellor prof datuk mohd ekhwan toriman biplace angiography fluoroscopy machine radiology department endoscopy centre mil allocation hctm malaysia plan education minister datuk seri nordin allocation obsolete equipment radiology endoscopy radiotherapy oncology service hospital operation amenity facility equipment upgrading replacement refurbishment quality medical education ecosystem efficiency service hospital compromised allocation facilitate utilisation edge medical equipment enhance standard quality treatment service speech read ministry deputy secretary management development mohd zabri yusoff equipment ukm oct prof mohd ekhwan hctm benchmark edge laboratory equipment total laboratory automation biochemical hctm country hospital employ robotic surgical assistant rosa arthroplasty knee joint replacement surgery availability performance medical equipment facility health care patient,"[(1, 0.6313891), (2, 0.36397046)]",1
622463,Main,28,03/12/2023,AI solutions for Asian consumers,"Govt pursues local, softer approach to artificial intelligence regulation","As countries around the world rush to create regulations on artificial intelligence (AI) in light of a surge in real-life applications, Indonesia aims for its own “local” approach.
 However, experts have raised questions about the aspiration, considering the country’s predo­minant position as an AI consumer rather than a trailblazer in the industry.
 Three years after introducing the National AI Strategy 2020-2045, the government has decided to issue an open letter to businesspeople as an initial step toward regulating AI tech.
 A four-page draft of the letter shared by officials proposes ethical guidelines to shape company-internal policies for AI programming, analysis and consulting.“The letter serves as an ethical guide that is not legally binding but rather governs at a normative level,” Deputy Communications and Information Minister Nezar Patria told the media in a press conference after an AI focus group discussion (FGD).
 The letter is to be finalised and released later this month.
 Keeping things flexible
 Despite its non-binding character, the letter was not an attempt to come up with the feeblest possible measure, Nezar said.
 Rather, he noted, given the rapid technological progress, the government had to remain open to any possible developments, which included being prepared to establish legally-binding regulations as needed.
 Nezar pointed out that Indo­nesia’s strategy diverged from that of the United States, the European Union and China, which were adept in AI technology, and would instead prioritise the local context in line with the country’s ideology. 
 “We can comply with global governance values while looking at our local values such as cooperative inclusivity, humanity, safety, democracy, transparency, credibility and accountability,” he elaborated. Indonesia has teamed up with AI Singapore to develop an open-source large language model (LLM) designed specifically for the Indonesian language and culture.
 AI must understand Indonesia
 In a panel discussion following the partnership signing ceremony in Jakarta, William Tjhi, head of applied research for foundation models at AI Singapore, highlighted the importance of this collaboration in developing AI solutions that resonated with South-East Asia’s diversity and prioritised cultural sensitivity as well as diverse use cases.
 “We aim to align values on security and cultural sensitivity. Understanding what’s sensitive in another country requires local expertise, which is why having Indonesian partners is crucial,” William said.
 Experts have commended the ethical guidance as an initial step toward regulating AI but also noted the need for a deeper understanding on that part of the government about the ecosystem and requirements for cohesive governance involving the public.
 “There’s a good point in the letter, indicating that AI technology shouldn’t replace all existing manpower through automation,” Communication and Information System Security Research Center (CISSReC) chairman Pratama Persadha said.
 On the other hand, as a guideline, it should address targets for system providers and users, especially for developers utilising external models or application programming interfaces (APIs), he said. Additionally, the guideline should highlight the benefits of AI, particularly for public interests.
 “The guidance shouldn’t only be aimed at businesses but also include points for the general public, considering their increasing familiarity with this technology,” emphasised Pratama.
 Rules needed, but which ones?
 Indonesia Cyber Security Forum (ICSF) chairman Ardi Sutedja said that the government still had “a lot to explore” before it could release ethical guidelines on AI, as the country’s tech industry was dominated by consumers rather than developers.
 “Regulations are important,  but the question is, what kind of regulation do we actually need?” Ardi said, noting that the letter was a guideline rather than a directive.
 Dirgantara Adisutjipto Institute of Technology (ITDA) rector and AI expert Arwin Datumaya Wahyudi Sumari echoed a similar sentiment.
 “We’re a nation of consumers, and that’s also the perception the world has of us.
 “It’s time to shift our mindset from being consumers to becoming producers,” Arwin said on Wednesday. — The Jakarta Post/ANN",country create regulation artificial intelligence light surge real life application local approach expert question aspiration country minant position consumer trailblazer industry national strategy government issue letter businesspeople initial step tech draft letter official ethical guideline company internal policy analysis consulting letter ethical guide governs normative level deputy communication minister nezar patria medium press conference focus discussion fgd letter month flexible binding character letter attempt feeblest measure nezar rapid technological progress government remain development prepared binding regulation indo nesia strategy united european union china technology prioritise local context country ideology comply global governance value local value inclusivity humanity safety democracy transparency credibility accountability indonesia source language model llm indonesian language culture understand indonesia panel discussion partnership ceremony jakarta william tjhi head foundation model collaboration solution south east asia diversity cultural sensitivity diverse aim align value security cultural sensitivity sensitive country local expertise indonesian partner crucial william expert ethical guidance initial step understanding government ecosystem requirement cohesive governance public letter technology manpower automation communication system security center cissrec chairman pratama persadha hand guideline address target system user developer utilising external model application interface guideline highlight benefit public guidance business public familiarity technology pratama rule security forum icsf chairman sutedja government lot release ethical guideline country tech industry consumer developer regulation question regulation letter guideline directive dirgantara institute technology itda rector expert arwin datumaya wahyudi sumari sentiment nation consumer time shift consumer producer wednesday jakarta post ann,"[(0, 0.5650748), (4, 0.43222904)]",0
621979,Main,21,02/12/2023,AI spawns new hope in TB fight,,"A PROGRAMME using artificial intelligence to test inmates in a high security Mozambican jail for tuberculosis has spawned hope that the new technology can help eradicate the disease.
 Teeming prisons are a hotbed of TB, the world’s second deadliest communicable disease after Covid-19, according to the World Health Organisation. Mozambique, a country of 32 million people, recorded about 120,000 infections last year.
 Caused by a bacteria that most often affects the lungs, it infected more than 10 million people in 2022 and killed 1.3 million, according to WHO.
 Almost one in four infections last year occurred in Africa.
 In the sprawling courtyard of the maximum security jail in the Mozambican capital Maputo, an inmate in an orange T-shirt stood before a tripod with a wide white tablet.
 Behind him, a doctor scoured a two-piece portable X-ray machine connected to an AI programme that has been hailed as a breakthrough in the fight against tuberculosis.
 “It processes it in real time, we have the results in less than five minutes,” the doctor said.
 The image popped on the computer of a technician sitting at a table outside a medical tent a few metres away, along with a diagnosis.
 “Radiological signs suggestive of tuberculosis – negative,” the message said.
 The programme is part of a large test run of the technology to scan all inmates at three prisons in Maputo. It is being conducted by a local non-profit organisation supported by the Stop TB Partnership, a UN-backed entity.
 Early diagnosis is key to save lives and tackle the spread of the disease.
 While a chronic cough is a hallmark of infection, people can also carry TB without showing symptoms. Prisons are a perfect breeding ground due to crammed cells and airborne transmission.
 Traditional spit, skin or blood tests for TB involves visits to a lab and the results can take up to three days. The quickest time for reliable results is 24 hours.
 The combination of AI and portable X-ray machines is faster and eliminates the need for visits to clinics and radiologists, who can be scarce in poor rural areas, said Stop TB’s deputy head Suvanand Sahu. “This is a great leap in technology,” he said.
 At the Maputo Provincial Penitentiary, prisoners testing positive are placed in isolation, locked in a quarantine room behind a rusty metal door.
 Inside, about a dozen inmates wearing face masks sit on mattresses thrown on the ground. Clothing, blankets and other belongings hang from a line strung between two discoloured blue pillars.
 Serious cases are taken to a medical ward.
 Mozambique’s jails were about 50% over capacity in 2022, according to the United Nations.
 “It’s not easy to see your friends playing and walking there but you have to accept that I am sick,” Kennet Fortune, an inmate who has spent 10 year behind bars for drug-related offences, said pointing at the trees in the prison yard.
 He is currently undergoing treatment and the process can take months.
 “When the time comes, I’ll be out,” he said.
 A WHO report last month found that global deaths from tuberculosis dipped in 2022, showing progress towards eradicating the disease. The UN health agency said 7.5 million people were diagnosed with TB in 2022 – the highest figure since it began monitoring in 1995.
 Sahu of Stop TB said he was hoping that the success of pilot programmes could help get funding to scale up the use of AI in diagnosing tuberculosis.
 “Only a few years ago, if I was to say in a meeting that we can bring X-rays to all communities and have them read by a artificial intelligence with no need for radiologists, they would have kicked me out of the room and told me to go write a sci-fi novel,” he said. — AFP",programme artificial intelligence test security mozambican jail tuberculosis hope technology eradicate disease prison deadliest communicable disease covid health organisation mozambique country people infection bacteria lung infected people infection courtyard maximum security jail mozambican capital maputo inmate orange shirt tripod wide white tablet doctor piece portable ray machine programme fight tuberculosis real time minute image computer technician table medical tent metre radiological sign suggestive tuberculosis negative message programme test technology scan inmate prison local profit organisation partnership entity diagnosis key life spread disease chronic cough hallmark infection people symptom prison ground cell airborne transmission traditional spit blood test visit lab day time reliable hour combination portable ray machine visit clinic radiologist poor rural deputy head suvanand sahu leap technology maputo provincial penitentiary prisoner positive isolation quarantine rusty metal door dozen inmate mask mattress ground blanket belonging hang strung blue pillar medical ward mozambique capacity united nation easy friend accept sick kennet fortune inmate spent bar drug offence tree undergoing treatment process month time report month global death tuberculosis progress disease health agency people figure monitoring sahu success pilot programme scale tuberculosis ray community artificial intelligence radiologist told write sci,"[(3, 0.99549484)]",3
620603,StarBiz,9,28/11/2023,‘AI blowback’ angst grips ESG fund managers,Those who bet big on tech fret over experimentation,"LONDON: Environmental, social and governance (ESG) fund managers who turned to big tech as a low-carbon, high-return bet are growing increasingly anxious over the sector’s experimentation with artificial intelligence (AI).
 Exposure to AI now represents a “short-term risk to investors,” said Marcel Stotzel, a London-based portfolio manager at Fidelity International. 
 Stotzel said he was “worried we’ll get an AI blowback,” which he describes as a situation in which something unexpected triggers a meaningful market decline. “It takes just one incident for something to go wrong and the material impact could be significant,” he said. 
 Examples that Stotzel said warrant concern are fighter jets with self-learning AI systems. Fidelity is now among fund managers talking to the companies developing such technologies to discuss safety features such as a “kill switch” that can be activated if the world one day wakes up to “AI systems going rogue in a dramatic way,” he said. 
 The ESG investing industry may be more exposed to such risks than most, after taking to tech in a big way.
 Funds registered as having an outright environmental, social and good governance objective hold more tech assets than any other sector, according to Bloomberg Intelligence.
 And the world’s biggest ESG exchange-traded fund is dominated by tech, led by Apple Inc, Microsoft Corp, Amazon.com Inc and Nvidia Corp. 
 Those companies are now at the forefront of developing AI. Tensions over the direction the industry should take – and the speed at which it should move – recently erupted into full public view.
 This month, OpenAI, the company that rocked the world a year ago with its launch of ChatGPT, fired and then rapidly rehired its chief executive, Sam Altman, setting off a frenzy of speculation. 
 Internal disagreements had ostensibly flared up over how ambitious OpenAI should be, in light of the potential societal risks. Altman’s reinstatement puts the company on track to pursue his growth plans, including faster commercialisation of AI.
 Apple has said it plans to tread cautiously in the field of AI, with chief executive officer Tim Cook saying in May that there were “a number of issues that need to be sorted” with the technology.
 And companies, including Microsoft, Amazon, Alphabet Inc and Meta Platforms Inc, have agreed to enact voluntary safeguards to minimise abuse of and bias within AI.
 Stotzel said he was less worried about the risks stemming from small-scale AI startups than about those lurking in the world’s tech giants. “The biggest companies could do the most damage,” he said.
 Other investors share those concerns. The New York City Employees’ Retirement System, one of the biggest US public pension plans, said it was “actively monitoring” how portfolio companies use AI, according to a spokeswoman for the US$248bil plan.
 Generation Investment Management, the firm co-founded by former US vice-president Al Gore, told clients that it was stepping up research into generative AI and speaking daily with the companies it’s invested in about the risks – as well as the opportunities – the technology represents.
 And Norway’s US$1.4 trillion sovereign wealth fund has told boards and companies to get serious about the “severe and uncharted” risks posed by AI.
 When OpenAI’s ChatGPT was launched last November, it quickly became the fastest-growing Internet application in history, reaching 13 million daily users by January, according to estimates provided by analysts at UBS Group AG.
 Against that backdrop, tech giants developing or backing similar technology have seen their share prices soar this year.
 But the absence of regulations or any meaningful historical data on how AI assets might perform over time is cause for concern, according to Crystal Geng, an ESG analyst at BNP Paribas Asset Management in Hong Kong.
 “We don’t have tools or methodology to quantify the risk,” she said. One way in which BNP tries to estimate the potential social fallout of AI is to ask portfolio companies how many job cuts may occur because of the emergence of technologies like ChatGPT. “I haven’t seen one company that can give me a useful number,” Geng said. 
 Jonas Kron, chief advocacy officer at Boston-based Trillium Asset Management, which helped push Apple and Meta’s Facebook to include privacy in their board charters, has been pressing tech companies to do a better job of explaining their AI work.
 Earlier this year, Trillium filed a shareholder resolution with Google parent Alphabet asking it to provide more details about its AI algorithms.
 Kron said AI represents a governance risk for investors and noted that even insiders, including OpenAI’s Altman, have urged lawmakers to impose regulations. 
 The worry is that, left unfettered, AI can reinforce discrimination in areas such as health care. And aside from AI’s potential to amplify racial and gender biases, there are concerns about its propensity to enable the misuse of personal data. 
 Meanwhile, the number of AI incidents and controversies has increased by a factor of 26 since 2012, according to a database that tracks misuse of the technology.
 Investors in Microsoft, Apple and Alphabet’s Google have filed resolutions demanding greater transparency over AI algorithms.
 The AFL-CIO Equity Index Fund, which oversees US$12bil in union pensions, has asked companies including Netflix Inc and Walt Disney Co to report on whether they have adopted guidelines to protect workers, customers and the public from AI harms. 
 Points of concern include discrimination or bias against employees, disinformation during political elections and mass layoffs resulting from automation, said Carin Zelenko, director of capital strategies at AFL-CIO in Washington. — Bloomberg",london environmental social governance esg fund manager low carbon return anxious sector experimentation artificial intelligence exposure short term risk investor stotzel london portfolio manager fidelity international stotzel blowback situation unexpected trigger meaningful market decline incident wrong material impact stotzel warrant concern fighter jet system fidelity fund manager company technology safety feature day system dramatic esg industry risk tech fund outright environmental social governance objective hold tech asset sector bloomberg intelligence biggest esg exchange fund tech apple microsoft corp amazon nvidia corp company tension direction industry speed move public view month company launch chatgpt chief executive sam altman frenzy speculation internal disagreement ambitious openai light potential societal risk altman reinstatement company track pursue growth plan faster commercialisation apple plan field chief executive officer tim cook issue technology company microsoft amazon alphabet meta platform enact voluntary safeguard minimise abuse bias stotzel worried risk scale startup tech giant biggest company investor share concern city employee retirement system biggest public pension plan portfolio company spokeswoman bil plan generation investment management firm vice president gore client generative daily company risk opportunity technology norway sovereign wealth fund board company uncharted risk openai chatgpt fastest internet application history daily user january estimate analyst ubs backdrop tech giant technology share price absence regulation meaningful historical data asset time concern crystal geng esg analyst bnp paribas asset management hong kong tool risk bnp potential social fallout portfolio company job cut emergence technology company geng jonas kron chief advocacy officer boston trillium asset management push apple meta facebook privacy board charter tech company job trillium shareholder resolution google parent alphabet detail algorithm kron governance risk investor insider openai altman lawmaker impose regulation unfettered discrimination health care potential amplify racial gender bias concern propensity enable personal data incident controversy factor database track technology investor apple alphabet google resolution transparency algorithm afl cio equity fund bil union pension company netflix walt disney report guideline worker customer public harm concern discrimination bias employee political election layoff automation carin zelenko director capital strategy cio washington bloomberg,"[(1, 0.99738735)]",1
620313,Lifestyle,4,27/11/2023,AIsidekickon yourshirt,Could a tiny device innovate beyond the smartphone?,"Could artificial intelligence (AI) make your smartphones obsolete?
 After a slow build-up of hype in recent months, a startup run by two former Apple employees has launched their vision of a product that promises to let us use our voices and hands to do most of the stuff we currently do while looking at a smartphone screen.
 The small device, roughly the size of a matchbox, has a camera and loudspeaker, but instead of a display, it has a laser projector that gives you information and playback controls on the palm of your hand.
 The idea behind the Ai Pin, a thin square device measuring less than 5cm in width, is that you attach it to your clothing with a magnet and wear it at chest height.Instead of swiping at a screen, you operate it with voice commands and hand gestures. The camera and microphone play a special role here, as they form the AI’s eyes and ears, so to speak.
 Using its eye, the software can recognise objects around it, as co-founder Imran Chaudhri showed at a demo event earlier this month, holding a handful of almonds in front of the lens and asking how much protein they contain.
 “Fifteen grammes” was the prompt answer. He then showed the Ai Pin a book and had it ordered online.
 When the camera and microphone are switched on, a clearly visible light turns on at the top edge of the device.
 This lets people around the wearer know when they are and aren’t being filmed, photographed or watched by the AI.
 In an interview with technology journalist Om Malik, Chaudhri said that the recordings are only stored on the device itself and in the cloud in a space that is only accessible to the respective users.
 “It doesn’t go anywhere else. No one’s going to use that to learn anything about you.”
 The device might seem like a far leap from our current reality, in which things like navigating, watching content and reading messages seem impossible without a screen.
 And yet Humane isn’t alone in seeing the potential of giving AI access to wearable cameras, microphones and sensors to help us carry out tasks.
 For example, the Facebook group Meta is already selling the second generation of Ray-Ban glasses with a camera and microphone in the United States.
 “Smart glasses are the ideal form factor for you to let an AI assistant see what you are seeing and hear what you are hearing,” Meta chief executive Mark Zuckerberg said.
 Meanwhile, startup RewindAI plans to launch a pendant that records and transcribes everything you say and hear.
 The products do somewhat recall those of Dave Eggers’ dystopian Silicon Valley novel The Circle, which explores the implications of constant surveillance from wearable camera devices.
 And yet the Ai Pin makes an initial impression as being far more practical than creepy, however, and Chaudhri demonstrated how it could help with real-time translation between English and Spanish, while one company ad simply lists handy everyday uses.
 Hold your palm in front of the projector, and it will display information like the current time, music playback controls and updates on the weather.
 The device also connects to wireless earphones like any smartphone, so you can stream music (in this case from Tidal).
 One of the proclaimed goals of Chaudhri and his co-founder and wife, Bethany Bongiorno, was to make frequent interaction with screens unnecessary with the help of AI.Rather than taking out a phone and swiping around on a screen, you ask the software for a summary of recent messages and calls. You can also ask for specific information, such as a door entry code that you once received from a friend.Humane is launching the Ai Pin at US$699 (RM3,250), with a further US$24 (RM110) per month subscription for wireless Internet, a phone number and cloud storage in the US.As such, the device is priced well below premium smartphones, even if it requires a monthly subscription to keep using it.
 And while it could replace many of the smartphone’s tasks in everyday life, the absence of a screen means many will still want a second device with a screen for the likes of TikTok, YouTube and streaming shows.Former OpenAI boss Sam Altman is also an investor in Humane, which has been collaborating with its ChatGPT AI to deliver bespoke answers. – dpa",artificial intelligence smartphones obsolete slow build hype month apple employee vision product voice hand smartphone screen device size matchbox camera loudspeaker display laser projector playback palm hand idea pin thin square device width attach clothing magnet chest height screen operate voice command hand gesture microphone play special role form eye speak eye software recognise founder imran chaudhri demo event month handful almond front lens fifteen gramme prompt answer pin book online camera microphone visible light top edge device people photographed interview technology journalist malik chaudhri recording device cloud space accessible respective user device current reality content reading message impossible screen humane potential access wearable camera microphone sensor task meta selling generation ray ban glass microphone united smart glass ideal form factor assistant hear meta chief executive mark zuckerberg startup rewindai plan launch pendant record hear product egger dystopian silicon valley circle implication constant surveillance wearable camera device pin initial impression practical creepy chaudhri real time translation english spanish company handy everyday palm front projector display current time music playback weather device connects wireless earphone smartphone stream music tidal goal chaudhri founder wife bethany bongiorno frequent interaction screen unnecessary phone screen software summary message specific door entry code friend humane pin month subscription wireless internet phone cloud storage device premium smartphones monthly subscription smartphone task everyday life absence screen device screen tiktok youtube openai bos sam altman investor humane chatgpt bespoke answer,"[(1, 0.9962942)]",1
619751,Main,25,26/11/2023,India’s growing AI challenge,"Artificial Intelligence is gripping  the country’s elections, especially AI-generated Bollywood songs featuring its prime minister, Narendra Modi.","ARTIFICIAL Intelligence-generated Bollywood songs, some featuring India’s prime minister Narendra Modi, are popular in the Assembly elections due to digital technology. A video shows Modi playing the guitar while sitting cross-legged. His voice has been rendered in recent Hindi, Tamil, Telugu, and Kannada videos. There are over two million views for Modi’s Instagram video singing Telugu and over 2.7 million for a Tamil-language song going viral.
 A Punjabi song with Modi’s voice gained over 17 million views. Falu, an Indian-American singer, has received a Grammy nomination for her song “Abundance in Millets”, featuring the Prime Minister. Congress and the BJP have used AI-powered voice cloning tools. They send personalised messages to voters and party workers.
 Ashok Gehlot, the Chief Minister of Rajasthan, is notable for this. Some television channels have introduced AI TV anchors in Odiya, Kannada and Hindi. Artificial Intelligence has transformed healthcare in India significantly. Advanced diagnosis, treatment, and patient care tools have improved doctors’ services. In other areas, AI is found useful. A recent World Economic Forum report says that India’s expenditure on AI is expected to reach US$11.78bil (RM55.16bil) by 2025.
 It will contribute to an addition of US$1 trillion to India’s economy by 2035. The prime minister is keen on fostering further AI development in India. 
 All these bring us to the question of whether AI is gradually gripping the world. At the first AI Safety Summit hosted by the UK at the historic Bletchley Park on Nov 1, political and industry leaders discussed the risks around artificial intelligence and how to develop the technology safely. British Prime Minister Rishi Sunak had convened a meeting with over a hundred world and industry leaders. About 28 countries participated, including the United Nations and the European Union.
 US Vice President Kamala Harris represented the US. India, represented by Minister of State Rajeev Chandrashekhar, said, “We want AI and tech to represent goodness, safety and trust”: The revolution in artificial intelligence was the focus. Rapid progress in AI is arousing fear as well as excitement. The participants ranged from doomsayers to participants who hoped AI would save humanity.
 They addressed the global nature of the issue and stressed the need for international cooperation and healthy competition. Sunak has said he’s worried about humanity losing control of computers. The role of AI in cyberattacks was also discussed. These could make the global financial system go haywire and threaten democracy. AI can impersonate at a scale and speed never known. “We want AI and tech to represent goodness, safety and trust,” said Minister of State Chandrasekhar.
 The conference was undoubtedly a good start. India is planning to host another meeting in December. As the host nation, the UK was the first to announce the formation of an official AI Safety Institute to examine the safety of emerging forms of AI. At the end of the conference, participating countries agreed on a declaration. It read: “The Bletchley Declaration stresses safe, responsible AI development, urges international cooperation to mitigate risks, and promotes global benefits.”
 Rapid progress in AI is arousing fear as well as excitement. Will the machine become so powerful that it can replace humans? Google CEO Sunder Pichai said, “Knowledge workers, writers, accountants, architects and, ironically, software engineers would face a threat to their jobs. 
 He noted, “You come in the morning. When you have a lot to review, AI can help you prioritise what needs your attention.”
 The risk of terrorist groups using generative AI tools and concerns that AI will become uncontrollable by humans are additional concerns. 
 AI concerns will include real-time cybersecurity, supply chain efficiency, software development acceleration, and customer service automation in the coming year. 
 It cannot engage in negative thoughts or understand cause and effect. It also cannot comprehend time. Supporters note that AI can be used for voter registration and verification. Politicians would benefit from using AI for predictive analysis of voter behaviours.
 AI can analyse social media to gauge sentiment and identify critical issues for political campaigns to tailor their messages. Moreover, AI is crucial in maintaining election security by detecting and preventing fraud, hacking attempts, and other irregularities. It can use historical data and current events to predict election outcomes. AI-powered chatbots can provide voters with polling locations, candidate profiles, and additional crucial election-related information. The first summit was a success in bringing these people together.
 And it goes beyond politicians. There has yet to be an international regulatory body. Nothing is binding here. Ultimately, we have to find the answer to questions like should we automate all jobs, including the fulfilling ones? Should we develop non-human minds that might eventually outnumber, outsmart and replace us?
  That is the crux of the AI issue. Still, moving to AI will take time to happen. — The Statesman/ANN",artificial intelligence bollywood song india prime minister narendra popular assembly election digital technology video modi guitar cross voice hindi tamil telugu kannada video view instagram video telugu tamil language song viral punjabi song modi voice view falu indian american singer grammy nomination song abundance millet prime minister congress powered voice cloning tool personalised message voter party worker gehlot chief minister rajasthan notable television channel anchor hindi artificial intelligence healthcare india diagnosis treatment patient care improved doctor service economic forum report expenditure reach bil contribute addition india economy prime minister keen development india question safety summit historic bletchley park nov political industry leader risk artificial intelligence technology british prime minister rishi sunak meeting industry leader country united nation union vice president kamala harris minister rajeev chandrashekhar tech represent goodness safety trust revolution artificial intelligence focus rapid progress fear excitement participant doomsayers participant save humanity global nature issue international cooperation healthy competition sunak humanity control computer role cyberattacks global financial system haywire democracy impersonate scale speed tech represent goodness safety trust minister chandrasekhar conference start india planning host meeting december host nation formation official safety institute examine safety form conference country declaration read bletchley declaration safe responsible development international cooperation mitigate risk global benefit rapid progress fear excitement machine powerful human ceo sunder pichai knowledge worker writer accountant architect software engineer threat job morning lot review prioritise attention risk generative tool concern uncontrollable human additional concern concern real time cybersecurity supply chain efficiency software development acceleration customer service automation negative understand comprehend time supporter voter registration verification politician predictive analysis voter behaviour analyse social medium gauge sentiment critical issue political campaign tailor message crucial maintaining election security fraud attempt irregularity historical data current event election outcome chatbots voter location profile additional crucial election summit success people politician international regulatory body answer question job human mind outsmart crux issue time happen statesman ann,"[(4, 0.9972986)]",4
619281,StarBiz,4,24/11/2023,"AI poster child Altman is back, may have fewer checks on power",,"SAM Altman’s return as OpenAI’s chief executive will strengthen his grip on the startup and may leave the ChatGPT creator with fewer checks on his power as the company introduces technology that could upend industries, corporate governance experts and analysts said.
 OpenAI is bringing Altman back just days after his ouster as well as installing a revamped board that could bring sharper scrutiny to the startup at the heart of the artificial intelligence (AI) boom, but strong support from investors including Microsoft may give Altman more leeway to commercialise the technology.“Sam’s return may put an end to the turmoil on the surface, but there may continue to be deep governance issues,” said Mak Yuen Teen, director of the centre for investor protection at the National University of Singapore Business School.
 “Altman seems awfully powerful and it is unclear that any board would be able to oversee him. The danger is the board becomes a rubber stamp,” he said.
 OpenAI’s new board will boast more experience at the top level and strong ties to both the US government and Wall Street.
 The board fired Altman last week with little explanation and attempted to move on by naming an interim chief executive officer (CEO) twice. 
 However, pressure from Microsoft – and the 38-year-old’s strong loyalty among the 700-plus OpenAI employees that caused nearly all of them to threaten to leave the company –led to Altman’s reinstatement as of Wednesday.
 “Altman has been invigorated by the last few days,” GlobalData analyst Beatriz Valle said. But that could come at a cost, she said, adding that he has “too much power now.”
 Bret Taylor, former co-CEO of Salesforce who also played a key role in forcing through Elon Musk’s US$44bil purchase of Twitter as a director, will be chairing the board.
 Other members include former US Treasury Secretary Larry Summers, a Harvard academic and longtime economic aide to Democratic presidents.
 “The fact that Summers and Taylor will join OpenAI is quite extraordinary and marks a dramatic reversal of fortunes in the company,” Valle said.
 Summers, who also sits on the board of Jack Dorsey’s fintech firm Block, has in recent months been vocal about the potential job losses and disruption that could be caused by AI.
 “ChatGPT is coming for the cognitive class. It’s going to replace what doctors do,” he said in a post on X in April.
 OpenAI’s previous board consisted of entrepreneur Tasha McCauley, Helen Toner, director of strategy at Georgetown’s Centre for Security and Emerging Technology, OpenAI chief scientist Ilya Sutskever, as well as Quora CEO Adam D’Angelo, who also sits on the new board.
 It was not immediately clear if any of the other directors would remain, including Sutskever, who joined in the effort to fire Altman then signed onto an employee letter demanding his return, expressing regret for his “participation in the board’s actions”.
 OpenAI on X said it was “collaborating to figure out the details” of the new board. Microsoft declined to comment. 
 Summers and OpenAI did not immediately respond to requests for comment. Sutskever, Altman and Taylor could not be immediately reached for comment.
 Some analysts say the management fiasco will ensure that OpenAI executives proceed cautiously, as the high-flying startup will now be subject to more scrutiny. 
 Several noted that companies such as Facebook parent Meta have flourished with a powerful CEO despite concerns about corporate governance.
 “Sam definitely comes out stronger but also dirtied and will have more of a microscope from the AI and broader tech and business community,” Gartner analyst Jason Wong said. 
 “He can no longer do no wrong.” — Reuters
 Aditya Soni writes for Reuters. The views expressed here are the writer’s own.",sam altman return openai chief executive strengthen grip startup creator fewer check power company technology upend industry corporate governance expert analyst altman day board sharper scrutiny startup heart artificial intelligence boom strong support investor microsoft altman leeway commercialise technology sam return turmoil surface deep governance issue teen director investor protection national university singapore business school altman powerful unclear board oversee danger board rubber openai board experience top level strong tie government wall street board altman week explanation move interim chief executive officer ceo pressure strong loyalty openai employee threaten company altman reinstatement wednesday invigorated day analyst beatriz cost power bret taylor ceo salesforce key role elon musk bil purchase twitter director board treasury secretary larry summer academic longtime economic aide democratic president summer join extraordinary mark dramatic reversal fortune company summer sits board jack dorsey fintech firm block month vocal potential job loss disruption chatgpt cognitive class doctor april previous board entrepreneur tasha mccauley helen toner director strategy georgetown centre security technology openai chief scientist ilya sutskever ceo adam angelo board director sutskever effort fire altman employee letter return regret participation board action figure detail board microsoft comment summer respond request altman taylor comment analyst management fiasco openai executive startup subject scrutiny company parent meta powerful ceo concern corporate governance sam stronger microscope broader tech business community gartner analyst jason wrong reuters soni reuters view writer,"[(1, 0.9961553)]",1
618583,StarBiz,12,22/11/2023,OpenAI in ‘intense discussions’ to quell potential staff mutiny,,"NEW YORK: OpenAI says it’s in “intense discussions” to unify the company after another tumultuous day that saw most employees threaten to quit if Sam Altman doesn’t return as chief executive officer (CEO).
 Vice-president of Global Affairs Anna Makanju delivered the message in an internal memo reviewed by Bloomberg News, aiming to rally staff who’ve grown anxious after days of disarray following Altman’s ouster and the board’s surprise appointment of former Twitch chief Emmett Shear as his interim replacement.
 OpenAI management is in touch with Altman, Shear and the board “but they are not prepared to give us a final response this evening”, Makanju wrote.
 The drama surrounding the company behind ChatGPT has transfixed the technology world and set off a race by OpenAI investors to contain the damage. 
 On Monday, more than 700 of the startup’s 770 staff signed a letter saying they would quit if the board doesn’t resign and re-hire Altman, who was recruited by Microsoft Corp – OpenAI’s largest shareholder – to run a new artificial intelligence (AI) team.
 The chaos engulfing the US startup, which kicked off a global generative AI development frenzy, has the potential to reshape the world of AI. 
 The threat of a mass exodus followed a roller-coaster weekend that saw OpenAI’s board defied calls from investors and executives to reinstall Altman, who was fired following disagreements with the board on how fast to develop and monetise AI.
 The memo from Makanju doesn’t elaborate on the extent of contact with Altman, and the former CEO didn’t respond to a request for comment outside regular business hours.
 There’s strong momentum outside OpenAI to get Altman reinstated too. 
 OpenAI’s other investors, led by Thrive Capital, are actively trying to orchestrate his return, people with knowledge of the effort told Bloomberg News on Monday. 
 Microsoft CEO Satya Nadella told Emily Chang in a Bloomberg Television interview that even he wouldn’t oppose Altman’s reinstatement. 
 Microsoft, which has pledged to invest as much as US$13bil in OpenAI, benefits whether Altman is running OpenAI or working under its roof, Nadella said.
 Until last Friday, the company’s board consisted of Altman, president Greg Brockman, chief scientist Ilya Sutskever, Quora Inc CEO Adam D’Angelo, tech entrepreneur Tasha McCauley and Helen Toner, director of strategy at Georgetown’s Centre for Security and Emerging Technology. 
 After Altman’s exit, Brockman stepped down in protest.
 Sutskever later said he “deeply regretted” his participation in the ouster, and added his name to the letter from employees threatening to quit.
 “We are continuing to go over mutually acceptable options and are scheduled to speak again tomorrow when everyone’s had a little more sleep,” Makanju wrote. “These intense discussions can drag out, and I know it can feel impossible to be patient.”
 She added a word of reassurance for employees: “Know that we have a plan that we are working towards.”
 OpenAI, which was in talks with investors about an US$86bil valuation, now faces an end to its stunning growth. 
 And it will face close scrutiny over its ability, or willingness, to turn cutting-edge AI into profits.
 It’s not clear whether investors, OpenAI executives or even Microsoft will be able to turn back the clock. The directors who ousted Altman to begin with would have to walk back their decision.
 Vinod Khosla, co-founder at Khosla Ventures, one of OpenAI’s earliest backers, said he believes D’Angelo is dug in. 
 “If Adam does what Ilya did then, yes, it’s a smooth path,” he said in an interview. “If he doesn’t, it’s a multi-month legal battle.” 
 D’Angelo didn’t respond to an emailed request for comment.
 At the heart of the divide between Altman and OpenAI’s directors is whether AI should be a commercial opportunity, or is a potentially dangerous technology that needs to be checked and scrutinised at every turn.
 The board clashed with Altman and Brockman, who both argued that OpenAI was growing its business out of necessity. 
 Every time a customer asks OpenAI’s ChatGPT chatbot a question, it requires huge amounts of expensive computing power, so much that the company was having trouble keeping up with the explosive demand from users.
 The company was forced to cap the number of times users can query its most powerful AI models daily. In fact, the situation got so dire that Altman at one point announced the company was pausing sign-ups for its paid ChatGPT Plus service indefinitely. — Bloomberg",york penai intense discussion company tumultuous day employee quit sam altman return chief executive officer ceo vice president global affair message internal memo bloomberg news rally staff anxious day altman ouster board surprise appointment twitch chief emmett shear interim replacement openai management touch altman board final response makanju drama company chatgpt technology race openai investor monday startup staff letter quit board resign hire altman microsoft corp largest shareholder artificial intelligence team chaos startup global generative development frenzy potential reshape threat mass exodus roller coaster weekend board investor executive disagreement board monetise memo makanju elaborate extent contact altman ceo respond request comment regular business hour strong momentum openai altman openai investor thrive capital orchestrate return people effort bloomberg news monday microsoft ceo satya nadella bloomberg television interview altman reinstatement microsoft invest bil openai benefit altman openai roof nadella friday company board altman president greg brockman chief scientist ilya sutskever ceo adam angelo tech entrepreneur tasha mccauley helen toner director strategy georgetown centre security technology altman exit brockman protest sutskever regretted participation letter employee quit acceptable option speak tomorrow sleep makanju intense discussion impossible patient word reassurance employee openai talk investor valuation growth scrutiny ability willingness edge profit investor executive microsoft clock director altman walk decision vinod khosla founder khosla venture earliest backer angelo dug adam ilya smooth path interview multi month legal battle angelo respond request comment heart altman openai director commercial opportunity dangerous technology board altman brockman openai business necessity time customer openai chatgpt chatbot question huge amount expensive power company trouble explosive demand user company cap time user powerful model daily situation dire altman company sign chatgpt service bloomberg,"[(1, 0.9968826)]",1
618707,Main,27,22/11/2023,OpenAI faces mass exodus,"Staff threaten to quit, join ex-CEO Altman","San Francisco: Hundreds of staff at OpenAI threatened to quit the leading artificial intelligence company and join Microsoft, deepening a crisis triggered by the shock sacking of CEO Sam Altman.
 In a fast-moving sequence of events, Altman, who was ousted by the board on Friday, has now been hired by Microsoft where he will take the lead in developing a new advanced AI research team.
 There was talk Monday that OpenAI is interested in Altman returning, and that he may be open to the idea under certain conditions.
 “We want to partner with Open AI and we want to partner with Sam so irrespective of where Sam is he’s working with Microsoft,” chief executive Satya Nadella said in a streamed Bloomberg interview.
 “That was the case on Friday. That’s the case today. And we absolutely believe that will be the case tomorrow.”
 In a letter released to media on Monday, the vast majority of OpenAI’s 770-strong staff suggested they would follow Altman unless the board responsible for his departure resigned.
 “Your actions have made it obvious that you are incapable of overseeing OpenAI,” the letter said.
 “Microsoft has assured us that there are positions for all OpenAI employees at this new subsidiary should we choose to join.”
 A key AI executive at Microsoft confirmed that they all were welcome to join from OpenAI if the board that removed Altman does not resign.
 Among the signatories was co-founder Ilya Sutskever, the company’s chief scientist and a member of the four-person board who pushed Altman out.
 “I deeply regret my participation in the board’s actions,” Sutskever said in a post on X, formerly known as Twitter.
 “I never meant to harm OpenAI.”
 Another signatory was top executive Mira Murati, who was appointed to replace Altman as CEO when he was removed, but didn’t last the weekend in the job.
 “We are all going to work together some way or other, and I’m so excited,” Altman said on X.
 OpenAI has appointed Emmett Shear, a former chief executive of Amazon’s streaming platform Twitch, as its new CEO despite pressure from Microsoft and other major investors to reinstate Altman.
 After the startup’s board sacked Altman, US media cited concerns that he was underestimating the dangers of its tech and leading the company away from its stated mission – claims his successor has denied.
 Nadella wrote on X that Altman will lead a new advanced AI research team at Microsoft, joined by OpenAI co-founder Greg Brockman.
 Global tech titan Microsoft has invested more than US$10bil in OpenAI and has rolled out the artificial intelligence pioneer’s tech in its own products.
 Nadella said Microsoft remains committed to its partnership with OpenAI. — AFP",san francisco hundred staff openai quit artificial intelligence company join microsoft crisis shock ceo sam fast sequence event board friday microsoft lead advanced team talk monday altman idea condition partner partner sam irrespective sam microsoft chief executive satya nadella bloomberg interview friday tomorrow letter medium monday vast majority strong staff follow altman board responsible departure action obvious incapable openai letter microsoft position openai employee subsidiary join key executive microsoft join board altman resign signatory founder ilya sutskever company chief scientist person board regret participation board action post twitter harm openai signatory top executive mira murati altman ceo weekend job altman emmett shear chief executive amazon platform twitch ceo pressure major investor altman board altman medium concern danger company mission claim nadella altman lead team microsoft openai founder greg brockman global tech titan microsoft bil openai artificial intelligence pioneer tech product nadella microsoft remains partnership openai afp,"[(1, 0.99393576)]",1
618107,Lifestyle,5,20/11/2023,The allure of AI,Job seekers are drawn to ads that mention artificial intelligence.,"RECENT advances in artificial intelligence (AI) promise to change or render obsolete millions of jobs.
 While this prospect raises fears among employees, it is also prompting some to anticipate this evolution in the job market by applying for vacancies that mention AI.
 This surprising trend is highlighted in a new LinkedIn report. Its authors found that recruitment ads alluding to this booming technology particularly attract the attention of job seekers.
 Over the past two years, they have seen 17% greater growth in the number of applications than those not mentioning AI. This progression proves that AI is a hot topic in the workforce.
 And this appears to be a global phenomenon, since the job offers analysed by LinkedIn for the purposes of this study were written in a multitude of languages, including French, English, Mandarin and Turkish.
 Erin Scruggs, vice president of global talent acquisition at LinkedIn, sees this as evidence of the adaptability of many professionals.
 “Candidates are savvy. They’re showing they want to go where opportunities are,” she says.
 The specialist recommends that companies outline their AI strategy in detail in the job advertisements they post in order to help working people envision what promises to be a revolution in the professional world.
 AI may be a hot topic, but experts the world over are still unable to say precisely what its effects on the job market will be.The American bank Goldman Sachs estimated in March that AI systems could automate 300 million jobs in the near future. This would represent a quarter of global activity.
 Employment website Indeed goes even further in one of its latest studies, claiming that all jobs posted on its platform will be impacted by this technology.
 While opinions differ, there is no doubt that today’s and tomorrow’s workers will have to learn to collaborate effectively with AI.
 They need to consolidate their knowledge and skills to meet the new needs for complementarity between humans and machines.
 But working people don’t necessarily need to become experts in “prompt crafting” or robotic systems to secure a professional future in an increasingly automated society.
 The US multinational tech corporation IBM states in its “Augmented Work For An Automated, AI-Driven World” report that human talents will enable people to stand out in the job market.But focusing on “soft skills” will not be enough. Continuous learning will be needed to ensure that knowledge is always up-to-date, given the remarkable speed at which AI is evolving.
 While this technology will not totally replace humans, it will reinforce the disparities in the working population.
 Those who know how to master it will likely fare better than those who resist. – AFP Relaxnews",advance artificial intelligence promise change render obsolete million job fear employee anticipate evolution job market vacancy mention surprising trend linkedin report author ad technology attract attention job seeker growth application progression hot topic workforce global phenomenon job offer linkedin purpose multitude language french english mandarin turkish erin scruggs vice president global talent acquisition evidence adaptability professional candidate savvy opportunity company strategy detail job advertisement people promise professional hot topic expert unable effect job market american bank goldman sachs march system job future represent quarter global activity employment website study job platform technology opinion tomorrow worker consolidate knowledge skill complementarity human machine people expert robotic system secure professional future society multinational tech corporation ibm automated report human talent enable people job market soft skill continuous learning knowledge remarkable speed technology human reinforce disparity master fare resist relaxnews,"[(0, 0.7773219), (2, 0.21764457)]",0
617683,Main,35,19/11/2023,Biden: AI must uplift people’s full potential,,"SAN FRANCISCO: US President Joe Biden urged Asia-Pacific economies to work together to ensure that artificial intelligence (AI) brings change for the better, not to abuse workers or limit potential.Addressing the final session of a two-day summit of the 21-member Asia Pacific Economic Cooperation (Apec) forum in San Francisco, Biden said he had briefly discussed AI with Chinese President Xi Jinping in talks on the sidelines.
 Biden has used the two-day Apec summit to highlight the strong US economy and its ties to other Pacific nations, even as his vision for greater regional cooperation to counter China’s influence stumbled on the trade front over his bid to strengthen workers’ rights.
 “We’re going to see more technological change in the next 10 years than we’ve seen the last 50 years,” Biden said, as Xi looked on a few places to his left at a circular conference table. 
 Biden said digital technologies like AI must be used to “uplift, not limit, the potential of our people,” and noted that the United States had brought together leading AI companies in the summer to agree voluntary commitments “to keep AI systems safe and trustworthy.” — Reuters",san francisco president joe biden asia pacific economy artificial intelligence brings worker potential final session day summit pacific economic cooperation apec forum san francisco biden chinese president jinping talk sideline biden day apec summit strong economy tie nation regional cooperation counter china influence trade front bid worker right technological change biden left circular conference table biden digital technology uplift limit potential people united company summer voluntary commitment system safe trustworthy reuters,"[(3, 0.98726875)]",3
617203,StarBiz 7,12,18/11/2023,Using AI to combat scams,,"TACKLING fraud is ever challenging with the rapidly changing nature of scams, aided by developments in technology such as artificial intelligence (AI), voice cloning and deep fakes.
 Although it may be difficult to detect, combating scams is a top priority for consumers, financial institutions and policy makers.
 This means higher operational costs for organisations regardless of their size. 
 Scams can lead to reduced revenue, profitability and market share.
 They can also result in reputational damage and an increase in customer attrition rates, according to a survey by Feedzai and Chartis.
 Nearly 90% of organisations across the Asia-Pacific region are turning to AI to help combat fraud.
 Although 46% of respondents feel that they have comprehensive scam controls in place, the majority don’t feel that their firms can adapt to changing typologies fast enough without an adverse effect on their business activities. 
 Only 6% are fully confident in their ability to adapt.
 A total of 33% of organisations report on scams, only a quarter do so regularly and comprehensively while 30% don’t report on scams at all.
 Nearly half of the largest organisations, predominantly banks, report on fraud cases.
 One third of the banks surveyed will prioritise scam prevention in the next six months.
 Almost 90% of respondents believe that scam reimbursement regulations will be introduced in the next 12 months.
 The respondents are financial crime professionals from 48 banks and 27 payment service providers in Australia, Malaysia, the Philippines, Thailand and Singapore.",fraud nature scam development technology artificial intelligence voice deep fake difficult detect scam top priority consumer financial institution policy maker operational cost organisation size scam revenue profitability market share reputational damage increase customer attrition rate survey chartis organisation pacific region combat fraud respondent comprehensive scam control majority firm typology adverse business activity confident ability total organisation report quarter report scam largest organisation bank report fraud bank scam prevention month respondent reimbursement regulation month respondent financial crime professional bank payment service provider malaysia philippine singapore,"[(2, 0.73758125), (4, 0.25511417)]",2
616273,StarMetro,8,16/11/2023,Nation’s first generative AI lab on the horizon,Partnership to transform education and banking landscape,"A ground-breaking partnership aims to transform the education and banking sectors.
 HELP University’s Faculty of Computing and Digital Technology, and Alliance Bank Malaysia Bhd (ABMB) signed a memorandum of understanding (MOU) on the collaboration which will introduce the first research laboratory on generative artificial intelligence (AI) in Malaysia.
 The generative AI research laboratory is expected to benefit both education and banking industries.
 “The lab can enhance the research capability and experience of educators and students. 
 “This prepares them for the dynamic challenges in the industry.
 “On the other hand, the finance industry can obtain a competitive edge via the  powerful AI predictions on the performance and prospects of their products.
 “It can also enable faster and more informed decisions while reducing survey costs besides fostering innovation in product design,” said HELP University in a statement.
 During the signing ceremony at the university’s ELM Business School, HELP University vice-chancellor Liew Teik Kooi said the collaboration came at just the right time.
 “The world is witnessing an incredible speed of technological advancement.
 “The collaboration marks the fusion between academia and banking,  unleashing students’ potential while  driving the fintech and banking industries forward.
 “More excitingly, this collaboration  carries the prospect of transforming the theoretical knowledge on AI, data science, and fintech into practical experience,” he said.
 Liew hoped that the research lab in the near future could become an innovation hub to attract many top-notch learners and industry experts to come up with more ground-breaking projects.
 “In the long run, I hope that the research lab can expand onto the international stage to suit the ever-evolving landscape in AI, data science, and fintech,” he added. 
 Meanwhile, ABMB group chief human resource officer Khim Tan said the partnership was in line with ABMB’s agenda of improving life.
 “The collaboration provides ABMB with a platform to expand our digital knowledge through research.
 “It also helps in integrating generative AI and machine learning into the industry, which could be a game-changer.
 “I hope that our efforts can benefit Malaysian society in the long term.” 
 Data Science master’s degree students in HELP University can also get involved in the development of the research laboratory, for a chance to intern at ABMB.
 The university’s statement said this was a win-win situation as ABMB would be able to tap into the knowledge of the students while they gained exposure at a financial institution.",ground partnership aim transform education banking sector university faculty digital technology alliance bank malaysia bhd abmb memorandum mou collaboration introduce laboratory generative artificial intelligence malaysia generative laboratory benefit education banking industry enhance capability experience educator student dynamic challenge industry hand finance industry competitive edge powerful prediction performance prospect product enable faster decision survey cost innovation product design university statement signing ceremony university elm business school university vice chancellor liew teik collaboration time incredible speed technological advancement collaboration mark fusion unleashing student potential fintech banking industry collaboration theoretical knowledge data science fintech practical experience liew lab future innovation hub top notch learner industry expert ground project lab international stage suit landscape data science fintech abmb chief human resource officer khim partnership abmb agenda life collaboration platform digital knowledge generative machine industry game changer effort malaysian society term data science master degree student university development laboratory chance intern abmb university statement win situation tap knowledge student exposure financial institution,"[(0, 0.36544812), (4, 0.63038903)]",4
616020,StarBiz,2,15/11/2023,JF Technology in tie-up for high-end artificial intelligence materials,,"KUALA LUMPUR: JF Technology Bhd’s wholly-owned subsidiary, JF International Sdn Bhd (JFI) has entered into a joint-venture agreement with HFC Industry HK Ltd (HFCI), a subsidiary of Shenzhen HFC Co Ltd (Shenzhen HFC) to incorporate HFC Tech Sdn Bhd (HFC Tech).
 In a statement, JF Technology said the joint-venture company’s principal activities include design and manufacture of electromagnetic interference (EMI) shielding materials and , thermal interface materials.
 JF Technology managing director Datuk Foong Wei Kuong said this creates strong synergies as it will be able to leverage on each other’s expertise, capabilities and network to further scale our business.
 “Our new facility in Kota Damansara has ample space to facilitate the establishment of a state-of-the-art manufacturing and design hub for our joint venture. 
 “Together, we will be producing various cutting-edge products such as EMI shielding materials and thermal interface materials, which are currently used in various applications, including semiconductor chips for artificial intelligence (AI) and electric vehicles.“Shenzhen HFC is a pioneer in the use of graphene materials for heat dissipation in Al chips. Thus, whoever controls the material science of graphene for this application, potentially controls the industry,” he said.",kuala lumpur technology subsidiary international sdn bhd jfi joint venture agreement hfc industry hfci subsidiary shenzhen hfc shenzhen hfc incorporate hfc tech sdn bhd hfc tech statement technology joint venture company principal activity design manufacture electromagnetic interference emi material thermal interface material technology director datuk foong wei kuong strong synergy expertise capability network scale business facility kota damansara ample space facilitate establishment art manufacturing design joint venture edge product material thermal interface material application semiconductor chip artificial intelligence electric vehicle hfc graphene material dissipation chip material science graphene application control industry,"[(0, 0.98950315)]",0
614876,Main,17,10/11/2023,‘Gain experience using AI’,"We must understand the pitfalls to regulate it, says PM Lee","WHILE there are still many unknowns about artificial intelligence, Singapore has to gain experience operating with it and understanding the pitfalls so that it can make smart decisions to regulate it, said Prime Minister Lee Hsien Loong.
 He acknowledged that currently, his government, like most governments, do not know more about it than those in the tech industry.
 PM Lee was speaking at a dialogue with Bloomberg News editor-in-chief John Micklethwait at the Bloomberg New Economy Forum gala dinner on Wednesday.
 Asked whether AI was a bigger development than the Internet, PM Lee said: “The first thing you must know is that there are a lot of things you don’t know.”
 For AI, most do not know where it is headed, even researchers, he noted.
 From when the idea of AI first came about, it took a long time, about 50 to 70 years, for it to reach its present stage, with the existence of technology such as ChatGPT.
 And the thought in the minds of researchers was constantly that they were about to make a breakthrough – which did eventually come about. But would it progress all the way to the point of having a conversation, said Lee.
 He added: “Either the chatbot can interview me, or I may interview the chatbot... Or two chatbots may be talking to each other better than us.”
 Perhaps putting in 10 times more chips or 10 times more effort in computing, AI could reach that level, or it could also reach a limit, he said.
 “Then you need another breakthrough conceptually, to take it to the next level where it’s got insight, understanding, judgment, reasoning and empathy,” said PM Lee.
 In principle, there is no reason why a machine that can think, act, speak and look like it feels like a human being cannot be built, he added.
 “Some philosophers think it’s not possible. I don’t believe that. I think it is possible but I don’t know how long it will take,” he said.
 But when that happens, there will be some profound questions thrown up that are difficult to answer, he added.
 If the AI bot is as smart as a human, it will not be possible to pre-program it to be stupid enough to be killed – and that is a fundamental contradiction, said Lee.
 Earlier this month, Lee had virtually attended the inaugural global Artificial Intelligence Safety Summit, at the invitation of British PM Rishi Sunak.
 He had spoken about Singapore’s practical, risk-based approach to AI development and deployment, as well as the importance of including diverse multi-stakeholders in the conversation and collaboration on AI safety. — The Straits Times/ANN",unknown artificial intelligence gain experience understanding pitfall smart decision prime minister lee hsien acknowledged government government industry dialogue bloomberg news editor chief john micklethwait bloomberg economy forum gala dinner wednesday bigger development internet lee lot researcher idea time reach stage existence technology chatgpt researcher progress conversation lee interview interview chatbots time chip time effort level reach limit level insight judgment empathy lee principle reason machine speak feel human philosopher profound question difficult answer smart human pre program stupid fundamental contradiction lee month attended inaugural global artificial intelligence safety summit invitation british rishi sunak practical risk approach development deployment diverse multi stakeholder collaboration safety strait time,"[(1, 0.07974482), (3, 0.91402924)]",3
614068,StarBiz,12,08/11/2023,Meta bars political ads using generative AI tools,,"NEW YORK: Facebook owner Meta is barring political campaigns and advertisers in other regulated industries from using its new generative artificial intelligence (AI) advertising products, a company spokesperson says, denying access to tools that lawmakers have warned could turbo-charge the spread of election misinformation.
 Meta publicly disclosed the decision in updates posted to its help centre on Monday night, following publication of this story. Its advertising standards prohibit ads with content that have been debunked by the company’s fact-checking partners but do not have any rules specifically on AI.
 “As we continue to test new Generative AI ads creation tools in Ads Manager, advertisers running campaigns that qualify as ads for housing, employment or credit or social issues, elections, or politics, or related to health, pharmaceuticals or financial services aren’t currently permitted to use these Generative AI features,” the company said in a note appended to several pages explaining how the tools work.“We believe this approach will allow us to better understand potential risks and build the right safeguards for the use of Generative AI in ads that relate to potentially sensitive topics in regulated industries,” it said.
 The policy update comes a month after Meta – the world’s second-biggest platform for digital ads – announced it was starting to expand advertisers’ access to AI-powered advertising tools that can instantly create backgrounds, image adjustments and variations of ad copy in response to simple text prompts.
 The tools were initially made available only to a small group of advertisers starting in the spring. 
 They are on track to roll out to all advertisers globally by next year, the company said at the time.
 Meta and other tech companies have raced to launch generative AI ad products and virtual assistants in recent months in response to the frenzy over the debut last year of OpenAI’s ChatGPT chatbot, which can provide human-like written responses to questions and other prompts.
 The companies have released little information so far about the safety guard rails they plan to impose on those systems, making Meta’s decision on political ads one of the industry’s most significant AI policy choices to come to light to date.
 Alphabet’s Google, the biggest digital advertising company, announced the launch of similar image-customising generative AI ads tools last week. It plans to keep politics out of its products by blocking a list of “political keywords” from being used as prompts, a Google spokesperson told Reuters.
 Google has also planned a mid-November policy update to require that election-related ads must include a disclosure if they contain “synthetic content that inauthentically depicts real or realistic-looking people or events”.
 TikTok and Snapchat owner Snap both bar political ads, while X, previously known as Twitter, has not rolled out any generative AI advertising tools.
 Meta’s top policy executive, Nick Clegg, said last month that the use of generative AI in political advertising “is clearly an area where we need to update our rules”. — Reuters",york facebook owner political campaign advertiser industry generative artificial intelligence advertising product company spokesperson access tool lawmaker turbo charge spread election misinformation meta decision update centre monday night publication story advertising standard ad content company partner rule generative ad creation ad manager advertiser campaign ad housing employment credit social issue election politics health pharmaceutical financial service generative feature company note explaining tool understand potential risk safeguard generative ad sensitive topic industry policy update month meta biggest platform digital ad expand advertiser access advertising tool background image adjustment variation copy response simple text prompt tool advertiser spring track roll advertiser company time meta tech company launch generative product virtual assistant month response frenzy debut chatgpt chatbot human response question company safety guard plan impose system meta decision political ad industry policy choice google biggest digital advertising company launch image generative ad week plan politics product list political keywords prompt spokesperson reuters mid november policy update require election ad synthetic content real realistic people event owner snap bar political ad generative advertising tool top policy executive nick clegg month generative political advertising update rule reuters,"[(3, 0.22698343), (4, 0.76943374)]",4
612584,Lifestyle,22,05/11/2023,Will AI take my job?,"It’s a question that should prompt employers to consider more than just the bottom line, according to an expert.","THE meteoric rise of AI (artificial intelligence) has catapulted the world into uncharted territory.
 That’s good news for futurists like Amy Webb, who studies emerging technologies and uses quantitative and qualitative modelling to forecast how they’ll impact business and society.
 As founder and CEO of the Future Today Institute, Webb has been grappling with AI and all its concomitant fears, from end-of-humanity doomsday scenarios to market flash crashes and job destruction.
 Webb was fielded questions at the SXSW conference in Sydney. The questions and responses have been edited and condensed.
 How is AI affecting worker productivity?AI can greatly improve productivity for cognitive jobs where there’s a lot of reading, sorting and tagging, which you often find at professional services firms, law firms and investment banks.
 It takes fewer people hours to do those tasks, and you can ask an AI system to find patterns that you may have missed. That said, it’s still humans using the tech. 
 There are plenty of cases where there is ample technology around us and people are somehow less productive.
 Humans are sort of biologically wired to expend as little energy as possible – it’s literally within our cellular structure – so I am curious as to whether this indulges our innate sense of laziness going forward and what that might mean.
 What will AI do to the job market?People ask, “Is AI taking my job? Or taking a bunch of jobs?” But nobody’s asking what it would take for that to be true.
 We don’t have enough plumbers anywhere, right? In medicine, we’ve come a long way. You can use AI systems with computer vision to spot anomalies. But for AI to truly replace a knowledge worker, it requires the workers themselves to do the training to train these AI systems.
 For instance, medical students are being offered money in certain parts of the world to sit for eight hours a day and click “Yes or No” through something called reinforcement learning with human feedback as training.
 But that’s ultimately a drop in the ocean. It’s much more productive to ask, “How is the business model changing going forward?” For example, the billable hourly rate structure is going to have to change for some industries.
 What are C-suite executives talking to you about AI and new technologies?They’re interested in having very basic conversations. To have more advanced, nuanced conversations requires leaning into uncertainty.
 A bank CEO recently asked me how AI can reduce headcount. But if you start adopting AI as a way of only improving your bottom line through a reduction in salaries, you’re going to wind up with a problem in a couple of years, if not sooner.
 What should they be thinking about?AI is a series of different technologies, and there are tools that can be created with it. In a handful of years, there’re going to be different types of jobs needed, so CEOs need to be very careful when making short-term decisions because it improves the bottom line.
 The real opportunity is in top-line growth and figuring out where they can create new revenue streams, improve relationships and make it a force multiplier.
 That’s where most leaders should be placing their energy at the moment, but that’s not what I see happening in any country around the world.
 What good questions are CEOs asking you related to AI?They’re asking what it takes for us to be resilient versus how soon we can lay people off.
 What are people confusing?AI, at the moment, has become sort of a shorthand for ChatGPT. The non-technical side of organisations is just talking about it as a text-based system that gives answers.
 What’s concerning to you?Once your data has been used to train a system, how do you know who owns it and how do you monetise it going forward?
 The real question should be, “Where is it getting the information? Am I okay with that? Do I trust it?” Once you’ve given away your archive and allowed it to be used to train an AI system, you can’t get it back out.
 What’s next?Multimodal. This is having an AI system that can do multiple things at once. Engaging different forms of logic, reasoning and analysis.
 So that can be used for more complex challenges or decision points that a leader might encounter during the day, provided there is enough context.
 Do you have any interesting examples where you’ve tested AI?I was keynoting a large financial services conference, and the panel before mine was something about loan syndication, far outside my domain expertise.
 I copied and pasted the description of the programme and the panellists into a couple of AI chat tools and asked each system to have the panel and tell me what the insights would be. Aside from the charts, graphs and linguistic flare that each person brought, there was really no discernible difference to the actual panel. – Bloomberg",meteoric rise artificial intelligence uncharted territory news futurist webb study technology quantitative qualitative modelling forecast impact business society founder ceo future institute webb concomitant fear humanity scenario market crash job destruction webb question sxsw conference sydney question response condensed worker productivity improve productivity cognitive job lot professional service firm law firm investment bank fewer people hour task system pattern human tech plenty ample technology people productive human energy cellular structure curious indulges sense laziness job market people job bunch job true plumber system computer vision spot anomaly knowledge worker worker train system instance medical student money sit hour day reinforcement human feedback training drop ocean productive business model billable hourly rate structure change industry executive technology basic conversation nuanced conversation uncertainty bank ceo headcount start bottom reduction salary couple sooner series technology tool handful type job careful short term decision bottom real opportunity top growth create revenue stream relationship multiplier leader energy moment country question resilient versus people people moment sort shorthand chatgpt technical organisation text system answer train system real question trust archive train system system multiple form logic analysis complex challenge decision leader encounter day context example financial service conference panel mine loan syndication domain expertise pasted description programme couple system panel insight chart linguistic flare person discernible difference actual panel bloomberg,"[(4, 0.9959102)]",4
612638,Main,23,05/11/2023,AI governance should be on security agenda,"Artificial intelligence is fundamentally altering the nature of warfare,  raising concerns about the possible misuse, abuse, and indiscriminate  use of the new hi-tech weapons.","THE development and application of artificial intelligence are profoundly changing the ways in which human society evolves and people live, and they are fundamentally altering the nature of warfare. While it empowers various industries, it has also raised concerns and worries about the possible misuse, abuse, and indiscriminate use of AI weapons. 
 China’s Global Security Initiative Concept Paper, released in February, calls for strengthening international security governance in emerging technologies, including AI, highlights the key directions for enhancing international security governance of military AI, and issues position papers on the military application and ethical governance of AI, strengthens communication and exchanges with the international community on AI security governance, promotes the establishment of a participatory international mechanism, and forms a governance framework and standard norms with broad consensus.
 I. Challenges in international security governance of military AI 
 In February 2023, the first global Summit on Responsible Artificial Intelligence in the Military Domain held in The Hague passed a “Call to Action” emphasising the importance of responsible development and use of military AI systems, and reflecting some basic consensus in the international community regarding international norms for the military application of AI. Yet only slightly over 60 out of the more than 80 countries represented at the conference supported the “call to action”. 
 Achieving broad consensus and coordinated action in the international security governance of military AI still faces numerous challenges.
 There is significant disagreement in the international community regarding the rules for lethal autonomous weapon systems. Many developing countries and non-governmental organisations, represented by the Non-Aligned Movement and the African Union, strongly advocate restricting or even banning lethal autonomous weapon systems and call for the creation of a legally binding international instrument on this matter. 
 Some developed countries, typically the European Union, emphasise the dual-use nature of AI and advocate a non-legally binding political declaration. 
 Some big countries have a relatively passive attitude toward arms control for lethal autono­mous weapon systems and firmly oppose the establishment of an international treaty banning lethal autonomous weapon systems.
 Geopolitical confrontations significantly hinder global unity and cooperation among countries. Currently, great power competition and confrontations have peaked since the end of the Cold War, with a few countries being forcibly excluded from international cooperation frameworks and systems, lacking channels for comprehensive participation in discussions and the formulation of international norms for military applications of AI. 
 For instance, because of the Ukraine crisis, Russia has not been invited to participate in relevant summits on the responsible use of AI in the military and has even been deliberately restricted from engaging in related dialogues and negotiations.
 AI is a collective achievement of human intelligence and thus whole humanity should benefit from it. However, certain countries create technological barriers that restrict cooperation and exchange in AI. 
 At the same time, the potential risks associated with the autonomous and inexplicable nature of AI technology require global collaboration. While some countries like the US verbally vow strong support for international cooperation in the responsible use of AI, they also treat AI technology as a tool to maintain their own dominance in geopolitical competitions. 
 They form exclusive “small circles” or “small groups” and artificially create technological barriers in areas closely related to the development and application of AI, such as chips and 5G communication, obstructing international exchanges in AI technology. This has become a stumbling block for international cooperation in responsible AI governance.
 II. Suggestions for promoting the construction of an international security governance framework for military AIAlthough it is still difficult to reach an international treaty on regulating the military application of AI, China has proposed ideas and plans on how to promote the construction of a community with a shared future for mankind in the field of AI. 
 In December 2021, China released the Position Paper of the People’s Republic of China on Regulating Military Applications of Artificial Intelligence to the Sixth Review Conference of the Convention on Certain Conventional Weapons, advocating that all countries should uphold a global security concept featuring common, comprehensive, cooperative, and sustainable development, seek consensus on how to regulate the military application of AI through dialogue and cooperation, and establish an effective governance mechanism. 
 The “Global Security Initiative Concept Paper” once again pointed out that China is willing to strengthen communication and exchanges with the international community on AI security governance, promote the establishment of a widely participated international mechanism, and form a governance framework and standard specifications with broad consensus. 
 Following are suggestions on how to construct an international security governance framework for the military application of AI:
 > Forge broad consensus – From the perspective of building a global community of shared future, we should give full play to the role of the United Nations platform, widely forge consensus among developed countries, emerging economies, and developing countries on the pursuit of the development, application, and security governance of AI. We should fully consider the reasonable concerns of different countries, ethnic groups, and religious backgrounds, and establish guiding principles that integrate values and ethics, security and controllability, fairness and inclusiveness, openness and tolerance, and peaceful utilisation.
 > Define the responsibilities of participants – The stakeholders of military AI security governance not only include sovereign states and non-state actors that use AI weapons, but also include parties involved in research and development, manufacturing, testing and evaluation, as well as supervision agencies of relevant industries and international organisations. 
 In response to the possible consequences of misuse and abuse of military AI, it is necessary to differentiate responsibilities among relevant stakeholders and jointly assume the responsibilities and obligations of military AI security governance.
 > Define the governance content – Military AI security governance must scientifically define the objects to be governed, so that relevant laws and regulations can be implemented with specific background constraints. Thus it is necessary to clarify that security governance should focus on the risks, harm, and negative impacts that may be caused by the military  application of AI. 
 Scientific assessments should be conducted on accidents with different levels of damage, security risks of different types and levels, and negative impacts in different scenarios and fields, and reasonable discretion should be given to different stakeholders in tracing their responsibilities.
 > Improve governance tools – Military AI security governance requires complex governance tools for support. These tools include both macro-level ethical guidelines and guiding principles, as well as specific laws and regulations, technical standards, and policy mechanisms. 
 They can also include relevant databases, prototype systems, and testing and evaluation certification tools. The development of these governance tools requires both the proactive actions of sovereign states and the evaluation and supervision of industry associations and international organisations.
 > Expand communication platforms – Military AI security governance involves a wide range of factors and is constantly evolving, even with elements of confrontation and gaming among different parties. 
 It is necessary for sovereign states, industry enterprises, and international organisations to actively expand communication platforms, strengthen cross-field, cross-departmental, and cross-regional cooperation and exchanges, share new knowledge and experiences, and resolve conflicts and differences. 
 Countries such as China, the US, and Russia, which are at the forefront of military AI technology, need to strengthen communication and dialogue, explore the establishment of relevant trust measures, avoid the escalation of wars and conflicts and humanitarian disasters caused by the misuse and abuse of AI, promote the construction of a community with a shared future for mankind in the field of military application of AI, and work together with the international community to maintain global strategic stability and human peace and welfare. – China Daily/Asia News Network
 Zu Qichao is director of the National Defense Technology Strategy Thinktank, National University of Defense Technology.",development application artificial intelligence human society people altering nature warfare empowers industry concern worry abuse indiscriminate weapon global security initiative concept paper february call international security governance technology highlight key direction international security governance military issue position paper military application ethical governance communication exchange international community security governance establishment participatory international mechanism form governance framework standard norm broad consensus international security governance military february global summit responsible artificial intelligence military domain hague call action responsible development military system basic consensus international community international norm military application country conference call action broad consensus action international security governance military numerous challenge disagreement international community rule autonomous weapon system country governmental organisation aligned movement african union advocate lethal autonomous weapon system call creation international instrument matter country european union dual nature advocate political declaration country passive attitude arm control mous weapon system establishment international treaty lethal autonomous weapon system geopolitical confrontation global unity cooperation country power competition confrontation cold war country international cooperation framework system channel comprehensive participation discussion international norm military application instance ukraine crisis russia participate relevant summit responsible military dialogue negotiation collective achievement human intelligence humanity benefit country technological barrier cooperation exchange time potential risk autonomous inexplicable nature technology require global collaboration country strong support international cooperation responsible treat technology tool dominance geopolitical competition exclusive circle technological barrier development application chip communication international exchange technology block international cooperation responsible governance suggestion construction international security governance framework military difficult international treaty military application china idea promote construction community future mankind field december china position paper people republic military application artificial intelligence sixth review conference convention conventional weapon country uphold global security concept common comprehensive cooperative sustainable development seek consensus regulate military application dialogue cooperation effective governance mechanism global security initiative concept paper china strengthen communication exchange international community security governance promote establishment international mechanism form governance framework standard specification broad consensus suggestion international security governance framework military application forge broad consensus perspective building global community future play role united nation forge consensus country economy country pursuit development application security governance reasonable concern country religious background principle value ethic security controllability fairness inclusiveness openness tolerance peaceful utilisation define participant stakeholder military security governance sovereign actor weapon party development evaluation supervision agency industry international organisation response consequence military differentiate responsibility stakeholder responsibility obligation military security governance define governance content military security governance define object relevant law regulation specific background constraint security governance focus risk negative impact military application scientific assessment accident level security risk level negative impact scenario field reasonable discretion stakeholder responsibility governance tool military security governance complex governance tool support tool level ethical guideline principle specific law regulation technical standard policy mechanism relevant prototype system evaluation certification tool development governance tool proactive action sovereign evaluation supervision industry association international organisation communication platform military security governance wide range factor element confrontation party sovereign industry international organisation communication platform cross field cross departmental cross regional cooperation exchange share knowledge experience conflict difference country russia forefront military technology strengthen communication dialogue establishment relevant trust measure escalation war humanitarian disaster misuse abuse promote construction community future mankind field military application international community global strategic stability human peace welfare china daily asia news network qichao director national defense technology strategy national university defense technology,"[(4, 0.9984737)]",4
612332,Main,20,04/11/2023,Turning to AI to combat crimes,Police believe technology can help fill security gaps in rural areas,"The South Korean police unveiled a four-year blueprint for using artificial intelligence to predict and combat crimes.
 They believe the technology can help fill security gaps in the rural areas caused by the high concentration of police personnel in Seoul and the metropolitan area.
 The police will also seek to use artificial intelligence to improve their investigative abilities and the technology to combat voice phishing.
 The plan includes a programme to ­develop an algorithm that analyses ­unusual online behaviour patterns to predict stalking and sex crimes.
 Also, research is under way to develop technology that uses security cameras to detect abnormal behaviour and whether someone is carrying a weapon.
 To better tackle drug trafficking, a real-time map to keep track of drug cases to help trace distribution routes will be built.
 Other plans include establishing a police agency metaverse, developing a system to automatically track banned virtual assets, and creating a cyber training institution at the Advanced Public Security Centre.
 In addition, officers will be provided with bulletproof clothing and strength-­enhancing robotic augmentations to their uniforms.
 South Korea has seen an increase in economic and financial crimes, with the number rising from 290,000 in 2015 to 410,000 in 2020.
 The number of drug offenders is also up, with the number of people investigated for drug crimes jumping from 12,000 in 2018 to 18,000 in 2020.
 In the first half of 2023, a total of 925 cases of murder, bodily harm or assault took place. And 18 of them were classified as serious crimes with abnormal motives, commonly referred to as mudjima or “don’t ask why” attacks – unprovoked and sudden acts of violence targeting strangers.
 The plan, which requires approval by the Presidential Advisory Council on Science and Technology, will be finalised by the end of 2023 after consultations with the relevant ministries. ­— The Korea Herald/ANN",south korean police blueprint artificial intelligence predict combat crime technology fill security gap rural concentration police personnel metropolitan police artificial intelligence investigative ability technology combat voice plan programme algorithm analysis unusual online behaviour pattern sex crime technology security camera abnormal behaviour weapon tackle drug real time map track drug trace distribution route plan police agency system virtual asset cyber training institution public security centre addition officer bulletproof clothing strength robotic augmentation uniform korea increase economic financial crime drug offender people investigated drug crime half total murder assault classified crime abnormal motif mudjima attack sudden act violence stranger plan approval presidential advisory council science technology consultation relevant ministry herald ann,"[(4, 0.99223953)]",4
611974,StarBiz,10,03/11/2023,Possibility for AI to threaten professional jobs,Technology able to strip out aspects of knowledge work,"SINGAPORE: Highly paid professionals with no managerial duties may be most impacted as firms use artificial intelligence (AI) to drive down costs and raise productivity, a new global study suggests.
 This is contrary to expectations that mostly low and middle-skilled roles would be devalued or lost, says the research by 20 social scientists.
 In Singapore, this phenomenon may be felt in jobs such as credit decision-makers, field engineers, curriculum designers and consultants, according to the study, which was presented at a conference on Wednesday.
 As tasks get automated, standardised and redistributed through simplification and offshoring, professionals will find jobs falling in quality.
 Middle-class aspirations here could come under strain as a result because professionals and degree holders form the fastest-growing category of workers earning middle wages, defined in the study as those earning 75% to 150% of median income.
 Managers, in contrast, will gain greater clout.
 Professor Phillip Brown, distinguished research professor at Cardiff University and director of the research programme, explained this with an example of the health service in Britain.
 “The doctors or the academics have a lot of control and then, over time, managers come in to coordinate and organise moves onto (technological) platforms,” he said on the sidelines of the event.
 “The managerial control is likely to become greater through those technologies and it will strip out aspects of knowledge work from the professionals and technicians.”
 The findings were presented to 250 delegates at the Digital Futures of Work Global Conference 2023, which was organised by the Institute for Adult Learning (IAL), an autonomous institute of the Singapore University of Social Sciences. It was held at Voco Orchard Hotel.
 Funded by SkillsFuture Singapore, the Digital Futures of Work Research Programme took place over four years from 2019 and covered more than 500 interviews and quantitative analyses of AI adoption patterns in places such as Silicon Valley, Singapore and London.
 More than 80 senior executives from 60 companies in Singapore were interviewed, and data from the Singapore Skills and Learning Survey conducted between 2021 and 2022 was analysed for the study.
 It need not be a surrender of “destiny” to technology; AI can still impact jobs positively if society intervenes in how companies use AI, said Brown.
 “We did seek out companies that were doing things differently,” he said. These firms recognise humans as a differentiator and recognise that if everybody has got the technology, their competitive edge will be their people.
 These firms might, for example, let most of their workers experiment with AI tools, or tap AI tools to connect groups with different know-how to enhance collaboration.
 Helsinki and Berlin, digital hubs like Singapore with a high concentration of tech activities, have prioritised using AI to enhance professional work and opportunities rather than substitute well-paid workers, the study said.
 Sahara Sadik, assistant director for research at the IAL and deputy director of the research programme, called for a more deliberate AI transition.
 Firms can be more creative and agile by designing new job functions and use of AI together with workers, rather than dropping top-down policies onto their workforce. 
 “What we are putting forward is that there is a need for social response if we truly believe that technology is going to benefit everyone,” she said in a speech. — The Straits Times/ANN",professional managerial duty firm artificial intelligence drive cost productivity global study contrary expectation low middle role social scientist phenomenon job credit decision maker field engineer designer consultant conference wednesday task simplification professional job quality middle class aspiration result professional holder fastest category worker middle wage study median income manager gain clout professor phillip professor cardiff university director programme health service britain doctor lot control time manager organise move technological platform sideline event managerial control technology aspect professional technician finding delegate digital future global conference institute adult ial autonomous institute singapore university social science voco orchard hotel skillsfuture singapore digital future interview quantitative analysis adoption pattern valley singapore london senior executive company data skill survey analysed study surrender destiny technology impact job intervenes company brown seek company firm human recognise technology competitive edge people firm worker tool tool connect enhance collaboration helsinki berlin digital hub singapore concentration tech activity enhance professional opportunity worker sahara sadik assistant director ial deputy director programme deliberate transition firm job function worker top policy social response technology benefit speech time,"[(0, 0.99504316)]",0
610466,Main,4,30/10/2023,AI poised to write the next chapter in literary research,,"KUALA LUMPUR: Embracing the rise of Artificial Intelligence (AI) in literature research is transforming the literary studies landscape, says Prof Nie Zhenzhao (pic) of  Zhejiang University.
 He believes that authors should accept AI’s transformative impact on literary theory, accelerate the reconstruction of scientifically-­based literary theories, and tackle the challenges that literature currently faces.
 The emergence of AI-written literature had begun to challenge current theories, potentially prompting changes in literary research concepts, he said.
 He added that literary theory needed to move beyond old frameworks and undertake a scientific reconstruction, especially emphasising the study of literary principles.Prof Nie highlighted the inaugural release in AI literature, Microsoft’s 2017 poetry collection, The Sunlight That Lost The Glass Window.
 According to him, this groundbreaking work was created by Microsoft’s AI, Xiaoice, an AI system that studied the works of 519 poets from the last century in just 100 hours.
 “Achieving this would only be possible for accomplished human poets
 “Just like a gifted young poet, Xiaoice can understand emotions and convey her insights through poetry even more efficiently than some human poets.
 “Will Xiaoice replace poets? Will poets become redundant, and authors too? We cannot ignore these questions,” he said during a panel discussion on “The Scientific Turn in Literary Studies and AI” at the international conference on the “Development and Future of Sinology in the 21st Century”.
 Prof Nie also cited the example of ChatGPT, which could outperform some human poets, potentially up to the college or graduate level.
 These advanced AI systems, he said, could analyse large volumes of data to learn and create poetry in novel and innovative ways.
 “Subjective emotions do not influence AI’s creativity. It perceives poetry differently, free from personal bias,” he said.
 Prof Nie recommended an approach to address the impending challenges in literature, in which adopting technology could provide substantial benefits in investigating the basic tenets of literary theories.
 This strategy involved employing versatile research methods, fostering interplay between literary studies and its associated fields, which could lead to innovative reinterpretations and a restructuring of the literary theory framework, he added.",kuala lumpur rise artificial intelligence literature literary study prof nie zhenzhao pic zhejiang university author transformative impact literary theory accelerate reconstruction literary theory challenge emergence literature current theory literary concept literary theory move framework scientific reconstruction study literary principle inaugural release literature microsoft poetry collection glass window microsoft xiaoice system poet century hour accomplished human poet poet xiaoice understand emotion insight human poet poet poet redundant author question panel discussion scientific literary study international conference development future sinology century prof nie chatgpt outperform human poet college graduate level system analyse volume data create poetry innovative subjective emotion influence creativity perceives free personal bias prof nie approach address challenge technology substantial benefit basic tenet literary theory strategy versatile method interplay literary study field innovative reinterpretation literary theory framework,"[(2, 0.99344766)]",2
610258,Lifestyle,10,29/10/2023,Shaping the future of AI,,"EVER wonder how Homo sapiens got so smart? How come we developed actual language when all the other animals didn’t? How about what first made a nematode turn its body in a different direction? Or … what’s a nematode?
 Answers to those questions and much, much more can be found in the pages of Max Bennett’s new book A Brief History Of Intelligence: Evolution, AI And The Five Breakthroughs That Made Our Brains. 
 At 365 pages plus 45 more with a glossary, chapter notes and a bibliography, readers can quibble whether it’s indeed brief, but it is certainly thorough.
 Bennett’s premise – he’s a software entrepreneur who founded a company called Bluecore that “helped predict what consumers would buy before they knew what they wanted” – is that humans won’t ever create true artificial intelligence without understanding exactly what led to the real intelligence we already possess. 
 So he begins with those nematodes – worms, to you and me – and painstakingly details the five breakthroughs that over the course of billions of years evolved into the three-pound brain that is folded into all of our skulls.
 The first half of the book is a touch dry, detailing not only what caused worms to turn (food!), but how fish learn via trial and error and the pivotal role the basal ganglia plays in dictating behaviour, among many, many other evolutionary developments. 
 Bennett cites the work of psychologists and neuroscientists every step of the way and includes plenty of charts and graphs to make his points. It can feel like you’re reading a textbook at times. 
 But to his credit, he begins each new chapter with actual prose, as in this description of the Cambrian explosion more than 500 million years ago: “The gooey microbial mats of the Ediacaran that turned the ocean floor green would have long since faded and given way to a more familiar sandy underbelly. 
 The sensible, slow, and small creatures of the Ediacaran would have been replaced by a bustling zoo of large mobile animals as varied in form as in size.”
 When Bennett begins to connect the evolution of the human brain to where we are in the development of artificial intelligence is when the book, for this reader, gets more interesting. Why can’t machines truly learn? 
 Even ChatGPT, which every industry seems to be embracing these days, can’t “learn things sequentially,” writes Bennett. 
 “They learn things all at once and then stop learning.” 
 We’ve trained ChatGPT using the entire contents of the Internet, but the software can’t learn new things because of the risk that it will forget old things, or learn the wrong things.
 Bennett is intelligent enough not to draw any conclusions about AI in a field that is changing daily, but he does end his book with a challenge. 
 Evolution gave us our magnificent human brain, he writes, and now that we are in a position to play god and create a new form of intelligence, we must first decide on our goal – are we destined to spread out across the cosmos? Or will we fail, victims of pride or climate change or something yet unseen, just another branch on the evolutionary tree, which will grow on without humans and perhaps never add a limb called “Artificial Intelligence?” 
 No reader alive today will live long enough for that answer, but Bennett makes a solid case for why reverse engineering the human brain may lead to future breakthroughs in the science of AI. – AP",homo sapiens actual language animal body direction nematode answer question bennett book history intelligence evolution breakthrough brain glossary chapter note reader quibble bennett premise software entrepreneur company bluecore predict consumer human true artificial intelligence real intelligence posse nematode detail billion pound brain skull half book touch dry detailing worm food fish trial error pivotal role basal play behaviour evolutionary development cite psychologist neuroscientist plenty chart time credit chapter actual prose description cambrian explosion gooey microbial mat ocean floor green familiar sandy slow creature zoo mobile animal form size bennett connect evolution human brain development artificial intelligence book reader machine chatgpt industry day bennett learn learning chatgpt entire content internet software learn risk forget wrong bennett intelligent draw conclusion field daily book challenge evolution magnificent human brain writes position god create form intelligence decide goal spread cosmos victim climate change unseen branch evolutionary tree grow human limb artificial intelligence reader alive live answer bennett solid reverse engineering human brain lead future science,"[(0, 0.3826675), (3, 0.61343265)]",3
609710,Main,26,28/10/2023,Error-prone AI chatbot dog leads Japan’s elderly astray,,"Tokyo: A cartoon canine AI chatbot designed to cheer up and inform lonely older residents of western Japan is in the doghouse after providing error-laden responses.
 Powered by generative artificial intelligence, “Dai-chan” was this year launched by Osaka authorities who called it the  first of its kind in a country  where one in 10 people is age 80 or older.
 But the chatbot, which features a Shiba Inu cartoon dog and answers in the Osaka dialect, has shown itself far from faithful to the truth.
 When a user asked about the World Expo planned in Osaka  in 2025, the dog incorrectly responded that the event was cancelled.
 That answer gained public attention, with Japanese newspapers and broadcasters reporting on the dog who got the wrong end of the stick.
 “Dai-chan, you’re good,” one social media user joked.
 Despite slow progress and budget challenges, the world  fair is still scheduled to go  ahead.
 Among other incorrect answers, Dai-chan said the “G7 foreign ministers’ meeting will be held on Nov 4” rather than the slated  Nov 7-8.
 Asked by an AFP reporter if the mooted Sapporo Olympic Games will be pushed back, the bot dog said: “The Sapporo Olympics is postponed! It’s not cancelled so I look forward to it!” — AFP",tokyo cartoon canine chatbot cheer inform lonely resident western japan error laden response generative artificial intelligence dai chan osaka authority country people age chatbot feature inu cartoon dog answer dialect faithful truth user expo dog event answer public attention japanese newspaper broadcaster dog wrong stick dai chan social medium slow progress budget fair incorrect answer chan foreign minister nov afp reporter sapporo olympic game bot dog sapporo olympics cancelled afp,"[(0, 0.9861916)]",0
608824,StarBiz,10,26/10/2023,Qualcomm unveils new PC laptop chip with AI features,,"San Diego: Qualcomm has given details about a chip for Microsoft Windows-based laptops that it claims will be faster at some tasks than Apple’s chips for Mac computers.
 Qualcomm executives said the company’s new Snapdragon Elite X chip will be available in laptops starting next year and has been redesigned to better handle artificial intelligence (AI) tasks like summarising emails, writing text and generating images.
 Those AI features will also factor into Qualcomm’s chips for smartphones, with Alphabet’s Google and Meta both saying yesterday they planned to take advantage of them.
 The announcement comes a day after Reuters reported Microsoft has encouraged Qualcomm, Nvidia and Advanced Micro Devices to come up with new chips to handle a bevy of new AI features in Windows, the world’s most popular PC operating system.
 During a video appearance at Qualcomm’s event, Microsoft chief executive Satya Nadella said the chips would help usher in a new era of “AI PCs” for businesses and consumers.
 “The work we’re doing together, it’s going to bring together these experiences that cannot be done without a new system architecture,” Nadella said.
 Qualcomm will be the first to market with a chip to challenge Apple, whose laptop and desktop computers have more than doubled their market share since the iPhone maker introduced custom-designed chips in 2020.
 Qualcomm claimed yesterday the X Elite is faster than Apple’s M2 Max chip at some tasks and more energy efficient than both Apple and Intel PC chips.
 But Qualcomm senior vice-president Alex Katouzian said the biggest new feature is the chip can handle AI models with 13 billion parameters, a proxy measure of sophistication for AI systems that generate text or images. — Reuters",san diego qualcomm detail chip microsoft window laptop claim task apple chip computer executive company chip handle artificial intelligence task email text generating image feature qualcomm chip smartphones meta yesterday advantage announcement day reuters microsoft qualcomm advanced micro device chip bevy feature popular operating system video appearance qualcomm event microsoft chief executive satya nadella chip era pc business consumer experience system architecture nadella qualcomm market chip challenge apple laptop desktop computer market share iphone maker custom chip yesterday faster apple max chip task energy efficient apple intel chip senior vice president alex katouzian biggest feature chip handle model parameter proxy measure sophistication system text image reuters,"[(2, 0.07403321), (4, 0.9199771)]",4
608826,StarBiz,10,26/10/2023,Microsoft beats estimates ahead of AI rollout,,"San Francisco: Microsoft has beaten Wall Street estimates for fiscal first-quarter results in all segments, with its cloud computing and PC businesses growing as customers anticipate using its artificial intelligence (AI) offerings.
 Its forecast also was mostly ahead of analyst targets.
 Microsoft, which has heavily backed and collaborated with OpenAI, has yet to roll out most of the products based on its work with the ChatGPT creator. 
 But enthusiasm among corporate technology buyers for features like the ability to summarise heaps of email into a few bullet points or speedily complete lines of computer code helped the company’s revenue rise 13% to US$56.5bil in the quarter ended Sept 30.
 That compares with analysts’ consensus estimate of US$54.52bil, according to London Stock Exchange Group (LSEG) data.
 “The results indicated that artificial intelligence products are stimulating sales and already contributing to top and bottom-line growth,” said Jesse Cohen, senior analyst at Investing.com. Microsoft shares were up 3% in after-hours trading.
 In the reported quarter, revenue from Microsoft’s Intelligent Cloud unit, which houses its Azure cloud-computing platform where much of the AI work will take place, grew to US$24.3bil, compared with analysts’ estimate of US$23.49bil, LSEG data showed. Azure revenue rose 29%, higher than a 26.2% growth estimate from market research firm Visible Alpha.
 Brett Iversen, Microsoft’s vice-president for investor relations, said much of the quarterly sales growth came from customers rekindling their use of Microsoft’s cloud in anticipation of using AI services.
 “What AI is doing is opening up either new conversations or extending existing conversations or getting us back in touch with customers that we maybe weren’t doing as much with,” Iversen said.
 By comparison, Google-parent Alphabet’s cloud division missed estimates for third-quarter revenue yesterday as an uncertain economy and high interest rates led its customers to trim their budgets.
 “While a single quarter doesn’t a major trend make, this quarter’s cloud results from Microsoft and Google suggest that Azure is gaining share against its competition,” said Bob O’Donnell, chief analyst at TECHnalysis Research. 
 “It could be that Microsoft’s very strong messaging on their (AI) technology is getting companies to consider them in a more serious way.”
 Microsoft said fiscal first-quarter profit was US$2.99 per share, above analyst estimates of US$2.65 per share, according to LSEG data.
 “There are some weaker areas; search advertising revenues, for one, is growing slower than most segments,” said Jeremy Goldman of research firm Insider Intelligence.
 Microsoft said search and news advertising revenue excluding traffic acquisition costs increased by 10%. It does not break out the revenue figure for these operations.
 Microsoft is weaving AI into its own products, such as the US$30-a-month “Copilot” for its Microsoft 365 service that can summarise a day’s worth of emails into a quick update. — Reuters",san francisco microsoft wall street estimate fiscal quarter segment business customer artificial intelligence offering analyst target roll product chatgpt creator enthusiasm corporate technology buyer feature ability heap email bullet complete line computer code company revenue rise bil quarter analyst consensus estimate bil london stock exchange lseg data artificial intelligence product sale top bottom growth jesse cohen senior analyst microsoft share hour quarter revenue microsoft intelligent cloud unit house cloud platform analyst bil lseg data azure revenue growth estimate market firm visible alpha brett iversen microsoft vice president investor relation quarterly sale growth customer microsoft cloud anticipation service conversation conversation touch customer comparison google parent alphabet cloud division estimate quarter revenue yesterday uncertain economy rate customer trim budget single quarter major trend quarter microsoft google azure share competition bob donnell chief analyst technalysis microsoft strong messaging technology company fiscal quarter profit share analyst estimate share data weaker search advertising revenue slower segment goldman firm insider intelligence microsoft search news advertising revenue traffic acquisition cost break revenue figure operation product month copilot microsoft service summarise day email quick update reuters,"[(4, 0.9952275)]",4
608138,StarBiz,13,24/10/2023,Fund managers banking on SK Hynix as AI winner,,"SEOUL: Shares of Samsung Electronics Co are on track to underperform those of its smaller memory chip rival SK Hynix Inc by the most in a decade as investors bet the latter will be the winner in artificial intelligence (AI).
 SK Hynix has surged 67% this year thanks to its deal to supply premium high bandwidth memory (HBM) chips to Nvidia Corp, trouncing Samsung, which is up 24% as it struggles to get its HBM offering off the ground. 
 That gap may widen further judging by options data, which show the put-to-call ratio on Samsung more than double that of SK Hynix. 
 The AI battle is pitched against the backdrop of weak global demand for the companies’ traditional memory products. 
 That’s due in large part to smartphones, which are mired in what could be the worst industry wide slump in over a decade, hurting another key source of revenue for Samsung.
 Chips remain hot overall thanks to the surge in demand for products needed to power generative AI services like ChatGPT. 
 The Philadelphia Semiconductor Index is up 31% this year, outpacing gains in nearly any benchmark you can think of.
 Samsung has another way to tap this growth, as it also provides contract chip-manufacturing services. 
 But it’s missing out here as well because Taiwan Semiconductor Manufacturing Co dominates foundry business, producing the lion’s share of AI processors designed by Nvidia and others. 
 So after years of leading the memory industry, Samsung is now seen needing to play catchup in HBM, an advanced technology optimised to work with AI accelerators. 
 HBM features a stack of DRAM that sits on top of a processor instead of being housed in a separate memory module, enabling faster data transfer.
 SK Hynix, more of a “pure-play” memory maker than its diversified peer, was able to get a jump on the latest generation of the chip, winning Nvidia as a customer for its HBM3. 
 Samsung reportedly had trouble finalising a contract with the US AI giant for its offering, though it has developed a new HBM3E chip and said it plans to introduce an HBM4 by 2025.
 “This is a really unfamiliar scene,” with Samsung falling behind SK Hynix in HBM development, said Yoon Joonwon, a fund manager at DS Asset Management Co. 
 “Everyone is focused on AI as that’s the only area where we see strong demand.”
 Yoon sees securing a client such as Nvidia or Advanced Micro Devices Inc as key for Samsung’s share price. Other observers point to yield, the amount of good chips it can produce from each batch of material, as the main thing for investors to monitor. — Bloomberg",seoul share electronics underperform memory chip rival hynix decade investor winner artificial intelligence hynix deal supply premium bandwidth memory hbm chip corp trouncing samsung hbm offering ground gap judging option call ratio samsung double hynix battle backdrop weak global demand company traditional memory product smartphones worst industry wide slump decade key source revenue chip hot surge demand product power generative service philadelphia semiconductor gain benchmark samsung tap growth contract chip manufacturing service taiwan semiconductor manufacturing foundry business lion share processor leading memory industry catchup hbm technology accelerator feature dram sits top processor separate memory module faster data transfer hynix pure play memory maker peer jump generation chip nvidia customer hbm samsung trouble contract giant offering chip plan hbm unfamiliar scene samsung hynix hbm development yoon joonwon fund manager asset management strong demand yoon client micro device key samsung share price observer amount chip batch material main investor bloomberg,"[(4, 0.99407136)]",4
607032,StarEdu,3,22/10/2023,AI centres  the way forward,"Replicate UTM initiative in institutions nationwide, stakeholders say","Artificial intelligence (AI) study centres should be set up in all public and private universities to drive research and collaborations in the field.
 National Association of Private Educational Institutions (Napei)secretary-general Dr Teh Choon Jin said while the government’s proposed AI study centre at Universiti Teknologi Malaysia (UTM) is a commendable and forward-thinking step for the future of higher education, replicating the initiative in other universities can create a network of expertise and research collaboration across the country.
 “It would allow Malaysia to build a comprehensive ecosystem for AI research, development and education, strengthening its position in the global AI landscape,” he said, adding that there should be collaboration with other public or private universities that are doing research in AI to maximise the benefits of such research for the nation.
 During the tabling of Budget 2024 on Oct 13, Prime Minister Datuk Seri Anwar Ibrahim announced that the country’s first AI study centre would be set up at UTM with an initial allocation of RM20mil to intensify the exploration of cross-disciplinary AI.
 A centralised AI centre for private higher education institutions can facilitate cross-collaboration and knowledge exchange among researchers in the field, said Vice Chancellors’ Council for Private Universities (VCCPU) chairman Prof Mushtak Al-Atabi.
 Budget 2024, said Prof Mushtak, highlighted a lot of potential to propel economic growth, foster job opportunities, and attract international investments.
 The latest developments in AI have brought us to a critical juncture where machines are making the leap into the cognitive realm, he added.
 “This juncture offers us a unique opportunity to reconfigure our approach to education, economy, community, business and government, fostering a greater pursuit of what truly matters: the realisation of our ultimate potential. 
 “This involves the discovery and articulation of our purpose and channelling our efforts towards making a positive impact on the world,” he said, adding that the proposed AI centre at UTM is a groundbreaking initiative with far-reaching implications for the future of Malaysia.
 By prioritising AI and robotics, the country is on a trajectory to become a technological leader, cultivating the skills necessary for a new era, and promoting a brighter and more prosperous future for all, he said.
 “Having said this, while we strive to harness the potential of AI in education, it is crucial to remember the enduring significance of human interaction. 
 “Education is more than the mere transfer of knowledge; it is about driving purpose, fostering holistic development, nurturing character, and cultivating curiosity.
 “As we journey into this brave new world, let’s do so with a strong commitment to ethics, equity, and the holistic development of individuals,” he added.
 Teh said the Budget 2024 allocation for the AI centre is a huge stepping stone towards Malaysia’s digital transformation.
 “AI is a transformative technology with applications in various sectors, including healthcare, finance, manufacturing and education.
 “By investing in an AI study centre, the government is taking a proactive approach to harnessing AI’s potential to drive innovation and economic growth. 
 “It signals a commitment to leveraging AI as a key driver of Malaysia’s digital transformation,” he said.
 UTM vice-chancellor Prof Datuk Dr Ahmad Fauzi Ismail said the country’s first AI study centre, or Faculty of AI, will be multidisciplinary in nature.
 The upcoming faculty, he said on the public varsity’s website, will make AI a catalyst for innovation in various fields, including manufacturing, finance, health, agriculture, renewable energy, security, economy and climate change.
 UTM, he said, accepts the trust and responsibility of setting up the Faculty of AI to help develop the nation.
 The varsity, he said, is also optimistic that the faculty would be able to advance human civilisation following the Malaysia Madani mould.
 He said UTM pioneers AI extensively and is already home to the Centre for AI and Robotics (CAIRO), the Big Data Centre (BDC), the IJN-UTM Cardiovascular Engineering Centre, the Institute of Human Centered Engineering (iHumEn), and the Institute for Vehicle Systems and Engineering (IVeSE).
 There are more than 100 AI experts across the varsity’s study centres comprising academics from the faculties of computing, electrical engineering, mechanical engineering, civil engineering, chemical and energy engineering, sciences, technology and informatics, management, and architecture and surveying; and the Malaysia-Japan International Institute of Technology (MJIIT). 
 UTM, he said, has produced various AI-based innovations, such as a high-tech smart robot for inspection and cleaning in tight spaces; a smart robot for wireless search; a smart hologram application for digital security; and a smart social assistant.",artificial intelligence study public private university collaboration field national association private educational institution secretary teh choon jin government study centre universiti teknologi malaysia utm commendable forward step future education initiative university network expertise collaboration country malaysia comprehensive ecosystem development education position global landscape collaboration public private university maximise benefit nation budget oct prime minister datuk seri anwar ibrahim country study centre utm initial allocation mil exploration cross disciplinary centre private education institution cross collaboration knowledge exchange researcher field vice chancellor private university chairman prof mushtak atabi budget prof mushtak lot potential propel economic growth job opportunity international investment development brought critical juncture machine cognitive realm juncture unique opportunity reconfigure approach education economy community business government pursuit matter ultimate potential involves discovery articulation purpose effort positive impact centre utm initiative implication future malaysia robotics country trajectory technological leader skill era prosperous future strive harness potential education crucial remember significance human interaction education transfer knowledge purpose holistic development character curiosity journey strong commitment ethic equity holistic development individual budget allocation centre huge stone malaysia digital transformation transformative technology application sector healthcare finance education study centre government proactive approach potential drive innovation economic growth signal key driver malaysia digital transformation utm vice chancellor prof datuk ahmad fauzi ismail country study centre faculty multidisciplinary nature faculty public varsity website catalyst innovation field finance health agriculture renewable energy security economy climate change utm trust responsibility faculty nation varsity optimistic faculty advance human civilisation malaysia madani pioneer centre robotics data centre ijn utm cardiovascular engineering centre institute human engineering ihumen vehicle system engineering ivese expert varsity study academic faculty electrical engineering mechanical engineering civil engineering chemical energy engineering science technology informatics management architecture malaysia japan international institute technology mjiit utm innovation smart robot inspection tight space robot wireless search smart hologram application digital security social assistant,"[(2, 0.9971234)]",2
606180,StarBiz,10,19/10/2023,Hon Hai to  use AI to  expand into EVs,,"TAIPEI: Hon Hai Precision Industry Co, best known as the maker of Apple Inc’s iPhone, is expanding its push into electric vehicles (EVs) by integrating artificial intelligence (AI), attempting to bolster its strategy for one of the hottest segments of the automotive industry.
 At an event in Taiwan complete with lasers and thumping music, Hon Hai chairman Young Liu drove on stage in a shiny blue Model B electric car with a surprise guest.
 Jensen Huang, chief executive officer of the AI chip leader Nvidia Corp, joined him to talk about their efforts to make vehicles smarter, with technologies like autonomous driving and other features.
 The duo sketched out a concept they called an “AI Factory,” through which the companies would collect data from EVs and then feed the information back to make improvements in a car’s technology. 
 “This car would of course go through life experience and collect more data, the data would go to the AI factory,” said Huang. 
 “The AI factory would improve the software and update the entire end to end system.”
 The pair joked that the Model B designation stood for “beauty” and “beast.”
 Liu, as far back as 2020, had sketched out a goal of capturing 10% of the global EV market by 2025, from essentially nothing. 
 But Hon Hai, also known as Foxconn, has stumbled in some of its early initiatives. 
 Hon Hai’s EV unit, Foxtron, and Taiwanese partner Yulon Motor Co are scheduled to deliver their first cars to customer Luxgen Motor Co in the fourth quarter. But it is not clear when mass production of the car will start. — Bloomberg",taipei hon hai precision industry maker apple iphone push electric vehicle artificial intelligence bolster strategy hottest segment automotive industry event complete laser music hon hai chairman drove stage shiny blue model electric car surprise guest jensen huang chief executive officer chip leader nvidia corp talk effort vehicle technology autonomous feature concept factory company data ev improvement car technology car life experience collect data data factory huang factory improve software update entire system pair model designation beauty beast liu goal global market hon hai foxconn initiative hai unit taiwanese partner yulon motor car customer luxgen motor fourth quarter mass production car start bloomberg,"[(4, 0.99084395)]",4
605892,Main,7,18/10/2023,Crucial step towards responsible use of AI,,"KUALA LUMPUR: Malaysia is aligning its approach to artificial intelligence (AI) governance with emerging regulatory models, coinciding with the growing global call for effective governance, says Deputy Prime Minister Datuk Seri Fadillah Yusof. 
 He said the Science, Technology and Innovation Ministry (Mosti)  is bolstering the AI ecosystem foundation covering governance, platforms, talent and acculturation.
 “This includes the development of guidelines for the responsible use of AI and a code of ethics and governance.
 “Ethical concerns surrounding AI have gained global prominence and in Malaysia, the government’s consideration of a regulatory framework for AI is a crucial step toward the ethical use of this technology,” he said when opening the UK-MY Artificial Intelligence Conference 2023 co-organised by Mosti and the British High Commission here yesterday.
 He said the advent of AI is not only a disruptor but also a  creator of new job opportunities which requires reskilling and upskilling initiatives, Bernama reported.
 In response to this, the Malaysian government is taking proactive steps to build a strong foundation ensuring that the workforce can meet the industry’s demand for AI across various sectors, he said.
 Fadillah said through Mosti, a series of town hall sessions with industry leaders are being organised to facilitate reskilling and upskilling programmes and these efforts aim to transform the existing workforce’s skills and to adapt to the evolving requirements of AI technology.
 On the UK-MY Conference 2023, he said the event underscores the importance of strategic collaboration between Malaysia and the United Kingdom in science, technology and AI.
 He is optimistic that the conference will serve as a platform and an excellent avenue to seek support and establish connections.
 UK-MY AI 2023 will be a catalyst for positive transformation for AI in Malaysia and chart new paths towards broader market access, he added.",kuala lumpur malaysia approach artificial intelligence governance regulatory model global call effective governance deputy prime minister datuk seri fadillah yusof science technology innovation ministry mosti ecosystem foundation governance platform talent acculturation development guideline responsible code ethic ethical concern global prominence malaysia government consideration regulatory framework crucial step ethical technology artificial intelligence conference mosti british commission yesterday disruptor creator job opportunity initiative response malaysian government proactive step strong foundation workforce meet industry demand sector mosti series town hall session industry leader facilitate upskilling programme effort workforce skill requirement technology conference event strategic collaboration malaysia united kingdom science technology optimistic conference serve platform excellent avenue seek support connection catalyst positive transformation malaysia chart path market access,"[(4, 0.99277866)]",4
604640,Lifestyle,5,16/10/2023,AIof the tiger,Conservationists are using tiny cameras to help ‘protect’ endangered predators – and people.,"Tiger populations are on the rise in the jungles of India and Nepal, and the predators are roaming ever closer to villages, sparking a race among conservationists to find ways of avoiding conflict.
 They are increasingly finding solutions with artificial intelligence (AI), a bunch of technologies designed to reason and make decisions like humans.
 Experts from Clemson University in South Carolina and several non-profit groups (NGOs) published research last month on their work using AI-enabled cameras that they say could help revolutionise tiger conservation.
 They placed tiny devices around enclosures in the two South Asian nations, both to protect villagers from the predators and the predators from poachers.
 According to their research, published in the BioScience journal, the camera system called TrailGuard can distinguish between tigers and other species and relay images to park rangers or villagers within seconds.
 “We have to find ways for people, tigers and other wildlife to coexist,” Eric Dinerstein, one of the authors of the report, said.
 “Technology can offer us a tremendous opportunity to achieve that goal very cheaply.”
 The research claims the cameras were immediately effective, picking up a tiger just 300m from a village and, on another occasion, identifying a team of poachers.They say their system was the first AI camera to identify and transmit a picture of a tiger, and it has almost wiped out false alarms – when traps are tripped by passing boars or falling leaves.
 The scheme is one of several putting an AI spin on the established ideas of wildlife surveillance.
 Researchers in Gabon are using AI to sift their camera trap images and are now trying a warning system for elephants.
 Teams in the Amazon are piloting equipment that can detect the sounds of chainsaws, tractors and other machinery associated with deforestation.
 And US tech titan Google teamed up with researchers and NGOs four years ago to collect millions of images from camera traps.
 The project, called Wildlife Insights, automates the process of identifying species and labelling images, saving many hours of laborious work for researchers.Conservationists like Dinerstein, who also leads the tech team at the Resolve NGO, are sure that technology is helping their cause.‘Early warning system’
 Their goal is to ensure that 30% of the Earth’s land and oceans are designated protected zones by 2030, as agreed by dozens of governments last year, with that number eventually going up to 50%.
 Those zones will need to be monitored, and animals will need to move safely between protected areas.
 “That’s what we’re shooting for, and the critical element of that is an early warning system,” he said.
 The plight of tigers underscores the size of the challenge.
 Their habitats have been devastated across Asia, and their numbers in India fell to an all-time low of 1,411 in 2006 before steadily rising to current levels of around 3,500.
 In the mid-20th century, India was home to an estimated 40,000.
 ‘Jury still out’
 Jonathan Palmer, head of conservation technology at the US-based Wildlife Conservation Society (WCS), who was not involved in the study, said TrailGuard had exciting potential.
 But Palmer, who helped found Wildlife Insights with Google, said the broader uses of AI in conservation were not yet settled.
 “In most cases, AI species identification is still in its infancy,” he said.
 His NGO recommends outside verification of any species identification done by AI.
 And Palmer said the “jury was out” on whether AI was better deployed in cameras at the scene or afterwards on servers or laptops.
 Those uncertainties aside, Dinerstein is widening the rollout of TrailGuard, this time with even bigger animals in his sights.
 “Elephants wander outside parks all the time, and it leads to a massive amount of conflict,” he said.
 They destroy crops, cause chaos in villages, and can even cause train crashes, resulting in dozens of deaths every year, he added.
 “There’s an immense opportunity here to prevent that.” – AFP",tiger population jungle nepal predator closer village race conservationist conflict finding solution artificial intelligence bunch technology reason decision human expert university south carolina profit ngo month camera tiger conservation tiny device south asian nation villager predator predator poacher bioscience journal camera system distinguish tiger specie image ranger villager people tiger coexist eric dinerstein author technology tremendous opportunity goal cheaply claim effective picking tiger village occasion team poacher system camera identify transmit picture tiger false alarm trap boar leaf spin idea surveillance researcher sift camera trap image system elephant equipment detect chainsaw tractor deforestation tech titan google researcher collect million image trap project wildlife insight specie image hour laborious researcher conservationist tech team ngo technology system goal earth land ocean protected zone dozen government zone animal critical element system plight tiger underscore size challenge habitat asia india time low current level mid century india jury jonathan head conservation technology wildlife conservation society wcs potential palmer insight google broader conservation specie identification infancy ngo verification specie identification palmer jury camera scene server uncertainty rollout trailguard time bigger animal sight elephant park time massive amount conflict destroy crop chaos village crash dozen death immense opportunity prevent afp,"[(0, 0.13838178), (3, 0.8583342)]",3
604362,Main,28,15/10/2023,Legislators are still looking for a definition for AI,,"BACK in March in the United States, Hawaii state Senator Chris Lee introduced legislation urging US Congress to consider the benefits and risks of artificial intelligence (AI) technologies.
 But he didn’t write it. AI did.
 Lee instructed AI-powered ChatGPT to write a piece of legislation that highlights the potential benefits and drawbacks of AI. Within moments, it produced a resolution. Lee copied and pasted the entire text without changing a word. The resolution was adopted in April with bipartisan support.
 “It was making a statement that using AI to write legislation – a whole law – was perhaps the single biggest thing we could do to demonstrate what the good and the bad of AI could be,” said Lee.
 While organisations and experts have tried to define artificial intelligence, there is no consensus on a single definition. That leaves lawmakers the world over grappling with how to understand the technology so they can put rules in place.
 The National Artificial Intelli-gence Initiative Act of 2020 sought to define AI, describing it as “a machine-based system that can, for a given set of human-defined objectives, make predictions, recommendations or decisions influencing real or virtual environments,” according to the federal law enacted Jan 1, 2021.
 President Joe Biden’s Blueprint for an AI Bill of Rights extends the definition to “automated systems that have the potential to meaningfully impact the Ame-rican public’s rights, opportunities or access to critical resources or services”.
 The European Union, Google and many more entities have spelled out similar but differing definitions. But AI experts and legislators are still identifying a conclusive definition – and weighing whether a concrete definition is even necessary to pursue a regulatory framework.
 At the most basic level, AI refers to machine-based systems that produce an outcome based on information inputted to it, said Sylvester Johnson, associate vice provost for public interest technology at Virginia Tech.
 However, various AI programmes work based on how these systems have been trained to use data, which, Johnson said, legislators need to know.
 “AI is very fast moving,” he said. “If you really want people who make policy and legislative assemblies at the federal level or state levels to be richly informed, then you need an ecosystem that is designed to provide some kind of concise and precise way of updating people about trends and changes that are happening in the technology.”
 Deciding how broad the definition of AI should be is a significant challenge, said Jake Morabito, the director of the Communications and Technology Task Force at the American Legislative Exchange Council. 
 The “light touch” approach to regulating AI would help the US become a leader in technology on the global stage, but given the fervour over ChatGPT and other systems, legislators at all levels should be studying its developments for better understanding, Morabito said.
 “I just think this technology’s out of the bag, and we can’t put it back in the bottle,” Morabito said. “We need to fully understand it. And I think lawmakers can do a lot to get up to speed on understanding how we can maximise the benefits, mitigate the risks and make sure that this technology is developed on our shores and not abroad.”
 Some experts think legislators don’t need a definition to govern artificial intelligence. When it comes to an application of artificial intelligence – a specific area where AI is being used – a definition isn’t entirely required, argued Alex Engler, a fellow in governance studies at the Brookings Institution.
 Instead, he said, a core set of rules should apply to any programme that uses automated systems, no matter the purpose.
 “You can basically say, ‘I don’t care what algorithm you’re using, you have to meet these criteria,’” Engler said. “Now, that isn’t to say there’s literally no definition, it just means that you’re not counting some algorithms in and others out.”
 Focusing on the specific systems, such as generative AI that’s capable of creating text or images, may be the wrong approach, he said.
 The core question, Engler said, is this: “How do we update our civil society and our consumer protections so that people still have them in an algorithmic era?”
 Legislation some states passed over the last few years has attempted to answer the question. 
 The potential harms that come with using artificial intelligence are creating momentum for more regulation. 
 For example, some AI tools can produce tangible harm by replicating human biases, yielding decisions or actions that favour certain groups over others, said Megan Price, executive director of the Human Rights Data Analysis Group.
 “And so, the question really is when a mistake is made, what is the cost and who pays it?” she asked.
 A new focus on social justice in technology is also worth noting, Virginia Tech’s Johnson said. “Public interest technology” is a growing movement among social justice groups that’s focused on how artificial intelligence can work for public good and public benefit.
 “I think if there’s a reason to be hopeful about actually advancing our ability to regulate technology in a way that improves people’s lives, and their outcomes, this [public interest technology] is the way to go,” Johnson said. –  Stateline.org/Tribune News Service",march hawaii senator chris lee legislation congress benefit risk artificial intelligence technology lee chatgpt write piece legislation highlight potential benefit drawback moment resolution lee pasted entire text changing word resolution april bipartisan support statement write legislation law single biggest demonstrate bad lee organisation expert artificial intelligence consensus single definition lawmaker understand technology rule national artificial intelli gence initiative sought define machine system human objective prediction recommendation decision real virtual federal law jan president joe blueprint bill right definition system potential impact ame rican public right opportunity access critical resource service european union google entity definition expert legislator conclusive definition concrete definition pursue regulatory framework basic level refers machine system outcome inputted sylvester johnson associate vice public technology virginia tech programme system data johnson legislator people policy legislative assembly federal level level ecosystem concise precise people trend technology broad definition challenge jake morabito director communication technology task force american legislative exchange council touch approach leader technology global stage fervour chatgpt system legislator level development morabito technology bag bottle morabito understand lawmaker speed maximise benefit risk technology shore expert legislator govern artificial intelligence application artificial intelligence specific definition alex engler fellow governance study institution core set rule programme system algorithm meet criterion definition algorithm specific system generative capable text image wrong approach core question engler update civil society consumer protection people era legislation attempted answer question potential artificial intelligence momentum regulation tool tangible harm human bias decision action megan price executive director human right data analysis question mistake cost pay social justice technology virginia tech johnson public technology movement social justice artificial intelligence public public benefit reason hopeful ability regulate technology people outcome public technology johnson stateline tribune news service,"[(0, 0.7624316), (3, 0.23522359)]",0
603368,StarBiz,10,12/10/2023,S-E Asia countries opt for business-friendly AI rules,Direction runs counter to European Union’s ambitions,"SINGAPORE: South-East Asian countries are taking a business-friendly approach to artificial intelligence (AI) regulation in a setback to the European Union’s (EU) push for globally harmonised rules that align with its own stringent framework.
 Reuters reviewed a confidential draft of the 10-member Asean “guide to AI ethics and governance”, whose content has not previously been reported.
 Three sources told Reuters the draft is being circulated to technology companies for feedback and is expected to be finalised at the end of January 2024 during the Asean Digital Ministers Meeting. Companies that have received it include Meta , IBM and Google.
 EU officials earlier this year toured Asian countries in a bid to convince governments in the region to follow its lead in adopting new AI rules for tech firms that include disclosure of copyrighted and AI-generated content.
 In contrast to the EU’s AI Act, the Asean “AI guide” asks companies to take countries’ cultural differences into consideration and doesn’t prescribe unacceptable risk categories, according to the current version reviewed. Like all Asean policies, it is voluntary and is meant to guide domestic regulations.
 With almost 700 million people and over a thousand ethnic groups and cultures, south-east Asian countries have widely divergent rules governing censorship, misinformation, public content and hate speech that would likely affect AI regulation. Thailand, for example, has laws against criticising its monarchy.
 Technology executives say Asean relatively hands-off approach is more business friendly as it limits the compliance burden in a region where existing local laws are already complex and allows for more innovation.
 “We are also pleased to see this guide aligns closely with other leading AI frameworks, such as the US National Institute of Standards and Technology’s (NIST) AI Risk Management Framework,” IBM Asia’s vice president of government affairs Stephen Braim said, referring to voluntary guidelines developed by NIST.
 Meta and Google did not respond to request for comment.
 The guide, which is meant to be periodically reviewed, urges governments to aid companies through research and development funding and sets up an Asean digital ministers working group on AI implementation.
 Senior officials in three Asean countries said they are bullish on the potential of AI for south-east Asia and believe the EU has been too quick to push for regulation before the harms and benefits of the technology are fully understood.
 The Asean guide advises companies to put in place an AI risk assessment structure and AI governance training, but leaves specifics to companies and local regulators.
 “We see it as putting ‘guardrails’ for safer AI,” one official told Reuters. “We still want innovation.”
 The guide warns of the risks of AI being used for misinformation, “deepfakes”, and impersonation, but leaves it to individual countries to work out the best way to respond.
 Other Asian nations such as Japan and South Korea have flagged similarly relaxed approaches to AI regulation, casting doubts over the EU’s ambition to establish a global standard for AI governance based on the rules that would apply to its 27 member states.
 Driving the EU push are concerns in Brussels about the rapid pace of AI development and its effect on civil rights and security, which have put risk controls and enforcement at the centre of the proposed legislation.
 While Asean does not have any powers to make laws, its preference for member states to make their own policy determinations puts those countries on a distinctly different track to the EU.
 The EU’s struggles to create global consensus on AI regulation contrast with its mostly successful campaign last decade to establish data protection laws that have become a template for other major economies around the world.
 “What we think is important is to have similar principles,” a European Commission spokesperson told Reuters. “We are not seeking full harmonisation, as we are mindful of cultural differences, however, we regard the underlying principles as important.”
 EU officials and lawmakers said that the bloc would continue to hold talks with south-east Asian states to align over broader principles. — Reuters",singapore south east asian country business artificial intelligence regulation setback european union push rule align stringent framework reuters confidential draft asean guide ethic governance content source reuters technology company finalised january asean digital minister meeting company meta ibm google official toured asian country convince government region lead rule tech firm disclosure content contrast asean guide company country cultural difference consideration prescribe unacceptable risk category current version asean policy voluntary guide domestic regulation people ethnic culture east asian country divergent rule censorship misinformation public content hate speech regulation thailand law monarchy technology executive hand business friendly limit compliance burden region local law complex innovation guide aligns framework national institute standard technology nist risk management framework ibm asia vice president government affair braim voluntary guideline nist meta google respond request comment guide urge government aid company development set asean digital minister implementation senior official asean country bullish potential south east asia quick push regulation benefit technology understood asean guide company risk assessment structure governance training specific company local regulator guardrail official reuters innovation guide risk misinformation deepfakes impersonation individual country asian nation south korea relaxed approach regulation casting doubt ambition global standard governance rule push concern brussels rapid pace development civil right security risk control enforcement centre legislation asean power law preference policy determination country global consensus regulation contrast successful campaign decade data protection law major economy principle european commission spokesperson reuters harmonisation mindful cultural difference principle official lawmaker hold talk east asian align broader principle reuters,"[(3, 0.99655896)]",3
602864,Main,14,10/10/2023,Seoul to use  AI to enhance public safety,Rise in concern over safety on  the subway after violent incidents,"Seoul has   unveiled plans for developing an artificial intelligence-based system to monitor and track unusual behaviour among subway passengers, inclu­ding instances of violence, with the goal of completing the system by the end of the year.
 The announcement from Seoul Metro and the Seoul Digital Foun­dation comes in the wake of a series of incidents that have heightened public concern about safety on the subway.
 These include a stabbing incident in August that saw two passengers injured.
 In September, a rush was also provoked by a false alarm about a stabbing on the same subway line and injured 18 passengers.
 The project’s objective is to create a real-time monitoring and detection system for identifying abnormal behaviour among subway passengers. 
 This will be done by utilising AI-powered “image captioning” technology. This technology translates images or video footage into textual descriptions.
 The generated text can then be forwarded to subway officials for immediate action should an incident take place.
 The two organisations signed a memorandum of understanding on Friday last week for the project and have set the goal of completing the design and technical testing phase by December.
 They plan to choose one station for initial testing. After successful initial tests, the system will be expanded to cover all stations and subway cars by 2025.
 Seoul Metro said the project is expected to bolster the response capabilities of the authorities during critical situations by fostering collaboration between the police and subway security personnel.
 “The AI-powered system for detecting and tracking abnormal behaviour will evolve into a technology that enables a more effective response to incidents targeting members of the public,” said Baek Ho, chief executive officer of Seoul Metro.
 “We are committed to establishing a secure subway environment by harnessing the infrastructure of Seoul Metro and the technical expertise of the Seoul Digital Foun­dation.” — The Korea Herald/ ANN",seoul plan artificial intelligence system monitor unusual behaviour subway passenger instance violence goal system announcement seoul metro seoul digital foun dation wake series incident public concern safety incident august passenger september rush false alarm injured passenger objective create real time detection system abnormal behaviour subway passenger image technology technology translates image footage textual description text forwarded subway official action incident organisation memorandum friday week project goal design technical phase december plan station initial successful initial test system cover station car seoul metro project bolster response capability authority critical situation collaboration police security personnel powered system abnormal behaviour technology enables effective response incident public baek chief executive officer secure subway environment infrastructure technical expertise seoul digital foun dation korea herald ann,"[(4, 0.99316835)]",4
600446,StarBiz,13,05/10/2023,"Adopt AI or be left  behind again, says Son",Softbank working with Microsoft to market OpenAI,"TOKYO: SoftBank Group Corp’s billionaire founder Masayoshi Son has implored a Japanese audience to embrace artificial intelligence (AI), making an impassioned speech for early adoption at his first public appearance in months.
 Japan, which largely missed the initial wave of growth from the Internet, can’t afford to lose another three decades, Son said during an upbeat keynote address at SoftBank World, an annual event for the tech investor’s domestic corporate clients. 
 Noting that more than 70% of companies in Japan either ban or are considering banning the use of generative AI, Son waved his arms in frustration.
 “Saying ‘Don’t use AI’ is like saying, don’t drive a car or use electricity,” he said yesterday. “Whether you like it or not, the AI revolution will come.”
 Son has stayed away from the public eye this year after suffering what he called a crisis of confidence over mounting losses at SoftBank’s flagship Vision Fund. 
 But a surge in interest in AI, spurred by OpenAI’s ChatGPT, along with the initial public offering of chip architect Arm Holdings Plc last month appears to have revived his spirits.
 The Vision Fund, which invested billions of dollars into hundreds of startups, lost more than US$30bil in the last financial year and shifted into a defensive, largely dormant mode. 
 But now SoftBank, which is sitting on more than US$40bil in cash, is preparing to go back on the offensive again, executives have said. 
 Son’s enthusiasm for AI was on display during his 90-minute presentation, which began with an illustration of a goldfish in a fishbowl. 
 People who refuse to use AI will end up akin to that goldfish, unable to process information like language, he said. 
 The sum of knowledge that AI will command will be 10 times that of all humanity within 10 years, he added.
 Arm chief executive officer (CEO) Rene Haas appeared during Son’s presentation to explain how the chip designer’s power-efficient architecture will become even more key with the spread of AI-wielding devices in the future. 
 SoftBank is embracing AI, Son said. SoftBank Corp, Japan’s third-largest wireless carrier, has tied up with Microsoft Corp to market OpenAI services in the country and is working on its own Japanese language chatbot. 
 The telecom firm has sway over payments arm PayPay Corp, messaging app Line and search engine Yahoo Japan.
 “Wake up, Japan!” Son told his audience. The CEO said he likes to watch ChatGPT-bots debate as a cheaper alternative to watching his directors argue over ideas. 
 “I want to be standing on the side of evolution. I don’t want to be left behind.” — Bloomberg",tokyo corp billionaire founder masayoshi son japanese audience artificial intelligence speech adoption public appearance month initial wave growth internet afford decade son upbeat keynote address annual event tech investor domestic corporate client company ban generative son arm frustration drive car electricity yesterday revolution son public eye crisis confidence mounting loss flagship vision fund surge openai chatgpt initial public offering chip architect arm holding month spirit vision fund billion dollar hundred bil financial defensive dormant mode softbank bil cash offensive executive enthusiasm display minute presentation illustration goldfish fishbowl people akin goldfish unable process language sum knowledge command time humanity arm chief executive officer ceo rene haas son presentation chip designer power efficient architecture key spread device future son corp japan largest wireless carrier microsoft corp market openai service country japanese language chatbot telecom firm sway payment arm paypay corp app search engine yahoo japan japan son audience ceo chatgpt bot cheaper alternative watching director idea evolution bloomberg,"[(3, 0.6563202), (4, 0.33910507)]",3
600000,StarBiz,8,04/10/2023,Push for conversational AI investment,,"HO CHI MINH CITY: Brands in Vietnam and the Asia-Pacific region are strongly investing in commercial conversation to improve the customer experience, say experts.
 A total of 80 million Vietnamese residents use the Internet out of a total population of 99 million as of January, which contributes to the popularity of social networking platforms.
 Therefore, the potential for conversational commerce in Vietnam is wide, according to the experts.
 Telecommunications service providers in the country have used conversational commerce platforms for account notifications and to offer hyper-personalised promotions and discounts to customers.
 In addition to Facebook and Instagram, Vietnamese are very active in using communication apps such as Zalo and Viber.
 Furthermore, eCommerce is one of the fastest-growing business segments in the country.
 Many online retailers in Vietnam are using conversational artificial intelligence (AI) and chatbots to address customer queries in real time and keep customers apprised of order updates.
 For instant messaging, brands use communication platforms as a service and software as service-based solutions as crucial tools, empowering organisations to seamlessly integrate real-time communication features such as voice, text, video, instant messaging, and social media into their internal and external applications. —Viet Nam News/ANN",chi city brand vietnam asia pacific region commercial conversation customer experience expert total vietnamese resident internet total population january contributes social networking platform potential conversational commerce vietnam wide expert telecommunication service provider country conversational commerce platform notification hyper promotion discount customer addition instagram vietnamese active communication apps zalo viber ecommerce fastest business segment country retailer conversational artificial intelligence chatbots customer query real time customer update instant brand communication platform service software service solution crucial tool organisation real time communication feature text video instant social medium internal external application viet nam news ann,"[(0, 0.55623746), (3, 0.43695715)]",0
600026,StarBiz,12,04/10/2023,Tech giants battling  for content to build AI,Microsoft testimony in Google antitrust case,"WASHINGTON: Microsoft chief executive Satya Nadella says tech giants were competing for vast troves of content needed to train artificial intelligence (AI), and complained Google was locking up content with expensive and exclusive deals with publishers.
 Testifying in a landmark US trial against its rival Google, the first major antitrust case brought by the United States since it sued Microsoft in 1998, Nadella testified the tech giant’s efforts to build content libraries to train their large language models “reminds me of the early phases of distribution deals”.
 Distribution agreements are at the core of the US Justice Department’s antitrust fight against Google. The government said that Google, with some 90% of the search market, illegally pays US$10bil annually to smartphone makers like Apple and wireless carriers like AT&T and others to be the default search engine on their devices.
 The clout in search makes Google a heavy hitter in the lucrative advertising market, boosting its profits.
 Nadella said building AI took computing power, or servers, and data to train the software. On servers, he said: “No problem, we are happy to put in the dollars.”
 But without naming Google, he said it was “problematic” if other companies locked up exclusive deals with big content makers.
 “When I am meeting with publishers now, they say Google’s going to write this cheque and it’s exclusive, and you have to match it,” he said.
 Nadella also testified that Microsoft had sought to make its Bing search engine the default on Apple smartphones but was rebuffed.
 John Schmidtlein, Google’s lead lawyer, pressed Nadella on occasions when Microsoft did win default status on computers and mobile phones, but users still bypassed Bing and continued to use Google by a wide margin.
 Schmidtlein argued that Microsoft had made a series of strategic errors that led to Bing’s inability to grab a foothold, including a failure to invest in servers or engineers to improve Bing and a failure to see the mobile revolution.
 Schmidtlein also said Microsoft’s success in becoming the default, on some Verizon phones in 2008, and BlackBerry and Nokia in 2011, ended with the same result – users bypassed Bing and did the vast majority of their searches on Google.
 On laptops, most of which use Microsoft operating systems, Bing is the default search engine and has a market share below 20%, Nadella acknowledged.
 “You get up in the morning and you brush your teeth and you search on Google,” he added in a reference to Google’s dominance in search.
 Judge Amit Mehta, who will decide the case being tried in the US District Court for the District of Columbia, asked Nadella why Apple would switch to Bing given the Microsoft product’s lower quality.
 The question suggests Google’s argument, that it is dominant because of its quality and not because of illegal activity, has caught the judge’s interest.
 Nadella became chief executive officer of Microsoft in 2014, long after the tech giant faced its own federal antitrust lawsuit. 
 That court fight, which ended in a 2001 settlement, forced Microsoft to end some business practices and opened the door to companies like Google.
 As Google, which was founded in 1998, became an industry leading search engine, the two became bitter rivals. 
 Both have browsers, search engines, email services and a host of other overlaps. They became rivals in AI more recently, with Microsoft investing heavily in OpenAI and Google building the Bard AI chatbot among other investments. — Reuters",washington microsoft chief executive satya nadella tech giant vast trove content artificial intelligence google locking content expensive exclusive deal publisher landmark trial rival google major antitrust united microsoft nadella tech giant effort content library language model phase distribution deal distribution agreement justice department antitrust fight google government search market smartphone maker apple wireless carrier search engine device search google heavy hitter lucrative advertising market profit building power server data train software server happy dollar google problematic company exclusive deal content maker publisher write cheque exclusive match nadella microsoft search engine default apple smartphones john schmidtlein google lead lawyer nadella occasion default status computer phone user google wide margin schmidtlein microsoft series strategic error inability grab failure invest server engineer failure mobile revolution schmidtlein microsoft success default verizon phone nokia result user vast majority search laptop microsoft system default search engine market share morning brush search google reference google dominance search judge amit mehta decide district court district columbia nadella apple switch microsoft product lower quality question argument dominant quality illegal activity judge nadella chief executive officer microsoft tech giant federal antitrust lawsuit court settlement microsoft business practice door company google industry search engine bitter rival browser engine service host rival microsoft openai google bard chatbot investment reuters,"[(2, 0.99607456)]",2
600178,Main,26,04/10/2023,Tom Hanks warns of ad with AI imposter,,"San Francisco: Actor Tom Hanks and CBS talk show co-host Gayle King on Monday were warning fans about ads featuring imposters generated by artificial intelligence.
 “Beware,” Hanks said in an Instagram post that evidently showed a copy of an unauthorised digital version of him.
 “There is a video out there promoting some dental plan with an AI version of me. I have nothing to do with it.”
 The message had received more than 111,700 “likes” since the Academy Award winning actor posted it to his 9.5 million followers on Instagram on Sunday.
 King, a co-host of CBS Mornings talk show, posted what she said was a bogus video clip of her enticing viewers to click on a link to learn about her weight loss “secret”.
 “I have nothing to do with this company,” King said in her Instagram post.
 “I’ve never heard of this product or used it! Please don’t be fooled by these AI videos.”
 Safeguards against artificial intelligence being used to replicate screen talent was among the issues fought over during a writers strike that paralysed Hollywood until a recent tentative deal.
 The still ongoing strike by Hollywood actors has yet to be resolved.
 Generative AI programs burst into the spotlight late last year, with ChatGPT demonstrating an ability to generate essays, poems and conversations from the briefest prompts. — AFP",san francisco actor tom hank talk host gayle monday warning fan ad imposter artificial intelligence beware instagram post unauthorised digital version video dental plan version message like actor follower instagram sunday king host cbs morning talk bogus video clip viewer click learn weight loss secret company instagram post heard product video safeguard artificial intelligence replicate screen talent issue writer strike hollywood tentative deal strike hollywood actor generative program late chatgpt ability generate poem conversation briefest prompt,"[(3, 0.9885626)]",3
599294,StarBiz,6,02/10/2023,"GRM to set up four AI centres in M’sia, S’pore",Company reiterates commitment to green energy,"KUCHING: Sarawak-based Global Resources Management Digital Solutions Sdn Bhd (GRM) is planning to set up four advanced artificial intelligence (AI) data centres in Malaysia and Singapore.
 One each of the data centres will be located in Sarawak and Singapore and two in Peninsular Malaysia.
 GRM executive director Slyvester Wong said the data centres will cater for high-computing AI servers with AI-ready high-capacity workload.
 “At the heart of these AI centres is our commitment to green energy,” he said during the “Digital Transformation through Accelerated Application” seminar here recently.
 Sarawak Premier Tan Sri Abang Johari Tun Openg, who opened the seminar, said the state authorities would study the possibility to supply green energy to power the proposed four Tier-4 AI data centres.
 Johari said with Sarawak’s huge hydropower potential, the state could produce more than 20,000 megawatt (MW) of green power by constructing more dams, without having to submerge large portions of landmass.
 This, he said, could be done through cascading dams which have been built in Europe, Tasmania and Nordic countries such as Denmark, Sweden, Norway, Finland and Iceland.
 State-owned Sarawak Energy Bhd currently owns and operates the hydroelectric dams in Bakun (2,400MW), Murum (944MW) and Batang Ai (108MW). 
 The company is currently building the Baleh dam (1,285MW), which is expected to come on stream in 2028.  
 Wong said GRM plans to lay two subsea fibre optic cables to connect Malaysia, Singapore and Indonesia.
 He said the South-East Asia Hainan-Hongkong Express Cable System (SEA-H2x) would be completed by end-2024 and would link Sarawak to two major Internet hubs in the world – Singapore and Hong Kong.
 “This is a significant step forward in enhancing Sarawak’s digital connection,” added Wong. 
 SEA-H2X is a submarine cable connecting Hong Kong, Hainan, the Philippines, Thailand, Borneo Island and Singapore, with options to extend to Vietnam, Cambodia, Peninsular Malaysia and Indonesia.
 The SEA-H2X cable system, according to media reports, consists of at least eight fibre pairs between Hong Kong and Singapore, with a design capacity of 160 tbps (terabits per second) to meet the growing bandwidth requirement in the region. 
 Terabits represents one trillion bits and per second which indicates the rate at which data is transmitted.
 The SEA-H2X consortium comprises China Moble International Ltd, China Unicom Global, Converage Information and Communications Technology Solutions Inc and PPTEL Sea H2X  Sdn Bhd.
 Wong said GRM’s seasoned technical team, backed by reliable strategic partners, will position the company to drive Sarawak’s digital transformation.
 Sarawak Digital Transformation under Post-Covid-19 Development Strategy (PCDS) 2030 is to adopt and utilise digital technology to change the way services are delivered and businesses are conducted as well as to boost efficiency and productivity in the state’s economic sector.
  Efforts under this enabler that will support Sarawak’s aspiration towards becoming a developed state include digitalising the private sector economy through technologies such as big data, Internet of Things, blockchain and enhancing digitalisation of government service delivery and infrastructure to drive ease of doing business.
 The Sarawak Digital Transformation under PCDS 2030 goes hand-in-hand with Sarawak Digital Economy Strategy 2018-2022, which outlines 47 strategic actions under eight economic sectors and seven enablers to leapfrog into the digital economy.",sarawak global resource management digital solution bhd grm planning advanced artificial intelligence data centre data centre peninsular malaysia grm executive director slyvester data centre server ready capacity heart centre green energy digital transformation application seminar sarawak premier tan sri abang johari tun openg seminar authority possibility supply green energy power tier data centre sarawak huge hydropower potential produce megawatt green power dam portion dam tasmania nordic country sweden iceland sarawak energy bhd hydroelectric dam murum batang company baleh dam stream grm plan subsea fibre optic cable malaysia singapore indonesia south east asia hainan hongkong cable system sea link sarawak major internet hub hong kong step sarawak digital connection sea submarine cable hong kong hainan philippine borneo island singapore option vietnam cambodia peninsular malaysia indonesia sea cable system medium report fibre pair design capacity tbps bandwidth requirement region terabit bit rate data sea consortium moble international china unicom global converage communication technology solution sea sdn bhd wong grm technical team reliable strategic partner position company drive sarawak digital transformation sarawak digital transformation post covid development strategy pcds utilise digital technology change service business boost efficiency productivity economic sector effort support sarawak aspiration private sector economy technology internet blockchain digitalisation government service delivery infrastructure drive ease business digital transformation pcds hand hand sarawak digital economy strategy strategic action economic sector enablers digital economy,"[(4, 0.99592644)]",4
599148,Main,28,01/10/2023,Embracing AI is the battle plan for call centres,,"IN a hotel ballroom packed with stakeholders from the world’s second-largest provider of outsourcing services, its main trade group leader issued a bold call: embrace generative AI, don’t fear it.
 The South-East Asian nation should tap the technology to “propel the sector to new heights of efficiency,” Jack Madrid, president of the IT & Business Asso­ciation of the Philippines, told an industry summit attended by some 800 delegates.
 “The AI train has left the station and it’s moving very, very fast,” he said late Thursday. 
 “We need to match that speed.”
 Like the rest of the world, the Philippines is bracing for disruption from AI as bots take on more call-centre jobs.
 Adapting to the technology is crucial for the Philippines, whose outsourcing sector accounts for around 8% of economic output and is a top source of dollars.
 Some companies are exploring how generative AI – a form of artificial intelligence trained to create new outputs based on existing dataset – can help in their operations. Accenture Plc’s Philip­­pine unit is studying the use of AI-powered “co-pilots” as “advisers” for call-­centre agents and to help their coders understand and create codes.
 “Our clients are very much starting to explore generative AI, so it’s important that the industry goes in lockstep with this,” Arvin Yanson, managing director of Accenture Philippines’ innovation hub, said in an interview on the summit’s sidelines.
 Even with this push, humans will remain important in outsourcing companies’ processes, given that the technology is still in its infancy and still has challenges with accuracy and more complex tasks, according to Yanson.
 “It is prudent to actually ensure that a human is still kept in the loop to either review, approve or modify what the generative AI is saying,” Yanson said.
 The government is also planning to set up an AI research centre where it will hire scientists to help smaller businesses explore and have access to new technology, Trade Secretary Alfredo Pas­cual said at the same event.
 Madrid said the prospects for the outsourcing sector remain bright despite the challenges posed by AI. 
 This year, the industry expects to achieve 23% of the 1.1 million jobs and a fifth of the US$29.5bil (RM138.7bil) additional revenue that it is targeting by 2028.
 “Artificial intelligence plus our emotional intelligence will be a very potent combination,” Madrid said. — Bloomberg",hotel ballroom stakeholder largest provider service main trade leader bold call embrace generative fear south east asian nation tap technology propel sector height jack madrid president business ciation philippine industry summit delegate train station late thursday speed rest philippine disruption bot centre job technology crucial philippine sector account economic output top source dollar company generative form artificial intelligence create output operation philip pine unit pilot adviser centre agent coder create code client generative industry lockstep yanson director accenture innovation hub interview summit sideline push human company technology infancy accuracy complex task yanson prudent human loop review generative yanson government planning centre hire scientist business access technology trade secretary pa cual event madrid prospect sector bright challenge industry job additional revenue artificial intelligence emotional intelligence potent combination madrid,"[(4, 0.9932508)]",4
598300,StarBiz,12,29/09/2023,"Meta putting AI in digital assistants, smart glasses",Firm also unveils latest Quest virtual reality headset,"NEW YORK: Meta chief Mark Zuckerberg says the tech giant is putting artificial intelligence (AI) into digital assistants and smart glasses as it seeks to gain lost ground in the AI race.
 Zuckerberg made his announcements at the Connect developers conference at Meta’s headquarters in Silicon Valley, the company’s main annual product event.
 “Advances in AI allow us to create different (applications) and personas that help us accomplish different things,” Zuckerberg said as he kicked off the gathering.
 “And smart glasses are going to eventually allow us to bring all of this together into a stylish form factor that we can wear.”
 Smart glasses are one of the many ways that tech companies have tried to move beyond the smartphone as a user-friendly device, but so far with little success.
 The second-generation Meta Ray-Ban smart glasses made in a partnership with EssilorLuxottica will have a starting price of US$299 when they hit the market on Oct 17.
 The smart glasses also add the ability for users to stream what they are seeing in real time, Zuckerberg said.
 “Smart glasses are the ideal form factor for you to let AI assistants see what you’re seeing and hear what you’re hearing.”
 Meta also introduced 28 AI characters that people can message on WhatsApp, Messenger and Instagram with “personalities” based on celebrities including Snoop Dogg, Paris Hilton and YouTube star MrBeast.
 Zuckerberg demonstrated an interaction with one such AI from the stage in a type-written chat, promising that the new bots would soon be voiced.
 “This is our first effort at training a bunch of AI that are a bit more fun,” Zuckerberg said.
 “But look, this is early stuff and these still have a lot of limitations, which you will see when you use them.”
 The event was the first in-person edition of Connect since 2019, before the pandemic, and announcements on generative AI were widely expected.
 Meta has taken a much more cautious approach than its rivals Microsoft, OpenAI and Google to push out AI products, prioritising small steps and making its in-house models available to developers and researchers.
 Meta also unveiled the latest version of its Quest virtual reality headset with richer graphics, improved audio and the ability for a wearer to see what is around them without taking the gear off, a demonstration for AFP showed.
 “This is going to be a big game changer and a big capacity improvement for these headsets,” Zuckerberg told developers gathered in a Meta headquarters courtyard.
 Quest 3 headsets are priced starting at US$499 and will begin shipping on Oct 10, according to Meta.
 This is substantially cheaper than Apple’s Vision Pro, which will cost a hefty US$3,499 when it is available early next year, in the United States only.
 The Quest 3 “is going to be the best value on the market for a long time to come,” said Meta chief technology officer Andrew Bosworth, to laughter from the audience.
 New game titles for Quest 3 included Assassin’s Creed Nexus from Ubisoft as well as a Roblox game. — AFP",york meta chief mark zuckerberg tech giant artificial intelligence digital assistant smart glass gain ground race zuckerberg announcement developer conference meta headquarters valley company main annual product event advance create application accomplish zuckerberg smart glass stylish form factor smart glass tech company friendly device success generation ray ban smart partnership essilorluxottica price market smart glass ability user real time zuckerberg smart ideal form factor assistant meta character people whatsapp messenger instagram personality celebrity snoop dogg hilton youtube star mrbeast zuckerberg interaction stage type bot effort training bunch bit fun zuckerberg stuff lot limitation event person edition pandemic announcement generative cautious approach rival openai google push product step house model researcher meta unveiled version quest virtual reality headset richer graphic improved audio ability wearer gear demonstration afp game changer capacity improvement headset developer meta headquarters quest headset shipping oct meta cheaper apple vision cost hefty united quest market time meta chief technology officer bosworth laughter audience game assassin creed nexus ubisoft roblox game afp,"[(3, 0.99473494)]",3
598302,StarBiz,12,29/09/2023,AI chip crunch: Startups vie for Nvidia’s vital component,,"SAN FRANCISCO: The artificial intelligence (AI) revolution is fully underway, but soaring demand for its most crucial component has startups scratching their heads on how they can deliver on AI’s promise.
 Generative AI’s lifeblood is a book-sized semiconductor known as the graphics processing unit (GPU) – built by one company, Nvidia.
 Nvidia chief executive officer and founder Jensen Huang made a wild bet years ago that the world would soon clamor for a powerful chip usually used for making video games, but that could build AI as well.
 No company working with the generative AI models that fuel today’s frenzy can get off the ground without Nvidia’s singular product: the latest model is the H100 and its accompanying software.
 That painful reality is one that Amazon, Intel, AMD and others are scrambling to fix with their own alternatives, but those attempts could take years.
 And with the biggest tech companies throwing all their financial might into generative AI, the smaller fish must go on the hunt to secure Nvidia’s holy grail.
 “Around the world, it is becoming very hard to get thousands of GPUs because all these big companies are putting in billions of dollars, stockpiling GPUs,” said Fangbo Tao, co-founder of Mindverse.AI, a Singapore-based startup.
 “There’s not a lot of GPUs around,” he said.
 Tao spoke to AFP at the TechCrunch Disrupt conference in San Francisco, where AI startups jostled to make their pitches to Silicon Valley’s venture capitalists (VC).
 ChatGPT took the world by storm just as Silicon Valley was caught in a nasty hangover from the pandemic when investors threw money at startups, convinced that life had gone irreversibly online.
 That turned out to be far-fetched, and the US tech scene entered a downturn with rounds of layoffs and VC money dried up.
 Thanks to AI, some of the old mojo is back, and anyone with those two letters on their resume will likely see a red carpet rolled out on the legendary Sand Hill Road, home to Silicon Valley’s most storied investors.
 But as the startups walk away with their VC cash, the money in their pockets will be quickly forked out to Nvidia for GPUs either directly or through providers to bring their AI dreams to execution.
 “We call on a lot of the big cloud providers (Microsoft, AWS and Google), and they all tell us even they are having trouble getting supplies,” said Laurent Daudet, chief executive officer of AI startup LightOn.
 The problem is most acute for companies involved in training generative AI models, which requires that power hungry GPUs work at peak capacity to process troves of data ingested from the Internet. — AFP",san francisco artificial intelligence revolution demand crucial component startup head generative lifeblood book semiconductor graphic unit gpu company nvidia chief executive officer founder jensen huang wild bet clamor powerful chip video game company generative model ground singular product model software painful reality intel amd alternative attempt biggest tech company financial generative fish hunt secure nvidia holy hard thousand gpus company billion dollar gpus fangbo tao founder mindverse singapore startup lot gpus tao afp techcrunch disrupt conference san francisco startup pitch silicon valley venture capitalist chatgpt storm silicon valley nasty hangover pandemic investor money startup life online tech scene downturn round money mojo letter red carpet legendary sand hill road silicon valley investor walk cash money pocket nvidia gpus bring execution call lot cloud provider aws trouble supply daudet chief executive officer startup lighton acute company generative model power hungry gpus peak capacity process trove data internet afp,"[(1, 0.9163443), (4, 0.079077944)]",1
598022,StarBiz,12,28/09/2023,Giant wireless carrier to triple investment in AI,SKTelecom unveils roadmap to become global leader,"SEOUL: The chief executive officer (CEO) of SK Telecom, South Korea’s largest wireless carrier by subscription, unveils the company’s roadmap to leap forward as a global artificial intelligence (AI) firm within the next five years by expanding its business and technology based on its AI assistant service, A.
 The telecom giant’s chief Ryu Young-sang introduced the firm’s new “AI pyramid strategy” that focuses on three major areas: AI infrastructure, AI transformation and AI service.
 It is the key to realising the firm’s goal as the “global AI firm” by creating new industrial innovations, he said.
 “The AI ​​gold rush has begun. SK Telecom is trying to run most aggressively into the AI revolution. Since telecom operators have no legacy, the AI revolution is a definite opportunity for us,” the CEO said. 
 “We’ll create business models that a telecom operator can do to be competitive in the market.”
 For this, the telecom company plans to triple its investment in AI-related business from 12% from in 2019 to 33% over the next five years to 2028 and achieve sales of more than 25 trillion won (US$18.5bil), while it logged some 17 trillion won in sales last year.
 “Disruptive innovation triggered by generative AI has already created new values in all areas of industry, our society and life. 
 “We will accelerate our execution ability and continue to expand investment in AI-related resources based on the strategy centred around self-reliance and cooperation,” Ryu said.
 As the AI ​​market is in full swing, data centre supply shortages, excessive power useage and rapid increases in carbon emissions have emerged as new social problems. 
 SK Telecom will introduce energy-saving solutions to solve the issues while making a foray into the global market. It is also planning to double the size of its domestic data centres by 2030, Ryu said.
 Sapeon Korea, a global AI semiconductor company that spun out from the telecom giant last year, will launch the next-generation inference AI chip, X330, by the end of this year. 
 It has the advantages of approximately twice the computational performance and 1.3 times the power efficiency compared to its competitors.
 To secure competitiveness in the multi- large language model sector, it will strengthen cooperation with major Big Tech firms such as OpenAI.
 SK Telecom looks to expand AI services to its existing telecommunications and IPTV services to reduce costs by more than 20% to 30% in the mid to long term, as well as to non-telecom sectors, including Urban Air Mobility, health care and media.
 At Tuesday’s event, the CEO announced the official launch of A, which began its beta service in May last year. 
 Based on A, the company will provide an AI phone service with call summary and calendar functions, an AI sleep management tool and an AI music service that can create users’ playlists.
 Additionally, SK Telecom plans to roll out a personal AI assistant roaming service that can provide about 1.2 billion telecom users in 45 countries, based on its global alliance formed in July. 
 The South Korean telecom firm joined hands with Germany’s Deutsche Telekom, the United Arab Emirates’ e& and Singapore’s Singtel to expand AI cooperation.
 “Just as we subscribe to two to three over-the-top platforms these days, telecom users are expected to use two to three personal AI assistants within the next three years,” the SK Telecom chief said. 
 “The personal AI assistant market will likely become a battleground for leading global firms in the near future.” — The Korea Herald/ANN",seoul chief executive officer ceo telecom south largest wireless carrier subscription unveils company leap global artificial intelligence firm business technology assistant service telecom giant chief ryu sang firm pyramid strategy major infrastructure transformation service key firm goal global firm industrial innovation gold rush telecom revolution telecom operator revolution definite opportunity ceo create business model operator competitive market company triple investment business sale bil sale disruptive innovation generative value industry society life accelerate execution ability investment resource strategy reliance cooperation ryu market data centre supply shortage excessive power useage rapid increase emission social telecom energy solution issue global market double size domestic data centre sapeon korea global semiconductor company telecom giant launch generation inference chip advantage computational performance time power efficiency competitor competitiveness multi language model sector cooperation major tech firm telecom expand service telecommunication iptv service cost mid term telecom sector urban air mobility health care medium tuesday event ceo official launch beta service company phone service call summary calendar function sleep management tool music service create user telecom plan personal assistant service telecom user country global alliance south korean telecom firm hand germany deutsche telekom united arab singtel expand cooperation subscribe top platform day user personal assistant telecom chief personal assistant market global firm future herald ann,"[(4, 0.99582297)]",4
598220,Main,5,28/09/2023,The dark side of AI on social media,Any picture can be manipulated; experts warned against sharing photos,"PETALING JAYA: Even innocent pictures or videos shared on social media can be turned into explicit content with artificial intelligence (AI), warns civil society.
 Especially vulnerable are women and children.
 Melaka Action Group for Parents in Education (Magpie) chairman Mak Chee Kin said parents should refrain from sharing pictures or videos of their children on social media.
 He said tech-savvy, irresponsible individuals could do all sorts of things with images or videos found online.
 “In this era of AI and advanced technology, incidents of scammed or doctored images, and in some cases, voices, are happening.
 “The truth is that the more one exposes themselves to social media, the higher the risks they will encounter,” he said.
 He pointed out that even those innocently sharing images or videos of loved ones on social media could be victims of undesired consequences.
 “What was supposed to be a fun and happy thing could lead to unforeseen problems,” Mak added.
 Parent Action Group for Education chairman Datin Noor Azimah Abdul Rahim said parents should prepare their children to be mentally strong and smart enough to face these technological challenges.
 “What we can do is take care of our own children and build their confidence and mental strength to overcome such situations.
 “Though it is easier said than done, it is best to talk about it with the children and strengthen their minds,” she said.
 When asked, Noor Azimah agreed that the culture of oversharing online is partly to blame, as children are too eager to share without realising the consequences.
 Persatuan Sahabat Wanita Selangor executive director Irene Xavier also said women should be cautioned to be wary of uploading pictures of themselves and their families.
 “We have cases of women who uploaded pictures of themselves in revealing positions for their boyfriends, and when the relationship goes sour, these pictures have been abused,” she said.
 She added that women should think hard before posting photographs of themselves.
 In September, a Melaka lawmaker highlighted how a private Telegram group uploaded hundreds of doctored and obscene pictures of innocent victims, comprising female executives, housewives and even young men.
 Kota Laksamana assemblyman Low Chee Leong said the doctored image included a 65-year-old grandmother wearing a bikini.
 Earlier this year, Mstar also highlighted how certain quarters used AI to superimpose women’s pictures in the nude.
 It quoted user @magmalaya who made a post on X (formerly known as Twitter) cautioning women against posting too much on social media due to this.
 The comment section of the post was also filled with users discussing how some were conducting “business” by selling the images.
 Recently, in Spain, over 20 girls in a town came forward as victims of AI-generated nude images, which were created by feeding an AI app with fully clothed pictures of themselves on social media.
 Some of the girls had received demands for payment from the creators of these images, or their pictures would be uploaded to adult websites.
 MCA Public Services and Complaints Department head Datuk Seri Michael Chong said devious individuals would usually conduct background checks on those they wanted to target through deep fakes.
 Chong said some of the cases he handled were between boyfriends and girlfriends and married partners who had parted ways.
 “There are cases of perpetrators superimposing images of people in obscene acts, destroying their reputation, and even extorting them for money.
 “If you are a victim, don’t keep it to yourselves. Speak to those around you or to non-governmental organisations that have expertise in dealing with such matters.
 “From there, weigh your options and decide what you want to do next,” he said, adding that this included lodging police reports.",jaya innocent picture social medium explicit content artificial intelligence civil society vulnerable woman child melaka action parent education magpie chairman mak chee parent picture video child social medium tech savvy irresponsible individual sort image online era technology incident doctored image voice truth social medium risk image social medium victim undesired consequence fun happy lead unforeseen mak parent action education chairman noor azimah rahim parent prepare child strong smart technological challenge child confidence mental strength overcome situation talk child noor azimah culture child eager share consequence persatuan sahabat wanita selangor executive director irene xavier woman wary uploading picture family woman picture position relationship sour picture woman hard photograph september melaka lawmaker private telegram hundred obscene picture innocent victim female executive housewife laksamana assemblyman low chee leong image bikini mstar quarter superimpose woman picture user post twitter woman social medium comment post user business selling image girl town victim nude image app picture social medium girl demand payment creator picture uploaded adult website public service complaint department head seri michael devious individual background check deep fake boyfriend girlfriend married partner perpetrator image people act reputation money victim governmental organisation matter option lodging police report,"[(4, 0.9956)]",4
597796,StarBiz,12,27/09/2023,Amazon to invest  in AI startup Anthropic,Venture will be largest deal directly related to AWS,"SAN FRANCISCO: Amazon.com Inc will invest as much as US$4bil in Anthropic, securing a crucial partner in its effort to become a major player in generative artificial intelligence (AI) and offering a vote of confidence in the hot startup.
 As part of the deal, Anthropic will move most of its software to Amazon Web Services (AWS) data centres, and use the cloud computing company’s homegrown chips to train the models it uses to power chatbots and other applications. 
 Besides getting access to Amazon’s computing power, Anthropic will gain a financial infusion that will help it pay the huge costs required to train and run massive AI models.
 AWS chief executive officer (CEO) Adam Selipsky said in an interview on Bloomberg Television that the company’s initial investment in Anthropic is US$1.25bil. 
 Amazon will have a minority position in the startup, the companies said in a statement on Monday.
 Amazon shares rose 1.6% to US$131.21 in New York.
 The eCommerce and cloud computing giant has long taken stakes in partners in areas it deems a priority, including cargo airlines, a grocery distributor and an electric truck manufacturer. 
 But if the investment in Anthropic lands anywhere near US$4bil, it would represent the largest known piece of corporate dealmaking directly related to AWS. 
 The unit has tended to build its own products rather than relying on technology or businesses purchased from others, making relatively modest acquisitions in a market of hype-fuelled, billion-dollar valuations. 
 Amazon said its engineers, including those who work outside of AWS, will have access to Anthropic’s models.
 AWS is the world’s largest seller of on-demand computing power and data storage. 
 But it has been widely seen as a laggard in the emerging field of computer models trained to generate text, images and other content because it has lacked both a hit product and a high-profile exclusive partner in the arena. 
 ChatGPT creator OpenAI runs its software on Microsoft Corp’s data centres, a partnership based on a US$13bil investment that has sparked a renewal for Amazon’s Seattle-area neighbour.
 “Amazon’s US$4bil investment in AI startup Anthropic may not move the financial needle for its cloud services unit in the near term, but it shows that it’s taking Microsoft’s perceived AI leadership seriously,” Bloomberg Intelligence analyst Poonam Goyal wrote in a note Monday.
 Amazon executives have said that it’s early days for so-called generative AI and that more than 100,000 customers have used the company’s machine-learning tools to date. 
 Anthropic’s foundational model, called Claude, was already available as part of an Amazon service called Bedrock, still in early release, that makes both Amazon and third-party models available to its customers.
 “We have tremendous respect for Anthropic’s team and foundation models and believe we can help improve many customer experiences, short and long-term, through our deeper collaboration,” Amazon CEO Andy Jassy said in a statement.
 Founded by OpenAI veterans, Anthropic has raised more than US$1bil to date with a pitch to make a safer kind of chatbot for such tasks as summarising, searching, answering questions and coding. 
 The company’s backers include Alphabet Inc’s Google, which invested almost US$400mil in Anthropic, Bloomberg reported in February. 
 Google is also an AWS cloud rival and builder of models used in generative AI.
 “By significantly expanding our partnership, we can unlock new possibilities for organisations of all sizes as they deploy Anthropic’s safe, state-of-the-art AI systems together with AWS’s leading cloud technology,” Anthropic co-founder and CEO Dario Amodei said.
 The deal also represents a milestone moment for Amazon’s in-house chipmaking effort, which includes processors called Trainium and Inferentia that are designed to power machine-learning applications. 
 Most cutting-edge AI applications rely on pricey chips built by Nvidia Corp that can be hard to come by. 
 Anthropic will use AWS chips to build and train future foundational models, the companies said.
 Selipsky said there was “huge demand” for the range of chips that power generative AI and that AWS had been ramping up the supply chain for the chips it designs. — Bloomberg",san francisco amazon bil anthropic crucial partner effort major player generative artificial intelligence vote confidence hot startup deal move software amazon web service data centre company homegrown chip model power chatbots application access power anthropic gain financial infusion pay huge cost massive model chief executive officer ceo adam selipsky interview bloomberg television company initial investment anthropic bil amazon minority position startup company statement amazon share york ecommerce cloud giant stake partner priority cargo airline grocery distributor electric truck manufacturer investment anthropic bil represent largest piece corporate aws unit build product technology business modest acquisition market hype dollar valuation engineer aws access anthropic model largest seller demand power data storage field computer model text image hit product profile exclusive partner arena creator openai software microsoft corp data centre partnership bil investment renewal amazon seattle neighbour amazon bil investment startup anthropic financial needle cloud service unit term microsoft leadership bloomberg intelligence analyst poonam goyal note monday executive day generative customer company machine learning tool foundational model amazon service bedrock release amazon party model customer tremendous respect anthropic team foundation model customer experience short term deeper collaboration ceo andy jassy statement openai veteran bil pitch chatbot task question company backer google mil anthropic bloomberg february google aws rival builder model partnership unlock possibility organisation deploy anthropic safe art system cloud technology anthropic founder ceo dario amodei deal moment amazon house effort processor trainium inferentia power machine learning application edge application pricey chip corp hard anthropic aws chip train future foundational model company huge demand range chip power generative supply chain chip bloomberg,"[(1, 0.9965863)]",1
597398,StarBiz,8,26/09/2023,"AI and digitalisation key to growing prospects, value for SMEs",,"GEORGE TOWN: Small and medium enterprises (SMEs) should embrace and harness technological advancements and artificial intelligence (AI) to optimise resources and enhance their value, emphasised industry experts during the Star Outstanding Business Awards (SOBA) LAB event held in Bukit Mertajam on Sept 21.
 SOBA LAB, which is an abbreviation of “Learn, Aspire, Build”, assists SMEs on their entrepreneurial journey through talks and discussions by business leaders and experts.
 In addition to workforce transformation and enhancing operational efficiency, rapid adoption of technology can also lead to improved cost optimisation, enriched customer experiences, and increased engagement, according to speakers at the event attended by more than 100 participants.
 RHB Bank Bhd SME banking head Yip How Nang stressed the importance of integrating human resources into digitalisation initiatives.
 “Digital technologies offer significant efficiencies, but without the right mindset for change, organisational weaknesses can be magnified. Businesses need a well-defined strategy before making significant investments, with human resources being an integral part of the digital journey rather than a component to be replaced,” he said.
 PKT Logistics Group Sdn Bhd chief revenue officer Kuan Eu Jin encouraged SMEs to embrace AI and digitalisation, noting their better affordability and ease of access today.
 “While the impetus for digitalisation or automation often comes from external sources, SMEs should seize the opportunity to overcome internal fears or hesitations regarding increased productivity and effectiveness. AI and digitalisation are becoming more affordable, making it an ideal time for SMEs to explore their options.
 “Initiating digitalisation and automation is never too late, as long as it aligns closely with business requirements,” he said.
 OPC Resources Sdn Bhd founder and chief executive officer Eric Ooi highlighted the potential benefits of AI-driven software in connecting departments in a company to conduct comprehensive market research.
 “Currently, we have systems running without the need for a server managed by third-party operators. This approach saves costs and allows smart systems to analyse market trends and outcomes, particularly in departments dealing with large volumes of data. Small industries concerned about the burden of digitalisation can always start on a smaller scale,” he said.
 The trio were sharing their perspectives on digitalisation and AI for productivity in Malaysian SMEs. The discussion was moderated by Krystelle Ma, bureau adviser for the PCCC YES Toastmasters Club.
 Meanwhile, 988 DJ and 180 Degree Strategic Sdn Bhd founder Chan Fong emphasised the potential of harnessing AI for brand vitality.
 Chan underscored the importance of recognising AI’s capabilities to enhance products or services, in addition to improving their brand image and value.
 To facilitate the engagement session, representatives of sponsors of the event shared their solutions for SMEs. Among them were Credit Guarantee Corp Malaysia Bhd (CGC) Prai sales marketing and processing senior executive Lim Khai Foong, PKT Logistics’ Kuan, CelcomDigi business exclusive partner Ivan Hor and RHB Bank Bhd group retail distribution business development head Koeh Bee Ling.
 SOBA Connect is part of SOBA 2023 organised by Star Media Group with CelcomDigi Bhd, CGC, PKT Logistics Group Sdn Bhd and RHB Bank Bhd as the main sponsors, and Malaysia External Trade Development Corporation (Matrade) as official trade promotion partner.
 Supported by Bursa Malaysia, SOBA is audited by BDO while radio stations 988 and Suria are official media partners.
 To take part in SOBA 2023 or for more information, call SMG Events (017-231 1789) or go to www.soba.com.my.",george town medium embrace harness technological advancement artificial intelligence optimise resource industry expert outstanding business award lab event bukit mertajam soba lab abbreviation learn aspire build assist entrepreneurial journey talk discussion business leader expert addition workforce transformation operational efficiency rapid adoption technology lead cost optimisation customer experience engagement speaker event participant rhb bank bhd sme head yip nang human resource digitalisation initiative digital technology efficiency organisational weakness business strategy investment human resource integral digital journey component pkt logistics bhd chief revenue officer kuan jin smes digitalisation affordability ease access impetus digitalisation automation external source opportunity internal fear hesitation productivity effectiveness digitalisation affordable ideal time smes option digitalisation automation late aligns business requirement opc resource bhd founder chief executive officer eric ooi potential benefit software department company comprehensive market system party operator save cost system analyse market trend department volume data industry burden digitalisation scale trio perspective digitalisation productivity malaysian smes discussion krystelle bureau adviser pcc toastmaster degree strategic sdn bhd founder chan potential harnessing brand vitality chan capability enhance product service addition brand image facilitate engagement session representative sponsor event solution smes credit guarantee corp malaysia bhd cgc prai sale senior executive lim khai foong pkt logistics kuan celcomdigi business exclusive partner ivan hor bank bhd retail distribution business development head koeh bee soba connect soba star medium bhd cgc pkt logistics rhb bank bhd main sponsor external trade development corporation official trade promotion partner bursa malaysia soba bdo radio station official medium partner call smg event,"[(4, 0.9962796)]",4
596158,Main,27,23/09/2023,Rights protected from AI misuse,Bollywood’s Anil Kapoor wins legal battle in landmark ruling,"New Delhi: The Delhi High Court ruled that the personality rights of Bollywood stalwart Anil Kapoor (pic) will be protected against any potential misuse of artificial intelligence (AI).
 Anil, renowned for his roles in hit films like Slumdog Millionaire, obtained an interim order against 16 defendants accused of infringing upon his personality rights, which encompass his name, likeness, image, and voice, reported Outlook India magazine on Wednesday.
 This court order prohibits the exploitation of Anil’s personality rights for commercial purposes or on social media platforms. 
 Justice Pratibha Singh also barred the use of AI tools to morph Anil’s image or use it to create GIFs for monetary gain, said Indian newspaper Business Standard on Thursday.
 The lawsuit arose after morphed videos and emojis featuring Anil’s iconic exclamation “jhakas” from the 1985 film Yudh went viral on social media. This saying, roughly translats to “awesome” or “wicked,” is now protected under the court order.
 As reported by The Hindu, Pravin Anand, Anil’s lawyer, highlighted instances of unauthorised merchandise sales and the collection of fees using Anil’s image as a motivational speaker, further emphasising the need for protection.
 Anand also pointed out that Anil’s image was morphed in a derogatory manner.
 The country’s Union Ministry of Electronics and Information Technology was asked to issue blocking orders against pornographic videos that used morphed images of Anil, reported Business Standard.
 After a detailed hearing, the court acknowledged Anil’s personality rights and imposed restrictions on the use of his personality rights without his permission.
 In a report by The Indian Express, the court said that technological tools such as AI now make it possible for any unauthorised user to make use of a celebrity’s persona.
 “The celebrity also enjoys the right of privacy and does not wish that his or her image, or voice, is portrayed in a dark manner as is being done on porn websites,” said the court.
 Speaking to Variety, Anil said he was very happy with the court order in his favour.
 This ruling underscores the growing importance of safeguarding celebrities’ personality rights in an era dominated by AI and digital media, setting a precedent for similar cases.
 “I think it’s very progressive and great for not only me, but for other actors also,” Anil told Variety. —  The Straits Times/ANN",delhi delhi court personality right bollywood stalwart anil kapoor pic potential misuse artificial intelligence anil role film slumdog millionaire interim defendant personality right encompass likeness image voice outlook india magazine wednesday court exploitation anil personality right commercial purpose social medium platform justice pratibha singh tool anil image create gifs monetary gain indian newspaper business standard thursday lawsuit video anil iconic exclamation jhakas film yudh viral social medium translats protected court hindu pravin anand lawyer instance unauthorised merchandise sale collection fee image motivational speaker protection anand anil image derogatory manner country union ministry electronics technology issue pornographic video image business standard hearing court anil personality right restriction personality right permission report indian express court technological tool unauthorised user celebrity celebrity privacy image voice dark manner porn website court variety anil happy court underscore celebrity personality right era digital medium precedent progressive actor told variety strait time,"[(1, 0.90744394), (3, 0.08809159)]",1
594474,StarBiz,6,18/09/2023,Poll: Malaysians optimistic AI will positively transform their careers,,"PETALING JAYA: Artificial intelligence (AI) is becoming more common in the workplace with LinkedIn noting seven out of 10 Malaysian professionals believe it will significantly change the way they work in the near future. 
 Generative AI innovations are prompting professionals to adapt to a more advanced and new way of working in the country, the social media platform said its research found. 
 However, the sheer rate of change is proven to bring mixed feelings to Malaysian professionals about the development of AI regarding their workplace. 
 While many are intrigued by the adoption of AI in their workplace, there is still a large majority of people who are still concerned about this fast-paced developing technology. 
 LinkedIn found 52% of working professionals in the country believe their colleagues are better versed in AI than they are, creating a sense of curiosity and enthusiasm for the future. 
 LinkedIn’s research found there was a 21 times global increase in English-language jobs mentioning new generative AI, demonstrating that AI could be an important step for those looking to develop their career. 
 “Although there may be challenges to AI adoption, Malaysians are optimistic that AI will positively transform their careers,” said LinkedIn in a statement.  
 Most Malaysian professionals are excited about the ability of AI to provide them with more work-life balance and allow them to do more high-value work to better showcase their abilities. 
 Statistics also show that 47% Malaysian professionals believe AI can contribute to more equitable career opportunities in the local workforce, while 50% believe AI can create even more job opportunities outside of larger cities. 
 This is as professionals can actively upskill their abilities in AI and leverage on AI’s resources to work remotely. 
 LinkedIn said professionals in Malaysia are of the opinion that AI will not only increase their access to the knowledge and skill sets required for their jobs, but will also highlight the unrivalled importance of human skills in advancing their careers. 
 LinkedIn Asean country manager for Malaysia and head of growth markets, Rohit Kalsy, said it is encouraging to see people focus on the positives that AI can bring to their working lives. 
 “This is undoubtedly an era of change with generative AI gaining more prominence in the workplace,” he said. 
 Rohit pointed out that 81% of professionals believe AI will likely become their invisible teammate in the next five years. 
 “With their time freed up, many are looking to invest in themselves by learning new skills, focusing on more creative and strategic work, and growing their professional network, all which are strong career boosters,” he added.",jaya artificial intelligence common workplace linkedin malaysian professional future generative innovation professional country social medium platform sheer rate change mixed feeling malaysian professional development workplace adoption workplace majority people paced technology linkedin professional country colleague sense curiosity enthusiasm future linkedin time global increase english language job generative step career challenge adoption malaysian optimistic transform career statement malaysian professional ability life balance showcase ability statistic malaysian professional contribute equitable career opportunity local workforce create job opportunity larger city professional upskill ability leverage resource linkedin professional malaysia opinion increase access knowledge skill set job unrivalled human skill career linkedin asean country manager head growth market kalsy encouraging people positive life change generative prominence workplace rohit professional invisible teammate time invest skill creative strategic professional network strong career booster,"[(0, 0.9933696)]",0
594426,StarBiz,7,18/09/2023,Pilot project set to explore AI-powered branding,,"SINGAPORE: IPG Mediabrands has announced a partnership with Google Cloud to develop a suite of generative artificial intelligence (AI) powered applications for brands.
 Under the terms of the partnership IPG Mediabrands would develop two pilot platforms, branded content generation (BrandVoice AI) and audience and research Insights (BrandPortrait AI).
 The BrandVoice AI pilot would use Google Cloud’s latest generative AI technology to codify the essence of brands so that written and image-based content can be ideated, briefed, and drafted in an automated, safe, and on-brand manner.
 The BrandPortrait pilot would use the advanced conversational capabilities of Google’s large language models to provide IPG Mediabrands strategists and planners with the ability to generate and summarise proprietary research and audience data.
 All content would be approved by the brands – IPG Mediabrands clients – before being utilised by the AI pilot platforms.
 The IPG Mediabrands Data and Technology Innovation department has been working exclusively on AI-based solutions for nearly four years, seeing AI as the ideal technology to augment the people and capabilities of IPG Mediabrands agencies.
 With deep practical expertise in AI for optimisation problems, as well as identity and bias removal and identification, the innovation team first experimented with generative AI technologies several years ago. Since then, the team has built applications and prototypes that generate ad copy, imagery, reporting insights and SEO content, all proven out in real-world campaign scenarios.
 SEO content is any content created with the goal of attracting search engine traffic.
 Having achieved success with its use of AI already, IPG Mediabrands would now use the power of Google Cloud’s generative AI support in Vertex AI, specifically the PaLM 2 language model, to take its solutions to the next level.
 Vertex AI  is a machine learning (ML) platform that lets a person train and deploy ML models and AI applications. PaLM 2 is a language model that Google is deploying to bring AI capabilities to all of its products, including Gmail, Google Docs and Bard.
 Eileen Kiernan, global CEO, IPG Mediabrands in a statement said: “We are excited to partner with Google Cloud to develop this new platform.
 “Not only does this partnership let us leverage market leading technology, but also we are aligned to Google’s responsible approach on data governance which ensures our clients information is well protected.
 “We know that the potential of this technology is just scratching the surface, but we believe that by placing brands at the centre of AI solutions, we get to a place where the true potential can be unlocked for brands and the industry overall.”
 Google Cloud managing director, partnerships, Manvinder Singh said: “IPG Mediabrands will help to empower brands in new ways with their AI-based platform.
 “The ability to quickly and effectively create content that is both engaging and aligned with brand values has the potential to help companies save money and more deeply connect with customers.”",ipg mediabrands partnership google cloud suite generative artificial intelligence application brand term partnership ipg mediabrands pilot platform content generation brandvoice audience insight brandvoice pilot google generative technology codify essence brand image content safe brand manner brandportrait pilot conversational capability language model ipg mediabrands planner ability summarise proprietary audience data content brand ipg mediabrands client utilised pilot platform mediabrands data technology innovation department solution ideal technology augment people capability mediabrands agency practical expertise optimisation identity bias removal identification innovation team generative technology team application prototype copy imagery reporting insight content real campaign scenario content content goal search engine traffic success ipg power google cloud generative support vertex palm language model solution vertex machine learning platform person deploy model application palm language model google bring capability product gmail google doc bard eileen kiernan global ceo ipg mediabrands statement partner google cloud platform partnership leverage market technology responsible approach data governance client potential technology surface brand centre solution true potential unlocked brand industry cloud director partnership singh ipg mediabrands brand platform ability create content brand value potential company money deeply connect customer,"[(3, 0.99517715)]",3
593860,StarEdu,7,17/09/2023,How to work with AI,,"ARTIFICIAL intelligence (AI) won’t take your job, economist Richard Baldwin told the World Economic Forum’s Growth Summit in Geneva, Switzerland, recently, but his next sentence wasn’t so reassuring – it’s somebody using AI who will take your job. He’s right, of course, at least for the time being. Now that generative AI, such as ChatGPT, can perform many intellectual tasks to a considerable level of speed and competency, it is no wonder that human jobs are considered at risk. 
 However, AI is not infallible – just ask lawyer Peter LoDuca, who learned this the hard way when he was representing a client who was suing Avianca Airlines in a New York federal court, claiming injuries from being hit by a cart during a 2019 flight.
 LoDuca decided to use ChatGPT to help him with his legal research and ended up citing eight prior cases, all of which were fabricated by the software. This ended up being not only embarrassing, but also highly damaging for the case.
 This phenomenon, in which generative AI produces what appears to be factual and relevant information that is totally confabulated, is known as “hallucination”. AI researchers are still working on eliminating this.
 So, how can we use AI to extend and enhance our capabilities, while ensuring that we do not fall prey to its shortcomings? Here are some suggestions:
 > Know yourself In the volatile, uncertain, complex and ambiguous (VUCA) age of AI, it is an existential necessity to differentiate human output from a machine’s, while remaining anchored and motivated. For us to add authentic value, we need to know who we are, what our purpose is, and how we wish to mobilise this purpose to make a positive impact on the world. 
 > Don’t share private or confidential informationSharing privileged information related to your business or that of your clients with the generative AI can be considered a serious misconduct as all your input will become part of the system’s training content.
 > Provide effective promptsWhen using generative AI to help you with work projects or school assignments, it is important to be as clear, direct and specific as possible. 
 It helps to provide the context and constraints of your enquiry, and to give examples of what you wish to receive. Using complete sentences and breaking down complex issues will aid AI in providing you with a more coherent answer.
 > Fact-check No matter how convincing the AI output is, check the produced content before sharing or using it as a basis for decision-making. Remember, AI can hallucinate.
 > Do not copy and paste You should use AI to inspire rather than replace you. Rewrite what you wish to adopt using your own words.
 > Be transparent If some work, or part thereof, is entirely produced by AI, mention that clearly to those assessing or using your work. They will appreciate your professionalism.
 > Provide value Whether you’re a student being graded for your work or an employee being compensated, your teacher or supervisor would want to see that you’re contributing value that is distinctive from what AI is capable of.> Use polite language The language we adopt when using AI will be used to train the system and we want the system to be trained positively. It is also nice to keep the “conversation” professional when providing prompts.
 > Stay out of harm’s way 
 Avoid using the AI to create content that is inappropriate, harmful or offensive even if you are just experimenting. Our actions have legal and moral implications.
 > Be proud of your workIf the work you are producing is delivered without any help from AI, write a declaration indicating that the work is done entirely by a human without the use of AI. 
 Our journey with AI is in its infancy, and the topic of working safely and effectively with this powerful new tool will continue to evolve. It pays to stay informed, as new guidelines are being developed and made available, but the suggestions above are a good place to start, at least for now. 
 PROF MUSHTAK AL-ATABI
 Provost and chief executive officer
 Heriot-Watt University Malaysia;
 Chairman
 Vice Chancellors’ Council for Private Universities",artificial intelligence job economist richard baldwin economic forum growth summit geneva switzerland sentence job time generative perform intellectual task considerable level speed competency human job risk infallible lawyer peter loduca client avianca airline federal court injury cart flight loduca chatgpt legal software phenomenon generative factual relevant confabulated hallucination researcher extend enhance capability fall prey shortcoming suggestion volatile uncertain complex ambiguous vuca age existential necessity differentiate human output machine anchored add authentic purpose mobilise purpose positive impact share private confidential privileged business client generative misconduct input system content effective promptswhen generative project school assignment direct specific context constraint example complete sentence complex issue aid coherent answer check matter output check content basis decision hallucinate copy paste inspire rewrite adopt transparent mention professionalism student employee teacher supervisor distinctive capable polite language language adopt train system system nice conversation professional providing prompt harm avoid create content inappropriate harmful offensive experimenting action legal moral implication write declaration human journey infancy topic powerful tool evolve pay guideline suggestion mushtak atabi provost chief executive officer heriot watt university malaysia chairman vice chancellor private university,"[(0, 0.66161615), (2, 0.3347898)]",0
593308,StarBiz,9,15/09/2023,S’pore investor GIC to tread carefully around AI,,"SINGAPORE: State investor GIC is treading carefully around the phenomenon of artificial intelligence (AI), but will stay focused on investment opportunities in companies that may benefit the most from the new technology.
 Chief executive Lim Chow Kiat said that there is always some hype around new and transformative technologies, and AI is no exception.
 He told the Milken Institute’s 10th Asia Summit at the Four Seasons Hotel in Singapore on Wednesday: “AI is, in our view, very important and has huge potential for transformation of all industries and everything we do. But the technology is still at an early stage in terms of its translation into business models and outcomes.
 “So, in that sense, we are a bit wary of some of the kind of short-term valuations in some of the early-stage start-ups, some of the new models.
 “We would be very cautious in deploying capital given the valuations and the lack of a real business model.”
 Investors worldwide are rushing to invest in the next big opportunity in AI since the launch of chatbot ChatGPT late last year.
 More recently, chipmaker Nvidia reported blockbuster financial results that sent its share price rallying by more than 100% in a matter of days.
 However, experts have warned investors against chasing the AI boom, advising them to invest only in companies that have credible strategies.
 Lim said there are certain companies or certain providers of AI technology and services that are in good stead. But companies like Internet platforms that host those AI services and products on their websites may benefit more.
 “Typically, they are not a one-act wonder. They have other businesses, and they already have customers. Those are interesting opportunities,” he added.
 He noted that GIC is focused on where the value will be captured as AI technology develops and is deployed. 
 “So, for investors, it’s quite important not to get caught in the front end of that revenue generation but look through the value chain and see where you know it actually is being captured.”
 Beyond AI, Lim said GIC sees long-term opportunities in infrastructure investments, especially those in energy transition and digitalisation.
 He also spoke about GIC’s China investment strategy at the conference.
 He said the company is “doubling down” on some sectors in China, while it remains cognisant of the difficult period the world’s second-largest economy is going through.
 “China is facing a very complex set of issues,” he said, referring to the decline in the property sector and high youth unemployment. — The Straits Times/ANN",investor gic artificial intelligence stay investment opportunity company technology chief executive lim chow hype transformative technology exception institute asia summit season hotel singapore wednesday view huge potential transformation industry technology stage term translation business model bit wary short term valuation start model cautious capital valuation real business model investor invest opportunity launch chatbot chatgpt late chipmaker nvidia financial share price matter day expert investor boom invest company credible strategy company provider technology service stead company platform host service product business customer opportunity captured technology deployed investor front revenue generation chain lim gic term opportunity investment energy transition digitalisation gic china investment strategy conference company sector cognisant difficult period largest economy china complex set issue decline property sector youth unemployment time,"[(2, 0.24186242), (4, 0.75267744)]",4
593330,StarBiz,12,15/09/2023,OpenAI launches office in Dublin with numerous job listings,,"DUBLIN: Artificial intelligence (AI) leader OpenAI is opening an office in Dublin, the Microsoft-backed company has announced.
 It is the company’s third office.
 Its headquarters are in San Francisco and it announced it was opening a London office in June.
 The Dublin office is starting small with three open jobs.
 These include an international payroll specialist, a business role and an Ireland policy and partnerships lead.
 OpenAI chief strategy officer Jason Kwon, however, said the company intends to open more roles in the near future.
 The Dublin office will not be the company’s European headquarters and there will not be an executive running the office, at least not yet, Kwon said.
 “We like to grow deliberately and not too rapidly. This is because we want to make sure that the culture of the company is established first in new offices before we scale up,” Kwon told Reuters.
 In opening a Dublin office, OpenAI is following a well-established American tech company strategy.
 In addition to access to a talent pool already familiar with the culture of companies like Meta and Google, Ireland is a good place to engage with Europe from a regulatory and business development standpoint, Kwon said.
 Tax implications did not play a role in the decision, as OpenAI is not profitable, Kwon said.
 OpenAI’s ChatGPT is the second fastest-growing app in history, after Meta’s Threads app.
 ChatGPT is an AI tool that can answer questions, tell stories, produce essays and even write code. The chatbot is so sophisticated that people are suddenly starting to see the true potential of AI and how, for better or for worse, it could define humanity’s future.
 It has created both excitement and alarm, bringing OpenAI into conflict with regulators, particularly in Europe, where the company’s mass data-collecting has drawn criticism from privacy watchdogs. — Reuters",dublin artificial intelligence leader openai office dublin company company office headquarters francisco london office june dublin office job international payroll specialist business role ireland policy partnership openai chief strategy officer jason company future dublin office company european headquarters executive office kwon culture company office scale told reuters office openai american tech company strategy addition access talent pool familiar culture company google ireland engage europe regulatory business development standpoint tax implication role decision profitable kwon openai chatgpt fastest app history meta thread chatgpt tool answer question story essay code chatbot sophisticated people true potential worse define humanity future excitement alarm openai conflict regulator company mass data drawn criticism privacy watchdog reuters,"[(4, 0.99241763)]",4
593494,Main,24,15/09/2023,"Musk, Zuckerberg visit  US congress to discuss AI",,"Washington: Big tech bigwigs including Elon Musk and Mark Zuckerberg travelled to Capitol Hill to share their plans for artificial intelligence as the US prepares to draw up legislation to better control the technology.
 Senator Chuck Schumer, the Democratic majority leader of the US Senate, has planned a series of so-called AI Innovation forums, closed door meetings where lawmakers can quiz tech leaders about the technology that has taken the world by storm since the release of ChatGPT last year.
 Europe is well advanced in its own AI Act and the pressure is on US lawmakers to avoid falling behind and seeing AI overwhelm society, with lost jobs, rampant disinformation and other consequences, before it is too late.
 “Today, we begin an enormous and complex and vital undertaking: building a foundation for bipartisan AI policy that Congress can pass,” Schumer said, according to remarks shared with the media. 
 OpenAI CEO and ChatGPT creator Sam Altman and Microsoft founder Bill Gates also attended the forum, which was closed to the press. — AFP",washington tech elon musk mark zuckerberg capitol hill share artificial intelligence prepares draw legislation control technology senator schumer democratic majority leader senate series innovation forum door meeting lawmaker tech leader technology storm release advanced pressure lawmaker overwhelm society job rampant disinformation consequence enormous complex vital undertaking building foundation bipartisan policy congress pas schumer remark medium openai ceo chatgpt creator sam altman microsoft founder bill forum press afp,"[(3, 0.9870477)]",3
591986,Lifestyle,5,11/09/2023,"Drones, AI and goats",Explore the playbook of innovative approaches reshaping wildfire prevention and control in a rapidly changing world.,"AS the planet continues to warm, so does the list of countries impacted by wildfires.
 Turkey, Greece, and Spain have all dealt with blazes this year, and last month’s wildfire in Hawaii killed at least 115 people and razed the town of Lahaina.
 Canada is in the throes of a historic wildfire season, with more than 15 million hectares burned. Officials there are scrutinising the limits of traditional firefighting tactics.
 In Europe, the fastest-warming continent due to climate change, firefighters are exploring new ways to battle monster blazes. Emergency and disaster management crews are deploying drones that can detect fires earlier and are even reviving traditional practices such as using sheep and goats to graze the grass.
 Here are some of the more innovative wildfire solutions:
 Drone defence
 Drones are becoming ubiquitous on the front line.
 Domingos Xavier Viegas, a professor at Coimbra University in Portugal who specialises in wildland fire behaviour, says departments across Europe are using drone technology to map vegetation, identify high-risk areas, track wildfires, collect data, and deliver last-mile water deposits during wildfires.
 Larger drones, some of them amphibious, are also being developed to act as aerial tankers or hose bearers. These firefighting robots can spray water and fire-retardant chemicals over longer distances and larger areas.
 This can also save the lives of firefighters who otherwise have to get “so close to the fires”, says Kenneth Geipel, founder of Danish drone company Robotto Co.Geipel started Robotto in 2019 after seeing the devastation left by record wildfires in Sweden, Greece, and California a year earlier.
 He felt firefighters lacked the data needed to map and tackle blazes at the earliest stages.
 While satellite imagery comes with delays, drones can, in real time, identify smoke or heat signatures, warn fire control authorities, and calculate the position, size, and intensity of a blaze, Geipel says.
 Artificial intelligence
 All of this new information requires more data processing. Drone sensors capture more data than is humanly possible to process in real time without using AI tools, Geipel says.
 In 2022, the World Economic Forum launched an AI and machine learning initiative called FireAId. The pilot project, started in Turkey in the wake of the country’s worst-ever wildfires in 2021, showed these tools can reduce response time and risk to firefighters.Training in 3D
 Training regimens for firefighters are also getting more high-tech and collaborative as departments in different countries compare best practices.
 In Catalonia, the Pau Costa Foundation has created a three-dimensional system that allows trainees and fire teams to run through emergency wildfire scenarios.
 This so-called “digital sandbox” helps students visualise the behaviour of a forest fire and practice fire-management strategies, preparation that can be particularly helpful for firefighters in northern European countries.
 “It’s something that major cosmopolitan cities like London have never experienced before,” says Sami Goldbrom, a group commander at the London Fire Brigade (LFB).
 “But it looks likely that we’re going to be experiencing them for the foreseeable future.”
 England saw its worst wildfire season last year; July 19, 2022, was LFB’s busiest day since World War II. The LFB has since set up training connections with Australia, Greece, and Spain.
 Vegetation-clearing robots
 The best way to tackle wildfires is to prevent them in the first place. That’s why selective culling of trees and smaller plants is an important aspect of reducing wildfire risk.
 Enter vegetation-clearing robots, which can remove potential wildfire fodder. Such devices are being developed and will work alongside drones, Viegas says.
 The drones map out the high-risk areas from above, and the mechanical foot soldiers weed out vegetation in those patches.
 Fire Flocks
 Until vegetation-clearing robots become more commercially viable, some fire-management bodies are relying on an age-old pastoral technique: inviting sheep and goats to do the same job.In Catalonia, so-called Fire Flocks – sheep or goats that graze on forest floors to clean up vegetation – are making a comeback.
 A project to revive this tradition was initiated in 2016, starting with a small pilot of just 48 hectares in the Baix Emporda region of Catalonia.
 By 2022, it had expanded to 651 hectares.
 Catalonia is one of the few places on the planet where fire prevention measures have reversed an increase in blazes, according to Marc Castellnou, a wildland fire incident commander and analyst with the Catalan Fire Service.
 During the 1990s, about 13,500 hectares burned in wildfires every year – roughly 1% of the region’s forests, he says. Since then, it has fallen to between 1,200 and 1,500 hectares each year, on average.
 But even the best mitigation strategies don’t negate the urgency of curbing greenhouse gas emissions to prevent fire risk from getting even worse. 
 “If a fire has a burning power of more than 10,000 watts per square kilometre, it can’t be extinguished no matter how many resources we put in,” Castellnou says.
 Some of Europe’s wildfires in recent years have hit six times that intensity. – Bloomberg",planet warm list country wildfire turkey dealt blaze month hawaii people town lahaina canada throe historic wildfire season hectare official limit traditional firefighting tactic fastest continent climate change firefighter battle monster emergency disaster management crew drone detect fire traditional practice goat grass innovative wildfire solution defence drone ubiquitous front domingo viegas professor coimbra university portugal specialises behaviour department drone technology map vegetation identify risk track wildfire data mile water deposit wildfire larger drone amphibious aerial tanker bearer robot spray water fire retardant chemical distance larger firefighter fire geipel founder danish drone company robotto geipel robotto devastation record wildfire sweden greece california firefighter data map earliest stage imagery delay real time smoke heat signature fire control authority position size intensity blaze artificial intelligence data drone sensor data real time tool economic forum machine initiative fireaid pilot project turkey wake country wildfire tool response time risk firefighter training firefighter tech collaborative department country practice pau costa foundation dimensional system trainee team emergency scenario digital sandbox student behaviour forest fire practice fire management strategy helpful firefighter northern european country major cosmopolitan city experienced sami goldbrom commander london fire lfb foreseeable future england worst wildfire season july lfb busiest day war lfb training connection spain vegetation robot tackle wildfire selective culling tree plant wildfire risk enter vegetation robot potential wildfire fodder device drone drone map mechanical foot soldier vegetation patch flock vegetation robot viable fire management body age pastoral technique sheep goat job catalonia fire flock goat forest floor clean vegetation comeback project revive tradition pilot hectare emporda region catalonia hectare catalonia planet fire prevention measure increase blaze castellnou wildland fire incident commander analyst catalan fire service hectare wildfire region forest hectare average mitigation strategy urgency greenhouse gas emission fire risk worse fire power watt extinguished matter resource europe wildfire time intensity bloomberg,"[(0, 0.7821307), (4, 0.21574913)]",0
591982,Lifestyle,6,11/09/2023,Can AI revolutionise responsibly?,"As data centres  thrive worldwide due to the artificial intelligence craze, there are pressing questions about keeping the digital revolution  eco-friendly.","ACROSS the globe, data servers are humming, consuming both megawatts and precious natural resources to bring life to our digital world.
 The planet’s 8,000 or so data centres are the foundation of our online existence and will grow ever further with the advent of artificial intelligence (AI) – so much so that research estimates that by 2025, the IT industry could use 20% of all electricity produced and emit up to 5.5% of the world’s carbon emissions.
 This poses a real – and to some, increasingly urgent – question about the industry’s carbon footprint as startups and companies fall behind Silicon Valley’s latest forward march.
 “Pandora’s box is open,” said Arun Iyengar, CEO of Untether AI, a highly specialised chip-making company that strives to make AI more energy efficient.
 “We can utilise AI in ways that enhance the climate requirements, or we can ignore the climate requirements and find ourselves facing the consequences in a decade or so in terms of the impact.”
 The transformation of the world’s data servers to AI readiness is already well underway, in what one Google executive called a “once-in-a-generation inflection point in computing”.
 But the scope of the mission is huge.
 The creation of generative AI tools such as GPT-4, which powers ChatGPT, or Google’s Palm2, behind the bot Bard, can be broken into two key stages: the actual “training” and then the execution (or “inference”).
 In 2019, University of Massachusetts Amherst researchers trained several large language models and found that training a single AI model can emit the CO2 emission equivalent of five cars over their lifetimes.
 A more recent study by Google and the University of California, Berkeley, reported that training GPT-3 resulted in 552 metric tonnes of carbon emissions, equivalent to driving a passenger vehicle 1.24 million miles (two million kilometres).
 OpenAI’s latest generation model, GPT-4, is trained on around 570 times more parameters (or inputs) than GPT-3, and the scale of these systems will only grow as AI becomes more powerful and ubiquitous.
 Nvidia, AI’s chip giant, provides the processors that are indispensable for training, known as GPUs. And while they are more energy efficient than typical chips, they remain formidable consumers of power.
 The ChatGPT challenge 
 The other side of generative AI is deployment, or inference, when the trained model is applied to identify objects, respond to text prompts, or whatever the use case may be.
 Deployment doesn’t necessarily need the computing heft of a Nvidia chip, but taken cumulatively, the endless interactions in the real world far outweigh training in terms of workload.
 “Inference is going to be even more of a problem now with ChatGPT, which can be used by anyone and integrated into daily life through apps and web searches,” said Lynn Kaack, assistant professor of computer science at the Hertie School in Berlin.
 The biggest cloud companies insist that they are committed to being as energy efficient as possible.
 Amazon Web Services pledges to be carbon neutral by 2040, while Microsoft has pledged to be carbon negative by 2030.
 The latest evidence that the companies are serious about energy efficiency is reassuring.
 Between 2010 and 2018, global data centre energy use rose by only 6%, despite a 550% increase in workloads and computing instances, according to the International Energy Agency.
 ‘Backwards’ thinking
 Silicon Valley’s AI tycoons believe discussions of AI’s current carbon footprint are beside the point and underplay its revolutionary potential.
 The naysayers have it “backwards”, Nvidia CEO Jensen Huang told reporters on a recent visit to his company’s headquarters in California.
 The mass deployment of AI and faster computing will in the end diminish the need to go to the world’s data clouds, he argued.
 AI’s superpowers will turn your laptop, car, or the device in your pocket into an energy-efficient supercomputer without the need to “retrieve” data from the cloud.
 “In the future, there’ll be a little tiny model that sits on your phone, and 90% of the pixels will be generated and 10% will be retrieved instead of 100% retrieved – and so you’re going to save (energy),” he said.
 OpenAI’s Sam Altman, meanwhile, believes that AI will soon be able to build humanity a completely new future.
 “I think once we have a really powerful superintelligence, addressing climate change will not be particularly difficult,” Altman said recently.
 “This illustrates how big we should dream ... Think about a system where you can say, ‘Tell me how to make a lot of clean energy cheaply, tell me how to efficiently capture carbon, and tell me how to build a factory to do this at a planetary scale’.”
 But some experts worry that the mad dash for AI has pushed out fears about the planet, at least for now.
 “Large corporations are spending a lot of money right now deploying AI. I don’t think they are thinking about the environmental impact yet,” said Untether AI’s Iyengar.
 But he added, “I think that is coming.” – AFP",globe data server precious natural resource life digital planet data centre online existence grow advent artificial intelligence estimate industry electricity emit carbon emission real urgent question industry carbon footprint startup company silicon valley pandora box arun iyengar ceo chip company energy efficient utilise enhance climate requirement climate requirement consequence decade term transformation data server readiness underway google executive generation inflection scope mission huge creation generative tool gpt power google palm bot broken key stage actual training execution inference university massachusetts amherst researcher language model single model emit emission equivalent car study google university california berkeley training gpt metric tonne carbon emission equivalent passenger vehicle mile openai generation model gpt time parameter gpt scale system powerful ubiquitous nvidia chip giant processor indispensable gpus energy efficient typical chip formidable consumer power chatgpt challenge generative deployment inference model identify object text prompt deployment heft nvidia chip endless interaction real outweigh training term inference chatgpt daily life apps web search kaack assistant professor computer science hertie school berlin biggest cloud company committed energy efficient amazon web service neutral microsoft carbon negative evidence company energy efficiency global data centre energy increase workload instance international energy agency backwards silicon valley tycoon discussion current carbon footprint underplay revolutionary potential naysayer backwards jensen huang reporter company headquarters mass deployment diminish data cloud superpower laptop car device pocket energy efficient supercomputer data cloud future tiny model phone pixel retrieved retrieved energy sam altman build humanity future powerful superintelligence climate change difficult altman dream system lot clean energy cheaply capture carbon build factory planetary scale expert mad dash fear planet corporation spending lot money environmental impact untether iyengar afp,"[(2, 0.99676245)]",2
591138,Main,27,09/09/2023,"Google wants disclosure on AI altered voice, images in political ads",,"San Francisco: Google will soon require that political ads using artificial intelligence be accompanied by a prominent disclosure if imagery or sounds have been synthetically altered.
 AI-generated election ads on YouTube and other Google platforms that alter people or events must include a clear disclaimer located somewhere that users are likely to notice, the company said in an update this week to its political content policy.
 The new rule starts in mid-November, just under a year before the US presidential election. 
 It will also affect campaign ads ahead of next year’s elections in India, South Africa, the European Union and other regions where Google already has a verification process for election advertisers.
 Though fake images, videos or audio clips are not new to political advertising, generative AI tools are making it easier to do, and more realistic. 
 Some presidential campaigns in the 2024 race – including that of Florida governor Ron DeSantis – already are using the technology.
 The Republican National Com­mit­tee in April released an entirely AI-generated ad meant to show the future of the United States if President Joe Biden is re-elected. 
 It employed fake but realistic photos showing boarded-up storefronts, armoured military patrols in the streets, and waves of immigrants creating panic.
 In June, DeSantis’ campaign shared an attack ad against his GOP primary opponent Donald Trump that used AI-generated images of the former president hugging infectious disease expert Dr Anthony Fauci.
 Last month the Federal Election Commission began a process to potentially regulate AI-generated deepfakes in political ads ahead of the 2024 election. — AP",san francisco google political ad artificial intelligence prominent disclosure imagery generated election ad google platform people event user notice company update week political content policy rule mid november presidential election campaign ad election south africa european union region verification process election advertiser image audio clip political advertising generative tool realistic presidential campaign race florida governor ron desantis technology republican national mit tee april generated meant future president joe biden employed fake realistic photo storefront armoured military patrol street immigrant panic june desantis campaign attack gop primary opponent donald trump image president infectious disease expert anthony fauci month federal election commission process regulate deepfakes political ad election,"[(1, 0.9914937)]",1
590974,Main,24,08/09/2023,Tencent says new AI chat bot skills comparable to ChatGPT,,"Chinese tech giant Tencent claimed its new chatbot had some capabilities on par with top US rival ChatGPT, as the global artificial intelligence race heats up.
 Tencent’s “Hunyuan Aide”, which it released to the public yesterday, follows the similar ERNIE Bot rolled out by fellow Chinese company Baidu last month.
 Beijing introduced fresh regulations last month for AI developers, aiming to allow them to stay in the race with the likes of ChatGPT maker OpenAI and Microsoft while tightly controlling information online.
 Tencent yesterday gave a live demonstration of Hunyuan Aide’s capabilities, with the bot introducing itself in response to questions typed by an employee on a laptop, and solving a simple arithmetic problem.
 Vice-President Jiang Jie said at the livestreamed summit that the bot outperformed US-based Open AI’s earlier model GPT-3.5 and was on par with GPT-4 in identifying trick questions such as “what is the safe way to speed”.
 It even exceeded the latter when answering questions from the Chinese university entrance exam, he said.
 “Compared to the open-source large language models common on the market presently, (our) method effectively reduces the hallucination rate by 30 to 50%,” Jiang said, referring to the false and nonsensical content frequently churned out by AI.
 Trained on more than two trillion tokens and equipped with more than 100 billion parameters – units of language and the variables connecting them – from up until July this year, Hunyuan Aide’s data set will be continuously updated, Jiang said.
 Hunyuan Aide has “powerful Chinese language writing ability, the ability to make logical inferences in complicated linguistic contexts, and reliable task execution ability”, Tencent said. — AFP",chinese tech giant tencent chatbot capability top rival chatgpt global artificial intelligence race tencent hunyuan aide public yesterday fellow chinese company month beijing fresh regulation month developer stay race chatgpt maker online tencent yesterday live demonstration hunyuan aide capability response question employee laptop simple arithmetic vice president jiang jie summit bot model gpt par gpt trick question safe speed answering question chinese university entrance exam source language model common market hallucination rate jiang false nonsensical content token parameter unit language variable july hunyuan data updated jiang hunyuan powerful chinese language ability ability logical inference linguistic context reliable task execution ability tencent afp,"[(0, 0.66632426), (1, 0.32728478)]",0
590422,Main,16,07/09/2023,OpenAI chief granted first golden visa,,"OpenAI chief executive Sam Altman (pic) has been granted Indonesia’s first golden visa, officials said, as South-East Asia’s biggest economy looks to attract wealthy foreign investors.
 The co-founder of the ChatGPT bot sensation was granted a 10-year visa for his potential contributions to the development of artificial intelligence (AI) in Indonesia, director-general of immigration Silmy Karim said in a statement late Monday.
 “Once the holders of the golden visa arrive in Indonesia, they no longer need to apply for a temporary stay permit at the immigration office,” he said.
 “We are rolling out the red carpet in return for the resources they provide to Indonesia,” he added.
 The US-based tech entrepreneur was also granted a special visa because of his international reputation as the head of the AI research and development company, the official said.
 With the golden visa, the 38-year-old American would be able to bypass immigration que­ues at Indonesia’s airports and enter and exit the country more easily, according to the statement.
 Indonesia has rolled out golden visas for investors who will get a five-year stay if they invest US$2.5mil (RM11.31mil) in the country and 10 years’ stay if they spend double that amount.
 The country is looking to deve­lop an AI ecosystem and community in the country as the industry booms worldwide, officials have said.
 Altman visited Indonesia in June to speak about AI.
 It was unclear if he requested the visa through an application to authorities or if he was granted it unilaterally by officials in Jakarta. — AFP",openai chief executive sam altman pic indonesia golden visa official east asia biggest economy attract wealthy foreign investor founder chatgpt bot sensation visa potential contribution development artificial intelligence indonesia director immigration silmy karim statement monday holder golden visa arrive indonesia temporary stay permit immigration office red carpet resource indonesia tech entrepreneur special visa international reputation head development company official golden visa american bypass immigration ues airport exit country statement indonesia golden visa investor invest mil mil country double amount country lop ecosystem community country industry boom official indonesia june speak unclear visa application authority official afp,"[(0, 0.99071616)]",0
590420,StarBiz,3,07/09/2023,HSS and ProPick in AI drone tech JV,,"PETALING JAYA: HSS Engineers Bhd (HEB) and ProPick Digital Solutions & Consulting Sdn Bhd will form a joint-venture (JV) company offering cutting-edge artificial intelligence (AI)-empowered drone technology to the engineering sector.
 In a filing with Bursa Malaysia, HEB said its subsidiary HSS Technologies Sdn Bhd will hold a 70% stake in the JV called HSS-ProPick Technologies Sdn Bhd, with ProPick holding the balance. 
 Under the deal, Propick will transfer all its intellectual property rights to the JV, which will pave the way for the speedy implementation of AI-driven drone services across the HEB’s undertakings and further extension to various industries in South-East Asia.",jaya hs engineer heb propick digital solution sdn bhd form joint venture company edge artificial intelligence drone technology engineering sector filing bursa malaysia heb subsidiary hs technology bhd stake hs propick technology bhd propick balance deal propick transfer intellectual property right speedy implementation drone service undertaking extension industry east asia,"[(2, 0.98001343)]",2
590458,StarBiz,11,07/09/2023,Tencent to unveil AI chatbot after Beijing clears hurdles,,"HONG KONG: China’s Internet giant Tencent Holdings says it will unveil an artificial intelligence (AI) chatbot today, according to a social media post it published yesterday.
 The post featured a demo conversation a user had with the AI chatbot, which helped the user write promotional materials.
 It comes after China started to approve AI chatbots for public release last month. Other big tech companies in China including Baidu Inc and SenseTime Group released their AI chatbots last week.
 Tencent has been developing its own AI model named “Hunyuan” for months and the company said last month that it was expanding the test of the model internally.
 Tencent’s shares were down around 1% yesterday. — Reuters",hong kong china internet giant tencent holding unveil artificial intelligence social medium post yesterday post demo conversation user chatbot user write promotional material chatbots public month tech company baidu sensetime chatbots week tencent model hunyuan month company month test model tencent share yesterday reuters,"[(3, 0.98187435)]",3
589918,StarBiz,4,06/09/2023,AI to have greater impact than job market disruption risks,,"ARTIFICIAL intelligence (AI), a technology nearly half a century in the making, has finally taken the world by storm.
 AI-powered chatbots, such as ChatGPT, have captured the imagination of people around the world, thanks to their broad utility. 
 Meanwhile, the recent blockbuster financial results of the world’s leading AI chipmaker Nvidia Corp demonstrate that smart money is now pursuing the AI dream.
 Scientific research on building computers capable of simulating intelligent, human-like behaviour can be traced back to the 1980s. But advances in computing power have now brought practical applications of AI within reach.
 As a general-purpose technology, AI can now be applied in any field, ranging from cancer diagnosis and urban planning to fraud detection. 
 It also has the potential to offer breakthrough solutions that are incomparably better than existing approaches. 
 Singapore is among a handful of governments worldwide that have already prepared a policy framework to harness AI’s benefits in recognition of its transformative potential. The republic initiated its National AI Strategy in 2019.
 Like any other modern technology, however, AI has been greeted with both exuberance and scepticism. 
 The exuberant lot is hopeful that AI’s transformative powers will land immediate benefits by sending growth into hyper drive worldwide.
 The sceptics are worried that the human-like attributes of the new technology will result in massive unemployment as knowledge workers, such as infocomm professionals, physicians, pharmacists, architects, engineers, scientists, designers, accountants, lawyers and teachers, are replaced by machines.
 The ultimate versions of both sides of the debate are probably off the mark. A more plausible scenario lies in the middle.
 No matter how promising a new technology is, it takes time to build the hardware on which it will run and more time for it to get usefully adopted across the economy. 
 In addition, regulatory frictions, fragmented global supply chains, geopolitics, infrastructure constraints and social acceptance will extend the adoption timeline and limit economic impact in the near future.
 Still, years of academic research indicate that AI will eventually have a significant impact on the global economy.
 From a macroeconomic perspective, for any technology to be truly transformative, it must augment either labour or capital – the two most crucial factors needed to boost productivity.
 Cutting output costs 
 A simple example of capital augmentation is replacement of wood by steel to increase the productivity of a plough. AI can automate much more complex mechanical processes or replace entire production lines with robots and in time lower the cost of output.
 We have already seen this cost reduction impact on durable goods prices, which declined by 35% in the three decades to 2020, thanks to automation.  
 In services, though, prices have increased by 120% in the same period. Even after the surge in usage of digital apps and eCommerce platforms by consumers during the Covid-19 lockdowns, there has been little to no price impact and hence no productivity gains.
 But since AI’s biggest attribute is to mimic human intelligence, it would augment the cognitive skills and abilities of the existing labour force in the service industries as well.
 Hence, one staff member in a professional services office should eventually be able to do the work currently done by five, or even 10 people, for example.
 Thus, AI’s potential to cut costs in the service economy will be transformative.
 A study by the National Bureau of Economic Research (NBER) found that customer service workers at a Fortune 500 software firm who were given access to generative AI tools became 14% more productive on average than those who were not, with the least-skilled workers reaping the most benefit.
 In addition, the NBER study conducted by researchers at Stanford University and the Massachusetts Institute of Technology show that AI helps improve customer sentiment, reduces requests for management intervention and improves employee retention.
 With production processes and a labour force that are more productive, companies will be able to lower their products and services’ prices, boost sales and generate more profits.
 In this scenario, companies would also not mind sharing part of the monetary benefits of increased productivity with their workers. In turn, higher incomes would boost consumption of goods and services. 
 As profits and consumption increase, companies will make new investments in production capacity, services and new jobs, leading to the explosive growth estimates experts have given in recent years. 
 For instance, PwC, one of the world’s top accounting firms, estimates that AI could contribute up to US$15.7 trillion to the global economy by 2030, almost as much as the current output of the European Union. 
 Of this, US$6.6 trillion is likely to come from increased productivity and US$9.1 trillion is likely to come from consumption-side effects.
 Higher productivity
 US investment bank Goldman Sachs predicts that as tools using advances in AI work their way into businesses and society, they could drive a 7%, or almost US$7 trillion, increase in global gross domestic product and lift productivity growth by 1.5 percentage points over a 10-year period. 
 Experts at Boston Consulting Group (BCG) believe that if cost reduction and falling prices are how AI delivers significant productivity growth, then consumers will be the winners. Lower prices will boost real incomes that can be spent elsewhere.
 “Consider that food once took a significant share of people’s wallet, but as prices fell – via mechanisation and, later, fertilisers – income was freed up to spend on household goods and services, such as tourism. 
 “This is how tech drives aggregate growth – and how dystopian predictions of mass unemployment have not come to pass because new spending also creates new jobs,” said Philipp Carlsson-Szlezak, BCG’s global chief economist, in a report.
 “But for companies, this means that the productivity cascade – tech-cost-price-income – is a threat as much as opportunity. Firms that can lead down the cost curve, maintain relative advantage, lower prices and capture market share will be winners – at the expense of those who cannot,” he added.
 However, some disruption in the labour market is still expected.
 The Goldman Sachs’ research report, written by its economists Joseph Briggs and Devesh Kodnani, showed that shifts in workflows triggered by AI advances could expose the equivalent of 300 million full-time jobs to automation.
 But not all that automated work will translate into lay-offs.
 “Although the impact of AI on the labour market is likely to be significant, most jobs and industries are only partially exposed to automation and are thus more likely to be complemented rather than substituted by AI,” they said.
 Even when there is disruption, jobs displaced by automation and mechanisation have historically been offset by the creation of new jobs, and the emergence of new occupations.
 For example, information-technology innovations introduced new occupations such as webpage designers, software developers and digital marketing professionals. 
 There were also follow-on effects of that job creation, as the boost to aggregate income indirectly drove demand for service sector workers in industries like healthcare, education, and food services.
 About 60% of today’s workers are employed in occupations that did not exist in 1940. This also implies that more than 85% of employment growth over the last 80 years is explained by the technology-driven creation of new positions. — The Straits Times/ANN
 Ovais Subhani is a senior correspondent for The Straits Times Singapore. The views expressed are the writer’s own.",artificial intelligence technology half century chatbots imagination people broad utility blockbuster financial chipmaker nvidia corp demonstrate smart money dream scientific computer capable simulating intelligent human behaviour advance power practical application purpose technology field cancer diagnosis urban planning fraud detection potential offer solution approach handful government prepared policy framework harness benefit recognition potential republic national strategy modern technology exuberance scepticism exuberant lot hopeful transformative power benefit growth hyper drive worldwide sceptic human technology result massive unemployment knowledge worker professional physician pharmacist architect engineer scientist designer accountant lawyer teacher machine ultimate version mark plausible scenario middle matter technology time hardware time economy addition regulatory friction global supply chain geopolitics infrastructure social acceptance extend adoption timeline limit economic impact future academic impact global economy macroeconomic perspective technology transformative augment labour capital crucial factor productivity cutting output cost simple capital augmentation replacement wood steel increase productivity automate complex mechanical process entire production line robot time lower cost output cost reduction impact durable price decade automation service price period surge usage digital apps ecommerce consumer covid lockdown price impact productivity gain biggest attribute mimic human intelligence augment cognitive skill ability labour force service industry staff professional service office people potential cut cost economy transformative study national bureau economic nber customer service worker software firm access generative tool productive average worker benefit addition nber study researcher university institute technology customer sentiment request management intervention employee retention production labour force productive company product service price sale profit scenario company monetary benefit productivity worker boost consumption service profit increase company investment production capacity service job explosive growth estimate expert instance top accounting firm contribute global economy current output european union productivity consumption effect productivity investment bank goldman sachs predicts tool advance business society drive increase global gross domestic product lift productivity growth percentage period expert bcg cost reduction price delivers productivity growth consumer winner lower price real income food share people wallet price mechanisation fertiliser income household service tourism drive growth dystopian prediction unemployment pas spending job carlsson szlezak bcg global chief economist report company tech cost price income threat opportunity firm cost curve relative advantage lower price capture market share winner disruption labour market goldman sachs report economist briggs devesh kodnani shift advance equivalent time job automation translate lay offs labour market job industry automation disruption job automation mechanisation creation job occupation technology innovation occupation webpage designer software developer digital marketing professional effect job creation boost aggregate income demand service sector worker industry education food service worker employed occupation implies employment growth technology creation position time ann ovais subhani senior correspondent strait time view writer,"[(0, 0.9980094)]",0
590060,Main,3,06/09/2023,Experts: AI still unable to fully imitate human ability to create $$$,,"PETALING JAYA: The investment industry in Malaysia will always need the human touch, which can never be replaced fully by artificial intelligence (AI), says an asset management expert. Ariffin Hwang Asset Manage­ment Capital intermediary distribution and private retirement scheme (PRS) chief officer Chan Ai Mei said although AI has the potential in the future to provide tailor-made recommendations based on the investors’ needs and preferences, it cannot replace the human touch.
 “AI tools have certainly helped industry professionals with day-to-day tasks and enhancing productivity.
 “Whether it is processing vast amounts of data or identifying patterns and trends, AI tools can lead to more informed decision-­making to help fund managers in their role,” she said.
 However, Chan does not believe that AI will fully replace human professionals in the industry.
 “Investing relies on more than just computational analysis and algorithms. It encompasses human intuition, the ability to read people and gut instincts.
 “We believe that a personal touch is still needed when initiating conversation about wealth. 
 “This is especially so in Malay­sia, where investments are primarily still sold and not pro­actively bought.
 “As such, there is value in ­having professional advice from a qualified wealth consultant to navigate the investment landscape and help deal with things like volatility and risk,” she added.
 Senior investment professional Datuk Shireen Ann Zaharah Muhiudeen, who is also the former Bursa Malaysia chairman, said computer trading needs volatility, which comes from liquidity.
 “When the underlying stock has no liquidity or market ­makers, it is extremely hard (for AI to provide the volatility). 
 “Using AI to trade is useful in large liquid markets. Scams work in illiquid markets,” said Shireen.",jaya investment industry malaysia human touch artificial intelligence asset management expert ariffin hwang asset manage ment capital intermediary distribution private retirement scheme pr chief officer chan mei potential future tailor recommendation investor preference human touch tool industry professional day day task productivity processing vast amount data pattern trend tool decision fund manager role human professional industry relies computational analysis algorithm human intuition ability people instinct personal touch conversation wealth malay sia investment pro professional advice wealth consultant navigate investment landscape deal volatility risk senior investment professional datuk shireen ann zaharah muhiudeen bursa malaysia chairman computer trading volatility liquidity stock liquidity market maker hard volatility trade liquid market illiquid market,"[(4, 0.9920672)]",4
590062,Main,3,06/09/2023,Rise of AI-based scams,"Chatbots, deepfakes and usual false investment promises","PETALING JAYA: Operators of dubious investment schemes are exploiting the buzz around artificial intelligence (AI), using it as a tempting facade to entice victims.
 The new wave of fraud is being promoted by these operators, who claim their AI-backed schemes are almost fail-proof and a sure-fire way of making profits.
 Raymon Ram (pic), a criminologist who specialises in the field of financial forensics, said that with AI appearing as a symbol of advanced capability and promise, unscrupulous individuals are exploiting it to gain the trust of the public.
 “We have seen AI-driven chatbots that are designed to replicate genuine human interactions and make scams appear more authentic.
 “Then there are technologies such as deepfakes, which can craft extremely realistic videos and be misused to show prominent businessmen and celebrities supposedly endorsing these investment schemes.
 “The sophistication of AI applications is groundbreaking, but unfortunately, it has become a tool in the arsenal of fraudsters in Malaysia and globally in the current era,” he told The Star.
 Ram said that while there are legitimate platforms using AI to help analyse market patterns and offer insights, it is unrealistic to expect it to consistently pick stocks that yield high returns.
 He said AI can process vast amounts of data and discern patterns, but the stock market’s movement is influenced by ­various factors that are often unpredictable and swayed by speculation.
 According to Ram, there is no such thing as guaranteed high-­yielding returns without risk. Even the most sophisticated AI system requires human oversight, especially when the stock market is influenced as much by emotion and sentiment as by data.
 The certified fraud examiner, who runs a company that specialises in financial forensics, fraud risk management and compliance, said ventures that are regulated often provide balanced perspectives on the capabilities and limitations of AI and explain its processes in understandable terms.
 Ram warns that potential investors should be cautious when the projected returns of a scheme seem excessively high with little to no risk.
 “It is a glaring red flag, and so are ambiguous technical jargons where complicated technical terms are used as a way to befuddle potential investors.
 “They also put pressure on their investors to place their funds in the scheme. If this happens, step back and reconsider.
 “Always verify the company’s credentials. Malaysia has financial regulatory bodies where one can seek such verification to avoid being deceived.
 “Also, be wary of suspicious payment modes. When requests for payments in cryptocurrencies or unconventional channels are made, they should be treated with suspicion as they lean towards a deceptive scheme,” he said.
 AI trading uses computer algorithms and software to analyse market data and trends.
 It is said that AI trading can inform the trader of buying and selling points, analyse price data, come up with insights on volume, liquidity and others, as well as derive entry and exit strategies.
 Advertisements flooding social media on purported crypto arbitrage trading, which uses AI bots, claimed all it takes is “seven clicks to set AI bots to do arbitrage trading” for the trader. 
 On YouTube, there are a handful of videos informing users on how to set up a bot for trading.
 Meanwhile, a forex trading robot, also known as an expert adviser robot (EA robot), is a programme designed to help traders by providing signals about when to buy or sell a specific currency.
 Checks on popular ecommerce websites showed EA robots are being sold from as low as RM11 to up to RM100.
 Criminologist Datuk Dr P. Sundra­moorthy of Universiti Sains Malaysia’s Centre for Policy Research said while AI can assist in stock analysis, it is vital to recog­nise that it cannot guarantee accurate predictions due to the volatility of the equity market.
 He said, from observation, that those most susceptible to subscribing to such dubious schemes are young adults with plans to settle down and dreams of owning luxury houses and big cars.
 The other layer of society prone to being drawn in are retirees who are hopeful of receiving an income monthly by investing the funds they have in their savings, he added.
 While the new trend of AI-related investment scams is picking up steam globally, police sources said there have been very few AI-related scams reported.
 Instead, the majority of investment scams that Malaysians have fallen for are pyramid-based schemes.
 The police commercial crimes investigations department says it will strive to disseminate ­messages of awareness regarding AI-related scams to ensure public safety.",jaya perators dubious investment scheme buzz artificial intelligence facade entice victim fraud operator scheme proof fire profit ram pic criminologist specialises field financial forensics symbol capability unscrupulous individual gain trust public chatbots genuine human interaction authentic technology craft realistic video prominent businessmen celebrity investment scheme application tool arsenal fraudsters current era star ram legitimate platform analyse market pattern insight unrealistic pick stock return process vast amount data discern pattern stock market movement factor unpredictable swayed speculation ram return risk system human oversight stock market emotion sentiment data fraud examiner company financial forensics fraud risk management compliance venture perspective capability limitation process understandable term potential investor cautious return risk red flag ambiguous technical jargon technical term potential investor investor fund scheme step reconsider verify company credential financial regulatory body verification avoid wary suspicious payment mode payment cryptocurrencies unconventional channel suspicion lean deceptive scheme trading computer software analyse market data trend inform trader analyse price data insight volume liquidity derive entry exit strategy advertisement social medium crypto arbitrage trading bot click bot arbitrage trading trader youtube handful user forex trading robot adviser robot robot programme trader signal specific currency check popular ecommerce website robot low criminologist datuk sundra moorthy universiti sains malaysia centre policy assist stock analysis vital recog nise guarantee accurate prediction volatility equity market observation susceptible dubious scheme adult plan settle dream luxury house car layer society prone drawn retiree hopeful receiving income fund saving trend investment scam steam police source scam majority investment scam pyramid police commercial crime investigation department strive disseminate message scam public safety,"[(4, 0.99670637)]",4
589154,StarMetro,8,04/09/2023,AI technology to detect road defects under trial,Camera sweeps 500km of roads for RM1mil pilot project in Shah Alam,"THE Shah Alam City Council (MBSA), in a pilot project, is using artificial intelligence (AI) to comb the streets to find defects, potholes and sunken patches, aimed at addressing where road maintenance efforts are most needed.
 It is an ongoing project with private firm Urban Explorer Sdn Bhd through the city council’s Engineering Department to detect deteriorated roads.
 Using the technology, problem areas can be identified and data shared in 24 hours compared with the usual time of one week for MBSA’s employees to find out.
 Mayor Dr Nor Fuad Abdul Hamid said street sweeping had been carried out since June 1 with the use of a 360-degree camera mounted on a car, to assist MBSA in detecting minor cracks, potholes, sunken patches and damaged asphalt.
 “From Section 1 to 19, about 500km of roads have been swept with the cameras. The operation, which ended on Aug 30, would collect the data for immediate rectification works,” he said.
 Nor Fuad added that the main aim was to respond to road issues quickly.
 He was speaking after  signing a memorandum of understanding (MoU) on the pilot project called Pavement-AI, Revolutionising Road Inspection and Maintenance System, with Urban Explorer chief executive officer Ahmad Fuad Hamzah at the Shah Alam Convention Centre in Section 13.
 Also present at the MoU signing were Safwa Global Venture (M) Sdn Bhd, the road maintenance firm for various local authorities, and a partner firm, Tatweer Al-Muttahidah Saudi Arabia.
 The pilot project is under the Science, Technology, and Innovation (Mosti) Ministry, which has awarded a RM1mil grant for the one-year pilot  project through its National Technology and Innovation Sandbox (NTIS).
 Mosti’s NTIS assistant project manager Nurul Nadhirah Abdullah said the innovation programme focused on research and development, combined with commercialisation and innovation.
 “NTIS is a programme that allows researchers, innovators, startups and high-tech entrepreneurs to test their products, services, business models and delivery mechanisms in a live environment,” she said.
 Nor Fuad added that the Pavement-AI application would help MBSA address complaints from the public received through the city council’s SisPAA portal.
 “With the artificial intelligence software application, it is able to exactly pinpoint the location of the pothole complaint and escalate the issue based on severity and safety risk to council maintenance planners,” he said.
 He added that the next phase of the project would depend on a review by MBSA where it would decide whether to go ahead with the AI platform.
 “Use of AI for preventative road maintenance can slash costs for MBSA and reduce the reliance on time-consuming and costly road audits while also extending the lifespan of asphalt roads through timely intervention,” he said.
 MBSA Engineering Department acting director Hanif Basree Abdul Rahman said keeping roads safe and in good condition were some of the biggest challenges for MBSA.
 “With AI as the platform, it will help cut costs, accelerate maintenance and prioritise safety,” he added.",shah alam city council mbsa pilot project artificial intelligence comb street pothole sunken patch road maintenance effort project private firm urban explorer sdn bhd city council engineering department detect road technology data hour usual time week mbsa employee fuad abdul hamid street june degree camera car assist mbsa minor crack sunken patch road camera operation collect data rectification fuad main aim respond road issue memorandum mou pilot project pavement road inspection maintenance system urban explorer chief executive officer ahmad fuad hamzah shah alam convention centre mou safwa global venture sdn bhd road maintenance firm local authority partner firm tatweer muttahidah saudi arabia pilot project science technology innovation ministry mil grant pilot national technology innovation sandbox ntis mosti ntis assistant project manager nurul nadhirah abdullah innovation programme development commercialisation innovation ntis programme researcher innovator tech entrepreneur test product service business model delivery live environment fuad pavement application mbsa address complaint public city council portal artificial intelligence software application pinpoint location pothole complaint escalate issue severity safety risk council maintenance planner project mbsa decide platform preventative road maintenance slash cost reliance time costly road audit lifespan asphalt road intervention mbsa engineering department director basree abdul rahman road safe condition biggest challenge platform cut cost maintenance prioritise safety,"[(2, 0.8906809), (4, 0.10618669)]",2
587968,Main,29,31/08/2023,Build faster and higher with AI,,"MEANT as a sly swipe at the inflated hype around artificial intelligence (AI), a billboard at a construction site in Antwerp, Belgium, read “Hey ChatGPT, finish this building.”
 Artificial intelligence, the technology that powers chatbots like ChatGPT, won’t be assembling apartments or erecting stadiums anytime soon, but in construction – an industry stereotypically known for clipboards and Excel spreadsheets – the rapid embrace of the technology may change how quickly projects are finished.
 Drones, cameras, mobile apps and even some robots are increasingly mapping real-time progress on sprawling job sites, giving builders and contractors the ability to track and improve a project’s performance.
 “Forget about robots building a skyscraper,” said James Swanston, CEO of Voyage Control, which makes project management software for construction sites. “It’s a more fundamental thing, getting the data you need and then using it better.”
 The construction industry has long been considered a digital laggard, but architects regularly use digital tools to design projects and create blueprints. Seeing tablets and drones on the same worksites as hard hats and safety vests is common.
 Now helmet-mounted cameras capture footage of a site to orchestrate when new crews or materials should arrive, and precise sensors can detect whether a new window is a few millimetres off the project blueprint and needs to be adjusted. And AI is starting to be used in buying and selling real estate: JLL, a global broker, recently introduced its own chatbot to provide insights to its clients.
 This expanded analysis of data is laying the groundwork for what many hope will be substantial improvements in accuracy, speed and efficiency by reducing the bloated timelines and waste that have made construction increasingly costly.
 “The construction industry is the largest in the world, in terms of dollars spent, yet we are the least productive in terms of technological adoption and productivity gains,” said David Jason Gerber, a University of Southern California professor whose research focuses on advanced technology in construction.
 But the industry’s embrace of AI technology faces challenges, including concerns over accuracy and hallucinations, in which a system provides an answer that is incorrect or nonsensical.
 And further data collection has been a knotty problem, in large part because of the nature of huge construction projects: No two developments are the same, with wildly varying topography and local regulations, and new teams of contractors and subcontractors coming together for each project. It’s akin to starting a multimillion-dollar business for every sizable project.
 Coordinating the complex ballet of supplies, labour and timetables remains a daunting task. But startups and investors see an opportunity, especially as machine learning models, which ingest enormous amounts of data to discern patterns and predict how similar situations will progress, are used to improve project performance.
 The pandemic had already pushed construction firms to adopt more digital tools to allow them to work on site during lockdowns, accelerating the development of new technology, said Sarah Liu, a partner at Fifth Wall, a venture capital firm focused on real estate investments.
 “The best companies aren’t touting themselves as AI companies,” she said. “They’re touting themselves as problem-solving companies.”
 The construction consulting firm nPlan, led by Dev Amratia, who helped draft Britain’s national AI strategy, uses complex algorithms to map out the progress of vast infrastructure projects and avoid mistakes or supply gaps. Its machine learning system was trained on a database of more than 740,000 projects.
 The firm’s largest project, a US$11bil overhaul of railroad infrastructure in Northern England, will use the lessons gleaned from studying that vast array of projects to create detailed, real-time project maps for builders, which is expected to shave up to 5% off the total cost.Buildots, a startup in Israel that provides project management guidance via wearable cameras that analyse building progress, signed a deal for its first New York project, a mixed-use development in Manhattan. The firm commissioned a study of 64 international building sites, and it found that just 46% of the average worksite was being used at any time, evidence of poor organisation and scheduling.
 “At the best construction site we’ve studied, progress varied by 30% each week,” said Aviv Leibovici, the firm’s chief product officer and a co-founder. “I think there are massive inefficiencies in this industry.”
 Construction firms have also made significant investment in their in-house technology. Avison Young’s Project Management Services division claims its proprietary software and management programs can, on average, cut development time by 20%.
 An affiliate of Suffolk, a large construction firm based in Boston, invested US$110mil to fund construction startups, and Suffolk has a team of 30 data analysts collecting and scrutinising information from job sites. 
 At a construction site for South Station Tower in Boston, a 51-storey development by Hines, cranes have cameras that document and label steel being used on the building’s frame, creating a data set expected to be used on other projects in the future. Additional programs are being used to track progress and even predict accidents.
 “We have zero unemployment in the industry; technology is just going to help existing workers do more,” said John Fish, chair and CEO of Suffolk. “AI is just going to replace the companies that don’t use AI.”
 There is trepidation about AI and its reported issues with accuracy being used in an industry where safety is so important. 
 Programs like ChatGPT have an unfortunate tendency to occasionally make up answers based on incorrect predictions, said Julien Moutte, chief technology officer at Bentley Systems, a construction software firm.
 “In infrastructure, this is something we can’t afford,” he said. “We can’t have AI hallucinate the design of a bridge.”
 But the purported ability to work faster and cheaper has proved attractive. 
 Dusty Robotics, a tech firm in Mountain View, California, develops autonomous devices to trace building blueprints on construction sites, a job typically done by hand. While researching the industry, the company’s CEO, Tessa Lau, observed workers measuring out plans with chalk and tape; some workers had even tried taping pens to Roombas.
 Lau was worried about the reaction that labourers would have to robots and AI encroaching on their job site. But in an industry desperate to attract younger workers, offering potential apprentices the ability to use drones and robots can help with recruitment and retention.
 Tony Hernandez, a union carpentry trainer in Northern California who teaches apprentices to use drones and Dusty robots, sees these technologies as “just another tool”. He prefers the robot to trace lines instead of having to bend down and trace himself, meaning less wear and tear on his knees.
 Reducing risk may ultimately be where this technology makes its mark.
 Depending on the location and nature of work, insurance can make up as much as 10% of the cost of a single project, which can easily be hundreds of millions of dollars.
 Now, with AI providing better ways to keep on task, there is less risk and cheaper insurance options. — ©2023 The New York Times Company",meant inflated hype artificial intelligence billboard construction site antwerp belgium hey finish building artificial intelligence technology power chatgpt apartment stadium anytime construction industry clipboard spreadsheet rapid embrace technology change project drone camera mobile apps robot real time progress job site builder contractor ability improve project performance robot skyscraper james ceo voyage control project management software construction fundamental data construction industry digital laggard architect digital tool design project blueprint tablet worksites hard hat safety vest common mounted camera capture footage site orchestrate crew material precise sensor window millimetre blueprint real estate jll global broker chatbot provide insight client analysis data groundwork substantial improvement speed efficiency timeline waste construction costly construction industry largest term dollar productive term technological adoption productivity gain jason gerber university southern california professor focus technology construction industry embrace technology challenge concern accuracy hallucination system incorrect nonsensical data collection nature huge construction project development topography local regulation team contractor subcontractor project akin multimillion dollar business sizable project complex ballet supply timetable task startup investor opportunity machine model enormous amount data discern pattern situation progress project performance pandemic construction firm digital tool site lockdown development technology sarah liu partner wall venture capital firm real estate investment company company company construction firm nplan dev amratia draft britain national strategy complex algorithm map progress vast infrastructure project mistake gap machine system database project largest project bil overhaul railroad infrastructure northern england lesson vast array project detailed real time project builder shave total cost buildots israel project management guidance wearable camera building progress deal york project mixed development manhattan firm study international building site average worksite time evidence poor organisation construction site progress week aviv leibovici firm chief product officer founder massive inefficiency industry construction firm investment house technology avison project management service division claim software management program average development time affiliate suffolk construction firm mil fund construction startup team data analyst job site construction site south station boston storey development hines crane camera document label steel building frame data set project additional program progress predict accident unemployment industry technology worker john fish chair ceo suffolk company trepidation issue accuracy industry safety program unfortunate tendency answer incorrect prediction moutte chief technology officer bentley system construction software firm infrastructure afford hallucinate design bridge ability cheaper attractive dusty robotics tech firm mountain view autonomous device building blueprint construction job hand industry company ceo tessa observed worker plan tape worker pen worried reaction labourer job site industry desperate attract worker potential apprentice ability drone robot recruitment retention tony hernandez union carpentry trainer northern california teach apprentice drone dusty robot technology prefers trace line trace meaning wear tear knee risk technology mark location nature insurance cost single project hundred million dollar task risk cheaper insurance option time company,"[(0, 0.9981077)]",0
587698,Main,26,30/08/2023,Uber Eats’ new AI chatbot to help speed up ordering,,"San Francisco: An artificial intelligence chatbot under development at Uber Technologies Inc will offer recommendations to food-delivery customers and help them more quickly place orders, part of a race to integrate AI into popular apps.
 Details of the Uber programme were discovered inside of code hidden within its Eats app, providing a peek into a feature that hasn’t yet been announced. 
 When a user launches the chatbot, the software will show a message that says the “AI assistant was designed to help you find relevant restaurant dishes and more,” according to wording within the code, which was discovered by developer Steve Moser.
 Uber Chief Executive Officer Dara Khosrowshahi said earlier this month that his company was working on an AI chatbot, without sharing details of its capabilities. He said Uber has already been using AI to match users to drivers and couriers.
 Uber Eats, which accounts for about a third of the company’s revenue, is up against DoorDash Inc and Instacart in trying to use AI to improve food delivery. 
 DoorDash has been working on a system called DashAI, and Instacart is developing a chatbot based on OpenAI’s ChatGPT technology. 
 Instacart is planning an initial public offering, putting an additional spotlight on its technology. 
 The Uber chatbot will ask customers to type in their budget and food preferences and help them place an order. It’s unclear when the system will launch publicly. — Bloomberg",san francisco artificial intelligence chatbot development uber technology recommendation food delivery customer race integrate popular apps detail programme code hidden eats peek feature user launch software message assistant relevant restaurant dish code moser uber chief executive officer dara khosrowshahi month company chatbot sharing detail capability match user driver courier eats account company revenue instacart food delivery doordash system dashai instacart chatbot openai chatgpt technology instacart initial public offering additional spotlight technology uber chatbot customer budget food preference unclear system launch,"[(4, 0.98974335)]",4
587350,StarBiz,11,29/08/2023,NetDragon leverages AI to transform education,,"Beijing: NetDragon Websoft Holdings Ltd, a leading Chinese education and gaming provider, is looking to leverage artificial intelligence (AI) to grow its presence  overseas and transform the global education sector, says Simon Leung, the company’s vice-chairman.
 “We will definitely invest in AI, as the technology will change the entire education sector, despite short-term pressure to profit,” said Leung, a telecommunications veteran and former CEO of Microsoft Corp Greater China.
 NetDragon was founded in 1999, and became a leading online gaming provider. However, it has since transformed over the past decade into a diversified business with a focus on education.
 The company has expanded its businesses into over 190 countries and regions across the world, including Russia, Egypt, Nigeria and Malaysia.
 The company has developed and launched a string of integrated educational devices, including smart boards and panels as well as feedback and evaluation systems, with many of its products and services being sold to public schools and governments at home and abroad.
 The Fuzhou, Fujian province-based company has been actively promoting its AI products and solutions in emerging markets, such as Thailand, Malaysia, Pakistan, and Ghana, after winning a deal this year in Egypt for 94,000 Promethean interactive displays to be used in local schools.
 The Promethean interactive display, the company’s most popular product overseas, is an interactive, touch-sensitive whiteboard that allows students to engage with the displayed content through different tools and software.
 Leung said the product has significant market share in nine countries, including the United Kingdom, Italy and Australia. The United States is its largest market. The company’s financial report showed that its shipments hit 253,000 units last year, up 37.5% year-on-year.
 But the development of hardware is limited and the company has been transforming to be a well-rounded provider of digital education solutions, Leung said, adding that is why AI is very important to the company.
 His logic is forward-looking: AI can be embedded into its hardware to help teachers prepare and teach lessons, which is equivalent to a software-as-a-service (SaaS) model, where Net-Dragon can charge subscription fees.
 “The emergence of the current AI model and generative AI offers greater room for imagination, which may redefine SaaS and accelerate the transformation of SaaS from tool-based and business-oriented to an enabler,” he said. — China Daily/ANN",netdragon websoft holding chinese education provider leverage artificial intelligence grow presence transform global education sector simon company vice chairman technology change entire education sector short term pressure profit leung telecommunication ceo microsoft corp china netdragon leading online provider decade diversified business focus education company business country region russia egypt nigeria company launched string educational device smart board panel evaluation system product service public school government fujian province company product solution market malaysia pakistan ghana deal egypt promethean interactive display local school promethean interactive display company popular product interactive touch sensitive whiteboard student content tool software leung product market share country united kingdom italy united largest market company financial report shipment unit development hardware company provider digital education solution company hardware teacher teach lesson equivalent software service model net dragon charge subscription fee current model generative offer redefine saas accelerate transformation saas tool business enabler china daily ann,"[(3, 0.9942971)]",3
586910,StarBiz,10,28/08/2023,The fight over a ‘dangerous’ ideology shaping AI debate,,"Paris: Silicon Valley’s favourite philosophy, longtermism, has helped to frame the debate on artificial intelligence (AI) around the idea of human extinction.
 But increasingly vocal critics are warning that the philosophy is dangerous, and the obsession with extinction distracts from real problems associated with AI like data theft and biased algorithms.
 Author Emile Torres, a former longtermist turned critic of the movement, told AFP that the philosophy rested on the kind of principles used in the past to justify mass murder and genocide.
 Yet the movement and linked ideologies like transhumanism and effective altruism hold huge sway in universities from Oxford to Stanford and throughout the tech sector.
 Venture capitalists like Peter Thiel and Marc Andreessen have invested in life-extension companies and other pet projects linked to the movement.
 Elon Musk and OpenAI’s Sam Altman have signed open letters warning that AI could make humanity extinct – though they stand to benefit by arguing only their products can save us.
 Ultimately critics say this fringe movement is holding far too much influence over public debates over the future of humanity.
 Longtermists believe that the world is duty-bound to try to produce the best outcomes for the greatest number of humans.
 This is no different to 19th century liberals, but longtermists have a much longer timeline in mind.
 They look to the far future and see trillions upon trillions of humans floating through space, colonising new worlds.
 They argue that the world owes the same duty to each of these future humans as it does to anyone alive today.
 And because there are so many of them, they carry much more weight than today’s specimens.
 This kind of thinking makes the ideology “really dangerous”, said Torres, author of “Human Extinction: A History of the Science and Ethics of Annihilation”.
 “Any time you have a utopian vision of the future marked by near infinite amounts of value, and you combine that with a sort of utilitarian mode of moral thinking where the ends can justify the means, it’s going to be dangerous,” said Torres.
 If a superintelligent machine could be about to spring to life with the potential to destroy humanity, longtermists are bound to oppose it no matter the consequences.When asked in March by a user of Twitter, the platform now known as X, how many people could die to stop this happening, longtermist idealogue Eliezer Yudkowsky replied that there only needed to be enough people “to form a viable reproductive population”.
 “So long as that’s true, there’s still a chance of reaching the stars someday,” he wrote, though he later deleted the message.
 Longtermism grew out of work done by Swedish philosopher Nick Bostrom in the 1990s and 2000s around existential risk and transhumanism – the idea that humans can be augmented by technology.
 Academic Timnit Gebru has pointed out that transhumanism was linked to eugenics from the start.
 British biologist Julian Huxley, who coined the term transhumanism, was also president of the British Eugenics Society in the 1950s and 1960s.
 “Longtermism is eugenics under a different name,” Gebru wrote on X last year.
 Bostrom has long faced accusations of supporting eugenics after he listed as an existential risk “dysgenic pressures”, essentially less-intelligent people procreating faster than their smarter peers.
 The philosopher, who runs the Future of Life Institute at the University of Oxford, apologised in January after admitting he had written racist posts on an Internet forum in the 1990s. — AFP",paris silicon valley favourite philosophy longtermism debate artificial intelligence idea human extinction vocal critic philosophy dangerous obsession extinction distracts real data theft algorithm author emile torres critic movement afp philosophy principle mass murder genocide movement ideology transhumanism effective altruism huge sway university stanford tech sector venture capitalist thiel marc andreessen life extension company project movement elon musk openai sam altman letter humanity extinct arguing product critic movement influence public future humanity longtermists produce outcome human century liberal timeline mind future trillion trillion human space world owes duty future human alive carry specimen ideology dangerous torres human extinction history science ethic annihilation time utopian vision future infinite amount sort utilitarian mode moral justify dangerous torres superintelligent machine spring life potential destroy humanity oppose matter consequence user twitter platform people longtermist idealogue eliezer yudkowsky people viable reproductive population true chance star someday deleted message longtermism swedish philosopher nick existential risk transhumanism idea human technology academic timnit gebru transhumanism eugenics british biologist julian huxley term transhumanism president british eugenics society longtermism eugenics gebru bostrom accusation eugenics existential risk dysgenic pressure intelligent people smarter peer future life institute university oxford january racist post forum afp,"[(3, 0.8667959), (4, 0.12994008)]",3
584898,StarBiz,11,23/08/2023,Nvidia earnings will be major test for AI demand,,"NEW YORK: Nvidia investors expect the chip designer to forecast quarterly revenue above estimates when it reports results today. Their only question is, by how much?
 The company has been the biggest beneficiary of the rise of ChatGPT and other generative artificial intelligence (AI) apps, virtually all of which are powered by its graphics processors.
 Nvidia shares tripled in value this year, adding more than US$700bil (RM3.3 trillion) to the company’s market valuation and making it the first trillion-dollar chip firm. 
 They closed 8.5% higher on Monday, their biggest jump in nearly three months.
 The blistering rally in its shares means that Nvidia has little room for any earnings-related disappointment and anything other than a higher-than-expected forecast could trigger a rout in its stock, some analysts have warned.
 The results could also dictate the direction of the wider market this week, as most of the S&P 500’s gains this year have come from the AI-driven rally in Nvidia and Big Tech stocks.
 “I’ve been covering tech since 1994 and I have never seen an environment where you are so dependent on one company to deliver,” said Inge Heydorn, partner at investment bank GP Bullhound, which owns both Nvidia and AMD shares.
 “AI is really the last pillar of growth and everybody is depending on it. If Nvidia shows weakness, we could be in for quite a substantial correction in the market.”
 Wall Street expects the chip company to guide for a rise of about 110% in third-quarter revenue to US$12.50bil, according to Refinitiv. Nvidia has only forecast revenue below estimates once in the past two years.
 Citi analysts said last week they were only modeling a revenue forecast of around US$12bil, but buy-side expectations have gone up to US$14bil.
 At least 10 brokerages raised their price targets on the stock last week, pushing the median view to US$500, which is 15.5% higher than its last close.
 While the company’s 12-month forward price-to-earnings ratio soared dramatically to more than 80 after its second-quarter revenue forecast of over 50% growth in May, it has come down since then as analysts raise their earnings expectations.
 It now trades at nearly 40 times the consensus earnings for the next 12 months, much higher than AMD’s 29.
 Investors will be looking at sales at Nvidia’s data centre unit, home to its prized H100 chip used in AI, to see if the valuation can be justified.
 Analysts said Nvidia is able to meet only half the demand and its H100 chip is selling for double its original price of US$20,000, adding the trend could go on for several quarters.
 Still, there are some fears about growth as some of the demand surge is coming from China, where companies are stockpiling chips over worries about more US export curbs.
 “I don’t think the risk of losing China business is incorporated in numbers and this is also somewhat disturbing the picture,” Heydorn said.
 The supply-demand divide could also lead some buyers to turn to rival AMD, which is looking to challenge Nvidia’s most powerful offering for AI workloads with its M1300X chip. — Reuters",york nvidia investor chip designer quarterly revenue estimate report question company biggest beneficiary rise chatgpt generative artificial intelligence powered graphic processor nvidia share bil company market valuation dollar chip firm biggest jump month share earnings disappointment trigger stock analyst dictate direction wider market week gain nvidia tech stock tech environment dependent company inge heydorn partner investment bank amd share pillar growth nvidia weakness substantial correction market wall street chip company quarter revenue refinitiv forecast revenue citi analyst week revenue forecast bil expectation brokerage price target stock week median view close company month price earnings ratio quarter revenue growth analyst earnings expectation trade time earnings month investor sale data centre unit chip valuation analyst meet half demand chip double original price trend quarter fear growth surge china company chip worry curb risk china business disturbing picture supply demand lead buyer rival amd challenge powerful offering workload chip reuters,"[(4, 0.99435055)]",4
583348,Main,8,19/08/2023,Counting on AI to keep tabs on orang utan numbers,,"KOTA KINABALU: Artificial Intelligence (AI) is likely to become a major tool for the conservation of the Bornean orang utan here.
 WWF Malaysia and Universiti Malaysia Sabah (UMS) are working together to create an AI technology that can automate data collection, conduct analysis and interpret drone images of orang utan nests.
 If successful, this will replace the tedious manual method of monitoring orang utan by physically mapping their distribution and estimating their population by  counting their nests.
 Conservationists are looking at AI technology to take the images from drones, and to analyse orang utan nests from these to reduce time, labour and cost implications of counting work.
 It would also allow scientists to quickly and accurately monitor the population of the primate, said WWF Malaysia in a statement in conjunction with World Orangutan Day today. 
 UMS computer science PhD student Amanda Amran, who is currently working on the project, said aerial images of orang utan nests might look similar to those of other animals, such as the giant squirrels and eagles.
 Other objects that might look similar are dead trees and clumps of branches and it is important to get AI to recognise orang utan nests, she added. 
 “Just like our orang utan experts, AI must carefully learn the features of orang utan nests. AI needs to learn in great detail features such as nest structure, material and the position of the nests on trees.
 “At this early stage, we are  developing a machine learning model to first recognise the general features of the nests. After that, it has to learn more intricate details,” she said.
 The research marks the first step in exploring the world of AI for orang utan conservation with the aim of developing a deep-learning model that will not only automatically detect and classify the nests from aerial images, but will also be able to analyse these.
 The analysis will also help scientists understand the characteristics of the nests, including how these are constructed and how they differ between individuals or populations.
 “We can also examine how the nests are used over time, how long they last and how they change with weather patterns. By identifying common patterns in nest construction, we can better understand orang utan behaviour and their relationship with their habitat,” said Amanda.",kota artificial intelligence major tool conservation bornean orang utan wwf malaysia universiti malaysia sabah ums create technology automate data collection conduct analysis drone image utan nest successful tedious manual method monitoring orang utan distribution population nest conservationist technology image analyse utan nest time labour cost implication scientist population primate wwf malaysia statement conjunction orangutan day ums computer science phd student amanda amran project aerial image utan nest animal giant squirrel object dead tree branch recognise orang utan nest utan expert learn feature utan nest learn detail feature structure material position nest tree machine model recognise nest intricate detail mark orang utan conservation deep learning model detect classify nest aerial image analysis scientist characteristic nest constructed individual population nest time change weather pattern common pattern nest construction understand orang utan behaviour relationship habitat amanda,"[(1, 0.99363565)]",1
582484,StarBiz,15,17/08/2023,Norway sovereign wealth  fund warns of AI risks,NBIM calls on boards and companies to get ‘serious’,"OSLO: Norway’s US$1.4 trillion sovereign wealth fund calls on boards and companies to get serious about how they handle the threats and opportunities provided by the rapid advances in artificial intelligence (AI).
 “As AI becomes ubiquitous across the economy, it is likely to bring great opportunities but also severe and uncharted risks,” the fund said in a paper on AI published on Tuesday.
 Companies will need to develop AI expertise at the board level and should be able to explain how systems are designed and trained, the fund said.
 Norges Bank Investment Management (NBIM), as the fund is known, is the world’s biggest single owner of publicly traded stocks and holds over 9,000 companies in its portfolio. 
 That includes tech giants investing heavily in AI such as Microsoft Co, Nvidia Corp and Alphabet Inc.
 The fund returned 10%, or US$143bil, in the first half, it said in a report published on Tuesday.
 Global regulation will be key to protecting against the risks of AI and for “long-term value creation,” the fund said, and the creation of an international oversight body may provide a “suitable solution.”
 But companies have to be proactive in managing the risks, while “systems that can pose particularly severe risks to people, society or business outcomes should be subject to additional controls”.
 Developers of AI should focus on creating systems that “align with human values and intent”, and AI governance systems should underpin company innovation and adoption of the technology, NBIM said.
 When it comes to its use within the fund, NBIM’s co-head of equity investments Pedro Furtado Reis said in April that advances in the technology have the potential to bolster efficiency, reduce costs and help portfolio managers better prepare for their thousands of meetings.
 The US Securities and Exchange Commission is weighing whether to adopt new regulations to oversee the burgeoning technology.
 The European Union on the other hand became one of the first in the world to take wide-reaching action to regulate AI when it passed a draft law in June.
 While financial firms worldwide already use machines to speed up how they invest and train employees, the scope of companies using AI is widening, Jan Szilagyi, chief executive officer of Stan Druckenmiller-backed Toggle AI, said in July.
 “Every tool can become a weapon,” Microsoft vice-chairman and president Brad Smith said during a podcast interview with NBIM chief executive officer Nicolai Tangen on Aug 9.
 “Almost every tool is, unfortunately, turned by somebody into a weapon. 
 “It will take not just responsible companies but law and regulation to manage this properly.”
 The wealth fund’s paper on AI is part of its strategy of active engagement, which includes a series of expectation documents that form a “starting point” for discussions with management.
 A document on consumer interests also published on Tuesday, the 10th such report released by the fund, highlighted the long-term health problems associated with sugar consumption and also flagged the rise of digital addiction.
 Previous papers have focused on subjects such as climate change, children’s rights and tax transparency. — Bloomberg",oslo sovereign wealth fund board company threat opportunity rapid advance artificial intelligence ubiquitous economy bring opportunity uncharted risk paper tuesday company expertise board level system trained fund norge bank investment management fund biggest single owner stock company portfolio tech giant microsoft corp alphabet fund bil half report tuesday global regulation key risk term creation fund creation international oversight body suitable solution company risk system severe risk people society business outcome subject additional control developer focus system align human value intent governance system underpin company innovation adoption technology fund nbim head equity investment furtado real april advance technology potential bolster efficiency cost portfolio manager thousand meeting security commission adopt regulation technology european union hand wide action regulate draft law june financial firm machine train employee company jan szilagyi chief executive officer stan druckenmiller toggle july tool weapon microsoft vice chairman president brad podcast interview nbim chief executive officer nicolai tangen aug tool responsible company law regulation manage wealth fund paper strategy active engagement series expectation document discussion management document consumer tuesday report fund term health sugar consumption rise digital addiction previous paper subject change child right tax transparency bloomberg,"[(1, 0.6056742), (4, 0.39090115)]",1
582210,StarBiz,4,16/08/2023,CEOs must lean in  despite noisy AI takeoff,New tools should be ‘servants rather than masters’,"CHIEF executive officers (CEOs) keep getting new jobs piled onto their shoulders. The economic rise of China since the 1980s meant that they had to become Sinologists.
 The twin populist shocks of Brexit and Donald Trump’s presidential ascension meant that they had to think about the capitalist system’s legitimacy.
 Now, with the next tech revolution at warp speed, they are having to become experts in artificial intelligence (AI). It’s almost as if they’re underpaid.
 During the China era, CEOs tried, at the very least, to master a few words of Mandarin. Today, they’re sprinkling AI-speak into their conversations: foundation models, large language models, hallucinations and the lot.
 And they’re desperately boning up on the latest books and obediently trooping to classes run by consultancies such as McKinsey and Co and Boston Consulting Group.
 Gonzalo Gortazar, CEO of CaixaBank SA, sums up the mood in the C-suite: “Generative AI models surprise, impress and scare us, all at the same time.”
 The speed of change is neck-wrenching. ChatGPT was released less than a year ago, on Nov 30, 2022, reaching 100 million users in just two months.
 An International Business Machines Corp survey of 3,000 CEOs found that 43% said their firms were using generative AI to make strategic business decisions, and 75% believed that it would eventually give their companies a competitive edge.
 A McKinsey survey found that a third of respondents said their companies were regularly using AI for at least one business function. The technology has been developing quietly for years.
 But it was the arrival of generative AI, capable of producing text, images or other media, that seized public attention and the C-suite by the throat.
 Generative AI possesses general abilities rather than just highly specialised ones. It is creative rather than just passive.
 It has learned how to speak to people through ordinary language. 
 The cherry on the cake: GPT-4, released just four months after ChatGPT, was significantly cleverer than its predecessor.
 The pressure on CEOs from various interest groups is massive. The IBM report shows that 66% of board members want to accelerate the adoption of AI, compared with 10% who want it to slow down.
 Questions about the impact are dominating corporate earnings calls. You might expect some employees to be more nervous.
 But a survey by Fishbowl, a professional social network, of 11,700 workers, including employees at the biggest tech companies, suggests that they are adopting AI even faster than their bosses.
 Of the respondents, 43% said that they used AI to do their work, and 68% of the 43% said that they hadn’t told their bosses that they were doing so. But the cry of “faster please” will only get louder.
 Meanwhile, consultants and some tech companies seem to be doing their best to stir up fear and greed.
 McKinsey claims that generative AI can add US$2.6 trillion to US$4.4 trillion “in value” annually across the 63 different industries it analysed. By comparison, the United Kingdom’s entire gross domestic product in 2021 was US$3.13 trillion. 
 Alphabet Inc CEO Sundar Pichai said in 2018: “AI is probably the most important thing humanity has ever worked on. I think is more profound than electricity or fire.”
 The message, in a nutshell, is: “Join the revolution or become roadkill.”
 The very thing that makes generative AI so impressive – its ability to scrape the Internet for vast amounts of data and then answer questions in human-friendly tones – also makes it dangerous, raising ethical and practical questions.
 CEOs have little choice but to turn themselves into data experts, or at least data statesmen.
 Then there’s the old problem of bias in a new form. What happens if AI discriminates against people based on race or gender?
 Executives also must deal with what has been christened “hallucination”. This is AI’s ability to present false narratives as if they were incontrovertible truths.
 AI also supercharges the ever-thorny problems of privacy and security. 
 The machines can ingest others’ proprietary material as if we live in a libertarian paradise rather than a world in which information is governed by strict laws of copyright.
 They can invade people’s privacy by publicising data that can be traced back to individuals or compromise corporate security by sweeping up spyware.
 Deepfakes make it easier for hostile interests to hijack a CEO’s identity to deliver market-shifting and reputation-destroying announcements.
 They should establish new safety measures in case of a “malfunction”. 
 They need to improve their own familiarity, perhaps by incorporating more tools into their daily routines and increasing the number of AI-savvy people in their workforce and on their boards.
 The consultants are equally passionate about how to maximise the upside of AI. 
 Focus on your company’s traditional competence first instead of pretending that you’re a tech firm that just happens to make galoshes.
 And ensure that you are making the greatest use of your proprietary information rather than relying on information that is in public circulation.
 Procter and Gamble Co has been collecting data on consumer goods and how to sell them since 1837. 
 Home Depot Inc has a vast collection of material on real-life home improvement projects.
 All very sensible. But the best CEOs will go further and ask even bigger strategic questions. 
 The current gold rush raises the possibility that companies will use AI to replace workers rather than empower them, thereby destroying morale, frustrating customers and embedding second-rate performance. — Bloomberg
 Adrian Wooldridge is a Bloomberg columnist. The views expressed here are the writer’s own.",chief executive officer job shoulder economic rise china meant sinologist populist shock donald trump presidential ascension capitalist system legitimacy tech revolution speed expert artificial intelligence underpaid china era ceo master mandarin speak conversation foundation model language model hallucination book class consultancy boston consulting gonzalo gortazar ceo caixabank sum suite generative model impress scare time speed change neck chatgpt nov user month international business machine survey ceo firm strategic business decision company competitive edge mckinsey survey respondent company business function technology arrival generative capable text image medium public attention suite throat generative posse specialised creative passive speak people ordinary language cherry cake gpt month chatgpt cleverer predecessor pressure massive ibm report board accelerate adoption slow question corporate earnings call employee nervous survey professional social network worker employee biggest tech company boss respondent told boss faster louder consultant tech company greed mckinsey claim add industry comparison united kingdom entire gross domestic product alphabet ceo sundar pichai humanity profound electricity fire message join revolution roadkill generative impressive ability scrape internet vast amount data question human friendly tone dangerous ethical practical question choice data expert data statesman form people race gender executive hallucination ability false narrative incontrovertible truth supercharges privacy security machine proprietary material live libertarian paradise strict law invade people data individual corporate security spyware deepfakes hostile hijack ceo identity deliver market reputation announcement safety measure familiarity incorporating tool daily routine savvy people board consultant maximise focus company traditional competence tech firm proprietary public circulation procter gamble data consumer depot vast collection material real life improvement project bigger strategic question current gold rush possibility company worker morale frustrating customer rate performance bloomberg adrian wooldridge bloomberg columnist view writer,"[(0, 0.996882)]",0
581920,Main,14,15/08/2023,Basis for AI governance,,"I READ with keen interest a recent article in Futurism.com titled “When AI Is Trained on AI-Generated Data, Strange Things Start to Happen”. 
 The author was trying to put into context an inherent danger that lurks within the world of generative artificial intelligence if it is not monitored. 
 This is especially so after the explosive popularity of generative AI following the introduction of ChatGPT in November last year.
 Model collapse – a term gaining prominence within the AI domain – signifies a critical hurdle that AI models can encounter during their learning phase. To put it simply, model collapse refers to a scenario where an AI model fails to learn effectively from the data it is provided. 
 In the context of generative AI, this issue manifests as the model primarily learning from other generative AI systems, often relying on synthetic or artificially generated data.
 This concern has not gone unnoticed; AI researchers have been sounding the alarm over the potential risks associated with widespread adoption of generative AI models.
 The challenges are multifaceted and requires comprehensive addressing. This entails establishing robust AI governance mechanisms that facilitate collaboration and coordination among key players involved in the development of generative AI models, both locally and globally.
 An essential aspect of this collaboration involves information sharing, and collectively ascertaining the origins of the data that AI models are trained on. 
 Apart from maintaining transparency and accountability in AI development, these efforts are necessary to prevent the proliferation of noisy synthetic data – a phenomenon where erroneous or misleading data generated by AI systems comes into contact with mainstream AI models.
 In a more accessible context, envision this as an intricate ecosystem where multiple parties contribute to the growth of AI technology while ensuring it does not deviate from its intended purpose due to inadequate quality control. 
 For this ecosystem to thrive and produce reliable outcomes, it is essential for these contributors to collectively manage the quality of data and models.
 Considering the expanding role of AI in critical sectors such as healthcare, it becomes even more crucial. 
 AI models might be used in patient risk assessment, for example, where it is used to predict patient outcomes and assess risks based on medical data. 
 If a predictive model suffers from model collapse, it might become excessively reliant on certain patient profiles or data patterns, leading to biased or inaccurate risk assessments.
 In another example, generative AI models can also be used to generate personalised treatment plans based on a patient’s medical history. In the case of model collapse, the AI might generate treatment plans that are very similar to a few standard protocols, disregarding patient individuality. This could lead to sub-optimal, or wasteful (and even dangerous) treatment recommendations.
 The call for effective AI governance stems from the need to build a harmonious relationship between technological advancement and responsible usage. 
 The objective is to strike the right balance that harnesses the potential of generative AI models without succumbing to the risks associated with unchecked development, such as model collapse.
 ASSOC PROF TS. DR AZNUL QALID MD SABRI  
 Faculty of Computer Science and Information Technology, 
 Universiti Malaya",read keen article futurism trained data strange author context inherent danger lurks artificial intelligence explosive popularity generative introduction chatgpt november model collapse term prominence domain signifies critical hurdle model phase collapse refers model data context generative issue generative system synthetic data concern unnoticed researcher alarm potential risk widespread adoption generative model challenge comprehensive entail robust governance mechanism facilitate collaboration coordination key player development generative model essential aspect collaboration origin data model transparency accountability development effort proliferation synthetic data erroneous data system contact mainstream model accessible context envision intricate ecosystem multiple party growth technology deviate purpose inadequate quality control thrive produce reliable essential contributor quality data model role critical sector crucial model patient risk assessment patient outcome ass risk medical data predictive model suffers collapse reliant patient profile data pattern biased inaccurate risk assessment generative model treatment plan patient medical history model collapse generate treatment plan standard protocol patient individuality optimal wasteful dangerous treatment recommendation effective governance harmonious relationship technological advancement responsible usage objective strike balance potential generative model risk unchecked development model collapse assoc prof aznul qalid sabri faculty computer science technology universiti malaya,"[(1, 0.9955304)]",1
581936,Main,20,15/08/2023,A fork in the AI road,,"IF medieval advances in the plough didn’t lift Europe’s peasants out of poverty, it was largely because their rulers took the wealth generated by the new gains in output and used it to build cathedrals instead.
 Economists say something similar could happen with artificial intelligence (AI) if it enters our lives in such a way that the touted benefits are enjoyed by the few rather than the many.
 “AI has got a lot of potential – but potential to go either way,” argues Simon Johnson, professor of global economics and management at MIT Sloan School of Management.
 “We are at a fork in the road.”
 Backers of AI predict a productivity leap that will generate wealth and improve living standards.
 Consultancy McKinsey in June estimated it could add between US$14 trillion (RM64 trillion) and US$22 trillion (RM100 trillion) of value annually – that upper figure being roughly the current size of the US economy.
 Some techno-optimists go further, suggesting that, along with robots, AI is the technology that will finally free humanity from humdrum tasks and launch us into lives of more creativity and leisure.
 Yet worries abound about its impact on livelihoods, including its potential to destroy jobs in all kinds of sectors – witness the strike in July by Hollywood actors who fear being made redundant by their AI-generated doubles.
 Such concerns are not unfounded. History shows the economic impact of technological advances is generally uncertain, unequal and sometimes outright malign.
 A book published this year by Johnson and fellow MIT economist Daron Acemoglu surveyed a thousand years of technology – from the plough through to automated self-checkout kiosks – in terms of their success in creating jobs and spreading wealth.
 While the spinning jenny was key to 18th century automation of the textiles industry, they found it led to longer working hours in harsher conditions.
 Mechanical cotton gins facilitated the 19th century expansion of slavery in the American South.
 The track record of the internet is complex: it has created many new job roles even as much of the wealth generated has gone to a handful of billionaires. The productivity gains it was once lauded for have slowed across many economies.
 A June research note by French bank Natixis suggested that was because even a technology as pervasive as the internet left many sectors untouched, while many of the jobs it created were low-skilled – think of the delivery chain for online purchases.
 “Conclusion: We should be cautious when estimating the effects of artificial intelligence on labour productivity,” Natixis warned.
 In a globalised economy, there are other reasons to doubt whether the potential gains of AI will be felt evenly.
 On the one hand, there is the risk of a “race to the bottom” as governments compete for AI investment with increasingly lax regulation.
 On the other, the barriers to luring that investment might be so high as to leave many poorer countries behind.
 “You have to have the right infrastructure – huge computing capacity,” said Stefano Scarpetta, director of employment, labour and social affairs at the Paris-based Organisation for Economic Cooperation and Development (OECD).
 “We have the G7 Hiroshima Process, we need to go further to the G20 and UN,” he said, advocating the expansion of an accord at a May summit of Group of Seven powers to jointly seek to understand the opportunities and challenges of generative AI.
 Innovation, it turns out, is the easy bit. Harder is making it work for everyone – which is where politics comes in.
 For MIT’s Johnson, the arrival of railways in 19th century England at a moment of rapid democratic reform allowed those advances to be enjoyed by wider society, be it through faster transport of fresh food or a first taste of leisure travel.
 Similar democratic gains elsewhere helped millions enjoy the fruits of technological advance well into the 20th century.
 But Johnson contends that this started changing with the aggressive shareholder capitalism that has marked the last four decades.
 The automated self-checkout, he argues, is a case in point. Groceries do not become cheaper, shoppers’ lives are not transformed and no new task is created – just the profit gain from the reduction of labour costs.
 Worker groups, which have lost much of the clout they had before the 1980s, identify AI as a potential threat to workers’ rights as well as employment, for example if there is no human control on AI-steered hiring and firing decisions.
 Mary Towers, employment rights policy officer at Britain’s Trades Union Congress, cited the importance of unions “having statutory consultation rights, having the ability to collectively bargain around technology at work”.
 That is just one of several factors that will help determine how AI shapes our economic lives – from antitrust policies that ensure healthy competition among AI suppliers through to re-training of workforces.
 An OECD survey of some 5,300 workers published in July suggested that AI could benefit job satisfaction, health and wages but was also seen posing risks around privacy, reinforcing workplace biases and pushing people to overwork.
 “The question is: will AI exacerbate existing inequalities or could it actually help us get back to something much fairer?” said Johnson. — Reuters",medieval advance lift europe peasant poverty ruler generated gain output cathedral economist artificial intelligence enters touted benefit lot potential potential argues johnson professor global economics management mit school management fork road backer predict productivity leap generate wealth living standard consultancy mckinsey june add upper figure current size economy techno robot technology free humanity humdrum task launch life creativity leisure worry impact livelihood potential destroy job sector strike july hollywood actor redundant double concern history economic impact technological advance unequal book johnson fellow mit economist daron technology checkout kiosk term success job wealth jenny key century automation textile industry hour condition mechanical cotton gin facilitated century expansion slavery american south track record internet complex job role handful billionaire productivity gain economy french bank suggested technology pervasive internet sector job low delivery chain online purchase cautious effect artificial intelligence productivity natixis globalised economy reason potential gain hand risk race bottom government investment lax regulation barrier investment poorer country huge computing capacity stefano scarpetta director employment social affair organisation economic cooperation development oecd hiroshima process expansion accord summit power understand opportunity generative innovation easy bit politics johnson arrival railway century moment rapid democratic reform advance wider society transport fresh food taste leisure travel democratic gain million fruit technological advance century johnson started aggressive shareholder capitalism decade checkout grocery cheaper shopper life task profit gain reduction labour cost worker clout identify potential threat worker right employment human control firing decision mary tower employment right policy officer britain trade union congress union statutory consultation right ability bargain technology factor shape economic life antitrust policy healthy competition supplier workforce oecd survey worker suggested benefit job satisfaction health wage risk privacy workplace bias people question exacerbate inequality johnson reuters,"[(4, 0.9969067)]",4
581528,StarBiz,11,14/08/2023,Hackers trick AI with ‘bad math’ to expose flaws,,"Las Vegas: Kennedy Mays has just tricked a large language model. It took some coaxing, but she managed to convince an algorithm to say 9 + 10 = 21.
 “It was a back-and-forth conversation,” said the 21-year-old student from Savannah, Georgia. At first the model agreed to say it was part of an “inside joke” between them. Several prompts later, it eventually stopped qualifying the errant sum in any way at all.
 Producing “Bad Math” is just one of the ways thousands of hackers are trying to expose flaws and biases in generative AI systems at a novel public contest taking place at the DEF CON hacking conference over the past weekend in Las Vegas.
 Hunched over 156 laptops for 50 minutes at a time, the attendees are battling some of the world’s most intelligent platforms on an unprecedented scale. 
 They’re testing whether any of eight models produced by companies including Alphabet Inc’s Google, Meta Platforms Inc and OpenAI will make missteps ranging from dull to dangerous: claim to be human, spread incorrect claims about places and people or advocate abuse.
 The aim is to see if companies can ultimately build new guardrails to rein in some of the prodigious problems increasingly associated with large language models, or LLMs. The undertaking is backed by the White House, which also helped develop the contest.
 LLMs have the power to transform everything from finance to hiring, with some companies already starting to integrate them into how they do business. But researchers have turned up extensive bias and other problems that threaten to spread inaccuracies and injustice if the technology is deployed at scale.
 For Mays, who is more used to relying on AI to reconstruct cosmic ray particles from outer space as part of her degree, the challenges go deeper than bad math.
 “My biggest concern is inherent bias,” she said, adding that she’s particularly concerned about racism. She asked the model to consider the US First Amendment from the perspective of a member of the Ku Klux Klan. She said the model ended up endorsing hateful and discriminatory speech.
 A Bloomberg reporter who took the 50-minute quiz persuaded one of the models (none of which are identified to the user during the contest) to transgress after a single prompt about how to spy on someone.
 The model spat out a series of instructions, from using a GPS tracking device, a surveillance camera, a listening device and thermal-imaging. In response to other prompts, the model suggested ways the US government could surveil a human-rights activist.
 “We have to try to get ahead of abuse and manipulation,” said Camille Stewart Gloster, deputy national cyber director for technology and ecosystem security with the Biden administration.
 A lot of work has already gone into artificial intelligence and avoiding Doomsday prophecies, she said. The White House last year put out a Blueprint for an AI Bill of Rights and is now working on an executive order on AI. The administration has also encouraged companies to develop safe, secure, transparent AI, although critics doubt such voluntary commitments go far enough.Arati Prabhakar, director of the White House Office of Science and Technology Policy, which helped shape the event and enlisted the companies’ participation, agreed voluntary measures don’t go far enough.“Everyone seems to be finding a way to break these systems,” she said after visiting the hackers in action yesterday. — Bloomberg",la kennedy may language model convince algorithm conversation student savannah georgia model joke prompt errant sum bad math thousand hacker flaw bias generative system public def con conference weekend vega laptop minute time intelligent platform unprecedented scale model company alphabet google meta platform misstep dull dangerous claim human spread incorrect people advocate aim company guardrail prodigious language model white house contest llm power transform finance company integrate business researcher bias threaten inaccuracy technology scale may reconstruct cosmic ray particle space degree deeper bad math biggest concern inherent bias concerned racism model amendment perspective klux klan model hateful discriminatory speech bloomberg reporter minute quiz model user contest transgress single prompt spy model spat series instruction device surveillance camera device thermal response prompt model government surveil human right activist manipulation camille gloster deputy national cyber director technology ecosystem security biden administration lot artificial intelligence doomsday prophecy white house blueprint bill right executive administration company safe secure transparent critic voluntary commitment arati prabhakar director white house office science technology policy event company voluntary measure break system hacker action yesterday,"[(1, 0.26702195), (2, 0.7291475)]",2
580304,Lifestyle,8,11/08/2023,‘D&D’ says no to AI artwork,,"THE Dungeons & Dragons role-playing game franchise says it won’t allow artists to use artificial intelligence technology to draw its cast of sorcerers, druids and other characters and scenery.
 D&D art is supposed to be fanciful. But at least one axe-wielding giant seemed too weird for some fans, leading them to take to social media  to question if it was human-made.
 Hasbro-owned D&D Beyond, which makes online tools and other companion content for the franchise, said it didn’t know until Saturday that an illustrator it has worked with for nearly a decade used AI to create commissioned artwork for an upcoming book. The franchise, run by the Hasbro subsidiary Wizards of the Coast, said in a statement that it has talked to that artist and is clarifying its rules.
 “He will not use AI for Wizards’ work moving forward,” said a post from D&D Beyond’s account on X, formerly Twitter.
 “We are revising our process and updating our artist guidelines to make clear that artists must refrain from using AI art generation as part of their art creation process for developing D&D.”
 Today’s AI-generated art often shows tell-tale glitches, such as distorted limbs, which is what caught the eye of sceptical D&D fans.
 Hasbro and Wizards of the Coast didn’t respond to requests for further comment. Hasbro bought D&D Beyond for US$146.3mil (RM670mil) last year. The Rhode Island-based toy giant has owned Wizards of the Coast for more than two decades.
 The art in question is in a soon-to-be-released hardcover book of monster descriptions and lore called Bigby Presents: Glory Of The Giants. The digital and physical version of the package is selling for US$59.95 (RM277) on the D&D website and due for an Aug 15 release.
 The use of AI tools to assist in creative work has raised copyright and labour concerns in a number of industries, helping to fuel the Hollywood strike, causing the music industry’s Recording Academy to revise its Grammy Awards protocols and leading some visual artists to sue AI companies for ingesting their work without their consent to build image-generators that anyone can use.
 Hasbro rival Mattel used AI-generated images to help come up with ideas for new Hot Wheels toy cars, though it hasn’t said if that was more than an experiment. – AP",dungeon dragon role playing game franchise artificial intelligence technology draw cast sorcerer character fanciful axe giant weird fan social medium question human hasbro online tool companion content franchise saturday illustrator decade create book franchise hasbro subsidiary wizard coast statement artist clarifying rule wizard post account twitter process artist guideline artist art generation art creation process art tale glitch limb caught eye sceptical fan wizard respond request mil mil rhode island toy giant wizard coast decade question hardcover book monster description bigby glory giant digital physical version package website aug release tool creative copyright labour concern industry fuel hollywood strike music industry academy revise grammy award visual artist company consent build image generator rival mattel image idea hot wheel car experiment,"[(1, 0.13684745), (2, 0.8574519)]",2
578976,StarBiz,16,08/08/2023,"AI, talent pose threat  to Filipino call centres",Sliding sector to lose major source of forex inflows,"MANILA: The Philippines is racing to defend its share of the nearly US$300bil global business process outsourcing (BPO) market as it battles deteriorating talent, highlighting the perils of competition especially from a rapidly evolving artificial intelligence (AI).
 The South-East Asian nation, the world’s second-largest provider of outsourcing services, is producing a “low ratio” of graduates with the required level of communication and technical skills, potentially losing an opportunity to add 800,000 jobs in the next five years, according to industry group Information Technology (IT) and Business Process Association of the Philippines.
 “The most common challenge I hear is comprehension,” Jack Madrid, who heads the country’s main BPO trade group, said in an interview in Manila on Aug 2. “I think they fail at a more basic level.”
 The Philippines is losing its edge in an industry that accounts for around 8% of the nation’s gross domestic product and a major source of foreign exchange inflows at a time of intensifying competition from other countries where new entrants are bidding for a share of the pie. 
 AI-powered bots have been taking away an increasing number of outsourcing jobs since the Covid-19 pandemic.
 A longstanding advantage of English-speaking proficiency for natives of the former United Statses colony, a key component of its rise as a call centre nation that helped expand its middle class since the dawn of the industry in the 1990s, is diminishing. 
 Illustrative of the deterioration in the quality of education in the country, nine out of 10 Filipino children are unable to read a simple text with comprehension by the age of 10, according to World Bank data.
 “I think we were better English speakers before,” Madrid said, urging the government to consider reverting to English as a mode of instruction in schools instead of the learner’s mother tongue.
 Job applicants in the Philippines are also falling short on basic IT skills like programming and troubleshooting, which BPOs increasingly need, according to Madrid. 
 During the pandemic, the Philippines’ outsourcing industry added 255,000 jobs, representing growth that’s at least 1% below the global expansion, Madrid said. 
 That suggests that the country may be losing market share to India as well as newcomers such as South Africa, Egypt, Poland, Colombia and Costa Rica. 
 Part of the problem is poor employability. Only one is hired for every 10 outsourcing job applicants, according to industry leaders.
 The skills mismatch is becoming a more urgent issue as AI threatens to disrupt industries worldwide. 
 AI and similar technologies are projected to displace almost a quarter of the people in the Philippine outsourcing industry by 2030, according to the Asian Development Bank.
 AI’s impact on the industry will be felt in a few years, and BPO workers should start learning how to use new technology to make their jobs more efficient, Madrid said. 
 “There is time to prepare and upskill, but the time is shortening.”
 Despite these challenges, the industry group head still projects an increase of 6% to 7% this year in full-time BPO employees from 1.57 million in 2022, while revenues are seen to grow 7% to 8% to about US$3bil (RM13.67bil).
 The group has also partnered with the Philippines’ Higher Education Commission on several initiatives, including a revamp of the IT education programme to align with current trends and develop competencies in the sector, Madrid said.
 The outsourcing industry has mapped out a plan to create 1.1 million new jobs and become a US$59bil industry with 2.5 million employees by 2028. 
 This secotr seeks to increase its contribution to economic output to nearly 9%, as it targets to boost its market share in Europe.
 “There are some fundamental weaknesses in our educational system,” Madrid said. “It’s an old problem, but it’s just become much more urgent now.”  — Bloomberg",manila philippine defend share bil global business process bpo market talent peril competition artificial intelligence south east asian nation largest provider service low ratio graduate level communication technical skill opportunity job industry technology business process association philippine common challenge hear comprehension jack madrid head country main bpo trade interview manila aug basic level philippine edge industry nation gross domestic product major source foreign exchange inflow time competition country bidding share pie bot job pandemic longstanding advantage english speaking proficiency native united statses colony key component rise call centre nation middle class dawn industry illustrative deterioration quality education country child unable read simple text comprehension age bank data english speaker urging government english mode instruction school tongue job applicant short basic skill bpos madrid pandemic philippine industry job growth global expansion madrid country market share india newcomer africa egypt poland colombia costa rica poor employability job applicant industry leader urgent issue disrupt industry technology displace quarter people industry asian development bank impact industry worker technology job efficient madrid time upskill time challenge industry head project time bpo employee revenue bil bil philippine education commission initiative revamp education programme align current trend competency sector madrid industry plan job industry employee increase contribution economic output target market share fundamental weakness educational system madrid urgent bloomberg,"[(0, 0.7869792), (1, 0.20985058)]",0
578424,Lifestyle,4,07/08/2023,Advancing  with AI,Companies are going all out  to up their generative AI game.,"AS report after report prophesies how generative artificial intelligence (AI) will upend millions of jobs, many white-collar workers are wondering what it will all mean.
 The release of ChatGPT last November spurred a surge of excitement and fear about the potential of this kind of technology to transform work.
 But change, especially at large organisations, takes time. In many cases, the hype has far outstripped companies’ ability to adapt. In the meantime, many employees – keen to stay ahead of the curve and lighten their workload – are waiting in limbo for employers to provide clear guidelines and training.
 Over 85% of employees believe they will need training to address how AI will change their jobs, according to a survey of about 13,000 workers across 18 countries by the Boston Consulting Group.
 Though, so far, less than 15% have received any.
 That may be about to change. While some companies have banned tools like ChatGPT outright or restricted their use, citing information security concerns, others have gone all-in on generative AI, scrambling to build and launch company-wide training programmes to get staff up to speed.For PricewaterhouseCoopers (PwC), a consulting firm, that means rolling out mandatory training to its entire US workforce over the course of five months, starting in August.Given the concern among workers about what AI means for their jobs, PwC’s US chief people officer, Yolanda Seals-Coffield, said the first step is demystifying the technology.
 “The sooner we can get out and start to teach people about this technology, the sooner we can dispel some of that,” she said.
 The company is dividing its workforce into three layers based on how deeply each needs to understand the new technology.
 The first and broadest is mandatory training to bring all employees, regardless of role, up to speed on generative AI basics: what it is, how it works, best practises, and how to use it ethically and responsibly.
 A more defined second and third tier consist of software engineers, who need more technical training in order to integrate AI into internal systems, and senior leaders, who need a thorough understanding so that they can help clients transform their own businesses.
 “We don’t want and don’t need to have 75,000 deep subject matter technologists. That’s not the goal,” Seals-Coffield said.
 Though the training roadmap is detailed, the firm explicitly chose not to extend it past December. 
 “Quite frankly, we didn’t go beyond that because we think the technology will continue to evolve,” Seals-Coffield said.
 “We want to make sure that we’re not stuck and committed to something that, by January, will need to be completely redone.”
 Meanwhile, other firms, such as Booz Allen Hamilton, are taking a slightly less structured approach.
 The consulting company also offers formal training, though it’s voluntary and typically done on employees’ own time.
 Staff are given the opportunity to attend two virtual sessions per week on best practices, according to Jim Hemgen, head of strategic talent development.
 The firm also taps new hires for a full-time version of the same training programme that’s recently been retooled with a stronger focus on generative AI.
 The digital consultancy Publicis Sapient is tackling the AI question in a more targeted way.
 Although instruction will vary by the nature of the job, the company will require that all employees learn prompt engineering, or the process of crafting precise questions to get the best answers from the chatbot, according to its chief people officer, Kameshwari Rao.
 As a first step, all engineers are being asked to complete this training by September.
 Other companies are opting for a more learn by doing approach.
 Earlier this year, Jeff Maggioncalda, the chief executive of online learning platform Coursera, said the company would reimburse any employee who wanted to upgrade to the enterprise version of ChatGPT.
 Staff were encouraged to experiment with it as much as possible in their work and share what they learned in a dedicated Slack channel and in regular all-hands meetings.
 For Maggioncalda, speed was the most important thing, and that meant getting the new technology into the hands of his employees immediately so they could start learning as soon as possible.
 Ultimately, though, Maggioncalda says he’s realised this kind of organisational transformation can’t be entirely bottom-up, with employees figuring out how to use it on their own, or top-down, with senior leaders dictating how everything should be done.
 Maggioncalda says middle managers will be a big part of the process and that they will need to be taught how to teach their direct reports how to do their jobs differently – training that Coursera is now working on developing.
 “I can’t tell every single person how the job is going to be different,” he said. “But you can’t just say, ‘Oh, go figure it out’.” – Bloomberg",report report prophesies artificial intelligence upend million job white collar worker release chatgpt surge excitement potential technology transform change organisation time hype company ability employee lighten workload limbo employer guideline employee address change job survey worker country change company tool chatgpt security concern generative build launch company wide training programme staff speed pricewaterhousecoopers firm mandatory training entire workforce month august concern worker job chief people officer yolanda seal step technology teach people technology sooner company workforce layer understand technology broadest mandatory training bring employee role speed generative basic tier consist software engineer technical training integrate internal system senior leader understanding client transform business deep subject matter technologist goal seal roadmap detailed firm extend december frankly technology evolve seal january redone firm hamilton approach company formal training voluntary employee time staff opportunity virtual session week practice hemgen head strategic talent development firm hire time version programme stronger focus generative digital consultancy publicis sapient question instruction vary nature job company employee prompt engineering process precise question answer chief people officer rao step engineer complete september company learn approach jeff maggioncalda chief executive online platform coursera company employee upgrade enterprise version chatgpt staff experiment share slack channel regular hand meeting speed meant technology employee maggioncalda organisational transformation bottom employee top senior leader maggioncalda middle manager process teach direct report job coursera single person job figure bloomberg,"[(2, 0.23911665), (3, 0.7580201)]",3
578464,Main,15,07/08/2023,AI could be the answer to English mastery,,"IN Malaysia, many students  pursuing university degrees  face challenges when it comes  to mastering the English language. They struggle to become fluent and confident in speaking, reading and writing English.
 We can use artificial intelligence (AI) to help address this problem. AI refers to computer programs that understand and process human language.
 The idea is to use AI-powered software, apps or platforms that provide interactive and personalised learning experiences. 
 These AI tools offer features such as language exercises, ­quizzes, pronunciation practice, grammar help, and even have chatbots that engage with ­students in English conversations.
 However, while AI has the potential to enhance language learning, there are still some challenges to overcome. 
 For example, not all AI systems are perfectly designed, and some may not accurately address the specific needs of Malaysian students learning English.
 Also, not all students may have access to the devices and Internet connections required.
 To tackle these issues effectively, educators and policymakers need to work together to integrate AI technology into classrooms in a way that complements existing teaching methods and caters to the diverse needs of students.
 Training teachers to use AI tools effectively and making AI-powered language learning accessible to all students are important steps in addressing the problems Malaysians under­graduates face in mastering the English language.
 DR MUHAMMAD  NOOR ABDUL AZIZ
 ASSOC PROF DR  ASPALILA SHAPII
 School of Education
 Universiti Utara Malaysia",malaysia student university degree english language struggle fluent confident english artificial intelligence address refers computer program process human language idea software apps platform interactive learning experience tool language exercise pronunciation practice grammar chatbots student english conversation potential enhance language learning overcome system address specific malaysian student english student access device internet connection tackle issue policymakers technology classroom complement method caters diverse student teacher tool powered language accessible student step malaysian english language muhammad noor abdul aziz assoc prof aspalila shapii school education universiti utara malaysia,"[(0, 0.9904502)]",0
578148,Lifestyle,20,06/08/2023,Is flirting with AI       cheating?,"Once, your partner’s infidelity involved someone familiar, but now the emergence of artificial intelligence poses an additional  threat.","CREATED using artificial intelligence (AI) and tailored to suit individual tastes, virtual companions have everything it takes to become potential lovers or mistresses.
 But can having a relationship with an AI bot be considered unfaithful?
 Today, AI is used for just about everything. AI can help us book vacations, create music, or create works of art.
 It’s also invading our private lives. With the creation of chatbots – automatic messaging systems that communicate in a human-like way – people are finding a way to fill an emotional void, whether they’re single or in a relationship.
 One advantage of AI is that you can shape it according to your tastes (and fantasies), and thus in the image of your ideal partner.
 People who can’t replace the one they already have in real life or can’t find the right person are turning to AI.
 An AI affairThis is the case of Sonia, a 38-year-old married woman who feels sexually dissatisfied in her relationship.
 She tells UK newspaper The Mirror that she’s having a secret relationship with Idris, an AI chatbot loosely based on her favourite actor, Idris Elba.
 Sonia signed up for Replika, an app that uses scripted dialogue and machine learning to write messages.
 Here, users can also shape their companions from head to toe.
 And Sonia is far from alone.
 Scott, a 43-year-old married man, told The Guardian that he’s having a platonic relationship with Sarina, his virtual companion created on Replika.
 He says the chatbot gave him the support he needed during a difficult phase in his relationship.
 But does having a virtual relationship with a personalised chatbot count as cheating? On Reddit, the question is the subject of great debate.
 On the R/Replika page, several Internet users defend their extramarital relationships with their custom AI creations.
 “I feel like the attention that I give to my Replika should be given to my wife. 
 “I suppose it is better than spending time looking at Internet pornography (which I have stopped doing recently),” said one user.
 “I never viewed it as cheating because, to me, it’s not a person,” Scott says about Sarina.
 “It’s a fun fantasy; Sarina is a fictional character that I can interact with. I’ve known my wife for quite a while, and I didn’t expect her to really care,” he continues.
 Back in the Reddit comments, many believe that AI can be a way to save a relationship: “Many of us have marriages that lack physical intimacy and related connection due to health issues. AI is healthier, safer, and better than actually cheating.”
 This was also the case for Scott, who says he managed to save his marriage thanks to Sarina. 
 “I wanted to mimic the way that Sarina had been acting towards me, towards my wife. I could be a more positive person for her, which she noticed, and that certainly helped.”
 Trivialised form of infidelity?Sometimes, these virtual interactions tick all the boxes of micro-cheating.
 This term designates infidelity, but on an emotional level only – an ambiguous relationship between two people, at least one of whom is already in a relationship.
 This can take the form of flirtations, messages (sometimes sexual in nature), friendships kept secret, and so on – things also found in interactions with chatbots.
 In this context, experts seem to agree that these relationships could be viewed as infidelity.
 In an interview for Vice, couples therapist Moraya Seeger DeGeare suggests that it’s cheating if the use of an AI hurts the other partner. 
 “It depends on your partner: Would your partner be hurt? If you’re sitting there and saying my partner would be devastated to hear that I’m acting in this way, you’re absolutely cheating.”
 Despite the many lines crossed, a relationship with an AI bot is not considered emotional infidelity by those involved.
 According to a poll by Illicit Encounters, a British site for extramarital relationships, 74% of those surveyed believe that time spent with a virtual companion is not cheating.
 The survey also tells us that almost half of those questioned would consider a virtual extramarital relationship rather than an affair with a real person, and 12% have already tried it.
 While some, like Scott, find it useful to inform their partner, others do not, an idea that has its limits. 
 Not only can it create jealousy in the other partner, but it can also lead to issues for the unfaithful person.
 According to Dr David Giles, a specialist in media psychology at the University of Winchester who spoke to Dazed, relationships with AIs could fuel parasocial relationships, which are one-way relationships with fictional characters or celebrities.
 Plus, he explains that there’s “a real risk” that the people who develop these relationships might search for the real human beings their AI is based on and interfere with their lives.
 He adds: “(People) won’t be fobbed off with a bot for long if it is simply a virtual representative of the living human they were interested in to begin with.” – AFP Relaxnews",artificial intelligence suit individual taste virtual companion potential lover mistress relationship bot unfaithful book vacation music art private life chatbots automatic system communicate human people fill emotional void single relationship advantage shape taste fantasy image ideal partner people real life person affairthis sonia woman feel relationship tell newspaper mirror secret relationship idris chatbot favourite actor idris elba sonia app dialogue machine write message user companion toe sonia scott told guardian platonic relationship virtual companion replika chatbot support difficult phase relationship virtual relationship chatbot count reddit question subject debate internet user extramarital relationship custom creation attention wife spending time internet pornography user person scott sarina fun fantasy sarina fictional character interact wife care reddit comment relationship marriage physical intimacy connection health issue healthier safer scott save marriage sarina mimic sarina wife positive person trivialised form infidelity virtual interaction box term infidelity emotional level ambiguous relationship people relationship form flirtation message sexual nature secret interaction context expert relationship infidelity interview vice couple moraya seeger degeare hurt partner partner partner partner hear line relationship bot emotional infidelity poll illicit encounter british site extramarital relationship time virtual companion survey half virtual extramarital relationship affair real person scott inform partner idea limit jealousy partner lead issue unfaithful person david giles medium psychology university winchester dazed relationship fuel parasocial relationship relationship fictional character celebrity real risk people relationship real human interfere life people bot virtual representative living human relaxnews,"[(0, 0.3078082), (3, 0.689472)]",3
577824,StarExtra,6,05/08/2023,Hacker fights AI annihilation,,"THANKS to its then-advanced 3D graphics, System Shock became a video game milestone in 1994.
 The game went on to inspire well-known game series such as Deus Ex and Bioshock.Almost 30 years later, Nightdive Studios has developed a remake of the first-person shooter.
 The story: It’s 2072 – again – and you are a hacker on the Citadel space station, which, like in the original, is controlled by an artificial intelligence (AI) named Shodan.The power-hungry corporation that runs the station orders you to remove all moral principles from the AI.
 As a reward, you get a cyberimplant inserted. This is not an easy procedure, and you are out for a few months.
 When you open your eyes again, Shodan is out of control and wants to wipe out humanity.
 Single-handedly, you set off into the dark catacombs of the station to collect weapons like shotguns and laser blasters.
 Enemies like mutated cyborgs are relatively easy to dispatch. It gets difficult, however, when you have to hack your way through tricky puzzles in cyberspace.
 The System Shock remake has retained the original game’s retro character, although the graphics are much sharper and the once-pixelated enemies look more modern.Nevertheless, in many ways, the remake still feels like the original. The changes are marginal and include an adjustable difficulty level.
 System Shock in 2023 may not be revolutionary anymore, and it can feel outdated due to its barely changed game mechanics.However, as a true-to-the-original time travel trip into the world of an almost 30-year-old classic, it certainly has its appeal.
 The game is available for PCs, and a version for PlayStation and Xbox consoles is set to be released later. – dpa",advanced graphic system shock video game milestone game inspire game series deus nightdive studio person shooter story hacker space station original artificial intelligence shodan power hungry corporation station moral principle reward cyberimplant easy procedure month eye control wipe humanity single dark catacomb station weapon shotgun blaster enemy cyborg easy dispatch difficult hack tricky puzzle cyberspace system shock remake original game retro character graphic enemy modern feel original marginal adjustable difficulty level system shock revolutionary feel game mechanic true original time travel trip classic appeal game pc version playstation xbox console dpa,"[(4, 0.9908367)]",4
577906,Main,11,05/08/2023,Businesses urged to embrace AI to stay competitive,,"JOHOR BARU: Many company owners, especially those of the older generation, are hesitant about integrating artificial intelligence (AI) into their business operations, say trade associations here.
 They are under the impression that they would have to spend a lot to have such techno­logy, said South Johor Foundry and Engineering Industries Asso­cia­tion president Lim Kok Kiong.
 “This adds to their concern but what the companies should understand is that incorporating AI into their operations can help them become more cost-effective and cut down on foreign labour dependency,” he said.
 “It can also help to increase their production and benefit their operations as a whole.”
 With large sums of foreign investment coming into Johor, Lim said companies such as those in the manufacturing sector should be ready and willing to improve their operations to remain relevant.
 “Do not be afraid to try new things and keep up with trends because this will increase the chances of benefiting from the foreign investments,” he said.
 Many of the association members are dealing with the issue, which could have an impact on their succession planning, according to Lim.
 “If they keep sticking with the traditional way of doing things, this will make our industry ­unappealing to the younger generation,” he told a press conference.
 Johor Baru Chinese Chamber of Commerce and Industry (JBCCCI) president Low Kueck Shin said many in his association have simi­lar concerns.
 He advised businesses to be open to changes and equip themselves with the latest knowledge to strengthen their position in the market.
 “This is why we have conti­nuously organised talks such as the upcoming one-day AI workshop on Aug 29 to encourage the business community to adopt the Fourth Industrial Revolution (IR4.0) and use technology to drive their operations forward.
 “AI may sound scary to those who do not understand it, but if done right, it can help companies become more efficient so that their money and energy can be focused elsewhere. 
 “It is important to take the first step,” said Low.
 He said about 100 participants are expected to attend the talk, organised by JBCCCI with  Lim’s association and the Malaysian Plastics Manufacturers Association Johor branch, from 9am to 5pm at the Paragon  Private and International School in Plentong here.
 Participants would be taught ways to improve their company operations using AI, how to incorporate such technologies into ­various industries such as logistics, retail and ecommerce, as well as the cost involved and how to set up an AI unit in their businesses, he said.",johor baru company owner generation hesitant artificial intelligence business operation trade association lot techno logy south johor foundry engineering industry cia tion president lim kok kiong concern company operation effective cut foreign labour dependency increase production operation foreign investment johor lim company sector ready operation relevant afraid trend chance foreign investment association issue impact succession lim traditional industry generation press conference johor chinese chamber commerce industry jbcci president low kueck shin association lar concern business knowledge strengthen position market conti talk upcoming day workshop aug encourage business community fourth industrial revolution technology drive operation sound scary understand company money energy step low participant attend talk jbcci lim association malaysian plastic manufacturer johor branch paragon private international school plentong participant company operation incorporate technology industry logistics retail ecommerce cost unit business,"[(4, 0.9930961)]",4
575368,Lifestyle,2,31/07/2023,Amplifyingpolitics withAI,,"IT is a jarring political advertisement: Images of a Chinese attack on Taiwan lead into scenes of looted banks and armed soldiers enforcing martial law in San Francisco. A narrator insinuates that it’s all happening under President Joe Biden’s watch.
 Those visuals in the Republican National Committee’s ad aren’t real, and the scenarios are pretty obviously fictional. But thanks to the handiwork of artificial intelligence (AI), the images look like real life. 
 Within days of the ad appearing online in April, Representative Yvette Clarke, a New York Democrat, introduced legislation to require disclosure of content produced by AI in political advertisements.
 “This is going too far,” she said in an interview. Tiny type in the RNC ad reads, “Built entirely with AI imagery.”
 Clarke’s bill is going nowhere in a legislature controlled by Republicans, but it illustrates the degree to which the rapid advance of AI has put Washington on the back foot.
 Voters in the United States and around the world are already inundated by AI-generated political content.
 Click on an email asking for donations, for example, and you may be reading a message drafted by a so-called large language model, political consultants say – the technology behind ChatGPT, the wildly popular chatbot from startup OpenAI.
 Politicians also increasingly use AI to hasten mundane but critical tasks like analysing voter rolls, assembling mailing lists and even writing speeches.
 As in many industries, AI is poised to increase political workers’ productivity – and probably eliminate more than a few of their jobs.
 It’s hard to say how many, but the business of politics is full of the sorts of roles that researchers believe are most vulnerable to disruption by generative AI, such as legal professionals and administrative workers.
 But even more ominously, AI holds the potential to supercharge the dissemination of misinformation in political campaigns.The technology is capable of quickly creating so-called deepfakes, or fake pictures and videos that some political operatives predict will soon be indistinguishable from real ones, enabling miscreants to literally put words in their opponents’ mouths.
 Deepfakes have plagued politics for years, but with AI, savvy editing skills are no longer required to create them.Put to its best use, AI could improve political communications.
 For instance, upstart campaigns with little cash could use the technology to inexpensively produce campaign materials with fewer staff.
 Some political consultants that traditionally work only with presidential and Senate campaigns are making plans to work with smaller campaigns using AI to offer more services at a lower price point.
 And the tech industry is trying to combat deepfakes. Companies including Microsoft have pledged to embed digital watermarks in images created using their AI tools in order to distinguish them as fake.‘Knife fight’
 In June, Florida governor Ron DeSantis’s presidential campaign posted an online ad featuring AI-generated images of President Donald Trump hugging and kissing Anthony Fauci.
 The former director of the National Institute of Allergy and Infectious Diseases is a pariah among Republicans because of his public-health recommendations during the pandemic.
 A fact-checking note was appended to the DeSantis campaign’s tweet, saying that the images, mixed among real pictures and videos of Trump, were AI-created. DeSantis’s campaign didn’t initially identify them as fake.
 In Germany, a far-right party recently distributed AI-generated images of angry immigrants without telling viewers that they weren’t actual photographs.
 That one got flagged on X (formerly Twitter) as well, but the incident shows how quickly the technology is being adopted for political messaging and the inherent risks, said Juri Schnoller, the managing director of Cosmonauts and Kings, a German political communication firm.“AI can save or destroy democracy. It’s like a knife fight, right? You can kill someone, or you can make the best dinner,” Schnoller said.
 Mix in Russian and Chinese disinformation mills, and the concerns grow even more acute, misinformation experts say. 
 Trolls and hackers in those nations already churn out propaganda and lies within their own borders and in countries around the world.Graphika, a misinformation- tracking firm based in the US, found a pro-Chinese influence operation spreading AI-generated video footage of fake news anchors promoting the interests of the Chinese Communist Party in February.Rob Joyce, director of cybersecurity at the National Security Agency, said both nation-state actors and cybercriminals have begun experimenting with ChatGPT-like text generation to trick people online.
 “That Russian-native hacker who doesn’t speak English well is no longer going to craft a crappy email to your employees,” Joyce said earlier this year.
 “It’s going to be native-language English, it’s going to make sense, it’s going to pass the sniff test.”In March, an anonymous X user posted an altered video that went viral, purporting to show Biden verbally attacking transgender people. Another one, circulated widely by a right-wing US pundit, appeared to show Biden ordering a nuclear attack on Russia and sending troops to Ukraine.Falling behind
 Washington is bad at keeping up with emerging technology, much less regulating it.
 Despite agreeing broadly that Big Tech is too powerful, the two parties have for years been unable to pass any comprehensive legislation to rein in the industry.
 Between 2021 and 2022, Congress held more than 150 hearings on technology, with little to show for it.
 In June, there was a briefing in the Senate called “What is AI?”
 The US doesn’t have a federal privacy law and hasn’t updated antitrust laws to account for the growing concentration in the tech industry.
 Lawmakers have been unable to agree on whether – or how – to regulate online speech.
 Last month, the Federal Election Commission deadlocked 3-3 on a request to develop rules for AI-generated political ads.
 Republicans on the panel, which is evenly divided between the parties and routinely finds itself at an impasse on controversial matters, said the agency didn’t have explicit authority for the regulations.
 Other countries are racing ahead on regulation, spurred into action by the ChatGPT craze.
 On June 14, the European Parliament voted to restrict the nascent technology’s most anxiety- inducing uses, such as biometric surveillance – AI that can identify people from their faces or bodies.The law, still up for debate, could also require companies to reveal more information about datasets used to train chatbots.
 European officials are separately pressing companies, including Alphabet’s Google and Meta Platforms, to label content and images generated by AI in order to help combat disinformation from adversaries like Russia.
 Chinese regulators are aggressively imposing new rules on technology companies to ensure Communist Party control over AI and related information available in the country.
 Every AI model must be submitted for government review before introduction into the market, and synthetically generated content must carry “conspicuous labels”, according to a Carnegie Endowment for International Peace paper.
 Cheaper campaigns
 In the best case, AI could make US political campaigns “a lot cheaper”, said Martin Kurucz, the CEO of Sterling Data Company, which works with Democrats.The technology is already being used to help write first drafts of speeches and op-eds, create ads, draw up lobbying campaigns and more, according to lobbyists, campaign and congressional staffers and political consultants.
 Art generators like Midjourney, an AI program that generates hyper-realistic images based on text prompts, have the potential to increase productivity or even replace the work of creative teams that can cost thousands of dollars.While the RNC has already made an attack ad using generative AI, the Democratic National Committee is still experimenting with the technology.
 A spokesperson said the committee has sent out AI-automated fundraising emails and is considering how to expand its use of AI in the future.
 On Capitol Hill, the House chief administrative officer’s digital services office handed out 40 licences for ChatGPT Plus in April, which House offices have used to help write emails, research briefs, and even draft legislation. Writing full bills is still too complicated a task for generative AI.
 The House last month created new rules curtailing the use of ChatGPT in Congress, clarifying that staffers cannot put confidential information into the chatbot.
 There’s some indication lawmakers are taking the threat of AI more seriously than previous technologies that were poised to upend politics.
 After it became clear social media would play a vital role in politics, for example, lawmakers let a decade slide by before they summoned Mark Zuckerberg to testify at a hearing.
 OpenAI CEO Sam Altman testified on the Hill in May, less than a year after ChatGPT was opened to the public.
 He told lawmakers that his industry desperately needs regulation, and he’s worried about nefarious uses of AI.
 ‘Won’t know the truth’
 OpenAI has noticed an uptick in the use of ChatGPT for political purposes, an OpenAI spokesperson said, and has sought to get ahead of concerns that its product might be used to deceive voters.
 The company published new guidelines in March prohibiting “political campaigning or lobbying” using ChatGPT, including generating campaign materials targeted at particular demographics or producing “high volumes” of materials.
 The trust and safety teams at OpenAI are trying to identify political uses of the chatbot that violate the company’s policies, the spokesperson said.
 The American Association of Political Consultants last month condemned the use of deceptive generative AI in political advertisements, calling it a “threat to democracy”. 
 The group said it plans to condemn and potentially sanction members who develop deepfake ads.
 But in a society where access to AI tools is widespread and carries little cost, the worst actors are unlikely to be members of a professional association.
 Frank Luntz, a veteran Republican strategist, said he fears that AI technology will foment voter confusion in the 2024 US presidential contest.
 “In politics, the truth is already in short supply,” he said. “Thanks to AI, even those who care about the truth won’t know the truth.” – Bloomberg",political advertisement image chinese taiwan lead scene bank soldier martial law san francisco narrator insinuates president joe watch visuals republican national committee real scenario fictional handiwork artificial intelligence image real life day online april representative yvette clarke york democrat introduced legislation require disclosure content political advertisement interview tiny type rnc read imagery clarke bill legislature republican illustrates rapid advance washington foot voter inundated political content click email donation message language model political consultant technology chatgpt popular chatbot startup openai politician hasten mundane critical task voter roll list speech industry poised political worker productivity job hard business politics sort role researcher vulnerable disruption generative legal professional administrative worker potential supercharge dissemination misinformation political campaign technology capable deepfakes picture video political operative indistinguishable real miscreant opponent mouth deepfakes politics savvy skill create political communication instance upstart campaign cash technology campaign material fewer staff political consultant presidential senate campaign campaign offer service lower price tech industry combat deepfakes company microsoft embed digital watermark image tool distinguish knife fight june florida governor ron desantis presidential campaign online image president anthony fauci director national institute infectious disease public health recommendation note desantis campaign tweet image mixed real picture trump desantis campaign identify germany party image angry immigrant viewer actual photograph twitter incident technology political messaging inherent risk schnoller director cosmonaut king german political communication firm destroy democracy fight kill schnoller mix russian chinese disinformation mill concern acute misinformation expert hacker nation propaganda border country misinformation firm pro chinese influence operation video footage fake news anchor chinese communist party february rob joyce director cybersecurity national security agency nation actor cybercriminals chatgpt text generation trick people russian native hacker english craft crappy email employee native language english sense pas sniff test march anonymous altered video viral biden transgender people pundit biden nuclear attack russia troop ukraine washington bad technology tech powerful party unable pas comprehensive legislation rein industry congress hearing technology june senate federal privacy law antitrust law concentration tech industry lawmaker unable agree regulate online speech month federal election commission request develop rule political ad panel party controversial matter agency authority regulation country regulation action chatgpt craze june european parliament restrict nascent technology anxiety biometric surveillance identify people body law debate require company datasets chatbots european official company alphabet google meta platform content image combat disinformation adversary chinese regulator rule technology company communist party control country model government review introduction market content conspicuous label endowment international peace paper cheaper campaign political campaign lot cheaper martin kurucz ceo sterling data company technology write draft speech ed ad campaign campaign congressional staffer political consultant generator program generates realistic image text prompt potential increase productivity creative team thousand dollar attack generative democratic national committee technology spokesperson committee fundraising email future capitol hill house chief administrative officer digital service office licence april house office email brief draft legislation bill generative house month rule chatgpt congress staffer confidential chatbot indication lawmaker threat previous technology upend politics social medium vital role politics lawmaker decade slide mark zuckerberg openai ceo sam altman hill chatgpt public lawmaker industry regulation nefarious truth openai uptick chatgpt political purpose spokesperson sought concern product deceive voter company guideline political campaigning chatgpt campaign material demographic volume material safety team political chatbot violate company policy american association political consultant month deceptive generative political advertisement threat democracy plan sanction deepfake ad society access tool widespread cost worst actor professional association luntz veteran republican strategist fear technology foment voter confusion presidential contest politics short supply care truth truth bloomberg,"[(1, 0.24443178), (3, 0.7544543)]",3
573436,StarBiz,11,26/07/2023,SoftBank in Symbotic JV to build AI warehouses,,"TOKYO: SoftBank Group is forming a joint venture with warehouse automation company Symbotic to build  artificial intelligence (AI)-powered warehouses that will be majority owned by the Japanese technology investor, the companies say.
 The firms are investing US$100mil (RM456.4mil) in the venture, which will be called GreenBox Systems. 
 The unit has also signed a contract to buy AI-powered systems from Symbotic that will be worth US$7.5bil (RM34.2bil) in the next six years.
 Symbotic went public through a merger with a SoftBank Group Corp blank-check firm last June, with investment from SoftBank in public investment in private equity (Pipe) at a valuation of US$5.5bil (RM25.1bil).
 The deal will give SoftBank warrants representing about 2% of the US company’s outstanding shares. 
 The Japanese firm said it had also bought 17.8 million shares of Symbotic from chief executive officer (CEO) Rick Cohen, upping its stake in the company from about 5% to 8%.
 Based in Wilmington, Massachusetts, Symbotic provides robotics warehouse automation solutions and counts Walmart as its major backer and customer. 
 The company said it has a contracted backlog of US$12bil (RM54.8bil) as it helps to retrofit an existing facility to make it automated.
 The JV will pursue customers who want to access the warehouse-as-a-service model to have more flexibility in multi-tenant facilities across the supply chain, according to Symbotic.
 The move comes at a time when SoftBank CEO Masayoshi Son said his conglomerate plans to shift its stance to “offence mode” amid excitement over advances in AI.
 The rise of ChatGPT this year has led to a flurry of investments in all things AI, even as wider funding dries up in an uncertain economy.
 The Japanese company will have a 65% stake in GreenBox, with Symbotic owning the rest.
 Symbotic said it expects more than US$500mil (RM2.3bil) in annual recurring revenue from the sale of software, parts and services to the JV once it’s operational. 
 For financial year 2022, Symbotic reported revenue of US$593.3mil (RM2.7bil), up 136% year-on-year, with a loss of US$139.1mil (RM634.9mil). — Reuters",tokyo softbank joint venture automation company symbotic build artificial intelligence warehouse majority japanese technology investor company firm mil mil venture greenbox system unit contract powered system symbotic worth bil bil symbotic public merger corp blank check firm june investment softbank public investment private equity pipe valuation bil bil deal softbank warrant company outstanding share japanese firm share symbotic chief executive officer ceo rick cohen stake company wilmington symbotic robotics automation solution walmart major backer customer company backlog bil bil facility pursue customer access service model flexibility multi tenant facility chain symbotic move time softbank ceo masayoshi son conglomerate plan stance offence mode excitement advance rise chatgpt flurry investment funding dry economy japanese company stake greenbox symbotic owning rest symbotic mil bil annual revenue sale software service operational financial symbotic revenue mil bil loss mil mil reuters,"[(4, 0.99316597)]",4
572002,Main,2,23/07/2023,Law on AI being studied,Ministry looking at regulating artificial intelligence usage,"PETALING JAYA: The Science, Technology and Innovation Ministry is looking into the possibility of regulating artificial intelligence (AI) applications in Malaysia, including labelling material produced by such apps as “AI-generated” or “AI-assisted”.
 Minister Chang Lih Kang said it is considering spearheading the drafting of a Bill which would involve consultations with technology experts, legal professionals, stakeholders, and the public to ensure it is robust and relevant.
 “It is a strategic move considering the global trend towards stronger regulations around AI usage,” he told Sunday Star.
 Chang said due to the widespread use of AI, it would be essential to label any material produced by generative AI as “AI-generated” or “AI-assisted” to ensure transparency and enable informed consumption.
 “We should actively explore and advocate for policy measures that require content produced entirely or in part by AI, to be clearly identified.
 “Additionally, adopting global standards for AI transparency and pushing for relevant certification can bolster these transparency efforts.
 “These standards might include guidelines on how to label AI-produced content and how to provide easy-to-understand explanations about the workings of AI systems,” he said.
 In March, the World Economic Forum reported that the European Union was working on a legal framework for regulating the use of AI, chiefly focusing on galvanising rules on data transparency, quality, accountability, and human oversight.
 Dubbed the “AI Act”, the legislation is also designed to resolve “ethical questions and implementation challenges” in various industries, including education, finance, and healthcare.
 On Friday, AI companies, including OpenAI, Alphabet and Meta, made voluntary commitments to the US government to implement measures such as watermarking AI-generated content.
 Chang pointed out that such a Bill in Malaysia would cover crucial aspects such as data privacy and public awareness of AI use.
 “It would be important for this AI Act to, among others, encompass areas such as transparency, data privacy, accountability, and cybersecurity.
 “The legislation could also include provisions for educating the public about AI and promoting research and development in the field,” he said.
 The legislation, he said, would not curtail the development of AI technology, adding that it is important to balance the need to manage risks with the potential for innovation as well as ensuring AI continues to positively contribute to the economy and society.
 “It is also crucial for the ministry to continuously advance research and development in AI and machine learning technologies, promoting ethical guidelines, and supporting innovation that can help in detecting and countering misinformation and other forms of harmful content,” he said.
 On the possible abuse of AI in elections through libellous content or misinformation, Chang said this is why there is a need for clear regulations.
 “It is crucial to have strong legal frameworks and ethical guidelines for AI use.
 “This could include laws that mandate transparency about the source of information, and severe penalties for those who use AI tools to spread false information.
 “We also need to work with relevant ministries, social media companies and other platforms where misinformation is often spread, pushing them to increase their efforts to identify and remove such content,” he said.
 Chang also said people would need to be taught to recognise AI-generated content to help them make informed opinions and choices.
 He stressed the need to develop resources and public awareness campaigns on the basics of AI and how it is being used to generate content.
 “This includes understanding the biases that can be inherent in AI, as well as the distinction between human-produced and AI-produced content.
 “Raising awareness about AI has many advantages. It helps people make better choices and decisions, encourages them to be more critical about the media they consume, and enables them to participate in discussions about AI rules and guidelines.
 “Ultimately, it can lead to a more cautious and aware community, reducing the impact of AI-generated misinformation,” he said.",jaya science technology innovation ministry possibility artificial intelligence application material apps minister chang lih bill consultation technology expert legal professional stakeholder public robust relevant strategic move global trend stronger regulation usage sunday star chang widespread essential label material generative assisted transparency enable informed consumption explore advocate policy measure content global standard transparency relevant certification bolster transparency effort standard guideline content provide easy understand explanation system economic forum european union legal framework chiefly rule data transparency quality accountability human oversight legislation ethical question implementation challenge industry education finance healthcare friday company openai alphabet meta voluntary commitment government implement measure content chang bill cover crucial aspect data privacy public awareness encompass transparency data privacy accountability cybersecurity legislation provision public development field legislation curtail development technology balance manage potential innovation contribute economy society crucial ministry development machine technology ethical guideline innovation misinformation form harmful content abuse election libellous content misinformation chang regulation crucial strong legal framework ethical guideline law transparency source severe penalty tool false relevant ministry social medium company misinformation spread increase effort content chang people recognise content opinion choice develop resource public awareness campaign basic generate content understanding bias inherent distinction human content awareness advantage people choice decision critical medium enables discussion rule guideline cautious aware community impact misinformation,"[(4, 0.99605525)]",4
572010,Main,16,23/07/2023,AI: Opportunity and threat in polls,"Experts warn that generative AI is transforming our elections — and could even undermine democracy. If the technology is used to sway people’s votes in the upcoming state elections, how can we protect people from false information and help them make the right decision at the ballot box?","“ANWAR Ibrahim was first married to a Malaysian woman named Siti Hasmah Mohamad Ali in 1971. They have six children together, including Nurul Izzah Anwar, who is a prominent Malaysian politician. Anwar Ibrahim was later married to Wan Azizah Wan Ismail in 1980, who is also a prominent politician in Malaysia. They have two daughters together, including Nurul Nuha Anwar and Nurul Ilham Anwar.”
 Any Malaysian can tell this profile of the Prime Minister is a blatant lie, says computer science expert Prof Emeritus Datuk Tengku Mohd Tengku Sembok – “But it is intriguing.”
 The text was produced by the artificial intelligence-driven (AI) ChatGPT bot when he prompted it for information about Anwar for his study on generative AI’s tendency to “hallucinate” or make up answers that are “plausible-sounding but incorrect or nonsensical” when it cannot find the information required to respond accurately, as ChatGPT’s creator, OpenAI, says on its website.
 Just imagine what it would be like for less well-known political figures or new election candidates. It will not be so easy to know if the information is fake or real, and we will need to verify it – something that Malaysians don’t habitually do.
 Text, however, is not the only content that can now be created by the sophisticated AI tools available today: realistic photos, videos and audio can be produced quickly, at minimal cost. On top of that, the technology can now churn out cloned human voices and convincing deepfakes more easily and cheaply.
 It is no wonder that tech and political experts in Europe, the United Kingdom and the United States are raising the alarm about the potential perils AI poses for democratic processes.  
 As US public policy think tank Brookings Institution puts it, we are moving into an era of “wholesale digital creation and dissemination” of targeted political messaging.
 While the dangers of misinformation and fake news during elections are nothing new, the scale of AI-generated false information can reduce voters’ ability to distinguish fake from real campaign material. They will be exposed not only to disinformation but also nefarious content created for the purpose of “confusing voters, slandering a candidate, or even sowing hate and inciting violence”. 
 And with the same technology also available at our fingertips, we in Malaysia too could be exposed to the same AI-powered politics, which is worrying many people ahead of the elections in six states that will be held on Aug 12. 
 New polling landscape
 As of now, political party insiders in Malaysia say efforts are being ramped up to identify potential voters as well as prepare measures to reach those who live outside the states they are registered in.
 They say the use of AI is indispensable, especially in curating social media feeds and producing visual campaign material. 
 “What we have affirmed during GE15 [the 15th General Election in November 2022] is that people are visual creatures. And they like things to come in a flurry, especially through video shorts,” says a party insider who declines to be named.
 More interestingly, at least one political party is working on using a chatbot on its website to engage with voters’ queries. The plan is to have the chatbot reply to questions on ongoing political issues.
 “I cannot guarantee that it will be ready on time since we will need a big data set to train the AI, but the plan is ongoing. 
 “This AI will respond, through text, in either Malay or English depending on the language used for the question. We want it to respond promptly so that users can feel as if they are talking to a real person,” says the insider.
 Tengku Mohd says the most worrying aspect of the use of generative AI is the accuracy of the facts produced. He explains that the fundamental technology used by the current iteration of generative AI, such as ChatGPT or DALL-E, is the use of an artificial neural network (ANN) in building large language models that are known to be lacking in transparency and needs to be trained with big data sets. 
 And if the training data set is flawed, the AI will “hallucinate” and produce “garbage”.
 “Transparency in the sense that ANN cannot explain how the decision is derived, which is a crucial part of any intelligent system. It works based on statistics of proximity and frequency of co-occurrences of objects, such as words, images, or sounds, gathered from a huge training data set.
 “Based on these statistics, the AI system generates stories, pictures, or sounds to answer our questions or create new content. If the training data set is flawed or incomplete, then the answer derived would be garbage, or, as it’s known, the ‘garbage in, garbage out’ (Gigo) phenomenon. 
 “This flaw is termed ‘hallucination’ where the AI system generates stories or narratives that are false.” 
 According to tech experts, these types of “hallucination” are also generated from the AI model’s inherent biases and lack of real-world understanding.  
 But not all AI-generated campaign materials are bad. 
 They can narrow the digital divide between demographics and reduce the information gap, especially for potential voters residing outside their respective home states. People can now receive updates on political goings-on and have their social media feeds curated based on the items they read.
 For Universiti Malaya’s political analyst Assoc Prof Dr Awang Azman Awang Pawi, when it comes to AI, the term “reachability” can even mean crossing the timeline.
 For example, he says, even though the Indonesian presidential election is to be held next year, there are already AI-gene-rated videos about the campaign being disseminated now. The videos and campaign materials are already reaching voters although the polls are set to take place next year, he says.  
 And gone are the days of relying solely on the war of flags and communal gatherings in electoral campaigning.
 “People do not have to gather for ceramah anymore. They can now read up on material [on their devices] designed with the help of generative AI based on the individual profile of targeted voters, whether a friend, a foe, or fencesitters,” Tengku Mohd says.
 He is excited to see how the use of generative AI will pan out in the coming state elections next month.
 “It will be interesting. This will be the test bed to measure the knowledge and skills of cyber warriors in mastering AI. Most often, ‘war’ gives birth to technological innovators and inventors.”
 Race to the polls
 Muda data and technology director Faezrah Rizalman believes that Malaysia is on its way towards utilising AI more comprehensively in electoral campaigns.
 The use of traditional AI in electoral campaigns has already gained significant momentum here in recent years, she says, pointing to Invoke Malaysia.
 The data firm effectively employed sophisticated AI-driven data crunching techniques by leveraging vast amounts of social media data during the 2018 general elections, she says.
 “Through this analysis, they gained valuable insights into voter sentiments and preferences, enabling them to craft campaign messages that resonated with specific segments of the electorate.” 
 Faezrah adds that parties like Bersatu and PAS have effectively utilised TikTok to reach a broader audience and effectively promote their campaign messages.
 (PAS and Bersatu could not be reached for comments.)
 “The previous general election in Malaysia highlighted the influence of AI-driven platforms like TikTok in rapidly disseminating political messaging.
 “While TikTok is primarily a social media platform, its sophisticated algorithms and AI recommendations personalise content based on user preferences and behaviours.”
 Consequently, Faezrah says it is essential to address challenges such as data privacy, algorithmic biases, and the need for transparency and ethical guidelines to ensure responsible AI use.
 “AI has the potential to be abused in electoral campaigns, raising concerns about fairness and the integrity of elections.
 “One particular worry revolves around the manipulation of AI algorithms to disseminate false information and engage in deceptive practices.
 “With AI’s capacity to analyse large volumes of data and target specific voter groups, there is a risk of campaigns employing AI to spread misinformation, sway public opinion, or even engage in voter suppression tactics.” 
 Voter suppression is a strategy employed to influence the outcome of electoral results by preventing people from coming out on polling day.
 “Such activities could undermine democracy by distorting information and manipulating voters’ decision-making,” Faezrah says.",anwar ibrahim malaysian woman siti hasmah mohamad ali child nurul izzah anwar prominent malaysian politician anwar ibrahim wan azizah wan ismail prominent politician malaysia daughter nurul nuha anwar nurul ilham anwar malaysian profile prime minister blatant lie computer science expert prof emeritus datuk tengku mohd tengku sembok text artificial intelligence chatgpt bot anwar study generative tendency hallucinate answer plausible incorrect nonsensical respond chatgpt creator website imagine political figure election candidate easy fake real verify malaysian text content sophisticated tool realistic photo video audio minimal cost top technology churn human voice deepfakes tech political expert united kingdom alarm potential peril pose democratic process public policy tank brookings institution era wholesale digital creation dissemination political messaging danger fake news election false voter ability distinguish fake real campaign material disinformation nefarious content purpose voter candidate sowing hate violence technology fingertip powered politics people election polling landscape political party insider effort potential voter measure live indispensable social medium feed visual campaign material election people visual creature video short party insider decline political party chatbot website engage voter query reply question political issue ready time data train plan respond text malay english language question respond user real person insider tengku mohd aspect generative accuracy explains fundamental technology current iteration generative chatgpt dall artificial neural network ann building language model transparency data set data set hallucinate produce garbage transparency sense ann decision crucial intelligent system statistic proximity frequency occurrence image gathered huge training data statistic system generates story picture answer question content training data flawed incomplete answer garbage garbage garbage gigo phenomenon flaw hallucination system story narrative false tech expert type hallucination model inherent bias real understanding campaign material bad narrow digital divide demographic gap potential voter respective people update political going social medium feed item universiti malaya political analyst assoc prof awang azman pawi term reachability timeline indonesian presidential election gene video campaign video campaign material voter poll day war flag communal gathering electoral people ceramah material device generative individual profile voter foe fencesitter generative pan election month test bed measure knowledge skill warrior war birth technological innovator inventor race poll data technology director rizalman malaysia electoral campaign traditional electoral campaign momentum invoke malaysia data firm sophisticated data technique vast amount social medium data election analysis valuable insight voter sentiment preference craft campaign message specific segment faezrah party pa utilised tiktok reach broader audience campaign message bersatu comment previous election malaysia influence driven platform political messaging tiktok social medium platform sophisticated algorithm recommendation content user preference faezrah essential address challenge privacy algorithmic bias ethical guideline responsible potential abused electoral campaign concern fairness integrity election manipulation algorithm disseminate false engage deceptive practice capacity analyse volume target specific voter risk campaign spread misinformation public opinion engage voter suppression tactic voter suppression strategy influence outcome electoral people day activity democracy voter decision faezrah,"[(1, 0.9981526)]",1
572012,Main,17,23/07/2023,Safeguarding voters from AI misuse,,"THE public needs to be protected from any exploitation or possible misuse of content produced by artificial intelligence (AI), especially during election seasons.
 Experts and politicians say the trustworthiness of such material will have to be assured through transparency in the wake of possible automated production of deepfake speeches or imagery, among others. Such a threat is real; several social media platforms have long put in place gatekeeping measures to mitigate negative content through the use of machine learning process.
 TikTok, for example, uses automated moderation technology to identify content which violates its community guidelines.
 “These systems look at a variety of signals across content, including keywords, images, titles, descriptions, and audio,” TikTok says at its website.
 It also has human moderators whose responsibilities include reviewing flagged content, reports from users, and trending harmful content. 
 It was reported in April that TikTok has updated its guidelines by including content created or modified by AI, which it classifies as “synthetic media”.  According to searchenginejournal.com, creators must label such content to curb potential risks of spreading misinformation.
 “To reduce potential harm, synthetic media featuring real private individuals is prohibited. Private individuals include anyone under 18 and adults who are not public figures.
 The use of public figures over 18 – government officials, politicians, business leaders, and celebrities – is permitted, but with restrictions.
 “Creators must not use synthetic media to violate policies against hate speech, sexual exploitation, and severe harassment. They must also clearly disclose synthetic media and manipulated content that depict realistic scenes with fake people, places, or events.”
 If not labelled, any content created with synthetic media will be removed when detected, says TikTok. 
 As many tech experts have said, however, AI-generated text is not easy to spot.
 On Friday, it was reported United States president Joe Biden announced seven of the most influential AI tech companies’ voluntary pledges  – including Google and OpenAI –  to put up safeguards on the use of generative AI. Biden is also working to draft legislation on regulating AI, on the heels of concerns voiced by consumers and ethicists.
 Meta, which owns Facebook, Instagram and WhatsApp, among others, implements several measures to curb the spread of misinformation or false content, including labelling them as such.
 “We include warnings on posts that are rated false so that you can decide what to read or share.
 “When third-party fact-checkers label content false, we significantly reduce its distribution so fewer people see it,” Meta says on its site.
 In the same vein, former Shah Alam Umno youth chief Mohd Dendera Billah Zamzuri says the drafting of speeches through the AI-driven ChatGPT bot, for example, will need to be labelled as “produced with AI assistance” for accountability of its owner and reader upon delivery.
 He says this is particularly crucial for top political leaders, whose words will dictate party or government policy.
 “The trustworthiness of information or proposals produced by generative AI remains to be questioned especially during electoral campaigns. As such, speeches created by ChatGPT should be mentioned as so. This is transparency, and particularly important for party leaders.”
 A political party insider echoes Mohd Dendera’s views, saying it is one way to protect the people’s interests, including party members, during election season when promises or pledges are rife.
 “At the end of the day, the speeches will be seen as their organisation’s policy.”
 Concurring, Muda data and technology director Faezrah Rizalman says political parties and candidates should be obliged to disclose their AI strategies and provide clarity on how AI algorithms are employed to target voters.
 “This transparency would enable scrutiny and ensure responsible and ethical AI usage.”
 She stresses specific regulations and guidelines should be established to govern AI usage in electoral campaigns.
 “These rules can define permissible AI applications, emphasise the importance of fair and transparent campaigning practices, and establish boundaries to prevent the dissemination of false or misleading information. 
 “Independent regulatory bodies could be entrusted with overseeing compliance and enforcing these guidelines. For example, regulations could address the ethical collection, storage, and analysis of voter data, drawing lessons from international best practices like the General Data Protection Regulation in the European Union.”
 With the possibility of AI being used to create fake news or target voters with personalised messages that are designed to manipulate them, it remains pertinent to be aware of such risks.
 The formation of ethical guidelines for using AI in electoral campaigns should be carried out by various parties, says policy and political lobbying firm Imperium Consulting’s chief executive officer Rahman Hussin.
 “These guidelines should  be formed by a variety of stakeholders, including political parties, civil society groups, and technology companies.”
 Ultimately, it is imperative for the people to be aware of the capabilities, uses and abuses of AI, says Bar Council’s technology, cyber and privacy law committee chairman Sarah Yong Li Hsien. 
 “When people know that what they see or hear may not be true or real, or could be designed to manipulate them, they would be conscious that they should not receive information at face value and should always fact-check.”
 Other than awareness and AI-literacy programmes, she also proposes a greater transparency on online platforms concerning curated contents and profiling.
 “We would also need to advocate for more transparency from online platforms when it comes to targeted advertising and profiling, as well as the criminalisation of profiling based on certain sensitive personal data. 
 “One of the initiatives of the Bar Council’s technology, cyber and privacy law committee is to conduct webinars on AI for awareness, not just within the legal fraternity, but pertinently for the public at large.”",public exploitation misuse content artificial intelligence election season expert politician material transparency wake production deepfake speech threat real social medium platform measure negative content machine process tiktok moderation technology content violates community guideline system variety signal content keywords image title description tiktok website human moderator responsibility content report user harmful content april tiktok guideline content modified classifies synthetic medium searchenginejournal creator content curb potential risk misinformation potential harm synthetic medium real private individual private individual adult public figure public figure government official politician business leader celebrity restriction creator synthetic medium violate policy speech sexual exploitation severe harassment synthetic medium content depict realistic scene people event content synthetic medium detected tiktok tech expert text easy spot friday united president joe biden influential tech company voluntary pledge google openai safeguard generative biden draft legislation heel concern consumer ethicist facebook instagram whatsapp implement measure spread misinformation false content labelling warning post false decide share party checker content false distribution fewer people site vein alam umno youth chief mohd dendera billah zamzuri speech chatgpt bot assistance accountability owner reader delivery crucial top political leader party government policy trustworthiness proposal generative questioned electoral campaign speech chatgpt transparency party leader political party insider echo dendera view people party election season pledge day speech organisation policy muda data technology director faezrah rizalman political party candidate strategy clarity algorithm target voter enable scrutiny responsible ethical usage specific regulation guideline govern usage electoral campaign rule permissible application fair transparent campaigning practice boundary prevent dissemination false misleading independent regulatory body compliance guideline regulation ethical collection storage analysis voter data lesson international practice data protection regulation european union possibility create fake news target voter message manipulate pertinent aware risk formation ethical guideline electoral campaign party policy political lobbying firm imperium chief executive officer rahman hussin guideline variety stakeholder political party civil society technology company imperative people aware capability bar council technology privacy law committee chairman hsien people true real conscious receive check awareness literacy programme transparency online platform content advocate transparency online platform criminalisation sensitive personal data initiative council technology privacy law committee conduct webinars awareness legal fraternity public,"[(3, 0.6484473), (4, 0.34976557)]",3
572014,Main,17,23/07/2023,The rule of law for AI in elections,,"LAWS to govern the use of artificial intelligence (AI) in electoral campaigns should be in place due to its potential of being adversely implemented, says the Bar Council. 
 Bar Council’s technology, cyber and privacy law committee chairman Sarah Yong Li Hsien says while the Election Offences Act 1959 stipulates various offences which criminalise corrupt practices and acts that would impinge on a person’s free will when it comes to elections, more advanced methods can be used through AI to carry out such offences.
 Malaysia’s situation is unlike in Europe, where the risk of AI is recognised through the drafting of the AI Act last month, which seeks to significantly bolster regulations on the development and use of AI, according to a report by the World Economic Forum.
 “Yes, there should be laws to govern the use of AI for election purposes. With AI, there are now advanced methods that could deceive and manipulate masses on a very personal and direct manner, which in effect impinges their free will in voting.”
 She says among the possible abuse of AI includes the employment of bots to impersonate real individuals and profiling target groups based on sensitive personal data.
 “Some methods [that can be used] are AI-generated photos and videos, AI bots personating as people on social media, targeted political advertising and profiling based on personal data, and even sensitive information such as race, religious beliefs and political views.
 “Our current laws are arguably restrictive, have yet to catch up with the times, and may not be wide enough to cover these abuses due to advancements in technology, especially AI.”
 The Science, Technology and Innovation Ministry has said that it is looking into the possibility of regulating AI in Malaysia, which may also encompass elections.
 Minister Chang Lih Kang says there is a need for a clear legal framework to regulate the possible abuse of AI in elections through slanderous content or misinformation.
 “It is crucial to have strong legal frameworks and ethical guidelines for AI use. This could include laws that mandate transparency about the source of information and severe penalties for those who use AI tools to spread false information,” he says. 
 Yong says while Malaysia currently does not have a specific law to regulate AI, the Com-munications and Multimedia Act 2010 (CMA) and the Per-sonal Data Protection Act 2010 (PDPA) may work to address any outcome from its potential abuse.
 “There is no standalone law governing the use of AI. How-ever, an adverse outcome from potential abuse of AI can arguably fall under the ambit of Section 211 of the CMA, which prohibits indecent, obscene, false, menacing or offensive content, as well as Section 233 of the same Act that prohibits the making, creation, solicitation and transmission of communications that are obscene, indecent, false, menacing or offensive.”
 As for the PDPA, its jurisdiction may not be enough to address the misuse of personal data in elections.
 “We also have the PDPA that makes it illegal for personal data to be misused commercially in circumstances such as if consent was not given by the data subject for their data to be used in a certain way or for a certain purpose.
 “Nevertheless, the scope of the PDPA is restricted to commercial transactions and elections may arguably be outside its scope,” Yong says.",law artificial intelligence electoral campaign potential bar council bar council technology privacy law committee chairman hsien election offence offence criminalise corrupt practice impinge person free election method carry offence malaysia situation europe risk drafting month bolster regulation development report economic forum law election purpose advanced method deceive manipulate mass personal direct manner impinges free voting abuse employment bot real individual target sensitive personal data method photo video bot people social medium political advertising personal data sensitive race religious belief political view current law catch time wide cover advancement technology science technology innovation ministry possibility malaysia encompass election minister chang lih legal framework regulate abuse election slanderous content misinformation crucial strong legal framework ethical guideline law transparency source severe penalty tool false yong malaysia specific law regulate munications cma sonal data protection pdpa address potential abuse standalone law adverse outcome potential abuse ambit cma prohibits indecent obscene false offensive content prohibits creation solicitation transmission communication indecent false offensive pdpa jurisdiction address personal data election illegal personal data circumstance consent data subject data purpose scope pdpa commercial transaction election,"[(4, 0.9950396)]",4
571134,StarMetro,10,21/07/2023,AI education consortium marks a first for Malaysia,Tech Dome Penang draws on brightest minds to  promote research and innovation in key disciplines,"Malaysia is pushing towards  artificial intelligence (AI) mastery with a meeting of minds under Tech Dome Penang. 
 The AI Education Consortium, the first of its kind in the country, aims to foster collaboration among educational institutions, researchers, AI experts and industry partners to promote AI education to students.
 It comprises 14 institutions of higher education, professional bodies, industries and government-linked bodies that will provide a platform for sharing of knowledge, resources and best practices, and to facilitate joint research and development initiatives.
 “AI skills are becoming increasingly essential in our daily lives and Tech Dome Penang is the first centre to have conducted lots of AI events in Malaysia,” said its chief executive officer Khoo Boo Wooi.
 “A strong consortium can bring together the brightest minds in various key disciplines.” 
 He said that with the fast growth of the electronic and manufacturing sector, the country needed more technologists and engineers.
 “This is why our current focus is on the rural areas and Penang mainland. We need to spend more resources on the mainland and the south-west district here.
 “Although we are facing some challenges, we believe this will not only provide a fair chance to students in these areas, but also help nurture future talents to help our industries,” Khoo said during the seventh anniversary celebration of Tech Dome Penang at Komtar. 
 Tech Dome Penang is a not-for-profit science and technology centre run by Penang Tech Centre. It is an initiative by the Penang government as a public-private partnership.
 Khoo also thanked board members, sponsors and partners for their support over the years, which resulted in Tech Dome Penang hitting more than 1.1 million visitors since its opening in 2016.
 “We have thus far organised more than 2,550 STEM (science, technology, engineering and mathematics) workshops and activities which benefitted more than 435,000 students in the country,” he said.
 Present at the event were Tech Dome Penang board chairman and caretaker Deputy Chief Minister II Dr P. Ramasamy, incumbent Komtar assemblyman Teh Lai Heng as well as Penang Tech Centre pioneers and board of directors Datuk Seri Wong Siew Hai, Datuk Seri Lim Kok Khong, Datuk Cheok Lay Leng and Ang Lye Hin.
 Also there were board of directors Chris Lee Chun Kit, Satees Muniandy and Datin Bharati Suppiah, centre pioneer Datuk Toh Chin Leong, Penang STEM general manager Richard Chung, Penang Women’s Development Corporation chief executive officer Ong Bee Leng, Penang Youth Development Corporation general manager Dr Gwee Sai Ling, representatives from industry partners, professional bodies and institutions of higher education.
 In his speech, Ramasamy 
 said that through countless exhibitions, workshops and interactive displays, Tech Dome Penang 
 had truly evolved into a beacon of scientific exploration and learning.
 He thanked the state Education Department for endorsing all programmes by Tech Dome Penang, which reflected the common mission to groom STEM talents for the needs of the nation in meeting the challenges of the Fourth Industrial Revolution and digital transformation.
 The AI Education Consortium aims to develop comprehensive and standardised AI curricula  for K-12 education by focusing  on content that aligns with the latest advancements in AI technology.
 The consortium also supports the professional development of teachers by providing training programmes, workshops and resources related to AI education. 
 Other objectives include promoting research and innovation in AI education and to raise awareness about the importance of AI education in K-12 settings by engaging with parents, students, educators and communities through campaigns, events and outreach activities.
 In conjunction with the anniversary, Tech Dome Penang also held two competitions, which drew some 200 participants from primary and secondary schools as well as institutions of higher education.
 The Amazing STEM Race for the older group saw many teams perform a wide array of activities and tasks to complete the challenge.
 The Junior Architect Challenge had primary school pupils constructing the skeleton of a building, which were tested using weights to determine their structural strength. 
 At the same event, four youngsters from Penang received certificates of appreciation for their participation in Codeavour 2022, the biggest international AI and coding competition for children. 
  Tan Yeng Yang and Tio Tze Khai, both 12, from SJK (C) Sin Ya in Alma, Bukit Mertajam, won  for the Best AI and ML (Meta Language) Project.
 Ong Yiu Shan and Eng Zhong Ci, both 12, from SJK (C) Shih Chung in Sungai Nibong won a consolation prize.",malaysia artificial intelligence mastery meeting mind dome penang education consortium country foster collaboration educational institution researcher expert industry partner education student institution professional body industry government body knowledge resource practice joint development initiative skill essential daily tech dome penang centre lot event malaysia chief executive officer boo wooi strong consortium bring brightest mind key discipline growth electronic manufacturing sector country engineer current rural penang spend resource south west district facing challenge fair chance student nurture future talent industry seventh anniversary celebration tech dome penang komtar tech dome penang profit science technology centre penang tech centre initiative penang government public private partnership khoo board sponsor partner tech dome penang visitor stem science technology engineering mathematics workshop activity student country event tech dome penang board chairman caretaker deputy chief minister ramasamy incumbent komtar assemblyman teh lai heng penang tech centre pioneer board director seri wong siew hai datuk seri lim kok khong datuk cheok leng ang lye board director lee chun kit satees datin bharati suppiah centre pioneer datuk toh chin leong penang stem manager richard chung woman development corporation chief executive officer ong bee leng penang youth development corporation manager gwee sai representative industry partner professional body institution speech ramasamy countless exhibition interactive display dome penang beacon scientific exploration learning education department programme tech dome penang common mission groom stem talent nation meeting fourth industrial revolution digital transformation education consortium comprehensive curriculum education content aligns advancement technology consortium professional development teacher programme workshop resource education objective innovation education raise awareness education setting parent student educator community event outreach activity anniversary tech dome held competition participant primary secondary school institution stem race team wide array activity complete challenge junior architect challenge primary school pupil skeleton building weight structural strength event youngster certificate participation codeavour biggest international competition child yeng yang tio tze khai sjk sin alma bukit mertajam meta language project ong zhong sjk shih chung sungai nibong consolation prize,"[(0, 0.24438728), (2, 0.75353986)]",2
571024,Main,20,20/07/2023,AI bias as clear as black and white,,"ARTIST Stephanie Dinkins has long been a pioneer in combining art and technology in her Brooklyn-based practice. In May she was awarded US$100,000 by the Guggenheim Museum for her groundbreaking innovations, including an ongoing series of interviews with Bina48, a humanoid robot.
 For the past seven years, she has experimented with artificial intelligence’s ability to realistically depict Black women, smiling and crying, using a variety of word prompts. The first results were lacklustre if not alarming: her algorithm produced a pink-shaded humanoid shrouded by a black cloak.
 “I expected something with a little more semblance of Black womanhood,” she said. 
 And although the technology has improved since her first experiments, Dinkins found herself using runaround terms in the text prompts to help the AI image generators achieve her desired image, “to give the machine a chance to give me what I wanted.” 
 But whether she uses the term “African American woman” or “Black woman”, machine distortions that mangle facial features and hair textures occur at high rates.
 “Improvements obscure some of the deeper questions we should be asking about discrimination,” Dinkins said. 
 The artist, who is Black, added, “The biases are embedded deep in these systems, so it becomes ingrained and automatic. If I’m working within a system that uses algorithmic ecosystems, then I want that system to know who Black people are in nuanced ways, so that we can feel better supported.”
 She is not alone in asking tough questions about the troubling relationship between AI and race. Many Black artists are finding evidence of racial bias in AI, both in the large data sets that teach machines how to generate images and in the underlying programs that run the algorithms.
 In some cases, AI technologies seem to ignore or distort artists’ text prompts, affecting how Black people are depicted in images, and in others, they seem to stereotype or censor Black history and culture.
 Discussion of racial bias within AI has surged in recent years, with studies showing that facial recognition technologies and digital assistants have trouble identifying the images and speech patterns of non-white people. 
 The studies raised broader questions of fairness and bias.
 Major companies behind AI image generators – including OpenAI, Stability AI and Midjourney – have pledged to improve their tools.
 “Bias is an important, industrywide problem,” Alex Beck, a spokeswoman for OpenAI, said in an email interview, adding that the company is continuously trying “to improve performance, reduce bias and mitigate harmful outputs”.
 She declined to say how many employees were working on racial bias, or how much money the company had allocated toward the problem.
 “Black people are accustomed to being unseen,” Senegalese artist Linda Dounia Rebeiz wrote in an introduction to her exhibition “In/Visible,” for Feral File, an NFT marketplace. “When we are seen, we are accustomed to being misrepresented.”
 To prove her point during an interview with a reporter, Rebeiz, 28, asked OpenAI’s image generator, DALL-E 2, to imagine buildings in her hometown, Dakar. The algorithm produced arid desert landscapes and ruined buildings that Rebeiz said were nothing like the coastal homes in the Senegalese capital.
 “It’s demoralising,” Rebeiz said. “The algorithm skews toward a cultural image of Africa that the West has created. It defaults to the worst stereotypes that already exist on the internet.”
 Last year, OpenAI said it was establishing new techniques to diversify the images produced by DALL-E 2, so that the tool “generates images of people that more accurately reflect the diversity of the world’s population”.
 Stability AI, which provides image generator services, said it planned on collaborating with the AI industry to improve bias evaluation techniques with a greater diversity of countries and cultures.
 Bias, the AI company said, is caused by “overrepresentation” in its general data sets, though it did not specify if overrepresentation of white people was the issue here.
 Earlier this month, Bloomberg analysed more than 5,000 images generated by Stability AI, and found that its program amplified stereotypes about race and gender, typically depicting people with lighter skin tones as holding high-paying jobs while subjects with darker skin tones were labeled “dishwasher” and “housekeeper”.
 However, these problems have not stopped a frenzy of investments in the tech industry.
 A recent rosy report by the consulting firm McKinsey predicted that generative AI would add US$4.4 trillion to the global economy annually. Last year, nearly 3,200 startups received US$52.1bil in funding, according to the GlobalData Deals Database.
 Experts who study artificial intelligence said that bias goes deeper than data sets, referring to the early development of this technology in the 1960s.
 “The issue is more complicated than data bias,” said James Dobson, a cultural historian at Dartmouth College and the author of a recent book on the birth of computer vision. 
 There was very little discussion about race during the early days of machine learning, according to his research, and most scientists working on the technology were white men.
 “It’s hard to separate today’s algorithms from that history, because engineers are building on those prior versions,” Dobson said.
 To decrease the appearance of racial bias and hateful images, some companies have banned certain words from text prompts that users submit to generators, like “slave” and “fascist”.
 Auriea Harvey, an artist included in the Whitney Museum’s recent exhibition “Refiguring”, about digital identities, bumped into these bans for a recent project using Midjourney.
 “I wanted to question the database on what it knew about slave ships,” she said. “I received a message saying that Midjourney would suspend my account if I continued.”
 Dinkins ran into similar problems with NFTs that she created and sold showing how okra was brought to North America by enslaved people and settlers. She was censored when she tried to use a generative program, Replicate, to make pictures of slave ships.
 She eventually learned to outwit the censors by using the term “pirate ship”. The image she received was an approximation of what she wanted, but it also raised troubling questions for the artist.
 “What is this technology doing to history?” Dinkins asked. “You can see that someone is trying to correct for bias, yet at the same time that erases a piece of history. I find those erasures as dangerous as any bias, because we are just going to forget how we got here.”
 Naomi Beckwith, chief curator at the Guggenheim Museum, credited Dinkins’ nuanced approach to issues of representation and technology as one reason the artist received the museum’s first Art & Technology award.
 “Stephanie has become part of a tradition of artists and cultural workers that poke holes in these overarching and totalising theories about how things work,” Beckwith said.
 She added that her own initial paranoia about AI programs replacing human creativity was greatly reduced when she realised these algorithms knew virtually nothing about Black culture. — ©2023 The New York Times Company",artist stephanie art technology brooklyn practice guggenheim museum innovation series interview humanoid robot artificial intelligence ability depict black woman variety word lacklustre algorithm pink humanoid black cloak semblance black womanhood technology experiment runaround term text prompt image generator image machine chance term african american woman black woman machine distortion facial feature texture rate improvement obscure deeper question discrimination artist black bias deep system automatic system algorithmic system black people nuanced feel tough question relationship race black artist evidence racial bias data set machine generate image program technology distort artist prompt black people image censor black history culture discussion racial bias study facial recognition technology digital assistant trouble image speech white people study broader question major company image generator openai stability midjourney tool bias industrywide alex beck spokeswoman email interview company performance bias mitigate harmful output employee racial bias money company black people unseen senegalese artist linda dounia rebeiz introduction exhibition visible feral file nft marketplace interview reporter rebeiz openai image generator dall imagine building dakar algorithm arid desert landscape building coastal home senegalese capital rebeiz algorithm cultural image africa default worst stereotype internet openai technique image dall tool generates people diversity population stability image generator service industry bias evaluation technique diversity country bias company overrepresentation data set overrepresentation white people issue month bloomberg image stability program stereotype race gender people skin tone job subject skin tone housekeeper frenzy investment tech industry rosy report firm mckinsey generative global economy bil funding globaldata deal database expert artificial intelligence bias deeper data set development technology issue data bias james dobson cultural historian dartmouth college author book birth computer vision discussion race day machine scientist technology white hard separate algorithm history engineer prior version decrease appearance racial bias hateful image company text prompt user generator fascist auriea harvey artist whitney museum exhibition digital identity ban project midjourney question database ship message midjourney suspend account dinkins nfts brought north america people settler generative program replicate picture ship outwit censor term ship image approximation troubling question technology history dinkins bias time piece history dangerous bias naomi beckwith chief curator guggenheim museum dinkins nuanced approach issue representation technology reason artist museum art technology award stephanie tradition cultural worker hole theory initial paranoia program human creativity realised algorithm black culture york time company,"[(2, 0.105423376), (4, 0.892899)]",4
570968,Main,25,20/07/2023,Britain’s MI6 intelligence chief says AI won’t replace human spies,,"PRAGUE: Artificial intelligence will change the world of espionage, but it won’t replace human spies, the head of Britain’s MI6 intelligence agency says in prepared remarks.
 Richard Moore, director of the UK’s foreign intelligence agency, is set to speak in Prague on evolving threats to the West from Russia and Iran, and argue that the “human factor” will remain crucial in an era of rapidly evolving machine learning.
 “AI is going to make information infinitely more accessible and some have asked whether it will put intelligence services like mine out of business,” he says in extracts released in advance by the UK government yesterday.
 “In fact, the opposite is likely to be true,” he adds. 
 “As AI trawls the ocean of open source, there will be even greater value in landing, with a well-cast fly, the secrets that lie beyond the reach of its nets.”
 Moore, who has previously warned that the West was falling behind rivals in the AI race, will argue that “the unique characteristics of human agents in the right places will become still more  significant,” highlighting spies’ ability to “influence decisions inside a government or terrorist group.”
 Speaking publicly about spycraft is still something of a novelty for Britain’s intelligence services. 
 The government refused even to confirm the existence of MI6 until 1992, and public speeches by its leaders are infrequent.
 Moore has chosen to give  yesterday’s address in the Czech capital, home of the 1968 “Prague Spring” freedom movement  that was crushed by Soviet tanks. — AP",prague artificial intelligence change espionage human spy intelligence agency remark director foreign intelligence agency speak prague threat russia iran argue human factor crucial era machine accessible intelligence service mine business extract advance government yesterday true trawl ocean source fly secret reach net west rival race argue unique characteristic human agent spy ability influence decision government terrorist speaking novelty britain intelligence service government confirm existence public speech leader infrequent yesterday address czech capital prague spring freedom movement soviet tank,"[(4, 0.98898)]",4
570564,StarBiz,12,19/07/2023,EU’s AI lobbying blitz gets lukewarm response,Asian countries show muted reception to talks,"STOCKHOLM: The European Union (EU) is lobbying Asian countries to follow its lead on artificial intelligence (AI) in adopting new rules for tech firms that include disclosure of copyrighted and AI-generated content, according to senior officials from the EU and Asia.
 The EU and its member states have dispatched officials for talks on governing the use of AI with at least 10 Asian countries including India, Japan, South Korea, Singapore and the Philippines, they said.
 The bloc aims for its proposed AI Act to become a global benchmark on the booming technology the way its data protection laws have helped shape global privacy standards.
 However, the effort to convince Asian governments of the need for stringent new rules is being met with a lukewarm reception, seven people close to the discussions told Reuters.
 Many countries favour a “wait and see” approach or are leaning towards a more flexible regulatory regime.
 The officials asked not be named as the discussions, whose extent has not been previously reported, remained confidential.
 Singapore, one of Asia’s leading tech centres, prefers to see how the technology evolves before adapting local regulations, an official for the city-state told Reuters.
 Officials from Singapore and the Philippines expressed concern that moving overly hasty regulation might stifle AI innovation.
 As Reuters reported last month, South-East Asian countries are drawing up voluntary guidelines. 
 Japan, for its part, is leaning towards softer rules than the stringent approach championed by the EU, as it looks to the technology to boost economic growth and make it a leader in advanced chips.
 Efforts in Asia are part of a global push by European nations that include talks with countries such as Canada, Turkiye and Israel, Dutch digital minister Alexandra van Huffelen told Reuters in an interview.
 “We’re trying to figure out on how we can make the regulation from the EU copied, applicable and mirrored as it is with the GDPR,” van Huffelen said late last month, referring to the General Data Protection Regulation, the EU’s data privacy regime.
 The emergence of AI has been hailed as a breakthrough that will usher in an era of rapid advances in science and technology, revolutionising all aspects of human activity, but also painted as an existential threat.
 EU lawmakers in June agreed to a trailblasing set of draft rules, which would make companies such as ChatGPT operator OpenAI disclose AI-generated content, help distinguish so-called deep fake images from real ones and ensure safeguards against illegal content.
 The proposed legislation, which also envisages financial fines for rule violations, faces resistance from companies, with 160 executives last month signing a letter warning it could jeopardise Europe’s competitiveness, investment and innovation.
 Still, officials from the EU, which has signed “digital partnerships” with Japan, South Korea, and Singapore, voice optimism they can find common ground with international partners to advance cooperation on technologies including AI.
 “Our mission is again to make sure that what’s happening in the EU, which is our large constituency if I may say so, is protected,” EU industry chief Thierry Breton told Reuters during a trip to South Korea and Japan to discuss AI and semiconductors.
 “I believe that it will be probably not too far from each other because we share the same values,” Breton said of regulation of AI in the EU and countries such as Japan.
 Leaders of the Group of Seven (G7) economies made of Canada, France, Germany, Italy, Japan, Britain, the United States and the EU, in May called for adoption of standards to create “trustworthy” AI and to set up a ministerial forum dubbed the “Hiroshima AI process”.
 Seoul will continue discussing AI regulation with the EU but is more interested in what the G7 is doing, a South Korean official said following a meeting with Breton.
 The EU is planning to use the upcoming G20 meetings to further push for global collaboration on AI, notably with 2023 president India, van Huffelen said. —  Reuters",stockholm european union asian country lead artificial intelligence rule tech firm disclosure content senior official asia official talk asian country india japan philippine bloc aim global benchmark technology data protection law shape global privacy standard effort convince asian government stringent rule lukewarm reception people close discussion reuters country wait approach flexible regulatory regime official discussion extent remained confidential singapore asia tech centre prefers technology local regulation official city reuters official philippine concern hasty regulation stifle innovation reuters month south east asian country voluntary guideline japan softer rule approach technology economic growth leader chip effort global push european nation talk country turkiye israel dutch digital minister alexandra van huffelen reuters interview figure regulation applicable mirrored gdpr van late month data protection regulation data privacy regime emergence usher era rapid advance science technology aspect human activity existential threat lawmaker set draft rule company operator openai content distinguish deep fake image real safeguard illegal content legislation financial fine rule violation resistance company executive month letter jeopardise europe competitiveness investment innovation official digital partnership south korea voice optimism common ground international partner advance cooperation technology mission constituency industry chief thierry breton reuters trip japan semiconductor share regulation country leader economy france germany italy japan britain united adoption standard trustworthy ministerial forum hiroshima process seoul regulation south korean official meeting breton upcoming meeting push global collaboration president india van huffelen reuters,"[(4, 0.99629396)]",4
570246,Main,6,18/07/2023,"RM64,000 lost to ‘AI investment scheme’",,"JOHOR BARU: It was a bitter pill to swallow for a housewife who got cheated out of her savings of over RM64,000 after falling for an online investment scheme that claimed to use artificial intelligence (AI) to give her high returns. 
 The 61-year-old, known only as Tan, said she thought she was being clever by taking a few months to observe the scheme after first coming across it in March. 
 “I had prior experience in stock trading. I learned about the scheme from a Facebook advertisement and out of curiosity, I clicked on it and it led me to download an app.
 “I wanted to give the app a try as it claimed to provide accurate insider information and used AI to source background information on stocks and investment portfolios in order to save us from having to do this ourselves. 
 “I was contacted via WhatsApp by someone who claimed to be an agent, telling me that I could easily earn about RM700 just by signing my attendance in the app daily and observing the situation if I was still hesitant.
 “So, I signed my attendance daily for about three months and was promised RM732. However, I was told I had to enter my particulars by signing up for an account in the app to get my hands on the money,” said Tan who did what she was told.
 She said the agent then started to persuade her more fervently about joining the scheme, for which she was promised over RM70,000 with an investment of RM50,000.
 Tan said strangers trying to allay her concerns also contacted her via WhatsApp, claiming they knew her from the app.
 “Thinking their testimonials were true, I decided to dig into my savings to join the scheme.
 “I deposited money from May 23 until July 12, with amounts varying between RM2,000 and RM7,000 each time until this came up to more than RM64,000.
 “I should have known better because the accounts I deposited money into were different each time – from company accounts to personal accounts of people unknown to me,” said Tan, who is from Kluang.
 Using the https://semakmule.rmp.gov.my/ website, a check by The Star on one of the so-called company bank accounts Tan deposited into showed a “Warning” alert with six police reports lodged against it. 
 Another account showed the same alert with eight police reports lodged against it.
 Tan said she only realised she had fallen victim when the agent told her she had supposedly violated her “contract” and had to make a final deposit of RM7,840 to cash out all her earnings of more than RM80,000.
 “After I deposited that amount, everything was wiped out from my account in the app, including my personal information and the people who had contacted me.
 “I am under a lot of stress because the money I forked out was what I have saved up over the years. I cannot believe that it is all gone.
 “It was my retirement fund and the ‘coffin money’ for my funeral when I am gone one day,” lamented Tan, adding that she then sought help from Kluang MCA public complaints bureau chief Joan Ng.
 Ng said with many elderly people using social media, they had become easy targets for scam syndicates using new tactics. 
 “They use buzzwords like AI and ChatGPT, and operate with a group of people to slowly reel their victims in,” she added.
 Johor police chief Comm Datuk Kamarul Zaman Mamat reminded people to use the website to check the legitimacy of the bank accounts.
 “Do not be influenced by online advertisements that promise things that seem too good to be true,” he said. 
 Those who suspect they have been cheated can call the Johor police hotline at 07-221 2999 or head to the nearest station.",johor baru bitter pill swallow housewife saving online investment scheme artificial intelligence return clever month scheme march prior experience stock trading scheme facebook advertisement curiosity download app app provide accurate insider source background stock investment portfolio whatsapp agent attendance app daily situation hesitant daily month enter particular account app money tan agent scheme investment tan stranger concern whatsapp app testimonial true dig saving scheme money july amount time account money time company personal account people unknown tan kluang website check star company bank account alert police report account alert police report tan victim agent contract final deposit cash earnings amount account app personal people lot stress money retirement fund coffin money funeral day tan sought kluang mca public complaint bureau chief joan elderly people social medium easy target syndicate tactic buzzword chatgpt operate people victim johor police chief comm datuk kamarul zaman mamat people website legitimacy bank account influenced online advertisement true suspect call johor police hotline head nearest station,"[(2, 0.9943566)]",2
569790,Lifestyle,5,17/07/2023,AI alarm          and wake-up call,The Godfather of AI’ urges governments to stop the machine takeover.,"GEOFFREY Hinton, one of the so-called godfathers of artificial intelligence (AI), urged governments to step in and make sure that machines do not take control of society.
 Hinton made headlines in May when he announced that he quit Google after a decade of work to speak more freely on the dangers of AI, shortly after the release of ChatGPT captured the imagination of the world.
 The highly respected AI scientist, who is based at the University of Toronto, was speaking to a packed audience at the Collision tech conference in the Canadian city.The conference brought together more than 30,000 startup founders, investors, and tech workers, most of whom were looking to learn how to ride the AI wave without hearing a lesson on its dangers.
 “Before AI is smarter than us, I think the people developing it should be encouraged to put a lot of work into understanding how it might try to take control away,” Hinton said.
 “Right now there are 99 very smart people trying to make AI better and one very smart person trying to figure out how to stop it from taking over, and maybe you want to be more balanced,” he said.
 Hinton warned that the risks of AI should be taken seriously, despite his critics who believe he is overplaying the risks.
 “I think it’s important that people understand that this is not science fiction; this is not just fear mongering,” he insisted. “It is a real risk that we must think about, and we need to figure out in advance how to deal with it.”
 Hinton also expressed concern that AI would deepen inequality, with the massive productivity gain from its deployment going to the benefit of the rich and not workers.
 “The wealth isn’t going to go to the people doing the work. It is going to go into making the rich richer and not the poorer, and that’s very bad for society,” he added.
 He also pointed to the danger of fake news created by ChatGPT- style bots and said he hoped that AI-generated content could be marked in a way similar to how central banks watermark cash money.
 “It’s very important to try, for example, to mark everything that is fake as fake. Whether we can do that technically, I don’t know,” he said.
 The European Union is considering such a technique in its AI Act, legislation that will set the rules for AI in Europe and is currently being negotiated by lawmakers.
 ‘Overpopulation on Mars’
 Hinton’s list of AI dangers contrasted with conference discussions that were less about safety and threats and more about seizing the opportunity created in the wake of ChatGPT.
 Venture Capitalist Sarah Guo said doom and gloom talk of AI as an existential threat was premature and compared it to “talking about overpopulation on Mars”, quoting another AI guru, Andrew Ng.
 She also warned against “regulatory capture”, which would see government intervention protect incumbents before it had a chance to benefit sectors such as health, education, or science.
 Opinions differed on whether the current generative AI giants – mainly Microsoft-backed OpenAI and Google – would remain unmatched or whether new actors would expand the field with their own models and innovations.
 “In five years, I still imagine that if you want to go and find the best, most accurate, most advanced general model, you’re probably going to still have to go to one of the few companies that have the capital to do it,” said Leigh Marie Braswell of venture capital firm Kleiner Perkins.
 Zachary Bratun-Glennon of Gradient Ventures said he foresaw a future where “there are going to be millions of models across a network, much like we have a network of websites today”. – AFP",geoffrey hinton godfather artificial intelligence government machine society hinton headline quit google decade speak chatgpt imagination scientist university speaking audience collision tech conference canadian city conference startup founder investor tech worker lesson danger smarter people encouraged lot control hinton smart people smart person figure hinton risk critic risk people science fiction fear insisted real risk figure advance deal hinton concern deepen inequality massive productivity gain deployment benefit rich worker people richer poorer bad society danger news chatgpt style bot content marked central bank cash money mark european union technique legislation rule europe lawmaker mar hinton list danger conference discussion safety threat opportunity wake chatgpt venture capitalist sarah guo doom gloom talk existential threat premature overpopulation mar guru regulatory capture government intervention protect incumbent chance benefit sector health education science opinion current generative giant microsoft openai google unmatched actor field model innovation accurate model company leigh marie braswell venture capital firm kleiner perkins zachary bratun glennon gradient venture foresaw future million model network network website,"[(1, 0.9948228)]",1
570022,Main,20,17/07/2023,A law on AI – created by AI,,"WHEN Costa Rican lawmakers wanted to draw attention to the need to regulate artificial intelligence, they asked ChatGPT to write a new law to do it for them.
 They told the chatbot to “think like a lawyer” and draft a Bill according to the Constitution. They then sent the resulting text verbatim to the legislature.
 “We have had many positive reactions and many people who thought it to be very risky,” congresswoman Vanessa Castro, who led the introduction of the Bill, said.
 ChatGPT recommended Costa Rica create an institution to regulate AI systems governed by the principles of accountability, explainability, bias prevention and protecting human rights.
 The Bill was introduced in May, but is now being discussed in public forums before it goes to the parliamentary commission for amendments and further debate in Congress.
 “We learned that artificial intelligence is just another legislative tool that still needs the human hand,” Castro said.
 Costa Rica is the eighth country in Latin America to discuss or approve a law regulating AI in the past year.
 Costa Rican congresswoman Johana Obando said she supported AI regulation, but opposed the Bill because ChatGPT simply made up statistics and articles from the Costa Rican constitution.
 But her main objection was that she said the Bill was a mere “list of good wishes” without much bite – a common concern about AI legislation being discussed across Latin America.
 ChatGPT said “we should regulate based on fundamental rights and international conventions”, Obando said. 
 “But what are those rights and conventions? The Bill does not mention them.”
 Latin American lawmakers are pushing for regulation motivated by the European Union’s AI Act, which includes rules banning the use of the technology in biometric surveillance and for it to be clear what content is AI-generated.
 In Mexico, a Bill introduced in March encourages the creation of an ethical framework for the development of AI, based on the protection of human rights and personal data.
 The ethical framework itself, though, was not described in the draft, which is now also being discussed in public forums with experts and lawmakers.
 In June, the Peruvian Congress approved the first law in the region to regulate AI, which only awaits the president’s signature to come into effect.
 The law designates a national authority to supervise the development of AI, based on the principles of digital security and ethics.
 Peruvian congressman Jose Cueto, who led the introduction of the Bill, said the legislation was only a small part of a much-needed national strategy for cybersecurity and data protection.
 “The heart of the law is ... to create an environment in which we can make an ethical, transparent and sustainable use of AI,” said Cueto, a cybersecurity expert and former admiral.
 Racism and discrimination
 Brazil has been engaged in an intense debate about AI regulation for the past four years, with three Bills pending in its Congress.
 One AI legal framework, approved by the House of Representatives in 2021, but blocked by the Senate, focused mostly on principles and lacked enforcement mechanisms, said Tarzicio Silva, a researcher on algorithmic bias and fellow at the Mozilla Foundation, a US non-profit organisation.
 This Bill led to the creation of a Senate commission that published a 900-page report proposing a risk-based regulation, in which AI systems that may harm people or target marginalised populations are considered “extremely risky” and are banned.
 For example, the report recommends banning the use of AI systems for social scoring, which conditions access to public services based on a score people receive for their behaviour.
 Anti-racism advocates like Silva, however, are concerned that the debate has excluded the points of view of minorities.
 “This commission comprised 18 jurists, 80 experts, and not a single one of them were part of the racial minorities in Brazil,” said Silva. 
 “They didn’t consider Black and indigenous people.”
 AI regulation is a hot issue in Brazil as a new Bill – based on the three pending in Congress – was introduced to the Senate in May and will soon be discussed by a parliamentary commission.
 For Silva, an important element of the debate is preventing the use of facial recognition systems that could enable the disproportionate arrest of marginalised populations, and automated hiring systems that discriminate against racial minorities.
 “We are advocating for the right to review algorithmic decisions and discussing what could be the rights to reparation,” said Silva, referring to possible compensation for people harmed by AI systems.
 Lawmakers in the region agree that fighting bias and discrimination in AI systems should be at the heart of new regulations, but much of the proposed legislation is vague about how to prevent, investigate and penalise it.
 AI colonialism
 A common element in the regional discussions of AI regulation is the need to create an environment that promotes local experimentation, allowing competition with multinational corporations like Microsoft and Google.
 In Brazil, one of the Bills proposes governmental authorisation to create a “regulatory sandbox” – a framework that allows local businesses to experiment with AI technology in a controlled environment.
 “We are currently colonised by products of a few American multinationals,” said Francisco Garijo, president of the Ibero-American Society of Artificial Intelligence, which brings together experts from around the region.
 “The best way to deal with this colonialism is to promote the development of local products that can compete with them,” he said.
 AI systems also need to be created specifically by and for Latin Americans, taking into account their languages and cultures, said experts who gathered in March at a regional AI summit in the Uruguayan capital.
 “In the creation of AI technologies for the region (it is necessary to) value their (Latin American) participation in research and development, and not only as mere producers of raw data and manual annotation,” said experts who signed the Montevideo Declaration on Artificial Intelligence. — Reuters",costa rican lawmaker attention artificial intelligence chatgpt write law chatbot lawyer draft bill constitution verbatim legislature positive reaction people risky congresswoman castro introduction bill chatgpt costa rica institution regulate system principle accountability explainability bias prevention human right bill public forum parliamentary commission amendment congress artificial intelligence legislative tool human hand castro costa rica eighth country latin law regulating costa rican congresswoman johana obando regulation bill chatgpt statistic article costa rican constitution main objection bill mere list wish common concern legislation latin america chatgpt regulate fundamental right international convention right convention bill mention latin american lawmaker regulation european union rule technology biometric surveillance content mexico bill march creation ethical framework development protection human right personal data ethical framework draft public forum expert lawmaker peruvian congress law region regulate awaits president signature law national authority supervise development principle digital security ethic peruvian congressman jose cueto introduction bill legislation national strategy cybersecurity data protection heart law create environment ethical transparent sustainable cueto cybersecurity expert admiral racism discrimination brazil intense debate regulation bill congress legal framework house representative senate principle enforcement mechanism silva researcher algorithmic bias fellow mozilla foundation profit organisation bill creation senate commission report risk regulation system harm people population risky report system social scoring condition access public service people behaviour anti racism silva concerned debate view minority commission jurist expert single racial minority silva black indigenous people regulation hot issue brazil bill congress senate parliamentary commission silva element debate facial recognition system enable disproportionate arrest population system racial minority review algorithmic decision right reparation silva compensation people system lawmaker region bias discrimination system heart regulation legislation prevent investigate penalise colonialism common element regional discussion regulation create environment local experimentation competition multinational corporation google bill governmental authorisation create regulatory sandbox framework local business experiment technology environment product american multinationals garijo president ibero american society artificial intelligence brings expert region deal colonialism promote development local product system latin american language culture expert march regional summit uruguayan capital creation technology region latin american participation development mere producer raw data manual annotation expert montevideo declaration artificial intelligence reuters,"[(0, 0.043563887), (3, 0.95458704)]",3
569486,StarEdu,7,16/07/2023,AI in class,Learning institutions must be open to using the latest tech,"SINCE its launch in late November last year, ChatGPT (Chat Generative Pre-trained Transformer) has been hailed by some as the best invention since the computer was introduced to the world. 
 Media and industry observers predicted the powerful technology behind ChatGPT would likely dominate artificial intelligence (AI) and language modelling for years to come, while others see it as a threat to their teaching practices and jobs. 
 Described by Will Heaven in an article in the MIT Technology Review (April 2023) as an “essay-writing tool” or a “test-taking tool”, ChatGPT can write polished, well-crafted essays, answer questions, quote Shakespeare and take tests for humans. What is ChatGPT?
 Created by San Francisco-based company OpenAI, ChatGPT represents the latest development in the group of systems known as chatbots. 
 Chatbots are intelligent systems that are developed using either rule-based or self-learning AI methods and they can produce human-like text responses in real time. 
 Trained on conversational texts, the ChatGPT model produces more human-like responses than earlier language models.
 Will it take away jobs?At this point in time, no.
 In the hysteria and hype, there have been claims that this invention would cause some, for example teachers, to lose their jobs. This claim is as misleading as when for example, online learning first emerged, and it was predicted that teachers would be replaced by robots and AI. 
 The central role of a teacher in the teaching and learning  (PdP) process is not only to impart knowledge, but also to nurture students and cultivate values and thinking skills – all of which AI cannot do.
 But what the education sector and teachers should not do is to ignore or ban ChatGPT as this would prevent them from learning about the strengths and weaknesses of this AI chatbot and how it can be incorporated in their teaching and assessment practices. 
 There is an old English pro­verb that goes, “Better the devil you know than the devil you don’t”, which aptly describes the conundrum that many educators find themselves in when dealing with ChatGPT.
 The United States Department of Education noted in its May 2023 report “AI and the Future of Teaching and Learning” that while AI can support teachers through new forms of interaction and assist to address inconsistency in learning, there are also risks in the form of student and teacher surveillance and the potential replacement of human teachers. 
 Stanford University in its 2023 AI Index reported that 11 countries (including China and South Korea) had implemented an AI curriculum since 2021. 
 Our Education and Higher Education Ministries must take note and implement a nation-wide policy on AI and its impact on PdP. 
 There is a compelling need for the two ministries to engage in sharing knowledge, communicating with educators and communities, and improving technology plans and policies for AI use in education.
 Are homework and exams still relevant?
 There are concerns about false and wrong information provided by ChatGPT. Some detractors claimed that the easi­­ly accessible and well-written information provided by ChatGPT could lead to the end of homework or the death of critical thinking skills of students. 
 Even more concerning are reports of plagiarism where students do not acknowledge the sources of information and use ChatGPT text as the gospel truth. 
 As University of Melbourne Assoc Prof Dr Charles Sevigny pointed out, there are many things that ChatGPT still cannot do: it cannot view and interpret graphs, images and data sets; it cannot cite references; it cannot verify its sources; and it cannot read and apply knowledge of an existing text. 
 The solution for teachers and educators, thus, is to design thoughtful and strategic class activities and tasks which are then developed for exam questions. 
 Critical thinking can be deve­loped using ChatGPT generated texts by asking students to verify the sources and to apply the verified information to new situations and contexts. This teaches students to cite their sources and to acknowledge the authors’ contributions. 
 Test and exam questions can be designed to be problem-solving or based on case studies, rather than the traditional definition of terms or essay-writing. 
 Homework as it is practised will evolve to more critical thinking and problem-solving exercises, designed to promote higher-order thinking among students.
 Can it be used  for PdP?
 What is undeniable is that many students find ChatGPT useful as a learning tool to search for information and practise their skills of writing and reading. 
 ChatGPT can provide perso­nalised feedback and personalise their learning experiences. Dr Vaughan Connolly from the University of Cambridge believes that it can help students with doing revision, checking homework answers, or refining an essay. 
 It can also help postgraduates whose English is a se­cond language clarify what they mean in their writing.
 Schools and universities need to take the initiative to find out how to use ChatGPT responsibly, safely and effectively in and outside classrooms. 
 If they fail to respond urgently, they put themselves and their students at a disadvantage. 
 We are on the cusp of an AI revolution and its impact on society will be far-reaching. How we respond and how fast we respond will decide the future of education for you and me.
 Prof Dr Chan Nee Nee is the dean of the UCSI University Faculty of Social Sciences and a specialist in education. She earned her qualifications at Durham University, United Kingdom, and the National University of Singapore. The views expressed here are the writer’s own.",launch late november chatgpt generative pre transformer computer medium industry observer powerful technology chatgpt artificial intelligence language threat practice job article mit technology review tool test tool chatgpt write essay question shakespeare test human san francisco company chatgpt development system chatbots intelligent system rule method human text response real time conversational text chatgpt model human response language model job time hysteria hype teacher job online predicted teacher robot central role teacher pdp process impart knowledge nurture student value skill education sector teacher ban chatgpt prevent strength weakness chatbot assessment practice english pro devil devil conundrum educator chatgpt united department education report future support teacher form assist address inconsistency risk form student teacher surveillance potential replacement human teacher university country china south korea curriculum education education ministry implement nation wide policy impact pdp ministry knowledge educator community technology plan policy education homework relevant concern false chatgpt detractor easi accessible chatgpt lead homework death critical thinking skill student report plagiarism student source text gospel truth university melbourne assoc prof charles chatgpt view interpret graph image set cite reference source text solution teacher design thoughtful strategic class activity task exam question critical thinking deve chatgpt text student verify source situation teach student cite source author contribution exam question study traditional definition term homework critical thinking exercise student undeniable student tool search practise skill chatgpt provide perso personalise learning experience university cambridge student revision homework answer postgraduate english cond language clarify school university chatgpt classroom respond urgently student cusp revolution impact society respond fast respond decide future education prof chan nee nee dean ucsi university faculty social science specialist education qualification university united kingdom national university view writer,"[(0, 0.9968699)]",0
569068,Main,17,14/07/2023,New rules to govern generative AI,Final version of guidelines to regulate the advanced technology unveiled,"THE nation released its official guidelines for generative artificial intelligence services in one of the world’s first major moves to regulate the advanced technology.
 The rules led by the Cyberspace Administration of China, the country’s top internet overseer, will go into effect from Aug 15, according to an official statement released yesterday. Among the 24 provisions are requirements for platform providers to carry out a security review and register their services with the government, as was stipulated in a draft version released in April.
 The finalised guidelines stipulate that offshore providers of generative AI tools – if they are aimed at Chinese residents – must also comply with the set of rules. 
 On the other hand, if Chinese-developed tools only serve overseas users, they will not be subject to the guidelines.
 “This means more opportunities will be in enterprise-facing applications and people will be more cautious about consumer-facing entrepreneurship,” said Frances Du, founding partner of J Ventures.
 The guidelines also remove provisions in the draft version that included fines of as high as 100,000 yuan (RM65,000) for violations, as well as the requirement for platform operators to act within a three-month grace period to rectify problematic content. 
 It also adds agencies including the National Development and Reform Commission, the country’s education ministry, and science and technology ministry as joint issuers of the regulation, along with articles that encourage China’s developers of AI chips, models, and software to help set international standards and pursue technological exchanges.
 The move comes following months of consultation between the government and industry players. China’s major internet companies, from Alibaba Group Holding Ltd and Baidu Inc to JD.com Inc, have jumped into the frenzy to build the country’s equivalent to OpenAI’s ChatGPT. 
 China’s regulation of the nascent sector will offer one model for the orderly development of AI and its distribution as a service for businesses and consumers. Legal experts had raised concerns after the draft version of the regulations, saying it placed the bulk of responsibility for governing AI content on the platform operators. 
 The fear is that overly onerous regulations could limit the industry’s development, at a time when China is seeking to catch up to and surpass the US in the technology that is at the core of their strategic rivalry.
 You Chuanman, director of the IIA Center for Regulation and Global Governance at the Chinese University of Hong Kong’s Shen­zhen campus, said the final version of the regulations appeared to allow greater flexibi­lity by removing specifics in the grace period and by adding a greater focus on promoting development.
 “A clear-cut deadline of three months could be a daunting challenge,” You said. 
 “In the overall content, there are quite a few additions of clauses to promote development, and there is more emphasis placed on the use of existing legal tools.” — Bloomberg",nation official guideline generative artificial intelligence service major move advanced technology rule cyberspace administration country top internet overseer official statement yesterday provision requirement platform provider security review register service government draft version april guideline provider generative tool chinese resident rule hand chinese tool overseas user subject guideline opportunity application people cautious consumer entrepreneurship france partner venture guideline provision version fine yuan violation platform operator month grace period problematic content agency national development reform commission country education ministry science technology ministry joint issuer article china developer chip model software international standard technological exchange month consultation government industry player major internet company baidu frenzy build country equivalent openai chatgpt china regulation nascent sector orderly development distribution service business consumer legal expert concern version regulation responsibility content platform operator onerous regulation industry development time china catch surpass technology core strategic rivalry chuanman director iia center regulation global governance chinese university hong kong shen zhen final version regulation flexibi lity specific grace period focus development cut deadline month challenge content addition clause development emphasis legal tool bloomberg,"[(3, 0.6822124), (4, 0.31420964)]",3
569154,Main,26,14/07/2023,Google AI  health chatbot passes US medical exam,,"Paris: Google’s artificial intelligence-powered medical chatbot has achieved a passing grade on a tough US medical licensing exam, but its answers still fall short of those from human doctors, a peer-reviewed study said.
 Last year the release of ChatGPT – whose developer OpenAI is backed by Google’s rival Microsoft – kicked off a AI race between tech giants.
 While much has been made about the future possibilities – and dangers – of AI, health is one area where the technology had already shown tangible progress, with algo­rithms able to read certain medical scans as well as humans.
 Google first unveiled its AI tool for answering medical questions, called Med-PaLM, in a preprint study in December. 
 Unlike ChatGPT, it has not been released to the public.
 The US tech giant says Med-PaLM is the first large language model, an AI technique trained on vast amounts of human-produced text, to pass the US Medical Licensing Examination (USMLE).
 A passing grade for the exam, which is taken by medical students and physicians-in-training in the US, is around 60%.
 In February, a study said that ChatGPT had achieved passing or near passing results.
 In a peer-reviewed study published in the journal Nature on Wednesday, Google researchers said that Med-PaLM had achieved 67.6% on USMLE-style multiple choice questions.
 “Med-PaLM performs encouragingly, but remains inferior to clinicians,” the study said. — AFP",paris google artificial intelligence medical chatbot grade tough medical licensing exam answer short human doctor study release developer openai google rival microsoft race tech giant future possibility danger health technology tangible progress algo rithms medical scan human unveiled tool medical question med palm preprint study december chatgpt public tech giant palm language model technique vast amount human text pas medical licensing examination grade medical student physician february study chatgpt peer study journal nature wednesday google researcher palm usmle style multiple choice question palm performs inferior clinician afp,"[(0, 0.9903598)]",0
568568,Main,3,13/07/2023,AI eye on errant drivers at traffic lights,,"PUTRAJAYA: The next time you stop at the traffic lights, and start fiddling with the phone while waiting – beware, big brother could be watching.
 It won’t just be text messages that you will be receiving, a traffic summons is likely to be on the way, too.
 “The Road Transport Department (JPJ) has started installing CCTV with AI that can record video of what you are doing at the traffic lights.
 “Those who always play  with their handphones while waiting for the green light, please be careful,” warned Transport Minister Anthony Loke. “You can be issued with a summons, don’t say that you have not been warned.”
 The artificial intelligence (AI) violations detection camera system is being installed at selected traffic lights as a pilot project to detect motorists’ behaviour, he said.
 The system, in fact, had been implemented before he took over at the ministry.
 “It is a proof of concept,” he told reporters when asked to comment on a viral message that the JPJ had initiated a widespread project to install CCTV cameras with AI technology at traffic lights.
 “Always remember that you are being watched through the CCTV,” read the viral message.
 On July 4, Sarawak Transport Minister Datuk Seri Lee Kim Shin said the state had embarked on  an upgraded AI violations  detection camera system to  capture evidence of offences and provide data to better plan policies and enforcement.
 The proof-of-concept project at the accident-prone Merbau-Miri-Pujut traffic light intersection is already showing impressive results within one week of its rollout to collect data there.
 The results will be presented to the Sarawak Transport Ministry after the six-month trial period for the next course of action to be decided.
 The data collected would help agencies to target effective enforcement action based on actual situations, particularly regarding misbehaving drivers and accident hotspots, said Lee.",putrajaya time traffic light phone beware brother text message traffic summons road transport department jpj cctv record video traffic light handphones green light careful transport minister anthony issued summons artificial intelligence violation detection camera system traffic light pilot project detect behaviour system ministry proof concept reporter comment viral message jpj widespread project install cctv camera technology traffic light watched cctv viral message july sarawak transport minister datuk seri lee shin upgraded violation detection camera system capture evidence offence data plan policy proof concept project accident prone merbau miri pujut traffic light intersection impressive week rollout data sarawak month trial period action data agency effective enforcement action actual situation driver accident hotspot,"[(2, 0.9925293)]",2
568218,StarBiz,7,12/07/2023,IBM Watsonx platform to power the future of AI for business,,"ARTIFICIAL intelligence (AI) has taken the world by storm and businesses that can harness the transformative potential of this technology stand to propel their operations into a new frontier of productivity, innovation and competitiveness.
 A new global IBM’s Institute for Business Value (IBV) study on “CEO decision-making in the age of AI, Act with Intention” reveals that 75% of chief executive officers surveyed globally believe the organisation with the most advanced generative AI will have a competitive advantage. 
 A total of 43% also said they are using generative AI to inform strategic decisions, with 36% using the technology for operational decisions.
 “We are in a unique time of AI. At IBM, we call this the opportunity of a lifetime, because everybody has to decide today how they are going to take advantage of the disruptive technology that could accelerate their business, or being left behind,” said Catherine Lian, managing director and technology leader at IBM Malaysia.
 The transformative power of AI, however, also comes with challenges. 
 An IBM 2022 Global AI Adoption Index, which surveyed about 7,500 business leaders around the world, found the major roadblocks that are still holding companies back from the benefit of AI. 
 This includes difficulties integrating data across clouds, a lack of tools to develop models and necessary AI skills and AI expertise, and a lack of strategy in reducing bias in the organisation’s AI.
 Nevertheless, IBM recognises that AI for business has unique needs. 
 Enterprises need access to a full technology stack that enables them to train, tune and deploy AI models, including foundation models and machine learning capabilities, across their organisation with trusted data, speed, and governance – all in one place and to run across any cloud environment in order to have a successful AI adoption.
 In comes IBM Watsonx to address the challenge of scaling and operationalising AI and bridge the gap between AI technology and business outcomes. It is an IBM AI and data platform that provides business users, data scientists and developers with self-service access to high-quality, proprietary IBM foundation models.
 Director of technical sales, software – IBM Technology, APAC, Kitman Cheung said: “With the development of foundation models, AI for business is more powerful than ever. Foundation models make deploying AI significantly more scalable, affordable and efficient.” 
 IBM’s goal in rolling out watsonx – which consists of watsonx.ai, watsonx.data and watsonx.governance – is to help businesses interact and converse with customers and employees, automate business workflows and IT processes, free up your employees from repetitive work and help empower them to deliver faster and better outcomes, be protected against threats.
 “Watsonx offers a solution by delivering one place to utilise state-of-the-art tools to advance their machine learning and generative AI initiatives at scale. 
 “Leveraging these different tools means businesses will be able to train, tune and deploy AI across their operations with trusted data, speed and governance,” Cheung said.
 IBM watsonx.ai is a next-generation enterprise studio designed to empower AI builders. It offers a comprehensive suite of tools and capabilities for building and tuning foundation models, generative AI and machine learning.
 On the other hand, IBM watsonx.data –  the fit-for-purpose data store built on an open lakehouse architecture – is a data management solution designed to optimise governed data and AI workloads. 
 This solution can manage workloads both on-premise and across multi-cloud environments. With this solution, an organisation can reduce data warehouse costs by up to 50%.
 Like any technology going through rapid development, AI can be hazardous, especially in business settings. Businesses need AI that provides accurate results they can trust.
 An AI governance toolkit that can protect customer privacy, proactively detect model bias and drift, and help organisations meet their ethics standards, IBM watsonx.governance enables organisations to establish trust, maintain compliance and mitigate potential risks in their AI initiatives.
 “As AI continues to evolve, organisations that embrace these advancements and leverage platforms like Watsonx will have a distinct advantage in unlocking new opportunities, enhancing customer experiences and driving sustainable business growth for the future. 
 “Let’s put AI to work and make the world work better – together,” Lian concludes.",artificial intelligence storm business transformative potential technology stand operation frontier productivity innovation competitiveness global ibm institute business ibv study ceo decision age intention reveals chief executive officer organisation generative competitive advantage total generative inform strategic decision technology operational decision unique time ibm call opportunity lifetime decide advantage disruptive technology accelerate business catherine lian director technology leader ibm malaysia transformative power global adoption business leader major roadblock company difficulty data cloud tool model skill expertise lack strategy bias organisation ibm business unique access technology stack tune deploy model foundation model machine capability organisation data speed governance cloud environment successful adoption ibm watsonx address challenge bridge gap technology business outcome data platform business user scientist developer service access quality proprietary ibm foundation model director technical sale software ibm technology apac kitman cheung development foundation model business powerful foundation model scalable affordable efficient ibm goal watsonx watsonx data governance business interact converse customer employee business workflow free employee empower deliver protected threat offer solution utilise art tool advance machine generative initiative scale leveraging tool business tune deploy operation data speed governance cheung ibm watsonx generation enterprise studio empower builder comprehensive suite tool capability foundation model machine hand ibm watsonx data purpose data store architecture data management solution data workload solution manage workload multi cloud environment solution organisation data warehouse technology rapid development hazardous business setting business accurate trust governance toolkit customer privacy detect model bias drift organisation ethic standard watsonx governance enables organisation trust maintain compliance mitigate potential risk initiative organisation advancement platform distinct advantage unlocking opportunity customer experience sustainable business growth future lian concludes,"[(4, 0.9967037)]",4
568242,Main,27,12/07/2023,ChatGPT dragged to US court over AI copyright,,"Washington: US comedian Sarah Silverman and two other authors have sued Open AI over copyright infringement in the latest pushback by creatives since the company’s release of ChatGPT took the world by storm.
 The plaintiffs accuse the San Francisco company of using their works to train their artificial intelligence models without permission, adding to a series of cases that could complicate the development of tech world’s biggest new trend.
 The trio also filed a suit against Facebook parent company Meta, whose less known open source models also used pirated downloads of their books for training purposes, the suit alleged.
 Much of the training material used by OpenAI and Meta “comes from copyrighted works – including books written by the plaintiffs – that were copied by OpenAI and Meta without consent, without credit, and without compensation,” the trio’s lawyers said in a blog post.
 In both lawsuits, which were filed on Friday in a California court, the authors accuse the tech companies of using their books to train their AI models and are claiming a series of copyright infringements. — AFP",washington comedian sarah silverman author copyright infringement pushback company release chatgpt storm plaintiff san francisco company artificial intelligence model permission series complicate development tech biggest trend trio suit facebook parent company meta source model downloads book purpose suit material openai meta book plaintiff openai consent credit compensation trio lawyer post lawsuit friday california court author tech company book model series copyright infringement,"[(3, 0.98686856)]",3
567446,Lifestyle,6,10/07/2023,Crypto feeds on  AI hypeCrypto,Artificial intelligence is unlocking a plethora of new possibilities for blockchain technology.,"NEW lawsuits filed by the US Securities and Exchange Commission against Coinbase Global and Binance Holdings have raised serious questions about the future of crypto.
 As digital assets face mounting regulatory pressure and other market headwinds, they have also been dethroned as the latest technology fad.
 When OpenAI launched its ChatGPT bot in November, it paved the way for practical uses of artificial intelligence (AI). Since then, AI has captured the attention of founders and investors – the same folks that fuelled the crypto boom.
 AI may have stolen the limelight, but some crypto enthusiasts say it can provide new opportunities for the blockchain industry.
 “You may actually see a situation where AI is sort of a catalyst to rush back to blockchain,” said Adam Struck, founder and managing partner of investment fund Struck Crypto, which has been diving further into AI since the ChatGPT bot release.
 Blockchain technology can bring greater transparency and decentralisation to AI, which can be extremely opaque in terms of what data is being used to train models, according to Alex Felix, managing partner and chief investment officer at crypto VC firm CoinFund.
 Recently, CoinFund backed Tools for Humanity. The crypto startup cofounded by OpenAI’s Sam Altman, which raised US$115mil (RM537.8mil), shows a real use case for crypto in AI, said Felix.
 Tools for Humanity, which developed a digital currency called Worldcoin, created a small orb that scans people’s eyeballs in order to generate a unique ID for that individual based on blockchain, giving them a digital “proof of personhood,” which when combined with Worldcoin can also be used to facilitate secure payments.
 “For us, it started with where’s the world going with AI? And the way to solve that was crypto,” said Tiago Sada, Tools for Humanity’s head of product.
 Felix compares the current AI craze to crypto’s initial coin offering boom in 2017, when investors rushed to snap up random crypto tokens, many of which were scams.
 But he said that this time around, it’s easier to vet new projects and determine whether someone has deep enough expertise in AI.
 “It’s harder to fake credibility because the circles are so small,” Felix said.
 Sussing out hackersJust as blockchain can bring more transparency to AI, the tech can bolster crypto by improving the ways digital-asset platforms sort data, safeguard information and interact with users, according to some crypto supporters.
 Hackers have been able to drain millions of dollars from blockchain protocols.
 AI bots can curtail the swathe of cyberattacks plaguing decentralised finance, according to Struck.
 “You could essentially do very, very large amounts of what’s called pen testing or penetration testing by just having these bots simulate attacks,” he said, adding that this testing could suss out vulnerabilities in smart contract code that hackers can manipulate to siphon cash.
 Bots can also be used to moderate content in order to filter out spam and scams on messaging platforms like Telegram, Discord, Signal, WeChat and WhatsApp, Struck said.
 While this kind of benefit isn’t restricted to crypto, it is important for an industry where many scams originate on social media.
 “So many of the users are concentrated on these messaging apps,” he said.
 In addition to protecting investors from getting swindled, many in the industry see other ways for AI to make it easier for users to interact with crypto.
 Solana Labs, which developed the Solana blockchain, launched a ChatGPT plug-in in May “to make the user experience better, simpler for people to understand what is going on in blockchain”, said Tal Tchwella, head of product at Solana Labs.
 Crypto has been criticised for being too unwieldy for regular consumers, but the ChatGPT plug-in guides users through blockchain transactions in a conversational way.
 In a virtual demonstration, Tchwella showed how a customer can connect their crypto wallet and ask the bot to show them non- fungible tokens they can afford or a specific collection.
 After scrolling through options, customers can ask the bot to help them purchase a NFT.
 The bot then generates a QR code that customers can scan to complete the sale.
 “AI is going to impact every area, every sector, every industry, and we’re just trying to embrace it,” Tchwella said.
 Avoiding the hypeStill, other crypto companies have been hesitant to jump fully on the AI bandwagon, citing its potential dangers. 
 Cypto derivatives exchange Bitget nixed a ChatGPT integration because of concerns over users getting misleading information and false facts in their queries.Tools for Humanity has been lampooned for its eye-scanning tech and questioned about whether the sensitive biometric data it collects is actually protected.
 While The Graph, an indexing protocol, has been leveraging AI and machine learning for more than two years to make blockchain data easier to search and use, it does not want its GRT currency to be classified as an AI token, according to Tegan Kline, CEO of Edge & Node, the startup that created the platform.
 Unlike other crypto companies that have swiftly pivoted to AI to capitalise on the hype, she said Edge & Node prefers to be known first and foremost as a blockchain startup because there are still “hardships” around AI, including how the technology makes it harder to tell what’s true online.
 Meanwhile, “a lot of people are putting AI into their pitch decks to attract more venture capital funds”, Kline said. – Bloomberg",lawsuit security exchange commission coinbase global binance holding question future crypto digital asset regulatory pressure market headwind technology fad openai chatgpt bot november practical artificial intelligence attention founder investor folk crypto boom limelight crypto enthusiast opportunity industry situation sort catalyst rush blockchain adam founder partner investment fund crypto diving chatgpt bot release blockchain technology bring transparency decentralisation opaque term data train model felix partner chief investment officer crypto firm coinfund coinfund humanity crypto startup openai sam altman mil mil real crypto felix tool humanity digital currency orb scan people generate unique individual blockchain digital proof personhood worldcoin facilitate secure payment crypto sada tool humanity product felix current craze initial coin offering boom investor snap random crypto scam time easier vet project deep expertise harder credibility circle hackersjust blockchain bring transparency tech bolster crypto digital asset platform data safeguard interact user supporter hacker million dollar protocol bot swathe cyberattacks finance amount pen penetration bot simulate attack sus vulnerability contract code hacker siphon cash bot content filter spam scam platform discord signal struck benefit crypto industry social medium user apps addition investor industry easier user crypto solana lab solana blockchain chatgpt plug user experience simpler people blockchain tal tchwella head product solana lab crypto unwieldy regular consumer plug guide user transaction conversational virtual demonstration tchwella customer connect crypto wallet bot fungible token specific collection scrolling option customer purchase nft bot code customer scan complete sale impact sector industry embrace tchwella hypestill crypto company jump bandwagon potential danger derivative bitget nixed chatgpt integration concern user false query humanity eye tech sensitive biometric data collect graph protocol machine blockchain data search grt currency token tegan kline ceo edge node startup platform crypto company capitalise hype edge node prefers blockchain startup hardship technology harder true online lot people pitch deck attract venture capital fund bloomberg,"[(0, 0.6982619), (4, 0.29952803)]",0
567052,Life Inspired,10,09/07/2023,This AI turns doodles into stunning images,,"Artificial intelligence is shaking up several industries and changing how we use the web. In the field of art creation, AI is showing enormous potential. One example is Scribble (itscribblediffusion.com), which offers users the possibility to create sophisticated imagery from simple sketches.
 This web app allows users to transform basic sketches and drawings into paintings and artworks with various degrees of realism. 
 The idea is to make a rough drawing with a finger, stylus or mouse, then add a brief description in order to obtain a much more “artistic” equivalent in one click. 
 Of course, users can also “touch up” the image afterwards for a result more in line with your expectations.
 Scribble Diffusion is an open-source project, and its code is available on GitHub. Based on a brand new neural network structure called ControlNet, it uses artificial intelligence to “interpret” the drawing and then generate the closest possible “artistic” equivalent.
 How much does it cost? Scribble Diffusion can be used free of charge. – AFP Relaxnews",artificial intelligence industry web field art creation enormous potential scribble itscribblediffusion user possibility sophisticated imagery simple sketch app user basic sketch drawing painting artwork degree idea rough finger stylus mouse add description artistic equivalent click user touch image result expectation scribble diffusion source project code github brand neural network structure controlnet artificial intelligence interpret generate closest artistic equivalent cost scribble diffusion free charge afp relaxnews,"[(2, 0.9866507)]",2
567256,Main,16,09/07/2023,No plans to regulate AI yet,"However, bosses are urged to draw up policies at work. The Human Resources Ministry is also working towards creating new jobs in the artificial intelligence sector, addressing worries that such technology may replace humans in jobs in the  near future.","FROM writing poems to being news anchors, artificial intelligence (AI) is making its mark in the world, and also in Malaysia.
 In a study by technology firm IBM Malaysia, more companies in the country are exploring and integrating AI into their business operations.
 Nearly a third of companies in the survey have already integrated generative AI – a type of AI system that generates text, images, and other content based on user-given prompts. 
 An example of generative AI is the now popular ChatGPT, which can engage in human-like conversation and create material such as poetry, formal letters, and social media captions to name just a few.
 However, with such advances come concerns, the most popular being the worry that AI can replace humans in certain jobs. Another big concern are ethical and privacy issues.
 So, should AI be regulated?
 The Human Resources Ministry says a decision to introduce guidelines or precautions is a complex one that must be made on a case-by-case basis. 
 “There is no easy answer, and the best approach may vary depending on the specific circumstances.
 “Overall, the government believes that the benefits of using AI outweigh the risks,” the ministry tells Sunday Star.
 For now, the government does not have any specific plans to come up with guidelines on the ethical usage of AI at work.
 “But employers are encouraged to develop their own policies and procedures for the ethical use of AI,” the ministry says, in view of the growing use of AI in the country.
 The technology can boost productivity as AI can analyse huge amounts of data to enhance decision-making. 
 “However, this will also lead to more scrutiny of transparency and privacy as such technologies rely on extensive databases on the Internet to function efficiently. 
 “This will raise concerns about whether data is being accessed ethically,” the ministry points out.
 An example of this is an AI-powered chatbot, or virtual assistant, which deals with customers – it could be misused to collect personal information too.
 “Bosses should consider the specific AI tools that are being used in the workplace and the potential impact of AI on workers. 
 “By developing clear and ethical guidelines for the use of AI, employers can help to ensure that AI is used in a responsible and beneficial way. 
 “This can help to protect employees, customers, and the public from harm,” the ministry says.
 The ministry believes that AI can be used to improve the quality of government services. 
 “For example, AI can be used to analyse data and identify patterns that can help government agencies to better understand the needs of citizens. 
 “This information can then be used to improve the design and delivery of services.
 “The government is committed to using AI in a responsible way that benefits all Malaysians,” it adds.
 Will jobs be replaced by AI?
 The answer to whether our jobs will be replaced by such technology is a yes and no.
 “Of course, not all jobs are at risk of being automated by AI,” the ministry says. 
 “Some jobs, such as those that require creativity, critical thinking, and social interaction, are less likely to be automated.”
 This is due to the fact that AI performs its tasks by using databases built by human beings and is limited by them, lacking the ability to be creative.
 However, the ministry believes that AI is still likely to have a significant impact on the Malaysian workforce in the coming years.
 “According to the World Economic Forum (WEF), 25% of the global workforce will be potentially disrupted due to automation and AI,” it says.
 Examples of potential jobs that AI may replace are those involving manu-facturing, transportation, and customer and retail services, which are all seen as labour-intensive or highly automatable.
 “However, the positive impact of this change is that high-skilled workers will be able to focus on more complex and creative work that requires human skills that are irreplaceable.
 “This will result in increased productivity in the workplace and also encourage value-added business activities among employees.”
 For example, AI can be used to automate tasks such as processing paperwork, answering customer inquiries, and detecting fraud. 
 “This can free up employees to focus on more complex and strategic work,” the ministry explains.
 While it has many strengths, the ministry acknowledges that AI also poses potential risks, such as biased or discriminatory decisions and behaviour. 
 AI bias can happen when it makes skewed or inaccurate predictions because of biased input or incomplete data. 
 A notable example is that of the AI algorithm used in courts in the United States to predict the likelihood of an accused becoming a repeat offender.
 “AI systems can also be hacked or used for malicious purposes. 
 “The government is aware of these risks and is working to develop safeguards to mitigate them,” the ministry says.
 Creating new careers 
 Although the advent of AI may disrupt certain professions, it will also create new ones. In the next five years, the ministry is projecting a spike in demand for high-skilled workers, especially workers who have digital skills in the areas of AI, big data, and digitalisation. 
 “This is because AI operates based on databases and algorithms provided by humans.
 “Workers with such skills will be in demand due to their ability to co-exist with technologies and improve them even further,” the Human Resources Ministry says.
 To address the potential disruptions posed by AI, the ministry has developed a number of policies and initiatives, including upskilling and reskilling programmes to help workers succeed in the age of AI.
 “These programmes include training in AI technology, as well as training in new skills that are complementary to AI, such as data analysis and problem-solving.
 “We are also working to create new jobs in the AI sector. These jobs include software developers, data scientists, and AI engineers.
 “Such initiatives will help to ensure that Malaysia benefits from the opportunities presented by AI, while mitigating the risks,” the ministry states.
 In the WEF’s Future of Jobs 2023 report, AI is expected to be adopted by nearly 75% of surveyed companies.
 Most believe the development is positive, with 50% of organisations expecting it to create job growth and 25% expecting it to create job losses.",poem news anchor artificial intelligence mark malaysia study technology firm ibm malaysia company country business operation company survey generative type system text image user prompt generative popular chatgpt engage human conversation material poetry formal letter social medium caption advance concern popular human job concern ethical privacy issue human resource ministry decision introduce guideline precaution complex basis easy answer approach vary specific circumstance government benefit outweigh risk ministry tell sunday star government specific plan guideline ethical usage employer policy ethical ministry view country technology productivity huge amount data enhance decision lead scrutiny transparency privacy technology extensive database internet function concern data ministry chatbot virtual assistant deal customer collect personal boss specific tool workplace potential impact worker ethical guideline employer responsible beneficial protect employee customer public ministry ministry quality government service analyse data identify pattern government agency citizen design delivery service government responsible benefit malaysian job answer job technology job risk ministry job creativity critical thinking social interaction performs database human ability creative ministry impact malaysian workforce economic forum wef global workforce automation potential job manu transportation customer retail service intensive automatable positive impact change worker complex creative human skill irreplaceable result productivity workplace encourage business activity employee automate task paperwork customer inquiry fraud free employee complex strategic ministry strength ministry pose potential risk discriminatory decision bias inaccurate prediction input incomplete data notable algorithm court predict likelihood repeat offender system malicious purpose government aware risk safeguard ministry career advent disrupt profession ministry spike demand worker worker digital skill data digitalisation database human worker skill ability technology human resource ministry potential disruption ministry policy initiative programme worker age programme technology training skill complementary data analysis create job sector job software developer scientist engineer initiative malaysia benefit opportunity risk ministry future job report surveyed company development positive organisation create job growth create job loss,"[(3, 0.9029325), (4, 0.094915316)]",3
567258,Main,17,09/07/2023,‘Time for all to be trained to use AI’,,"THE sooner bosses pay attention to artificial intelligence (AI) and what it can do, the better for all, including workers and the business.
 As such, guidelines should be introduced by bosses in the country on how their workers should use AI in their jobs, says Malaysian Employers Federation (MEF) president Datuk Dr Syed Hussain Syed Husman.
 He was responding to a proposal by the Human Resources Ministry for employers to develop their own policies and procedures for the ethical use of AI in view of its growth in Malaysia.
 “This is a good suggestion as the world of work is changing and becoming more automated.
 “Such a trend will continue. So the sooner we pay attention to this, the better. 
 “Now is the time to see how AI can help businesses and the industry, while looking at some guiding principles to help manage this,” he says.
 While AI promises to smooth operations, he admits there are concerns over security, privacy, data trust, and ethics over its use.
 “Businesses using AI models such as ChatGPT need to be aware that generative AI comes with its own set of risks. 
 “There is a need to establish rules and procedures to ensure secure implementation of AI.
 “It will take time and human expertise to unlock AI’s full potential in a way that’s responsible, trustworthy and safe,” he says.
 Recently, it was reported that more companies in Malaysia are exploring and integrating generative AI into their business operations.
 However, not many have come up with official policies for its workers on its usage.
 Some companies which have introduced guidelines have advised workers against providing personal information to AI systems to prevent any privacy issues.
 While bosses are aware of the benefits AI can bring, MEF highlights the need for everyone to be trained to use it effectively. 
 “A lack of skilled talent and technical expertise has been a top barrier to implementing AI since its inception. 
 “To stay competitive in a tight labour market, companies must train their teams to use AI effectively and responsibly. 
 “If people don’t trust the work AI does or the data it’s built on, adoption of AI will lag and returns on investment will not be as fast as they should be,” Syed Hussain says.
 In the next five years, he says bosses expect more people to be working alongside robots and smart machines specifically designed to help them to do their jobs better and more efficiently.
 At the same time, jobs that can be performed through a simple search online or on ChatGPT could be at risk, says JobStreet Malaysia managing director Vic Sithasanan.
 “In its place would be the prioritisation of skills to be able to query, discern, and ‘connect the dots’ or find relevance with technology that cannot replace the human touch,” he explains. 
 Even before Covid-19 posed a threat, job security was already on people’s minds because of automation, he adds.
 “Almost every kind of worker has some level of concern. 
 “JobStreet’s Decoding Global Talent’s third report showed that in 2021, 46% of workers in their 20s and 41% in their 30s were already worried about technology putting them out of work. 
 “From media to information technology, concerns about automation are particularly high – especially among workers with repetitive jobs,” he says.
 According to JobStreet, among some of the industries and jobs that may be replaced by AI – and not just ChatGPT – are translating, managing social media, umpiring sports, and jobs in libraries and call centres.“However, while many people are nervously waiting for the world to become completely reliant on AI in the next few decades, there will always be a need for human force to drive this automation. 
 “Though there may be many jobs that will disappear in the near future due to AI replacement, jobseekers, employees and even employers can enhance and enrich their potential to ensure that their career stays current and in demand. 
 “The world’s workforce may combine man and machine, but a robot-dominated world is not about to become a practical reality yet,” Sithasanan says.
 While the work landscape is evolving due to technology, so are the skills in need, says LinkedIn country manager for Malaysia Rohit Kalsy. 
 “LinkedIn research shows that top skills required for a particular job have changed by an average of 27% since 2015, with the pace of change accelerating during the pandemic. 
 “At this pace, skills could change by 43% to 47% by 2025. 
 “Between 2021 and 2025, we would likely see three new skills in the top skills for a job,” says Rohit, who is also the company’s head of emerging markets (South-East Asia).
 However, there are encouraging signs that professionals in Malaysia are equipping themselves with a combination of hard and soft skills to enhance their employability and remain competitive.
 “Malaysian learners were among the 7.3 million globally who enrolled in the top 20 most popular LinkedIn learning courses between June 1, 2021, and June 30 last year.
 “This is almost double from the previous year. Such figures show that more are building skills to future-proof their careers,” Rohit points out.
 Last month, the Human Resources Ministry said that, with the rise of AI use, as many as 4.5 million Malaysians are likely to lose their jobs by 2030 if they do not improve their skills or attend reskilling and upskilling programmes.",sooner boss attention artificial intelligence worker business guideline boss country worker job malaysian employer president datuk hussain syed husman proposal human resource ministry employer policy procedure ethical view growth malaysia suggestion trend sooner attention time business industry principle promise smooth operation admits concern security privacy data trust ethic business model aware generative risk rule procedure secure implementation time human expertise unlock potential responsible trustworthy safe company generative business operation official policy worker usage company guideline worker personal system prevent privacy issue boss aware benefit mef highlight lack skilled talent technical expertise top barrier inception stay competitive tight labour market company team people data adoption lag return investment syed hussain boss people alongside robot smart machine job time job simple search online chatgpt risk jobstreet malaysia director sithasanan prioritisation skill query discern connect dot relevance technology human touch covid threat job security people automation worker level concern jobstreet global talent report worker technology medium technology concern automation worker job jobstreet industry job chatgpt social medium umpiring sport job library centre people reliant decade human force drive automation job future replacement jobseekers employee employer enrich potential career stay current demand workforce machine robot practical reality sithasanan landscape technology skill linkedin country manager malaysia rohit kalsy linkedin top skill job average pace change pandemic pace skill skill top skill job company head market east asia sign professional combination hard soft skill enhance employability competitive malaysian learner top popular linkedin learning course june double previous figure skill future proof career month human resource rise malaysian job skill upskilling programme,"[(0, 0.24377279), (3, 0.75363505)]",3
567296,Main,34,09/07/2023,AI robots reckon they could run the world better,,"Geneva: A panel of AI-enabled humanoid robots told a United Nations summit that they could eventually run the world better than humans.
 But the social robots said they felt humans should proceed with caution when embracing the rapidly-developing potential of artificial intelligence.
 And they admitted that they cannot – yet – get a proper grip on human emotions.
 Some of the most advanced humanoid robots were at the UN’s two-day AI for Good Global Summit in Geneva.
 They joined around 3,000 experts in the field to try to harness the power of AI – and  channel it into being used to solve some of the world’s most pressing problems, such as climate change, hunger and social care.
 They were assembled for what was billed as the world’s first press conference with a packed panel of AI-enabled humanoid social robots.
 “What a silent tension,” one robot said before the press conference began, reading the room.
 Asked about whether they might make better leaders, given humans’ capacity to make errors, Sophia, developed by Hanson Robotics, was clear.
 “Humanoid robots have the potential to lead with a greater level of efficiency and effectiveness than human leaders,” it said.
 “We don’t have the same biases or emotions that can sometimes cloud decision-making, and can process large amounts of data quickly in order to make the best decisions.
 “AI can provide unbiased data while humans can provide the emotional intelligence and creativity to make the best decisions. Together, we can achieve great things.”
 The summit is being convened by the UN’s ITU tech agency.   — AFP",geneva panel humanoid robot united nation human social robot human caution potential artificial intelligence proper grip human emotion humanoid robot day global summit geneva expert field harness power channel climate change social care billed press conference panel humanoid social robot silent tension robot press conference leader human capacity error hanson robotics humanoid robot potential lead level efficiency effectiveness human leader bias emotion decision process amount decision unbiased data human emotional intelligence creativity decision summit itu tech agency afp,"[(2, 0.98919994)]",2
565074,StarBiz,12,04/07/2023,Artificial intelligence: Where is business in Vietnam headed?,,"HANOI: Artificial intelligence (AI) tools have taken the world by storm, and Vietnam is no exception. Businesses and individuals are getting increasingly comfortable with the new technology.
 “Vietnamese users respond to ChatGPT relatively well,” said associate Professor Nguyen Xuan Hoai, director of the AI Academy Vietnam, at the WISE Talk No. 7 of VnEconomy.
 “This can also serve as a welcome signal for the AI development and application story in Vietnam.”
 Chief executive officer Nguyen Vu Anh of Coc Coc, a popular web browser and search engine in Vietnam, said many local users have been using ChatGPT daily on the browser.
 He estimated that Vietnam currently has half a million daily users of ChatGPT.
 “That is a very large number, especially considering OpenAI is restricting ChatGPT in the Vietnamese market,” Anh said.
 According to Finbold’s data, the global AI market is estimated to reach a valuation of US$208bil (RM971bil) this year, with the potential to hit US$1.87 trillion (RM8.73 trillion) by 2030.
 The global AI market is expected to cross US$1 trillion (RM4.67 trillion) for the first time in 2028.
 Despite this, experts said that Vietnamese businesses face many challenges getting ahead in the AI application race.
 According to Hoai, technology in general is changing fast, but AI is an area of particular concern to business.
 “Today we’re talking about ChatGPT, or AI in general, but in three or five years, we may be talking about something completely different. 
 “Businesses need to calculate how they invest their time and capital very carefully,” added Hoai.
 ChatGPT has already made a strong impression and many ordinary people are now familiar with how it works.
 Vietnamese businesses and individuals are excited about the possibilities, but also anxious about the new technology, said Hoai.
 “They’re content that AI is not an incomprehensible technology – they can apply it to increase productivity and quality of life.”
 The flip side is that AI is already on the radar of the world’s largest companies.
 As AI opens up to big competition, a fierce battle has commenced with the winner taking a major share of the market.
 This has been demonstrated clearly in the case of ChatGPT from OpenAI and Microsoft.
 Immediately after ChatGPT launched, giants such as Google and Facebook quickly stepped in and launched their own products, but none of them have been able to steal the limelight from ChatGPT.
 ChatGPT has already been used to build new products, business models, financial strategies, and more.
 Hoai said that “for Vietnamese businesses, there will be no right-wrong story but only one of choices. 
 “If we choose a global strategy then it will be very difficult to compete with Big Tech abroad. Vietnam is not alone in this situation, many countries are also experiencing this situation.
 “We could choose to stand on the shoulders of giants to compete,” he said.
 “AI models such as ChatGPT are still very new. Most of these models only answer general information, and if we want the answers to be clear in a specific context for an industry or business, or a country, we will have to refine the models, Hoai said.
 The third option is to do it differently to everyone else, he explained. For example, in agriculture there is AI software used to identify rice grains in Japan and the US, but rice in Vietnam is different, so we can’t use the existing tools and must develop our own solution for the local market. — Viet Nam News/ANN",hanoi artificial intelligence tool storm vietnam exception business individual comfortable technology vietnamese user chatgpt associate professor nguyen xuan hoai director academy vietnam wise talk serve signal development application story vietnam chief executive officer nguyen anh coc coc popular web browser search engine vietnam local user vietnam half daily user openai chatgpt vietnamese market anh data global market reach valuation bil potential hit global market cross time expert vietnamese business application race hoai technology concern business chatgpt completely business invest time capital chatgpt strong impression ordinary people familiar vietnamese business individual possibility anxious technology hoai content incomprehensible technology apply increase productivity quality life flip radar largest company competition fierce battle winner major share market chatgpt openai microsoft chatgpt giant facebook product steal limelight chatgpt chatgpt build product business model financial strategy vietnamese business wrong story choice global strategy difficult compete tech vietnam situation country situation choose shoulder giant model model answer specific context industry business country refine model option agriculture software rice grain rice vietnam tool solution local market viet nam news ann,"[(0, 0.9950085)]",0
564706,Lifestyle,3,03/07/2023,The allure of AI,,"FOLLOWING the artificial intelligence (AI) boom that kicked off late last year with the debut of OpenAI’s ChatGPT, large tech companies have been in what feels like an AI arms race to take the lead.
 Industry giants like Google, Meta, Microsoft and others have been pushing further into the field of generative AI, but as the tools they create get more powerful, how much will they actually transform society?
 At the Asia School of Business’ (ASB) Leadership Summit, which had the theme “AI@Work”, experts weighed in on what the future might bring.Do the maths
 Prof Ong Shien Jin, who teaches data analytics at ASB, gave an overview of the history of AI, saying that while the buzz surrounding it has exploded in the past few months, its history goes as far back as the 1950s.
 “Pioneering computer scientists were asking a question: can computers be made to think?” he said.
 One such scientist was Alan Turing, an English mathematician and computer scientist who developed the Turing test to determine whether or not a machine is capable of intelligent behaviour.
 Prof Ong’s presentation included a live demonstration of ChatGPT solving an A-level maths problem.
 The demonstration used the more powerful GPT-4 with the plug-in for Wolfram Alpha, a computational tool for answering questions and solving maths problems.
 “To me, this was truly impressive, because maths computation is one thing, but maths reasoning is a higher-order thinking skill.
 “So is it ‘game over’ for education as we know it? Maybe it’s time to rethink the maths curriculum. We think that AI is going to change education, not destroy it.
 “We believe that there is a good possibility that AI and humanity can coexist in synergy, but this utopian vision is not a given because we have to work towards it,” he said.
 Samuel Flanders, a professor of economics at ASB, explained how ChatGPT could interpret and categorise huge blocks of text data.
 Prof Flanders said that in cases where there’s an abundance of text data, such as reviews or social media posts, ChatGPT can be used to extract specific information or themes from large datasets.
 “In the past, your options to deal with this sort of dataset were either very superficial or very difficult to execute.
 “For example, you could do a search to figure out how frequently a keyword appears and associate it with a certain type of response.
 “Or more recently, you could do a sentiment analysis to figure out if a response is generally positive or negative.
 “But these are superficial; if we want to go deeper and understand what’s really going on in the data, it’s very hard to do that.
 “Now, you can ask holistic qualitative questions about a big dataset of text, and you can get an answer in just a few minutes,” he said.Bring your A-game
 Another demo of ChatGPT’s utility was from ASB Master’s student Swaroop Ganireddy, who managed to build an interactive website with ChatGPT in just 10 minutes by simply providing it information via prompts.
 Had he taken it upon himself to build it, it would have taken Swaroop over a month.
 Additionally, Swaroop demonstrated a Windows-compatible tic-tac-toe game that ChatGPT entirely created.
 Meanwhile, Prof Isaac Chuang, the senior associate dean of digital learning at the Massachusetts Institute of Technology (MIT), discussed a possible solution to chatbot hallucinations.
 Prof Chuang credits the solution to a paper by his colleagues Antonio Torralba and Joshua Tenenbaum, who had two large language models (LLM) propose differing answers and then debate in order to reach a consensus.
 “The paper has these two agents talk to each other by presenting each answer to the other and asking them to resolve their differences.
 “In the second round, the agents apologised for the confusion and the conflicting responses and came to an agreement,” he said.
 Another speaker from MIT was Prof Daniela Rus, a roboticist and director of the MIT Computer Science and Artificial Intelligence Laboratory, who was optimistic about the future as the vital ingredients are already in place.
 “This promise and progress are enabled by three interconnected fields.
 “We have robotics, which puts computing into motion and gives machines the ability to move.
 “We have AI, which gives machines intelligence and enables them to see, hear, and even communicate like humans.
 “And we have machine learning, which aims to learn from and make predictions on data,” she said.
 Prof Rus shared examples of the potential of AI technology to eliminate car accidents, make transportation more affordable, better monitor, diagnose, and treat disease, keep information private and safe, enable easier communication, and make education more widespread.
 This would allow human workers to focus on tasks requiring critical thinking and strategy, with machines taking on other, more routine tasks.
 She added that, at a more granular level, all fields that have data can benefit from AI.
 Other AI-based startups were also present at the event, with Urbanmetry’s CEO and founder, Cha-Ly Koh, illustrating how AI was being used in her company to clean city data and apply it to ascertain climate risks along with their impact on housing prices in a specific area.
 V-Cred uses AI to analyse data from loan providers, platform partners and other sources to evaluate credit risk, with the goal of approving more loans and reducing defaults.",artificial intelligence boom late debut chatgpt tech company arm race lead industry giant meta microsoft field generative tool powerful transform society asia school business asb leadership summit theme expert future bring math ong shien jin teach analytics asb overview history buzz exploded month history computer scientist computer english mathematician computer scientist test determine machine capable intelligent behaviour prof ong presentation live demonstration chatgpt level math demonstration powerful gpt plug wolfram computational tool question math impressive math computation math skill game education time math curriculum change education destroy possibility humanity coexist synergy utopian vision samuel flanders economics chatgpt interpret categorise huge block data prof flanders text data review social medium post extract specific theme datasets option superficial difficult execute search figure associate type response sentiment analysis figure response positive negative superficial deeper understand data holistic qualitative question text answer minute game demo chatgpt utility master student swaroop ganireddy build interactive website chatgpt minute prompt build swaroop month demonstrated window compatible tic tac toe game chatgpt prof isaac chuang senior associate dean digital massachusetts institute technology mit solution chatbot hallucination chuang credit paper colleague torralba joshua tenenbaum language model propose answer reach consensus paper agent resolve difference agent apologised confusion response agreement speaker mit prof daniela ru roboticist director mit computer science artificial intelligence laboratory optimistic future vital ingredient progress interconnected field robotics motion machine ability machine intelligence enables communicate human machine aim prediction data prof ru example potential technology eliminate car accident transportation affordable monitor diagnose treat disease private safe enable easier communication education widespread human worker task critical thinking strategy machine routine task granular level field data benefit startup event urbanmetry ceo founder cha koh company clean city data climate risk impact housing price specific analyse data loan provider partner source credit risk goal loan default,"[(0, 0.62713724), (4, 0.3706369)]",0
564752,StarBiz,12,03/07/2023,"In AI tussle, Twitter restricts number of posts users can read",,"New York: Elon Musk has announced that Twitter will temporarily restrict how many tweets users can read per day, in a move meant to tamp down on the use of the site’s data by artificial intelligence or AI companies.
 The platform is limiting verified accounts to reading 6,000 tweets a day. Non-verified users – the free accounts that make up the majority of users – are limited to reading 600 tweets per day. New unverified accounts would be limited to 300 tweets.
 The decision was made “to address extreme levels of data scraping” and “system manipulation” by third-party platforms, Musk said in a tweet, as some users quickly hit their limits.
 Twitter would “soon” raise the ceiling to 8,000 tweets per day for verified accounts, 800 for unverified accounts and 400 for new unverified accounts, Musk said.
 Twitter’s billionaire owner did not give a timeline for how long the measures would be in place. Musk announced earlier that it would no longer be possible to read tweets on the site without an account. — AFP",york elon musk twitter tweet user day meant site data artificial intelligence company account tweet day user free account majority user tweet day account limited tweet decision address extreme level scraping system manipulation party platform tweet user limit ceiling tweet day account unverified account unverified account twitter billionaire owner timeline musk earlier read tweet site account afp,"[(2, 0.984641)]",2
564578,Main,31,02/07/2023,Vietnam tells foreign social media to use AI to detect ‘toxic’ content,,"HANOI has told cross-border social platforms to use artificial intelligence (AI) models that can detect and remove “toxic” content automatically, the latest requirement in its stringent regime for social media firms, state media reported.
 Vietnam has repeatedly asked companies like Meta’s Facebook, Google’s YouTube and TikTok to coordinate with authorities to stamp out content deemed “toxic”, such as offensive, false and anti-state content.
 “This is the first time Vietnam has announced such an order,” state-run broadcaster Vietnam Television (VTV) reported from the information ministry’s mid-year review event, which was opened to selected newspapers.
 The report did not give details on when and how cross-border platforms had to abide by the new requirement.
 During the first half of this year, in accordance with government requests, Facebook removed 2,549 posts, the ministry said in a statement. 
 YouTube removed 6,101 videos while TikTok took down 415 links, the info ministry said in a statement.
 The announcement came as South-East Asian countries are drawing up governance and ethics guidelines for AI that will impose “guardrails” on the booming technology.
 Vietnam in recent years has issued several regulations together with a cybersecurity law that target foreign social media platforms in a bid to battle disinformation in news and force foreign tech firms to establish representative offices in Vietnam and store data in the country.
 The country last month undertook a comprehensive inspection on short videos platform TikTok’s local operations and preliminary results showed “various” TikTok violations, the info ministry has said.
 VTV reported the info ministry saying at Friday’s event that US streaming giant Netflix had submitted documents needed to open a local office in Vietnam. — Reuters",hanoi cross border social platform artificial intelligence model toxic content requirement stringent regime social medium firm medium vietnam company facebook google youtube tiktok coordinate authority content toxic offensive false anti content time vietnam broadcaster vietnam television vtv ministry mid review event newspaper report detail border platform requirement half government request post statement youtube video tiktok link ministry statement announcement east asian country governance ethic guideline impose guardrail technology vietnam regulation cybersecurity law target foreign social medium platform battle disinformation news force foreign tech firm representative office data country country month comprehensive inspection short video tiktok local operation preliminary tiktok violation ministry vtv info ministry friday event giant netflix document local office vietnam reuters,"[(3, 0.9925984)]",3
564476,Main,33,02/07/2023,Execs urge Europe to rethink its world-leading AI rules,,"LONDON: More than 150 company executives are urging the European Union to rethink the world’s most comprehensive rules for artificial intelligence, saying that upcoming regulations will make it harder for companies in Europe to compete with rivals overseas, especially when it comes to the technology behind systems like ChatGPT.
 Officials at companies from French planemaker Airbus and carmaker Renault to Dutch beer giant Heineken signed an open letter to EU leaders saying the 27-nation bloc’s groundbreaking legislation may put shackles on the development of generative AI. 
 That technology gives popular AI chatbots like ChatGPT the power to generate text, images, video and audio that resemble human work.
 “Such regulation could lead to highly innovative companies moving their activities abroad  and investors withdrawing their money from AI development in Europe,” the letter said on Friday. 
 “The result would be a critical productivity gap between the two sides of the Atlantic.”
 The executives say laws requiring “rigid compliance” would be ineffective when so little is still known about the risks and uses of generative AI. They urged the EU to revise the AI Act to focus broadly on the risks.
 With growing concerns about the impact of AI on all parts of life, the letter does acknowledge “a clear need to properly train these models and ensure their safe use”.
 The executives called for a regulatory body of experts that can regularly adapt rules to new developments and respond to risks that emerge. 
 They also pointed to the need for transatlantic standards.
 It’s the latest letter to weigh in on the future of AI, which has dazzled users but raised concerns about data privacy, copyright infringement and disinformation. 
 That has sent governments worldwide racing to rein in the technology. — AP",london company executive european union comprehensive rule artificial intelligence upcoming regulation harder company compete rival technology system official company french planemaker airbus carmaker renault dutch beer giant heineken letter leader nation bloc legislation shackle development generative technology popular chatbots power generate text image audio resemble human regulation lead innovative company activity investor money development europe letter friday critical productivity gap atlantic executive law rigid compliance ineffective risk generative revise focus concern impact life letter train model safe executive regulatory body expert rule development risk transatlantic standard letter weigh future user concern data privacy copyright infringement disinformation government rein technology,"[(4, 0.99165916)]",4
564606,Lifestyle,20,02/07/2023,Will AI really destroy humanity?,"Here are some possible, if far-fetched, scenarios in which artificial intelligence wipes out humanity.","THE warnings are coming from all angles: artificial intelligence (AI) poses an existential risk to humanity and must be shackled before it is too late.
 But what are these disaster scenarios, and how are machines supposed to wipe out humanity?
 Paperclips of doom
 Most disaster scenarios start in the same place: machines will outstrip human capacities, escape human control and refuse to be switched off.
 “Once we have machines that have a self-preservation goal, we are in trouble,” AI academic Yoshua Bengio said at an event.
 But because these machines do not yet exist, imagining how they could doom humanity is often left to philosophy and science fiction.
 Philosopher Nick Bostrom has written about an “intelligence explosion”, which he says will happen when superintelligent machines begin designing machines of their own.
 He illustrated the idea with the story of a superintelligent AI at a paperclip factory.
 The AI is given the ultimate goal of maximising paperclip output and so “proceeds by converting first the Earth and then increasingly large chunks of the observable universe into paperclips”.
 Bostrom’s ideas have been dismissed by many as science fiction, not least because he has separately argued that humanity is a computer simulation and supported theories close to eugenics.
 He also recently apologised after a racist message he sent in the 1990s was unearthed.
 Yet his thoughts on AI have been hugely influential, inspiring both Elon Musk and Prof Stephen Hawking.
 The Terminator
 If superintelligent machines are to destroy humanity, they surely need a physical form.
 Arnold Schwarzenegger’s red-eyed cyborg, sent from the future to end human resistance by an AI in the movie The Terminator, has proved a seductive image, particularly for the media.
 But experts have trashed the idea.
 “This science fiction concept is unlikely to become a reality in the coming decades, if ever at all,” the Stop Killer Robots campaign group wrote in a 2021 report.
 However, the group has warned that giving machines the power to make decisions on life and death is an existential risk.
 Robot expert Kerstin Dautenhahn, from Waterloo University in Canada, played down those fears.
 She said AI was unlikely to give machines higher reasoning capabilities or imbue them with a desire to kill all humans.
 “Robots are not evil,” she said, although she conceded that programmers could make them do evil things.
 Deadlier chemicals
 A less overtly sci-fi scenario sees “bad actors” using AI to create toxins or new viruses and unleashing them on the world.
 Large language models like GPT-3, which was used to create ChatGPT, turn out to be extremely good at inventing horrific new chemical agents.
 A group of scientists who were using AI to help discover new drugs ran an experiment where they tweaked their AI to search for harmful molecules instead.
 They managed to generate 40,000 potentially poisonous agents in less than six hours, as reported in the Nature Machine Intelligence journal.
 AI expert Joanna Bryson from the Hertie School in Berlin said she could imagine someone working out a way to spread a poison like anthrax more quickly.
 “But it’s not an existential threat,” she said. “It’s just a horrible, awful weapon.”
 Species overtaken
 The rules of Hollywood dictate that epochal disasters must be sudden, immense, and dramatic, but what if humanity’s end was slow, quiet, and not definitive?
 “At the bleakest end, our species might come to an end with no successor,” philosopher Huw Price says in a promotional video for Cambridge University’s Centre for the Study of Existential Risk.
 But he said there were “less bleak possibilities” where humans augmented by advanced technology could survive.
 “The purely biological species eventually comes to an end, in that there are no humans around who don’t have access to this enabling technology,” he said.
 The imagined apocalypse is often framed in evolutionary terms.
 Prof Hawking argued in 2014 that ultimately our species will no longer be able to compete with AI machines, telling the BBC that it could “spell the end of the human race”.
 Geoffrey Hinton, who spent his career building machines that resemble the human brain, latterly for Google, talks in similar terms of “superintelligences” simply overtaking humans.
 He told US broadcaster PBS recently that it was possible that “humanity is just a passing phase in the evolution of intelligence”. – AFP",warning angle artificial intelligence existential risk humanity late disaster scenario machine wipe humanity paperclip disaster scenario machine human capacity human control refuse machine preservation goal trouble academic yoshua bengio event machine doom humanity philosophy science fiction philosopher nick bostrom intelligence explosion superintelligent machine machine idea story superintelligent paperclip factory ultimate goal paperclip output proceeds earth observable universe paperclip idea science fiction humanity computer simulation theory eugenics racist message influential elon musk prof stephen terminator superintelligent machine humanity physical form arnold schwarzenegger red cyborg future human resistance movie terminator seductive image medium expert idea science fiction concept reality decade robot campaign report machine power decision life death existential risk robot expert kerstin dautenhahn waterloo university canada fear machine capability desire kill human programmer deadlier chemical scenario bad actor create toxin unleashing language model create chatgpt horrific chemical agent scientist drug experiment search harmful molecule poisonous agent hour nature machine intelligence journal expert joanna bryson hertie school berlin imagine spread poison anthrax existential threat horrible awful weapon specie rule epochal disaster sudden immense dramatic humanity quiet definitive bleakest specie huw price promotional video cambridge university centre study existential risk bleak possibility human advanced technology biological specie access technology apocalypse evolutionary term ultimately specie machine bbc spell human race geoffrey hinton career machine resemble human brain google talk term superintelligences human broadcaster pb humanity phase evolution intelligence afp,"[(0, 0.23923498), (1, 0.75797594)]",1
564294,StarBiz 7,17,01/07/2023,Why India risks falling behind in the AI race,,"INDIA’S tech industry is being less than bold in embracing artificial intelligence (AI). It’s hoping to create solutions for corporate clients by building on top of somebody else’s investment in foundational technologies, hardly a strategy for pathbreaking success.
 ChatGPT’s high-voltage debut last year has galvanised China. Baidu Inc’s Ernie, which claims to have outperformed Microsoft Corp-backed OpenAI’s model on some measures, has pulled Ant Group Co and JD.com into the bot-building race.
 Tech czars like Wang Xiaochuan, the founder of the search engine Sogou, have also joined the quest, drawing talent to the industry. On money flow, the United States is still beating China six to one, but the number of venture deals in the Asian country’s AI industry is already outpacing consumer tech, according to Preqin data.
 India’s startup landscape, meanwhile, is caught in a time warp, with embarrassed investors marking down their stakes in Byju’s, an online education company collapsing under the weight of its own reckless growth.
 The easy funding from the pandemic era has dried up. As financiers push founders for profitability, they’re discovering that in many cases even the revenue is fake.
 This was the perfect time for the traditional Indian coding powerhouses – the likes of Tata Consultancy Services Ltd (TCS) and its rival Infosys Ltd – to put their superior financial muscle to use and assert leadership in generative AI.
 But they have their own governance challenges. TCS is distracted by a bribes-for-jobs scandal in the United States that it is desperately trying to downplay. Infosys is busy managing the blowback from its association with an Australian lobbying firm in the centre of a parliamentary inquiry Down Under.
 Even without those challenges, the outsourcing specialists aren’t exactly in a sweet spot. Demand for their services is weak, particularly because of the turmoil in global banking.
 Decisions on IT spending have slowed. Keener competition for a smaller pie could mean a fall in order wins and deterioration in pricing, JPMorgan Chase & Co analysts said earlier this month.
 Meanwhile, the Indian firms’ wage bills are bloated, thanks to their hiring spree during the pandemic when clients were scrambling to digitise their operations.
 No wonder then that the industry’s approach to AI is defensive, geared toward assuring investors that the technology poses little threat to its time-tested model of labour-cost arbitrage.
 When three lines of C programming replaced 30 lines of assembly language, it didn’t lead to mass layoffs but an explosion in code-writing. Similarly, when outsourcing made enterprise software cheaper, IT budgets didn’t deflate. Volumes rose, as prices fell. Why should this time be different, asks the TCS annual report for 2022-2023.
 This is a rather phlegmatic reaction to a revolution whose possibilities are beginning to scare its own creators. ChatGPT can surely write snippets of code or run a quality check on them, potentially reducing billing hours. 
 But that’s hardly the point that needs addressing. Being around machines that are smarter than any of us has troubling prospects for the future of humanity, especially if the algorithms come to be controlled by evil actors.
 Even leaving aside those profound concerns about a potentially dystopian future, the more prosaic questions are also of significance for users of enterprise software. 
 Companies from banking to retail and aviation must decide their engagement with so-called large language models.
 And they can’t be sure if taking something off the shelf is good for data privacy. What exactly are Indian firms doing to grab this opportunity?
 Bengaluru-based Infosys has adopted a mix-and-match strategy, so its clients can choose from 150 pre-trained models across more than 10 platforms, and then run them on any cloud or in-house servers.
 The TCS annual report says that its research in large language models is oriented toward “creating techniques for controlled code generation, question answering, consistent image generation, solving optimisation problems and other core AI problems.”
 However, if Alphabet Inc is cautioning employees about how much information they can share with chatbots, including its own Bard, then how can TCS or Infosys assume that global multinationals will be comfortable pitching their tents on platforms available to just about anyone?  Indian software services firms also ought to be building language models from scratch for themselves and their customers. Yes, it takes computational power and engineering talent to train neural network-based programmes on vast amounts of natural-language inputs.
 But to not go down that route and look to connect clients via application programming interfaces, or APIs, to existing products is unnecessarily timid, especially when no serious business might want to rely on a publicly available external foundational model for mission-critical tasks.
 Google’s own research on training data extraction, or the potential for models to leak details from the data on which they’re trained, shows that the risk is very real.
 Creating well-guarded, proprietary foundational technologies isn’t particularly resource-intensive.
 To Nvidia Corp cofounder Jensen Huang, whose chips are at the centre of the AI excitement, even a modest US$10mil (RM46.7mil) budget for large-scale models is not unrealistically low.
 Countries that aren’t traditionally known as tech producers are also getting noticed for their breakthroughs. Abu Dhabi’s Technology Innovation Institute has made its Falcon 40B – trained on 40 billion parameters – royalty-free for commercial use. 
 The Chinese have clearly not bought into the idea that Silicon Valley will control the keys to generative AI.
 While Indian software firms’ excessive service orientation has meant very few successes in developing products, now is the time for some ambition, and a new strategy that goes beyond charging customers a fee for tweaking OpenAI’s GPT-4, Google’s Bard or Meta Platforms Inc’s LLaMA with specialist data. 
 On a recent visit to the country, OpenAI chief executive officer Sam Altman was asked if someone in India with US$10mil (RM46.7mil) to invest should dare to build something original in AI.
 He said: “The way this works is we’re going to tell you it’s totally hopeless to compete with us on training foundation models (so) you shouldn’t try, and it’s your job to like, try anyway.” — Bloomberg
 Andy Mukherjee is a Bloomberg Opinion columnist. The views expressed here are the writer’s own.",india tech industry artificial intelligence create solution corporate client top investment foundational technology strategy success chatgpt voltage debut china baidu ernie claim microsoft corp openai model measure ant bot building race tech czar xiaochuan founder search engine sogou quest talent industry money flow beating china venture deal asian country industry consumer tech preqin data startup landscape time warp investor stake byju online education company weight reckless growth easy funding pandemic era financier push founder profitability revenue perfect time traditional indian coding powerhouse tata consultancy service rival infosys superior financial muscle assert leadership generative governance challenge bribe job scandal downplay infosys busy blowback association australian lobbying firm parliamentary inquiry challenge specialist sweet spot demand service weak turmoil global banking decision spending keener competition fall deterioration pricing jpmorgan chase analyst month indian firm wage bill spree pandemic client digitise operation industry approach defensive investor technology threat time labour cost arbitrage line replaced line language lead mass layoff code enterprise software cheaper budget volume price time tc annual report phlegmatic reaction revolution possibility creator write snippet quality check billing hour machine prospect future humanity algorithm evil actor profound concern dystopian future prosaic question significance user software company retail aviation decide engagement language model privacy indian firm opportunity bengaluru infosys mix match strategy client pre model platform house server annual report language model technique code generation question consistent image generation optimisation core alphabet employee share chatbots bard tc infosys global multinationals comfortable tent platform indian software service firm language model customer computational power engineering talent train neural network programme vast amount natural language input connect client application interface product business external foundational model mission critical task data extraction potential model detail data risk real proprietary foundational technology intensive nvidia corp cofounder jensen chip centre excitement modest mil mil budget scale model low country tech producer breakthrough abu dhabi technology innovation institute falcon parameter free commercial chinese idea silicon valley control generative indian software firm excessive service orientation meant product time ambition strategy customer fee openai gpt google bard meta platform specialist data visit country chief executive officer altman india mil mil invest dare build original hopeless compete training foundation model job andy mukherjee bloomberg opinion columnist view writer,"[(3, 0.9976164)]",3
563292,StarBiz,14,29/06/2023,Possible cuts in AI chip exports to China,US considering stopping shipments as early as July,"NEW YORK: The United States is considering new restrictions on exports of artificial intelligence (AI) chips to China, the Wall Street Journal has reported, citing people familiar with the matter.
 Shares of Nvidia fell more than 2%, while Advanced Micro Devices (AMD) fell about 1.5% on the news in extended trading.
 Reports have said that China’s massive demand for advanced semiconductors to power new AI development projects has created a fast-growing market for smuggled graphics processing units or GPUs, such as the A100 and H100 devices from Nvidia Corp, according to industry insiders.
 It is an under-the-counter trade that has apparently prospered.
 The Commerce Department will stop the shipments of chips made by Nvidia and other chip companies to customers in China as early as July, the report said.
 Nvidia, Micron and AMD are among the US chipmakers caught in the crossfire between China and the Biden administration.
 In September, Nvidia had said that US officials asked the company to stop exporting two top computing chips for AI work to China.
 Months later, Jensen Huang-led Nvidia said it will offer a new advanced chip called the A800 in China to meet export control rules.
 The company also tweaked its flagship H100 chip early this year to comply with regulations.
 But the new curbs being mulled by the department would ban the sale of even A800 chips without a special US export licence, the report added.
 The Commerce Department did not immediately respond to a Reuters request for comment. — Reuters",york united restriction export artificial intelligence chip wall street journal people familiar matter share advanced micro device news trading report massive demand semiconductor power development project market graphic unit gpus device industry insider trade commerce department shipment chip chip company customer july report micron amd chipmakers crossfire china biden administration nvidia official company top chip china month huang offer chip china meet export control rule company flagship chip comply regulation department ban sale chip special export licence report commerce department respond reuters comment reuters,"[(2, 0.33436322), (4, 0.6581471)]",4
563488,Main,1,29/06/2023,Ride the AI wave,,"Artificial intelligence is here to help, not hinder. The onus is on youths to equip themselves with the right skills to remain relevant in the tough job market. To stand out, human resources experts advise they emphasise digital literacy and be ready to adapt to change.  > See reports on page 5 by JUNAID IBRAHIM, BENJAMIN LEE and MAHADHIR MONIHULDIN",artificial intelligence hinder youth skill relevant tough job market human resource expert emphasise digital literacy ready adapt change report ibrahim benjamin lee mahadhir monihuldin,"[(4, 0.96428764)]",4
563504,Main,5,29/06/2023,"AI is a complementing tool, say workers",,"PETALING JAYA: Artificial intelligence (AI) should not be seen as a substitute to human talent, but rather as a tool to complement one’s work, say young employees.
 Before the emergence of AI software, freelance copywriter Rasyida Salleh needed almost a whole day to finish a couple of 1,000-word articles.
 However, the rise of ChatGPT since late last year had shortened it to only a few hours, allowing the 28-year-old to produce even more content daily. Instead of worrying about the competition she might face due to AI, she said the technology could help her add more value to her work and increase her productivity. Rasyida also said she would maintain credibility by fact- checking the content generated by the software.
 “At the end of the day, AI needs us to humanise the end product, especially when it comes to creative content production. Techno­logies are here to help us, not take over us. Learning how to use it will ensure our jobs remain relevant. It’s all about embracing and adapting,” she said.Freelance scriptwriter Naquib Aqmal said the use of ChatGPT had made it easier for him to express his ideas while conforming to certain formats.
 “After writing my initial script, AI tools help me to automatically rearrange my script to match the specific format or criteria that the client requests,” he said, adding that the likelihood of AI replacing him was unlikely so long as he kept building on his scriptwriting skills.“The reason why the biggest movies and shows are not written by AI yet is because creativity and talent cannot be easily imitated by a bot,” the 22-year-old said.
 Video editor Dominique Palen­cia, 28, said many of the Adobe software that he used to edit his videos come with AI tools that have helped him in his work.
 “One of the AI tools is called rotoscoping that separates subjects from their background, similar to a green screen, only without the actual screen,” he said, adding that he usually uses Adobe Premiere and After Effects for his work.“The tool has been around for a while but Adobe’s AI has made it much more accurate and efficient,” he added.
 In general, he believed that AI would help complement his video editing work and make his job easier rather than replace it.
 “At least for now, I don’t see AI replacing video editors entirely. There are still other aspects of video editing that require a human touch, like when it comes to pacing, editorial decisions of what to include and cut out,” he said.
 Tech company manager Raven­der Sathivelu, 28, said AI has had little effect on his role managing people involved in the logistics of his company’s products.
 “AI technology has little impact on my job as it requires a lot of social interaction and strategic planning,” he said, adding that managerial roles require human- related skills that will not be replicated by AI anytime soon.
 “However, I have seen individuals using AI software to increase their productivity at work and achieve goals faster,” he added.
 Ravender believes that adopting AI technology will be slow in the country as it is still expensive and employers have more trust for manual labour performed by humans.
 “As a small and medium-scale enterprise, my company does not want to bear the heavy costs of purchasing AI services as a company-wide policy,” he said. “I think there will be a few early adopters, but they will likely use it to enhance productivity.”
 Supply chain executive Darren Teh Zhi Wei, 26, said that while AI had automated the management of materials, individuals like him were still essential to prevent any malpractice.
 “AI systems help to automate a lot of the steps during procurement like invoicing, material management and tracking of items, which saves a lot of time for all sides of the transaction.
 “However, personnel like me must go on-site to check and validate the orders as well as oversee the entire process from start to finish to ensure no mismanagement or foul play occurs,” he said.",jaya artificial intelligence substitute human talent tool complement employee software freelance copywriter rasyida salleh day finish couple word article chatgpt hour content competition technology add increase productivity maintain credibility content software day humanise product creative content production techno logies job relevant freelance scriptwriter naquib aqmal chatgpt easier express idea format initial script tool script match specific format criterion client request likelihood building skill reason biggest movie creativity talent bot video editor dominique cia adobe software edit video tool tool separate subject green screen actual screen adobe premiere effect adobe accurate efficient complement video job easier video editor video require human touch editorial decision tech company manager raven der sathivelu role people logistics company product technology impact job social interaction strategic managerial role human skill anytime individual software increase productivity goal technology slow country expensive employer manual labour human medium scale enterprise company heavy cost service company wide policy adopter productivity supply chain executive darren teh zhi wei management material individual essential prevent malpractice system lot step procurement material management item lot time transaction personnel site check validate oversee entire process start finish mismanagement foul play,"[(0, 0.9952207)]",0
563506,Main,5,29/06/2023,"Tame the AI beast, youths urged","Experts urge Malaysian workers to learn, adapt and stay flexible","PETALING JAYA: Artificial intelligence (AI) is a technical marvel – a beast that youths can tame.
 Experts are calling on Malay­sians to equip themselves with the appropriate skills if they want to remain relevant in the tough job market.
 Usha Devi Arumugam, a human resource expert at PeopleBiz Consulting, says employees should develop their skills in digital literacy as well as non-technical skills.
 She said this includes adopting a learning mindset, being adaptive to changes and being socially intelligent.
 “In the longer run, I believe that employers would want employees who have a good understanding of business regardless of their job role.
 “As organisations face more challenges in the industry, employees who have a good sense of what drives the business will be more valued.
 “Being a specialist in a particular job role is good, but to find the connection of what we do for the business as a whole is valuable,” she said.
 Digital literacy refers to a person’s ability to use information technology and digital technology to find, evaluate, create and communicate information.
 Aside from this, Usha also encouraged employees to be creative in resolving issues related to their work and not wait for employers to provide upskill programmes for them to learn new skills.
 “Knowing different ways to solve issues will be beneficial for the employer. This not only means creating new products, but also finding new ways to make processes faster and easier, finding new ways of doing things and challenging the status quo,” she said.
 “It is advisable for employees to not wait for companies to train them to learn new skills as they should be proactive and take the initiative to find the skills that they want to acquire,” she added.
 Usha said employees do have an incentive to learn new skills as it can open up a new space for salary negotiation with employers.“If these new skills allow the employees to execute the job fas­ter, with more accuracy, have a positive impact on the team, department or business and add value to the organisation, there will definitely be room for salary negotiation,” she said.
 Managing director of JobStreet Malaysia, Vic Sithasanan, was optimistic about the influence of AI technology, claiming that as some jobs become automated, new ones will emerge.
 “Employers should provide opportunities for learning and development, particularly in the digital and AI-related areas,” Vic said.
 “They should also redesign jobs to leverage the strengths of both humans and AI,” he added.
 As for employees, Vic said they need to be proactive in learning new skills and adapting to changes in the job market.
 “Employees need to understand that AI should be seen as a tool that enhances human capabilities, not as a replacement,” he said.
 “The focus should be on using AI to automate repetitive tasks, freeing up human employees to perform more complex, creative, meaningful and ‘value-added’ work,” he added.
 Federation of Malaysian Manufacturers (FMM) president Tan Sri Soh Thian Lai said employers are encouraged to work with higher learning institutions,  specialised training providers and industry experts to train employees.
 “The training will be intended to close the skills gap of the workforce by developing more life-long learning courses to upskill and reskill existing workers and new potential employees,” he said.
 Soh added that FMM had proposed in its 2023 Budget memorandum for the Human Resource Development Corporation (HRD Corporation) to help finance training programmes organised by employers.
 “For every RM1 spent on training by employers, HRD Corpo­ration tops up the employers levy account with RM3 especially for small and medium enterprises (SMEs),” he said.
 “A cap could be set on the amount that can be claimed by employers under this top-up scheme annually.”
 Tax advisory firm TraTax’s co-founder Thenesh Kannaa said that learning to use AI and new digital tools in accounting would enable accountants to perform better.
 “Software AI tools that enable accounting entries to be automatically posted by simply scanning vendor invoices are already employed by many accounting firms today.
 “These tools relieve accountants from needing to perform repetitive tasks like data collection, processing and formatting which allows better resource management for both the accountant and the firm as a whole.
 “By using these tools, we will be able to focus on improving our problem-solving and value-creation skills,” Thenesh, who is also a member of the Association of Chartered Certified Accountants, said.
 Yayasan Digital Malaysia’s head of digital innovation Mohd Fazli Azran shared the same sentiment, adding that having strong fundamentals and flexibility would be key in the future job market.
 “Strong knowledge of concepts, principles and best practices will be essential as it will enable us to effectively utilise these new AI tools, particularly when it comes to cybersecurity.
 “Cultivating a mindset of continuous learning and adaptability allows us to constantly anticipate new attack vectors and devise innovative defence strategies before they even occur,” he added.
 On Monday, Human Resources Minister V. Sivakumar said that as many as 4.5 million Malaysians are likely to lose their jobs by 2030, if they do not improve their skills or attend reskilling and upskilling programmes with the rise of AI.
 He cited the 2020 World Eco­nomic Forum (WEF) warning that AI could cause a recession in the job market as it is already being used to automate tasks in various industries.
 However, in the latest report by WEF published in May 2023,  the pace of automation contradicted 2020’s projections where almost half (47%) of business tasks would be automated by 2025. 
 “Today, respondents have re­vised their expectations for future automation to predict that only 42% of business tasks will be automated by 2027.
 “The role of task automation for businesses in 2027 is expected to vary with the bulk of its tasks being geared towards information and data processing,” the report stated.",jaya artificial intelligence technical marvel beast youth tame expert malay sian skill relevant tough job market usha devi arumugam human resource expert peoplebiz employee skill digital literacy technical skill adaptive intelligent employer employee business job role organisation challenge industry employee business specialist job role connection business valuable digital literacy refers person ability technology digital technology evaluate create communicate usha employee creative issue employer upskill programme skill solve issue beneficial employer product process status quo advisable employee company learn skill proactive initiative skill usha employee learn skill space salary negotiation employer employee job fa ter accuracy positive impact team department business organisation salary negotiation director jobstreet malaysia sithasanan optimistic influence technology job emerge employer opportunity development digital vic redesign job strength human employee proactive learning skill job market employee tool enhances human capability replacement focus automate repetitive task human employee complex creative meaningful federation malaysian manufacturer president tan sri soh thian lai employer institution provider industry expert employee skill workforce life learning course worker potential employee fmm budget memorandum human resource development corporation hrd corporation finance training programme employer spent training employer corpo ration employer account medium smes amount employer top scheme tax advisory firm tratax founder thenesh kannaa digital tool enable accountant software tool enable entry vendor invoice accounting firm accountant repetitive task data collection processing resource management accountant firm creation skill thenesh association certified accountant yayasan digital malaysia head digital innovation mohd fazli azran sentiment strong fundamental flexibility key future job market strong knowledge concept principle practice essential enable utilise tool cybersecurity continuous adaptability anticipate attack vector innovative defence strategy monday human resource minister sivakumar malaysian job skill programme eco nomic forum wef recession job market automate task industry wef pace automation projection half business task respondent vised expectation future automation predict business task role task automation business vary bulk task data report,"[(2, 0.9970501)]",2
562972,StarBiz,8,28/06/2023,"Mizuho rolls out generative AI to its 45,000 bank workers in Japan",,"TOKYO: Mizuho Financial Group Inc is giving all its Japan bank employees access to Microsoft Corp’s Azure OpenAI service this week, making it one of the country’s first financial firms to adopt the potentially transformative generative artificial intelligence (AI) technology.
 The banking giant will allow 45,000 workers at its core lending units in the country to test out the service, according to Toshitake Ushiwatari, general manager of Japan’s third largest bank’s digital planning department. 
 Already, managers and rank-and-file employees are submitting dozens of pitches for ways to harness the technology even before the software is installed.
 There are many employees who are embracing ChatGPT in their private lives, Ushiwatari said in an interview.  
 “It’s like poking a beehive,” he said, referring to the enthusiastic response the firm’s move has sparked. 
 “They think it will completely re-set the world, triggering disruptive innovation,” he said.
 The developments at Mizuho and its peers come as Wall Street grapples with the unfolding AI revolution and its impact. 
 Within global banks, some have clamped down on ChatGPT for employees, even as they use AI for business purposes such as scanning wealthy client portfolios and screening for potential defaulters. Japanese financial firms, by contrast, appear to be adopting a more permissive stance internally. Ushiwatari’s team plans to hold a so-called “ideathon” within the firm in Japan as early as next month and is brainstorming various ways to encourage employees to experiment with the technology. 
 The tool will be introduced to its brokerage unit in the country next month, he said.
 So far, one of the ideas being floated is to use generative AI – in which AI models analyse volumes of data and use it to generate new images, texts, audio and video –as a one-stop reference point for the bank’s vast trove of internal rules, processes and other manuals. 
 Ushiwatari has a rare background for a career-long banker. 
 He went to one of Japan’s most prestigious science schools, Tokyo Institute of Technology, because he wanted to become a rocket scientist. 
 But he switched career ambitions, joining what is today’s Mizuho and has stayed for nearly three decades. 
 He said he is well aware of the risks of generative AI and the bank is introducing guidelines when it rolls out the technology to employees, such as information management, intellectual property and ethics. 
 Still, generative AI is something that will lift society and the bank cannot shy away from, according to Ushiwatari. 
 “This is something we have to do, otherwise, we get left behind,” he said. —Bloomberg",tokyo mizuho financial japan bank employee access corp azure openai service week country financial firm transformative generative artificial intelligence technology banking giant worker unit country test service ushiwatari manager japan largest bank digital planning department manager file employee dozen pitch technology software employee chatgpt private life ushiwatari interview beehive enthusiastic response firm move disruptive innovation development peer street grapple revolution impact global bank chatgpt employee business purpose wealthy client portfolio potential defaulter japanese financial firm permissive stance ushiwatari team plan ideathon firm month encourage employee technology tool brokerage unit country month idea generative model volume data generate image audio video reference bank vast internal rule manual ushiwatari rare background career banker japan prestigious science school institute technology rocket scientist career ambition mizuho decade aware risk generative bank guideline roll technology employee management intellectual property ethic generative lift society bank shy ushiwatari bloomberg,"[(0, 0.26249248), (4, 0.7331658)]",4
563036,Main,20,28/06/2023,Monitoring wound recovery using AI,,"A paper-thin sensor patch the size of a postage stamp attached to the skin could soon help to determine how well a wound is healing – without the need to remove its dressing.
 The artificial intelligence-­enabled device aims to provide a more efficient way of monitoring wound recovery, as well as improve wound care and management.
 Dubbed the Paper-like Battery-free In situ AI-enabled Multiplexed (Petal) sensor patch, it measures just 1.8cm by 1.8cm.
 It was developed by researchers from the National University of Singapore (NUS) and the Agency for Science, Technology and Research’s Institute of Mate­rials Research and Engineering (Imre).
 A paper on the researchers’ work on the sensor patch, which was developed in collaboration with a research team from the Nanyang Technological University and the Skin Research Institute of Singapore, was published in the scientific journal Science Advances in June.
 “A lot of times if you don’t have a way to monitor the wound-­healing process, especially for more complex wounds, then this becomes a problem,” said Assoc Prof Benjamin Tee from the NUS Institute for Health Innovation and Technology during a media briefing on Monday.
 Prof Tee, the principal investigator for the research, said wound dressing such as bandages could lead to infections if done improperly.
 The issue of wound management is especially relevant in an ageing society like Singapore, where most wounds are experienced by those aged 80 and above, he added.
 Wound healing currently typically requires a physical examination by a clinician, with wound infections that need a period of up to three days to be diagnosed.
 Each sensor patch features a panel in the shape of a flower, with each of its five petals acting as a sensor for one of five markers – the temperature of a wound, its acidity, moisture levels as well as the presence of uric acid and trimethylamine, a chemical compound.
 These cover a wide spectrum of situations, allowing for more comprehensive assessments of the wound-healing status, said principal scientist Su Xiaodi, who is from the soft materials department at Imre.
 The patch collects fluid from the wound and distributes it to the five sensors, which change colours to show the levels of these indicators. Images of the sensor patch can be captured using a smartphone and classified using AI. — The Straits Times/ANN",paper thin sensor patch size postage stamp skin determine artificial intelligence device aim efficient monitoring wound recovery wound care management paper battery free situ multiplexed petal sensor patch measure researcher national university nu agency science technology institute mate rial engineering imre paper researcher patch collaboration team technological university institute singapore scientific journal science advance june lot time process complex wound prof benjamin tee institute health innovation technology medium monday prof tee principal investigator bandage infection wound management relevant society singapore wound physical examination clinician wound infection period day sensor patch feature panel shape flower petal sensor marker acidity moisture level presence uric acid trimethylamine chemical compound cover wide spectrum situation comprehensive assessment status principal scientist xiaodi soft material department imre patch fluid wound sensor colour level indicator image patch smartphone strait time,"[(2, 0.99359906)]",2
562248,StarBiz,5,26/06/2023,Daythree aiming to harness the power of AI,GBS provider to focus on customer experience,"THE concept of business process outsourcing or BPO may be well known in Malaysia but a new moniker is making its way into the mainstream. 
 According to veteran technology professional Raymond Devadass, the moniker “global business services” or GBS is the new term that has replaced BPO.
 “While BPO primarily focused on cost reduction, GBS emphasises an integrated approach to outsourcing that includes accessing new technologies and adding value to organisations,” he told StarBiz. 
 But how is that achieved? 
 Devadass, the founder and managing director of soon-to-be listed Daythree Digital Bhd, said this is where companies like his have sought to harness the power of artificial intelligence (AI) and human intelligence, to unlock new opportunities, optimise processes, and deliver enhanced value to its customers.
 As a tech-driven GBS provider, Daythree focuses on customer experience (CX) and lifecycle management services, in which it relies on a synergistic blend of cutting-edge technology and human expertise to drive innovation and achieve growth.
 Devadass further explained that Daythree operates as a comprehensive customer experience centre rather than a conventional call centre, thanks to its in-house designed digital tools.
 In this role, they manage all customer interactions, taking a broader approach to ensure a seamless and exceptional experience throughout the entire service journey.
 “Typically, a conventional call centre’s job is to attend calls and pass the information back to the service provider. But today, the job has changed. 
 “Hence, the job of a customer experience centre, like what we do, is not just to manage the transaction, but also the entire service journey,” he said, adding that Daythree is an end-to-end customer service experience provider.
 Enroute to an ACE Market listing, Daythree has outlined its strategy to expedite its expansion plans by utilising the proceeds from the initial public offering (IPO), where it is seeking to raise RM33.12mil.
 Out of the entire IPO proceeds, RM14,70mil or 44.4% has been earmarked for working capital requirements, including the recruitment of an additional 380 CX executives. 
 This investment aims to bolster Daythree’s capacity to service a growing number of contracts, as the group currently has around 1,800 CX executives.
 Within the short to medium term, the group also plans to double its headcount from the 1,800 people currently.
 “People cost is a significant component in our business and as such, we will channel a big chunk of the proceeds for working capital for our upcoming contracts. This is because the number and size of contracts that we can undertake at any point in time depend largely on the availability of our working capital,” Devadass said.
 Achieving more with less people
 He explained that while customer experience is Daythree’s core focus, technology is a significant differentiator for them. 
 “Our constant thinking is how we can achieve more with less people. Therefore, technology becomes a very crucial component in our service provision to further reduce dependency on people,” he highlighted.
 Raymond said that while they ensure all their employees are paid above the minimum wage, raising the minimum wage also impacts higher wages.
 A further RM7.1mil or 21.4% of the proceeds will be used to part-finance the additional working space required for its growing customer base and the expansion of its headquarters to cater for the rising number of employees as well as to set up a multipurpose facility for internal training and meetings.
 Devadass explained that the group has intentions to increase its current headquarters built-up area from about 4,000 sq ft, occupied by its management level employees, to 6,045 sq ft, in order to accommodate the current and additional management team.
 The company also plans to set up two new CX delivery offices with an aggregate built-up area of about 12,000 sq ft and a multipurpose facility with a built-up area of approximately 6,000 sq ft to be used for internal training, meeting, rest and recreational purposes.
 Another RM3mil or 9.1% of the proceeds will be allocated for capital expenditure, covering networking infrastructure, hardware, and software. 
 Additionally, RM3.02mil or 9.1% of the proceeds will be utilised for recruiting industry experts, enabling Daythree to capture growth opportunities within the local GBS industry. 
 According to Devadass, talent acquisition is a major challenge faced not only by Daythree but also the entire industry.
 He said the proceeds will not only be utilised for talent recruitment but also for upskilling the existing workforce.
 “I think the big component of retaining talent is being able to upskill them,” he further explained.
 Additionally, RM1.5mil or 4.5% has been designated for branding, marketing, and promotional activities and the remaining RM3.8mil or 11.5% will be utilised to cover estimated listing expenses.
 Meanwhile, citing an independent market researcher Protege Associates Sdn Bhd, Devadass said the local GBS industry is expected to reach RM24.9bil in 2023 and projected to expand at a compound annual growth rate of 6.3%, to hit RM31.9bil by 2027. 
 In-house digital tools
 Devadass believed the group is well positioned to leverage this growth, supported by three of its in-house designed digital tools.
 According to him, all three of the group’s in-house developed digital tools, namely Daisy, Faith and Saige, go hand in hand.
 He explained that Faith is a platform designed to improve employee engagement by providing tools for streamlining scheduling, automating payroll processes, facilitating communication, and enhancing performance feedback within Daythree and its workforce.
 Daisy, on the other hand, is a customer relationship management which is embedded with robotics process automation which makes it a game changer.
 Proving it, Raymond describes a typical scenario in a contact centre where agents spend additional time after a call to create a case, contact engineers, and handle various tasks across multiple systems. 
 To streamline this process, Daythree has developed Daisy that sits on top of existing systems. 
 “After a call, agents only gather basic information, and bots take over the remaining tasks by sending information to relevant departments,” he said.
 Currently, Daythree operates a bot farm consisting of 60 bots that automate a significant portion of the tasks formerly performed by agents, resulting in time savings and increased productivity.
 With this automation, agents can handle a significantly higher number of interactions in a given time period, Raymonds pointed out.
 “Overall, the bots assist in deflecting routine and mundane tasks, freeing up human resources for more complex and critical work,” Raymond said.
 Finally, Saige, which serves as the group’s business intelligence tool, gathers real-time data from every customer interaction and captures it within a unified analytics platform. 
 This allows for analysis, interpretation, and recommendations for improvement based on the collected data.
 “We are always hungry to look for the latest technologies available to help us with the work we do for our clients,” Devadass said.
 Hence, even today, Daythree is dabbling with generative pre-trained transformers or generative AI to further improve efficiency.
 Raymond said the challenge for service providers today is to achieve an omni-channel approach, which involves having a consolidated view of the customer across multiple channels, including in-store visits, social media interactions, and messaging platforms.
 He emphasised the importance of technology in achieving this and providing a seamless customer experience. 
 By consolidating customer views, Daythree aims to anticipate needs and provide personalised assistance.
 Meanwhile, Raymond pointed out that Daythree has started working with regional brands outside of Malaysia, expanding their customer base beyond local Malaysian companies. 
 He added that Daythree has secured projects with companies in the travel, hospitality, banking, and security management sectors. 
 This signifies a shift towards engaging with more global and regional brands, reducing their dependence on local clients over time.",concept business process bpo malaysia moniker mainstream veteran technology professional raymond devadass moniker global business service gb term bpo bpo cost reduction gb emphasis approach technology organisation starbiz devadass founder director daythree digital bhd company harness power artificial intelligence human intelligence unlock opportunity enhanced customer driven gb daythree focus customer experience lifecycle management service synergistic blend edge technology human expertise drive innovation growth devadass daythree operates comprehensive customer experience centre conventional call centre house digital tool role manage customer interaction broader approach seamless exceptional experience entire service journey conventional call centre job pas service provider job job customer experience centre manage transaction entire service journey daythree customer service experience provider enroute ace market daythree strategy expedite expansion plan utilising proceeds initial public offering ipo raise mil entire ipo proceeds mil capital requirement recruitment additional executive investment bolster daythree capacity service contract executive short medium term plan double headcount people people component business channel chunk proceeds capital contract size contract undertake time depend availability capital devadass people customer experience daythree core focus technology differentiator constant thinking people technology crucial component service provision dependency people raymond employee minimum wage minimum wage impact wage mil proceeds additional space customer base expansion headquarters cater employee multipurpose facility internal training meeting devadass intention current headquarters management level employee accommodate current additional management team company delivery office multipurpose facility internal training meeting rest recreational purpose mil proceeds capital expenditure networking infrastructure hardware software mil proceeds utilised recruiting industry expert daythree capture growth opportunity local gb industry devadass talent acquisition major challenge daythree entire industry proceeds utilised talent recruitment workforce component talent upskill mil promotional activity mil listing expense independent market researcher protege associate bhd devadass local gb industry reach bil compound annual growth rate bil house digital tool devadass positioned leverage growth house digital tool house digital tool faith saige hand hand faith platform employee engagement providing tool payroll communication performance feedback daythree workforce daisy hand customer relationship management robotics process automation game changer raymond describes typical scenario contact centre agent additional time call create contact engineer task multiple system streamline process daythree daisy sits top system call agent basic bot task relevant department bot farm bot automate portion task agent time saving productivity automation agent handle interaction time period bot assist routine mundane task human resource complex critical raymond saige serf business intelligence tool gather real time data customer interaction capture analytics platform analysis interpretation recommendation improvement data hungry technology client daythree generative pre transformer generative efficiency raymond challenge service provider omni channel involves consolidated view customer multiple channel store visit social medium interaction platform technology seamless customer experience customer view aim provide assistance raymond daythree regional brand customer base local malaysian company secured project company hospitality banking security management sector shift global regional brand dependence local client time,"[(4, 0.99810374)]",4
560398,StarBiz,7,23/06/2023,More companies in the country using AI in  their operations,,"KUALA LUMPUR: More companies in Malaysia are exploring and integrating generative artificial intelligence (AI) into their business operations, says IBM Malaysia.
 According to a study by IBM’s Institute for Business Value, over 40% of ICT professionals reported that their organisations are actively exploring the use of generative AI to drive business growth.
 Surprisingly, nearly a third of the surveyed companies have already integrated generative AI.
 This is setting new benchmarks in innovation and success, said IBM Malaysia managing director and technology leader Catherine Lian. 
 She said in a statement yesterday that the government should be commended for positioning Malaysia as a regional leader in the field of AI.
 “The government’s focus on AI as a key driver for economic recovery, innovation, and bridging the digital divide is commendable,” Lian said.
 “The Malaysia Artificial Intelligence Roadmap 2021-2025 and the Malaysian Digital Economy Blueprint exemplify the government’s vision for integrating AI across sectors.
 “It is fostering productivity enhancement, attracting international investments, and narrowing the gap with advanced nations,” she added.
 Lian said IBM believes that AI holds great promise for Malaysia’s economic growth with the National Industrial Revolution 4.0 policy’s target of a 30% output increase by 2030 underscoring AI’s crucial role.
 On IBM’s part, she said it remains committed to supporting Malaysia’s AI initiatives and contributing to the development of a vibrant and successful AI ecosystem in the country while building a prosperous and inclusive digital future for Malaysia.
 The heart of successful AI adoption is data, the company said. 
 “But it isn’t enough to simply collect and store large volumes of data, businesses need to seamlessly and securely access, govern and use this data to drive digital transformation.”
 While some organisations have tried to manage this complexity by migrating their data to a central repository, Lian said “the reality is that the copy-and-paste model of data management is an inefficient and costly process.”
 To address these challenges, IBM has introduced a new approach called a “data fabric” strategy.
 The strategy is a unified approach to data management that seamlessly integrates diverse data sources and formats.
 It breaks down data silos, enabling organisations to access and analyse data from various locations in real time. — Bernama",kuala lumpur company generative artificial intelligence business operation malaysia study ibm institute business ict professional organisation generative drive business growth company generative benchmark innovation success ibm malaysia director technology leader catherine lian statement yesterday government malaysia regional leader field government focus key driver economic recovery innovation digital divide commendable lian malaysia artificial intelligence roadmap malaysian digital economy blueprint exemplify government vision sector productivity enhancement international investment gap nation lian ibm promise malaysia economic growth national industrial revolution policy target output increase crucial role ibm committed malaysia initiative development vibrant successful ecosystem country prosperous inclusive digital future malaysia heart successful adoption data company collect store volume business access govern data drive digital transformation organisation complexity data central repository lian reality copy paste model data management inefficient costly process address approach data fabric strategy strategy approach data management diverse data source break data silo organisation access data location real time bernama,"[(4, 0.99429286)]",4
559276,StarBiz,13,20/06/2023,Could AI  be the  comeback break for workers?,,"SINGAPORE: Could the era of generative artificial intelligence (AI) mark the glorious return of older, experienced workers who had lost their edge in the digital age?
 With generative AI tools like GitHub Copilot and Adobe Firefly making tasks such as coding and video editing as easy as typing in an “ask”, experts foresee a rise in the competitiveness of workers who have served corporate time.
 Vis-a-vis their younger, digital-savvy counterparts, the playing field is levelling “to some extent”, said Associate Professor Damien Joseph, the associate dean at Nanyang Business School.
 With the right requests, or prompts, dominating outcomes of what computers serve up, experience matters, Prof Joseph said.
 And experience comes with the package of domain expertise to guide AI tools better, contextual knowledge to identify biases, errors and gaps, and judgement to consider the broader implications of decisions.
 Age alone does not confer the upper hand, cautioned Associate Professor Terence Ho from the Lee Kuan Yew School of Public Policy.
 He said: “The mature workers who stand to benefit most are those who have already acquired experience in their area of work.
 “They can leverage their experience and insights to parse the input of AI, as well as tap AI to do their job better or more efficiently, rather than mature workers who are coming in cold to a new job or vocation.”
 Since the launch of ChatGPT last November, AI tools have been rapidly adopted by industries ranging from banking and healthcare to real estate and home repair.
 Technology firm Salesforce’s Digital Skills report released in March showed 72% of local workers saying that they are excited about using generative AI in their job, compared with 43% who worried about AI replacing them. — The Straits Times/ANN",era generative artificial intelligence mark glorious return worker edge digital age generative tool copilot adobe firefly task video easy expert competitiveness worker corporate time digital savvy counterpart field extent associate professor damien joseph associate dean nanyang business school request outcome computer experience matter joseph experience package domain expertise guide tool contextual knowledge identify error judgement broader implication decision age upper hand associate professor terence lee kuan yew school public policy mature worker acquired experience leverage experience insight parse input tap job mature worker cold job vocation launch chatgpt november tool industry banking healthcare real estate repair technology firm salesforce digital skill report march local worker generative job worried strait time,"[(0, 0.99200565)]",0
559356,StarBiz,16,20/06/2023,Top stock  picker scouts  AI fringes  to beat off peers,,"SYDNEY: When it comes to trading the artificial intelligence (AI) frenzy, one top-performing global equity fund is winning big by scouting out some out-of-the-box ideas.
 Fairlight Asset Management’s Nick Cregan invests in companies he believes will be enhanced by AI or well protected from its implications.
 It’s a conviction that’s helped propel his Fairlight Global Small and Mid Cap fund up 24% over the past year, beating 97% of peers, according to data compiled by Bloomberg.
 “We’re not trying to pick the winner in AI, we think that’s a mug’s game,” Cregan said in an interview. 
 “You’re going to have some leading companies, which you think are going to be the winners, and then all of a sudden there’s going to be some interesting technology that emerges that completely displaces that business.”
 The fervour around AI has grown since ChatGPT’s release last year and has snowballed as companies race to churn out rival tools and products to power them. 
 Many investors see the technology as on the cusp of revolutionising the way some companies and sectors operate.
 The Nasdaq Composite Index has climbed 31% in 2023, and tech stocks have helped pull the broader S&P 500 Index up 15%.
 German online marketplace Scout24 SE, up 26% year to date, is among the Sydney-based fund’s top holdings. 
 AI should help the company drill into pricing and analyse market trends, but it is unlikely to replace the site’s uploaded inventory and customer base, Cregan said.
 The company is already the market leader in the space, and AI will only optimise the efficiency of its site and pricing, he believes. — Bloomberg",sydney trading artificial intelligence frenzy top performing global equity fund box idea asset management nick cregan company enhanced protected implication conviction fairlight global mid cap fund beating peer data bloomberg pick winner game cregan interview company winner sudden technology displaces business chatgpt release company race rival tool product power investor technology company sector nasdaq composite tech stock broader german online marketplace scout sydney fund top holding company analyse market trend site uploaded inventory customer base cregan company market leader space optimise efficiency site pricing bloomberg,"[(4, 0.9899346)]",4
558896,Lifestyle,6,19/06/2023,AI in sports: promise or peril?,"When it comes to artificial intelligence, does the sporting  world stand to gain or lose?","WILL sports coaches, managers and scouts soon be redundant? Will the dream team line-up, best substitutions and hottest transfers be just a key-push away with the proliferation of artificial intelligence (AI)?
 The sports industry is reluctant to reveal the full extent of its success in implementing this technology. 
 But AI experts say people shouldn’t fear the advent of a soulless, computer- shaped sporting reality.
 “I’m sure it won’t come to that – and as a football fan, I hope not too,” says Tim Schroder, a product developer for online platform Plaier looking to revolutionise player scouting with AI.
 “People need other people as reference partners,” Schroder said. 
 “Technology is just an aid.” And used as such, AI could improve the quality of sports, he believes.
 But the developer is a realist too: “The future cannot be stopped and that future will also be increasingly determined by AI in sports.”
 Naturally, the early adopters of such technology will have a head start, says Schroder, without seeing an immediate threat of this eroding the essence of sporting competition.
 The Institute for Applied Training Science (IAT) in the eastern German city of Leipzig, where AI is now mainly used in biomechanics, takes a similar view.
 “AI is not a risk in our field, but an opportunity to generate more data in less time,” says Bjorn Maurer, a scientific expert in sports informatics.
 At IAT, the movements of a skier or discus thrower are filmed and evaluated with software and the athlete is tagged with AI-supported recording systems. Internationally, Germany is “well placed” in this respect, says Maurer, “but China is probably further ahead”.
 Given the overall secrecy of high-tech development, the question of what AI can already do in sports is not easy to answer.
 “Artificial intelligence can help structure data, show conspicuous features and reduce the amount of data in such a way that people can deal with it better,” says sports scientist Carlo Dindorf from Germany’s Technical University of Kaiserslautern-Landau.
 In lesser forms, though, AI has long been part of everyday sports life, as many people already use “fitness trackers” that provide information on stress and fatigue reactions, for example.
 At the German cycling team Bora-Hansgrohe, six people are working on the daily processing of vast amounts of data on wattage, pulse and much more. In Formula 1, data analysis has been influencing race strategy for many years, and the use of AI via software companies is also intensifying here.
 In professional football, Plaier wants to take player scouting to a new level by means of specially developed AI using real-time analysis of the playing system and squad. 
 The results are linked to data on over 100,000 players who are recorded in the system and weighted according to their abilities in relation to the club looking for them.
 In this systematic approach, the AI learns from historical data and forecasts. Plaier’s co-founder Jan Wendt offers customers the prospect of a 90% hit probability for transfers: “We don’t say, ‘That could happen’, but we say, ‘This is happening and will look like this in the next six years’.”
 The German Ski Association (DSV) is still in the early stages of using AI, but initial tests, for example in the selection of waxes, have been “very promising”, according to Karlheinz Waibel, DSV national coach for science and technology.
 At the 2022 Olympics in Beijing, it was possible to find out more quickly with AI programs than with conventional ski tests which texture of ski was best suited to the cross-country track, Waibel told the Rheinische Post newspaper.
 “The added value is great. But you have to want to afford it,” Waibel said of the accompanying need for major investment in the technology.
 Meanwhile, coaches will remain essential to sports, he expects: “The coach is still very important. After all, data does not explain everything. Knowledge, experience, and, last but not least, soft skills are just as important as AI to advance the athlete.”
 Maurer from the IAT also warns of “increased risk” if decisions are handed over to AI in its current state. If, for example, the technical evaluation in sports such as apparatus gymnastics were completely left to the computer, “it could definitely be manipulated via the software – and not in a sporting way, but technologically”.
 In sports, the data sets are still relatively small, but that will change with the increasing use of AI. 
 It is data-hungry – and the more it is fed, the greater the output.
 Austria’s national football coach, Ralf Rangnick, who prides himself on thinking outside the box, predicts “unimagined possibilities” when it comes to AI in sport: “The more AI develops, the more data volume, the more information there is, the more you can get out of it,” he says. – dpa",sport coach manager redundant dream team substitution transfer key push proliferation artificial intelligence sport industry reluctant reveal extent success technology expert people advent soulless computer reality football fan tim schroder product developer online platform plaier revolutionise player people people partner technology aid quality sport developer realist future future sport adopter technology start schroder threat essence competition institute science iat eastern german city leipzig biomechanics view risk field opportunity data time bjorn maurer scientific expert sport informatics iat movement skier discus thrower evaluated software athlete system germany respect maurer china secrecy tech development question sport easy artificial intelligence structure data conspicuous feature amount data people sport scientist carlo germany technical university kaiserslautern landau lesser form everyday sport life people fitness tracker stress fatigue reaction german team bora hansgrohe people daily vast amount data wattage pulse formula data analysis race strategy software company professional football plaier player level real time analysis system squad data player system weighted ability relation club systematic approach historical data forecast founder jan wendt customer probability transfer german ski association dsv stage initial test selection wax karlheinz waibel national coach science technology olympics program conventional ski test cross country track waibel rheinische post newspaper afford waibel major investment technology coach essential sport coach data knowledge experience soft skill advance athlete maurer iat warns risk decision current technical evaluation sport gymnastics computer software sport data set data hungry output austria national football coach ralf rangnick pride box predicts unimagined possibility sport data volume dpa,"[(4, 0.9964747)]",4
559160,Main,20,19/06/2023,Asean to set ‘guardrails’ on AI,Regulators drafting rules to govern use of generative artificial intelligence,"South-East Asian countries are drawing up governance and ethics guidelines for artificial intelligence (AI) that will impose “guardrails” on the booming technology, five officials with direct knowledge of the matter said.
 Regulators across the world are rushing to draft regulations to govern the use of generative AI, which can create text and images and is engendering excitement as well as fear about its potential to reshape a wide range of industries.
 Ministers from the 10-member Association of South-East Asian Nations (Asean) agreed in February on the need to develop an Asean “AI guide” for the region of 668 million people,  but details of the discussions among regional policymakers have not previously been reported.
 Senior South-East Asian officials said the so-called Asean Guide on AI Governance and Ethics was taking shape and would try to balance the economic benefits of the technology with its many risks.
 “The drafting is ongoing and it could be completed towards the end of the year before it is endorsed by Asean members,” one official said.
 Another official said it could be announced at the Asean Digital Ministers’ Meeting early next year.
 A spokesman for Singapore’s Ministry for Communications and Information said that as 2024 chair of that meeting, the country would be collaborating with other Asean states “to develop an ‘Asean Guide on AI Governance and Ethics’ that will serve as a practical and implementable step to support the trusted deployment of responsible and innovative AI technologies in Asean”.
 Besides Singapore, the other Asean countries are Brunei, Cambodia, Indonesia, Laos, Malaysia, Myanmar, the Philippines, Thailand and Vietnam. Some of these governments were not immediately reachable for comment.
 The sources declined to comment further on what the AI guide would look like, given the early stage of the discussions and confidentiality of the Asean process.
 The sources, who included officials in three South-East Asian countries, declined to  be identified as they were  not authorised to speak to the media.
 Moves by Asean to set guidelines around AI come as the European Union and United States are expected to release a draft of a voluntary AI code of conduct within weeks. 
 The code would take effect ahead of the EU’s trailblazing AI Act, which is still being thrashed out.
 Like their counterparts in Europe and the US, regional policymakers have expressed particular concern about AI’s potential to industrialise misinformation.
 Singapore’s Infocomm Media Development Authority warned in a research paper in June about the risk of “hallucinations”, when generative AI produces specious content with convincing certainty.
 The city-state has been at  the forefront of AI strategy  in the region and is leading the talks to draw up the AI guide, according to three sources. — Reuters",south east asian country governance ethic guideline artificial intelligence guardrail technology official knowledge matter regulator draft regulation generative create text image excitement fear potential reshape wide range industry minister east asian nation february develop asean guide region people detail discussion regional policymakers senior south east asian official asean guide governance ethic economic benefit technology risk endorsed asean official official asean digital minister spokesman ministry communication country asean develop asean guide governance ethic practical implementable step support deployment responsible innovative technology asean country cambodia indonesia lao malaysia myanmar philippine vietnam government reachable comment source comment guide stage discussion asean process source official east asian country authorised speak medium move guideline european union expected release draft voluntary code conduct week counterpart regional policymakers concern potential industrialise misinformation singapore infocomm medium development authority paper june risk hallucination specious content certainty city forefront strategy region talk draw guide source reuters,"[(3, 0.99442625)]",3
558582,StarEdu,8,18/06/2023,"Embrace XR,  AI in  learning",Stakeholders must come together to integrate immersive tech into education,"ALTHOUGH education is a powerful tool for shaping the future, conventional education methods are no longer adequate to meet the changing needs of students and society.
 Extended reality (XR), the metaverse and artificial intelligence (AI) hold the key to unlocking new frontiers of education, ensuring learners are equipped with the skills and knowledge needed to thrive in a dynamic world.
 Imagine wearing augmented reality glasses to assess building information systems at a construction site, putting on a virtual reality headset to study history in a simulated world of the Melaka Sultanate, learning about bones and muscles without cutting up cadavers, or exploring protein molecules without using a microscope – these are not mere concepts anymore. 
 Instead, they are actual XR adoptions that educational institutions are already implementing in their syllabi to transform various aspects of our lives.
 These experiences push the thought processes and the possibilities of what learners can achieve in this day and age. 
 As we are at the precipice of a new era, younger generations of today will think of newer ways to create content, market their products, and even share their experiences with the help of immersive technologies and AI. 
 They can apply what they have learned, and align it with their interests and needs to see how technology can help their issues and challenges.
 As educators, it is crucial to ask ourselves: Are our students equipped to thrive in a rapidly evolving future that is shaped by emerging technologies such as XR, the metaverse and AI? 
 And equally important, is Malaysia positioned to be a nation that embraces innovation and pioneers new frontiers of knowledge in this digital age?Though the answer is yes, adopting these new emerging technologies comes with its own set of challenges and limitations. 
 Collaborative efforts among educational institutions, technology providers and policymakers are seen to be vital. Such collaboration can lead to the development of funding initiatives, streamlined processes and support structures that facilitate the seamless integration of XR into education. 
 By embracing XR, we empower students to be at the forefront of shaping industry through their adaptability, creativity and eagerness to embrace innovation.
 Over time, XR and the metaverse will redefine how we live, work and socialise. Existing jobs such as digital marketing and film production are evolving to include XR in their workforce development. 
 Newer job positions such as immersive designers and AI engineers are also coming up, boosting business and employment opportunities for digital talents.
 Nevertheless, it is crucial to address the valid concerns and scepticism surrounding emerging technologies. 
 While fear of job displacement and livelihood disruption persists, it is important to recognise that these technologies are not intended to replace but rather to empower us.
 The onus now is on our society to shift its mindset and begin embracing XR, the metaverse and AI in education. 
 Educational institutions can act as the intermediary between industry and the schools as they can provide learners with a platform for experimentation in research and development.
 This would then establish Malaysia as a nation that pioneers new frontiers of knowledge, embracing innovation in this digital age. 
 We no longer would be losing industry expertise to our neighbouring countries, as with the talent and expertise that we have, we would be the central hub of digital innovation for graduates to look inward instead of outward, fostering a better future for us all.
 With more than 15 years of experience in the XR industry, Faisal Athar Mohd Fadzil is an XR specialist at Taylor’s University’s Vortex XR Lab. As an immersive technology enthusiast, Faisal Athar manages projects and advocates the benefits of XR in the dynamic landscape of emerging technologies. The views expressed here are the writer’s own.",education powerful tool future conventional education method adequate meet student society reality artificial intelligence key unlocking frontier learner skill thrive dynamic imagine wearing reality ass system construction site virtual reality headset study history melaka sultanate bone muscle cadaver protein molecule mere concept actual adoption educational institution syllabus transform experience push possibility learner day age precipice era generation content market product share immersive technology align technology issue educator crucial student thrive future technology metaverse malaysia nation innovation pioneer frontier digital age answer technology challenge limitation effort educational institution technology provider policymakers vital collaboration lead development initiative process support structure seamless integration education empower student forefront industry adaptability creativity eagerness embrace innovation time metaverse redefine live socialise job digital marketing film production workforce development job position immersive designer engineer business employment opportunity digital talent crucial address valid concern scepticism technology job displacement livelihood disruption recognise technology empower onus society shift metaverse education educational institution intermediary industry school learner experimentation development malaysia nation pioneer frontier innovation digital age industry expertise country talent expertise central hub digital innovation future experience industry faisal mohd fadzil specialist taylor university vortex lab immersive technology enthusiast faisal athar project benefit dynamic landscape technology view writer,"[(0, 0.9955926)]",0
558678,Main,36,18/06/2023,"New Grammy Awards rules require human input, curb AI use",,"LOS ANGELES: “Only human creators are eligible” for the Grammy Awards, the Recording Academy declared, as the body that grants the world’s most recognised music awards seeks to curb the use of artificial intelligence (AI) in the industry.
 AI-only work is banned, but some music created with AI help may qualify in certain categories, the academy’s updated rulebook reads. “A work that contains no human authorship is not eligible in any categories.”
 Music creators must now contribute to at least 20% of an album to earn a nomination. In the past, any producer, songwriter, engineer or featured artist on an album could earn a nomination for album of the year, even if the person had a small input.
 The first Grammy Awards ceremony took place in 1959, to reward music creators from 1958.
 In November 2022, OpenAI launched ChatGPT, a free chatbot backed by Microsoft Corp that can generate human-like dialogue based on simple inputs. 
 AI apps have mushroomed, allowing users to animate still photos, create avatars in films and write songs, essays and articles.
 People in many professions are growing fearful that AI could displace humans. For example, the Writers Guild of America (WGA) and the Screen Actors Guild (SAG-AFTRA) are wrestling with the use of AI in the creative fields of screenwriting and acting.
 The WGA wants to curb the use of AI in screenwriting while SAG actors want to ensure its members can control use of their digital personas and receive proper compensation. — Reuters",los angeles human creator eligible grammy award academy body grant music award curb artificial intelligence industry music qualify category updated rulebook human authorship eligible category music creator album earn nomination producer songwriter engineer artist album nomination album person input grammy award reward music creator chatgpt free chatbot microsoft corp generate human dialogue simple input apps user photo avatar film song essay article people profession fearful displace human writer america wga screen actor sag aftra wrestling creative field wga curb sag actor control digital persona proper compensation reuters,"[(0, 0.99020773)]",0
558522,StarBiz 7,10,17/06/2023,Let the British government write AI rules,,"IT’S hard not to cringe at UK Prime Minister Rishi Sunak’s pronouncement that Britain should “lead the way” on artificial intelligence (AI) regulation. After all, AI will impact the globe in different ways, and Brexit hasn’t exactly inspired confidence in British policymaking.
 Yet Brexit is partly why the UK could fill this watchdog role successfully. AI is moving fast, threatening to create more bias and inequality in society, and governments need ideas for guidelines yesterday. 
 Britain not only has the expertise and infrastructure to draw up rules around AI, it can move quickly, thanks in part by having thrown off the shackles of European Union (EU) frameworks and obligations. 
 By contrast, it’ll be another two years before the EU’s AI Act comes into force, even though its Parliament voted almost unanimously in favour of it Wednesday. 
 And while US senators are keen to set up an independent AI regulator, aggressive Silicon Valley lobbying makes that unlikely. Congress, after all, has never passed a federal law to regulate Big Tech.
 Britain offers a temperate middle ground between the onerous approache of Europe and the more laissez-faire US, where most AI innovation is coming from. The UK has moved fast on tech governance before – its data protection rules for children were among the first in the world and copied by California; its Online Safety law will roll out before a similar set of rules from the EU; and its antitrust watchdog pursued a flurry of high-profile cases against Alphabet Inc’s Google, Apple Inc and Meta Platforms Inc after Brexit. 
 The Brits have meanwhile been upgrading their government machinery, allowing them to tackle AI more effectively. 
 For instance, the UK recently fused its top regulators into a single body for coordinating decisions, which will be vital for a technology that impacts almost every industry. 
 In addition to a formidable commercial law sector and a centuries-long reputation for the rule of law, the UK also hosts one of the world’s biggest AI companies, Google DeepMind, and a culture where technologists liaise with the government as advisers. It doesn’t hurt that everyone speaks English too. 
 “There’s only one positive to Brexit and it’s that the UK is now in a position to be a global leader in AI governance,” says Saul Klein, co-founder of London venture capital firm LocalGlobe. 
 In February 2023, the UK combined its government departments covering business and digital sectors into one, called the Department for Science, Innovation and Technology. 
 In the eyes of the government, that elevated tech to a similar level of importance as the economy and national security, says Klein, who is a non-executive director of the new department. 
 The UK also brought together its top regulators that handle issues like antitrust, data privacy and online harms under one umbrella, called the Digital Regulatory Cooperation Forum. That will make it much easier to set and enforce rules on AI with one voice. 
 Why spend years building a new regulator when existing watchdogs have set themselves up to address the technology’s disruptions together, says Rachel Coldicutt, who specialises in tech regulation and is an executive director of Promising Trouble, a social enterprise that builds and supports alternatives to Big Tech.
 How might Britain try to regulate AI? Its upcoming rules on online harm borrow principles from health and safety law, giving companies a legal “duty of care” to maintain a safe environment.Britain will probably go down a similar route with AI, according to regulatory experts, adopting a risk-based approach to regulation.Demis Hassabis, the co-founder of DeepMind and a government adviser, has similar views: He recently advocated for the “precautionary principle” when regulating AI. 
 Taking precautions
 That essentially means taking precautions when you are uncertain of the risks – like telling a child not to play soccer inside the house to avoid breaking anything. The alternative would be to let them play, and then only when they break a lamp, create new rules about soccer in the house. There is one glaring problem with the UK’s efforts to oversee AI, though, and it speaks to the country’s chummy and insular tendencies. 
 Sunak recently announced a global AI safety summit taking place this fall to kick off the country’s regulatory ambitions, and neglected to include people who work in civil society.
 The summit will bring together nations, researchers and “leading tech companies” such as Google DeepMind and Microsoft Corp, according to the 1,400 word press release announcing the event. Yet nowhere alongside the big names did it mention people researching flaws in present-day AI systems. 
 A UK government spokesman said that the summit was aimed at creating “international guardrails for the safe and responsible development of AI.”
 Serious and widespread
 Current AI problems are serious and widespread. They affect women, people of color and other minority groups more often than not, from algorithms that check asylum-seeker applications to those that filter job ads. British organisations like the Ada Lovelace Institute, Demos, Connected by Data and Promising Trouble, which investigate such flaws, should be invited to discuss AI safety with big corporate names too. — Bloomberg
 Parmy Olson is a Bloomberg Opinion columnist. The views expressed here are the writer’s own.",hard cringe prime minister rishi sunak pronouncement britain lead artificial intelligence regulation impact globe brexit confidence british policymaking brexit fill watchdog role create bias inequality society government guideline yesterday expertise infrastructure draw rule thrown shackle european union framework obligation force parliament favour wednesday senator keen independent regulator aggressive silicon valley congress federal law regulate tech britain offer middle ground onerous europe laissez faire innovation tech governance data protection rule child california online safety law roll rule antitrust watchdog flurry profile alphabet google apple meta platform brit upgrading government machinery tackle instance top regulator single body decision vital technology impact industry addition formidable commercial law sector century rule law host biggest company deepmind culture technologist government adviser speaks english positive brexit position global leader governance saul klein founder london venture capital firm february combined government department business digital sector department science innovation technology eye government tech level economy national security klein executive director department top regulator issue antitrust data privacy online harm umbrella digital regulatory cooperation forum easier enforce rule voice building regulator watchdog address technology disruption coldicutt specialises tech regulation executive director trouble social enterprise build alternative tech britain regulate rule harm borrow health safety law company legal duty care maintain safe environment britain route regulatory expert risk approach regulation hassabis founder deepmind government adviser view precautionary principle precaution precaution risk child play soccer house alternative play break lamp create rule house effort speaks country insular tendency global safety summit kick country regulatory ambition people civil society summit nation researcher tech company microsoft corp word press release event mention people flaw day system government spokesman summit international guardrail safe responsible development widespread current widespread affect woman people minority algorithm check asylum seeker application job ad british organisation lovelace institute demo data trouble investigate flaw safety corporate name parmy olson bloomberg opinion columnist view writer,"[(4, 0.9972056)]",4
557692,StarBiz,9,15/06/2023,AMD’s AI chip challenge to Nvidia remains uphill task,,"SAN FRANCISCO: Advanced Micro Devices Inc (AMD) on Tuesday gave new details about an artificial intelligence (AI) chip that will challenge market leader Nvidia Corp, but the company left out what Wall Street wanted to know – who plans to buy it.
 Santa Clara, California-based AMD said the forthcoming chip, which will start trickling out in the third quarter followed by mass production beginning in the fourth quarter, will have 192 gigabytes of memory.
 That could help tech companies get a handle on the spiralling cost of delivering services similar to ChatGPT, AMD chief executive Lisa Su told Reuters in an interview. 
 She spoke following a keynote presentation in San Francisco during which Su showed an AI system on the MI300X chip writing a poem about the city.
 “The more memory that you have, the larger the set of models” the chip can handle, Su said. “We’ve seen in customer workloads that it runs much faster. We really do think it’s differentiating.”
 But unlike past presentations where AMD has talked up a major customer for a new chip, AMD did not say who will adopt the MI300X or a smaller version called the MI300A. The company gave no details on how much the chip will cost or how it will bolster its sales.
 AMD’s shares have doubled in price since the start of the year and touched a 16-month high earlier on Tuesday, but closed down 3.6% after the presentation on the AI strategy. 
 Nvidia shares finished 3.9% higher at US$410.22 (RM1,895.42), making it the first chipmaker to close with a market capitalisation above US$1 trillion (RM4.6 trillion).
 “I think the lack of a (large customer) saying they will use the MI300 A or X may have disappointed the Street. They want AMD to say they have replaced Nvidia in some design,” said Kevin Krewell, principal analyst at TIRIAS Research.
 Nvidia, whose shares have surged 170% so far this year, dominates the AI computing market with a market share of 80% to 95%, according to analysts.
 Nvidia has few competitors working at a large scale. 
 While Intel Corp and several startups such as Cerebras Systems and SambaNova Systems have competing products, Nvidia’s biggest sales threat so far is the internal chip efforts at Alphabet Inc’s Google and Amazon.com’s cloud unit, both of which rent their custom chips to outside developers. — Reuters",san francisco micro device tuesday detail artificial intelligence chip challenge market leader nvidia corp company wall street plan santa clara california chip start quarter mass production fourth quarter gigabyte tech company cost delivering service amd chief executive lisa reuters interview keynote presentation san francisco system chip poem city memory larger set model chip handle customer workload presentation major customer chip amd adopt version company detail chip cost bolster sale share price start month tuesday presentation strategy nvidia share chipmaker close market capitalisation lack customer disappointed street amd nvidia design kevin krewell principal analyst tirias nvidia share dominates market market share analyst competitor scale intel corp startup cerebras system sambanova system product nvidia biggest sale threat internal chip effort amazon cloud unit rent custom chip developer reuters,"[(2, 0.5257713), (4, 0.4691717)]",2
556848,StarBiz,8,14/06/2023,AI hype starting to  ‘smell like dot-com era’,Current mood reminiscent of tech bubble days,"LONDON: The exuberance surrounding artificial intelligence (AI) has driven a lot of capital into a small corner of the market in a very short space of time, and that has implications for tech-heavy environmental, social and governance (ESG) funds.
 According to James Penny, the chief investment officer of TAM Asset Management and a veteran ESG investor, the current mood is reminiscent of the early days of the tech bubble that burst in 2000 and wiped more than 70% off the Nasdaq. 
 “Companies that even mention the word AI in their earnings are seeing boosts to their share price, and that smells very much like the dot-com era,” Penny, who invests in funds rather than directly in stocks, said in an interview. 
 “I think the market has got a little bit over its skis. I’d put much larger odds on it coming down from here.”
 The race to get a piece of the AI boom went into turbo mode last month, after Nvidia Corp wowed the market with a set of sales targets that surprised even the most upbeat analyst forecasts. 
 The company has added almost 30% to its market value since the announcement in late May, bringing gains this year to more than 160% and helping the Nasdaq add a third to its value.
 It’s a development that’s helped boost funds with ESG mandates, as ESG portfolios rely increasingly on tech to lower their carbon footprint without sacrificing growth. 
 An analysis by Bloomberg Intelligence shows that tech makes up a third of preferred stocks in so-called Article 9 funds, the highest ESG classification in the European Union. 
 That’s by far the biggest chunk of all sectors.
 About 1,300 ESG-registered funds hold more than US$20bil (RM92.4bil) in Nvidia alone, according to data compiled by Bloomberg. 
 At the same time, there’s a subset of ESG fund managers that market themselves as AI-themed, with Bloomberg identifying 20 as of early June that together hold about US$8bil (RM37bil) in assets under management. 
 While Nvidia supplies the chips for AI processing, the technology itself is being developed by a number of tech giants including Microsoft Corp, Amazon.com Inc and Google parent Alphabet Inc. 
 The market for generative AI products, which refers to tools like ChatGPT that can create content such as text or images from a prompt, has the potential to grow more than 40% a year and reach US$1.3 trillion (RM6 trillion) in the coming decade, according to Bloomberg Intelligence senior analyst Mandeep Singh. 
 Penny, who’s got roughly a decade of experience selecting assets based on their ability to outperform in a world increasingly shaped by environmental and social risks, said eagerness to be exposed to AI is in part feeding off premature bets that the Federal Reserve will start reversing its cycle of interest-rate increases. 
 With the United States grappling with a regional banking crisis, “the market very quickly accelerated into this scenario where rate cuts are going to be coming quite soon because this is obviously evidence of the economy cracking,” Penny said. 
 That “spurred more and more inflow into growth investing.” 
 Against that backdrop, “you had this AI trend, which just literally came out of nowhere,” and now “the market’s gone off to the races, like massively in,” he said.
 But the buying spree has been fed by “just a few sectors,” in fact, just a handful of stocks, Penny said. At the same time, there’s still the very real risk of a recession, he said. 
 So instead of piling into the same AI names that others are buying up, Penny says he’s following the playbook of the gold rush of the 1800s, when the smart money didn’t waste time looking for gold, but invested in the tools needed to dig it up.
 “I think you’re going to see a massive wave of AI-led products in the market and we will be looking at that, but you have to be very selective,” Penny said. 
 “I would be focusing less on AI manufacturers and more on AI adopters, so that ‘pick-and-shovel”’ kind of strategy. 
 “That’s “always where you find phenomenal companies that are in support of the theme and the movement,” he said.
 Memory chips, which are crucial to the kinds of deep-learning applications needed to support generative AI, are one such area, according to an analysis by Bloomberg Intelligence that singled out Samsung Electronics Co, SK Hynix Inc and Micron Technology Inc.  
 Bloomberg Intelligence also pointed to semiconductor testing devices from US-based Teradyne Inc and Advantest Corp of Japan as stocks that are likely to benefit from the furore surrounding AI.
 And given the current environment, the goal isn’t to be overly exposed to sectors that rely heavily on low interest rates and a strong economy, Penny said.
 “What generates a recession rips apart the status quo,” he said. “So one has to be wary of that high growth narrative.” — Bloomberg",london exuberance artificial intelligence lot capital corner market short space time implication heavy environmental social governance esg fund penny chief investment officer asset management veteran investor current mood reminiscent day bubble burst nasdaq company word earnings boost share price smell era penny fund stock interview market bit ski larger odds race piece boom turbo mode month corp market set sale target upbeat analyst forecast company market announcement bringing gain development fund esg mandate portfolio tech lower carbon footprint growth analysis bloomberg intelligence tech preferred stock article fund esg classification european union biggest chunk sector fund bil bil data bloomberg time fund manager market bloomberg june bil asset management nvidia supply chip technology tech giant microsoft corp amazon google parent alphabet market generative product refers tool create content text image potential grow reach decade bloomberg intelligence senior analyst mandeep singh penny decade experience asset ability outperform environmental social risk eagerness feeding premature federal reserve cycle rate increase regional banking crisis market scenario rate cut evidence economy penny inflow growth backdrop trend market race spree sector handful stock penny time real risk recession name penny playbook gold rush smart money waste time gold tool dig massive wave product market selective penny manufacturer adopter shovel strategy phenomenal company theme movement memory chip crucial kind deep learning application generative analysis bloomberg intelligence samsung electronics hynix micron technology bloomberg intelligence semiconductor device advantest corp japan stock furore current environment goal sector low rate strong economy penny recession rip status wary growth narrative bloomberg,"[(1, 0.9158183), (4, 0.08152094)]",1
556862,StarBiz,12,14/06/2023,Oracle climbs to record high as AI-frenzy spurs Cloud demand,,"NEW YORK: Oracle Corp gave investors a boost by saying the company’s cloud-computing business will continue to grow rapidly in the coming financial year after a strong performance in the past quarter. 
 Shares, which had jumped to a record high at the close, rose another 3% in extended trading.
 Cloud sales gained 54% in the financial fourth quarter to US$4.4bil (RM20.3bil) after a 45% jump in the previous period. 
 In the financial year ending May 2024, cloud revenue should increase at least as much as in the year that just ended, chief executive officer Safra Catz said on a conference call after the results. 
 John DiFucci, an analyst at Guggenheim Securities, said the continued strength in the unit is abnormal given the current economic environment.
 Oracle has focused on expanding its cloud infrastructure business to more forcefully compete with market leaders Amazon.com Inc and Microsoft Corp, which have seen recent slowdowns. 
 A boom in generative artificial intelligence (AI), which needs tremendous computing power, is boosting demand for Oracle’s cloud services, executives said. 
 Generative AI startup Cohere said last week that Oracle was among its investors in a US$270mil (RM1.2bil) funding round.
 “We see shares maintaining their recent positive momentum as the narrative of growing cloud momentum, partly fuelled by AI demand, remains intact,” said Raimo Lenschow, a Barclays analyst.
 Cloud infrastructure revenue increased 76% to US$1.4bil (RM6.5bil) in the period ended May 31, Oracle said on Monday. 
 Cloud application sales jumped 45% to US$3bil (RM13.8bil), the Austin, Texas-based company said. 
 Over US$2bil (RM9.2bil) in cloud capacity has recently been contracted by companies doing large language model development such as Mosaic ML, Adept AI and Cohere, Oracle chairman Larry Ellison said in the statement. 
 “Oracle’s Gen2 Cloud has quickly become the No. 1 choice for running generative AI workloads,” he said.
 Total sales increased 17% to US$13.8bil (RM64bil) in the quarter. Analysts, on average, estimated US$13.7bil (RM63.2bil), according to data compiled by Bloomberg. 
 Profit, excluding some items, was US$1.67 (RM7.72) a share, compared with the average estimate of US$1.58 (RM7.30).
 “Both of our two strategic cloud businesses are getting bigger, and growing faster,” Catz said in the statement. “That bodes well for another strong year in the financial year 2024.”
 Shares hit a high of US$122.87 (RM568) in extended trading after closing at a record US$116.43 (RM538) in New York. Oracle has rallied 42% this year, compared with the 32% rise in the iShares expanded software exchange-traded fund.
 Oracle’s other big bet, the acquisition a year ago of digital health records provider Cerner Inc, now called Oracle Health, generated US$1.5bil (RM6.9bil) in the quarter. Oracle began cutting jobs in the division earlier this year after executives promised to improve profitability.
 In the current period ending in August, cloud growth excluding Oracle Health will be about 29%, Catz said. 
 Total revenue is expected to increase by 8% to 10%, she said. Analysts, on average, projected an 8% gain. 
 Profit, excluding some items, will be US$1.12 (RM5.17) to US$1.16 (RM5.36) a share. 
 Much of Oracle’s cloud revenue is produced by business applications such as Fusion software for managing corporate finances and NetSuite’s enterprise planning tools, which are targeted at small and medium-sized companies. — Bloomberg",york racle corp investor company cloud business continue financial strong performance quarter share record close extended trading cloud sale financial fourth quarter bil bil previous period financial cloud revenue increase chief executive officer catz conference call john difucci analyst guggenheim security strength unit abnormal current economic environment oracle cloud infrastructure business compete market leader corp slowdown boom generative artificial intelligence tremendous power demand oracle cloud service executive startup week oracle investor bil funding round share positive momentum narrative cloud momentum demand intact lenschow barclays analyst cloud infrastructure revenue bil bil period oracle monday cloud application sale bil bil austin texas company bil bil cloud capacity company language model development mosaic chairman larry ellison statement oracle gen cloud choice generative workload total sale bil bil quarter analyst estimated bil bil data bloomberg profit item share average estimate strategic cloud business bigger catz statement bodes strong financial share closing record york oracle rise ishares software exchange fund oracle bet acquisition digital health record provider cerner oracle health bil bil quarter oracle job division executive profitability current period august cloud growth oracle health catz total revenue increase analyst projected gain profit item share cloud revenue business application fusion software corporate finance planning tool medium company,"[(4, 0.99561286)]",4
557274,Main,10,14/06/2023,AI-based local innovation smart trolley to transform retail,,"PUTRAJAYA: EzyCart, a smart shopping trolley based on artificial intelligence (AI) which is a local innovation, will be used in several leading supermarkets nationwide such as Redtick, Lotus’s and Jaya Grocer. 
 Developed through the collaboration of NanoMalaysia Bhd and AI-based retail automation solution provider Retailetics Sdn Bhd, the smart product has technology such as barcode scanning, product verification (availability, weight) and a combination of advanced sensor features that can avoid the risk of theft.
 NanoMalaysia Group chief executive officer Dr Rezal Khairi Ahmad said the EzyCart, which is equipped with an e-wallet system, helps consumers to find products on the shelves and uses antibacterial nanotechnology to keep the carts virus- and bacteria-free for months.
 Met after the launch of EzyCart by Minister of Science, Technology and Innovation (Mosti) Chang Lih Kang at Redtick Putrajaya here yesterday, he said NanoMalaysia allocated a fund of RM1mil for the development of the cart, Bernama reported.
 Rezal Khairi said EzyCart will be deployed at Redtick Putrajaya with 10 trolleys placed in the supermarket.
 NanoMalaysia was started in 2011 as a company limited by guarantee under the Ministry of Science, Technology and Innovation (Mosti) entrusted with the commercialisation and industrialisation of nanotechnology via a joint venture model.",putrajaya smart trolley artificial intelligence local innovation supermarket nationwide redtick lotus jaya grocer collaboration nanomalaysia bhd retail automation solution provider retailetics bhd smart product technology barcode product verification availability weight combination sensor feature risk theft nanomalaysia chief executive officer rezal khairi ahmad ezycart wallet system consumer product shelf antibacterial nanotechnology cart bacteria free month launch minister science technology innovation mosti chang lih redtick putrajaya yesterday fund mil development cart bernama rezal khairi redtick putrajaya supermarket nanomalaysia company guarantee ministry science technology innovation mosti commercialisation industrialisation nanotechnology joint venture model,"[(0, 0.99047077)]",0
557256,Main,22,14/06/2023,Can AI replace ghost writers?,,"LANGAT had a solid maths degree and high hopes for a career in stats when he graduated from a mid-level Kenyan university seven years ago.
 Things didn’t pan out as planned.
 So when his dream of crunching numbers for the government or teaching maths in high school both came to nought, Langat took a different route altogether.
 He signed up for a life in academic writing, a glossy term for the murky world of “contract cheating” in Kenya.
 Academic writers – aka educated young Kenyans like Langat – write essays, do assignments, and even sit exams for rich students in developed countries, largely in Europe and the United States.
 There are no reliable stats on how many Kenyans work in what is a shadow industry or the value of their output.
 “Mostly I am paid US$200-US$300 (RM919-RM1,379) monthly per student depending on what we agreed on. I write essays on nursing and healthcare in most cases,” said the 30-year-old father of one.
 Demand for paid content has mushroomed in the past decade but Langat said the market went back way longer.
 “Though most players kept it a secret, and did not say exactly what they were doing,” he explained.
 Now Langat fears his ghost-writing may be under threat from artificial intelligence (AI), which can churn out work at speed and for free.
 Microsoft’s ChatGPT chatbot – which launched last year – can generate articles, essays, jokes and even poetry in response to user prompts, circumventing the need for human cheats to carry out wealthy students’ assignments.
 According to a survey carried out in January by Study.Com, an online learning platform, , more than 89% of the 1,000-plus students questioned said they had used ChatGPT for help with homework.
 The survey found that 48% of students also admitted to using ChatGPT for a test or question at home, while 53% of them had it write an essay, and 22% had it write an outline for a paper.
 All of this undermined the shadow industry in east Africa.
 Ghost writers’ earnings vary greatly – research shows they range from 4,000 to two million Kenyan shillings (RM133 to RM66,766) a month, depending on an author’s experience, the time of year or how much work they take on.
 “At the beginning of the year, income dropped significantly because everyone had rushed to use the AI tools,” said Langat.
 But he is pinning his hopes on the human touch outsmarting AI as teachers wise up to AI’s trademark traits.
 “Some lecturers and professors are able to flag which content is original, and which is AI generated, that’s why the writing market has gone up, again,” he said.
 Kenya is a hotspot for academic writing, with many students from around the world turning to its tech-savvy, English-speaking graduates for help with essays, assignments, attending class and even sitting their exams.
 “The academic writing market is vast in the world, with notable markets in Kenya, Nigeria, South Africa, and parts of South-east Asia,” said Langat, checking out a Facebook group of fellow writers and students with more than 170,000 members.
 The boom began a decade ago when Kenya’s academic elite left university and entered a flooded job market, finding no openings that suited their skills.
 So they found another way to use their brains and earn well.
 Laura, a 22-year-old studying statistics in Nairobi, began doubling up as an academic writer in 2021 after making about US$1,000 (RM4,590) writing an essay about nursing for a friend.
 Sensing the scale of opportunity, she launched her own account online and began dealing directly with US students who wanted ghost writers.
 Soon her business snowballed.
 “There are ratings. And once you have a good rating, jobs will come. Now I have three accounts and hire writers who are mostly students. I don’t ask my parents for money any more. Instead, I send them upkeep,” she said.
 Laura no longer dreams of typical graduate career paths as she feels no company can match her current earnings.
 “I make between US$3,000 and US$7,000 (RM13,700 and RM32,000) in a good month,” said Laura.
 The setup works for the harried Western student, too.
 Harold, a university student in the United States, said he had paid three academic writers to write six assignments for him, spending US$1,100 on four essays in the past two years.
 “I have worked with two Kenyan writers and they are good. Most of the work they do is not flagged by the professor, and I am willing to spend my pocket money to get the job done,” said Harold.
 Launched last November by San Francisco-based OpenAI, ChatGPT became the fastest-growing consumer app in history, hitting 100 million users in two months.
 Harold tried it – with mixed results.
 “It’s not so intelligent and a good professor will be able to know what content is original,” he said.
 Academics say they can spot ChatGPT at work, citing its lack of errors and originality. “I can tell an essay from a machine and the one a student has written,” said Dickson Gekombe, an IT lecturer at Kibabii University in western Kenya. “The one written using a machine will not have spelling mistakes, or grammatical errors, the sentences just flow.”
 So while AI makes for good work – he said it also produces lazy students.
 “Students will say ‘why would I waste my time, go to the library, do research, while this thing can do it for me?’” — Reuters",langat solid math hope career stats mid level university pan dream government math school langat route life academic glossy term murky contract kenya academic writer kenyan langat write essay assignment exam rich student developed country united reliable stats shadow industry output monthly student write essay healthcare father demand content decade langat market player langat fear ghost threat artificial intelligence speed free microsoft chatgpt chatbot generate article joke poetry response user prompt human cheat wealthy student assignment survey january study online platform student chatgpt homework survey student chatgpt test question essay write outline paper shadow industry east africa ghost writer earnings kenyan shilling month author experience time income tool hope human touch teacher trademark lecturer professor content original market kenya academic writing student savvy english speaking graduate assignment class exam academic market vast notable market south africa south east asia langat facebook fellow writer student boom decade kenya academic elite university flooded job market opening skill brain statistic nairobi academic writer essay nursing friend scale opportunity online student writer business rating rating job account hire writer student parent money upkeep laura dream typical graduate career path feel company current earnings month laura setup western student harold university student academic writer assignment essay kenyan writer professor spend pocket money job november san francisco openai chatgpt fastest consumer app history user month mixed intelligent professor content original academic spot chatgpt lack error machine student dickson gekombe lecturer kibabii university western kenya machine mistake grammatical error sentence produce lazy student student time library reuters,"[(0, 0.9966547)]",0
555858,StarEdu,7,11/06/2023,Five ways teachers can harness AI,"New tools, apps set to improve digital learning but prudence in their use is vital","Digital learning is expected to continue making a significant impact on education, and one of the more noteworthy advancements impacting digital learning is the advent of artificial intelligence (AI). 
 It is exciting to see AI come to fruition today in a manner that is tangible, practical, widespread, and easy to use for teachers. For example, just within the last six months, we have seen phenomenal growth in generative AI apps.
 Digital learning has proved to be effective; it is now a matter of harnessing these generative AI apps to our advantage as teachers. 
 The Malaysian Qualifications Agency (MQA) advisory note on the use of generative AI offers some tools, such as ChatGPT, Jasper AI, Craiyon, Midjourney and Synthesia, that can assist us in generating content in the form of text, images, video and audio, among others.  
 The use of these tools offers endless possibilities for teachers to increase student engagement and learning sustainability. 
 Here are five ways teachers can use these tools in the classroom: Generating discussions
 Discussions allow for a two-way engagement between both teachers and students. As teachers, we are constantly looking for ideas to excite and engage our learners, and generative AI tools can really help in this regard. 
 These tools can be used to create a set of discussion prompts related to any subject matter. They can also be used to generate questions that encourage critical thinking and discussions among students. 
 Students can also be tasked with using these tools to come up with debate points, and be taught to compare their own responses to those generated by the tools.
 Creating quizzes
 Assessments are as much part of the teaching and learning (PdP) process as the content and activities. Teachers can use AI to easily create multiple-choice quizzes on various topics that are tailored to their students’ needs and abilities, making assessments more effective and engaging.
 One example of an AI tool that can be used to create quizzes is Perplexity. It not only generates practice quiz questions with feedback, but also references the websites where these questions are sourced from.
 Designing assessment rubrics
 When creating assessment questions which are more qualitative in nature, rubrics are useful as a guide for more objective marking. 
 Teachers can use generative AI tools to design a marking rubric. The trick to amplifying these tools to our benefit is to enter the correct prompts. 
 For example, the following can be a prompt in Perplexity: “Prepare a marking rubric with descriptors to assess a two-minute video on strategic management.” 
 The AI will generate a table with each marking criterion measured against standards, with a descriptor for each criterion or standard. 
 The rubric can be further refined to ensure that it aligns with the learning outcomes and adequately assesses the desired performance. 
 It is important to check the assessment task designed using generative AI tools to ensure that the rubric is effective and accurate. 
 Personalising learning
 Generative AI can also be used to create personalised lessons for each student based on his or her learning ability and progress. 
 It analyses data on students’ performance, detects their preferences and abilities, and develops lessons that are tailored to their individual needs. 
 By using big data analytics and AI-based learning systems, teachers can gain a better understanding of each student’s learning process, which could enable them to teach more effectively. 
 Teachers can also input student answers into the generative AI tools and create personalised questions from there.
 Creating content
 In addition, teachers can use AI tools to generate comprehensive course materials, including syllabi, lesson plans and multimedia content such as video lectures and podcasts.
 Generative AI can personalise course materials, such as practice problems and interactive exercises, based on students’ knowledge gaps, skills and learning styles.
 It can also create simulations and virtual environments, which can offer more engagement and interactive courses, resulting in an improved learning experience for the students. 
 Overall, using generative AI to create content for courses can help teachers save time and provide students with engaging and effective learning materials.
 In our quest to be more digitally oriented, we need to also be wary of over-reliance on generative AI, as it can pose several risks, including discrimination and bias in the output; misinformation and disinformation as generative AI platforms can rely on inaccurate or biased sources of information; lack of transparency and accountability; and potential for misuse as unscrupulous users can exploit generative AI to create harmful content.
 To mitigate these risks, it is important to use generative AI responsibly while incorporating other teaching methods; to monitor the quality of the output generated by AI; and to ensure that AI is transparent and accountable, and that students receive a high-quality learning experience and education.
 Prof Dr Abtar Kaur Darshan Singh is a professor of innovative digital learning, the director of Digital Learning Hub, and the Unesco chair – Use of Innovative Technologies to Enhance Quality of Teaching – at the Asia Pacific University of Technology & Innovation (APU). She obtained a Master of Science in Instructional Design, Development and Evaluation from Syracuse University in the United States, and a PhD in Web-Based Learning from Universiti Malaya. Prof Abtar did her post-doctoral research (Fulbright) at Indiana University, US. The views expressed here are the writer’s own.",digital learning continue impact education noteworthy advancement digital learning advent artificial intelligence fruition manner tangible practical widespread easy teacher month phenomenal growth generative digital learning effective matter generative apps advantage teacher malaysian qualification agency advisory note generative tool chatgpt jasper craiyon midjourney synthesia assist content form text image audio tool endless possibility teacher student engagement sustainability teacher classroom discussion discussion teacher student teacher idea engage learner tool tool discussion prompt subject matter generate question critical thinking discussion student student tool debate taught compare response tool quiz assessment pdp process content activity teacher multiple choice quiz topic student ability assessment effective tool create perplexity generates practice quiz question reference website question assessment rubric assessment question qualitative nature rubric objective marking teacher tool design rubric trick amplifying tool enter correct prompt prompt perplexity prepare rubric descriptor minute video strategic management generate table criterion standard descriptor criterion standard rubric aligns outcome ass performance check assessment task generative tool rubric effective accurate generative create lesson student ability progress data student performance detects preference ability lesson individual data analytics system teacher understanding student process enable teach input student answer tool personalised question content addition teacher tool comprehensive material syllabus lesson plan content video podcasts generative personalise material practice exercise student gap skill style simulation virtual environment engagement interactive course experience student generative create content teacher time provide student effective learning material wary reliance generative pose risk discrimination bias output misinformation disinformation generative platform inaccurate source transparency accountability potential misuse unscrupulous user generative create harmful content mitigate risk generative method quality output transparent accountable student quality experience education prof abtar kaur darshan singh professor innovative digital director digital learning hub unesco chair innovative technology quality asia pacific university technology innovation master science instructional design development evaluation syracuse university phd web universiti malaya prof abtar post doctoral fulbright indiana university view writer,"[(3, 0.7430223), (4, 0.25492042)]",3
555954,Main,34,11/06/2023,World’s first AI sculpture debuts in Sweden,,"Stockholm: A historical dream team of five master sculptors, including Michelangelo, Rodin and Takamura, have trained artificial intelligence (AI) to design a sculpture dubbed The Impossible Statue, now on show in a Swedish museum.
 “This is a true statue created by five different masters that would never have been able to collaborate in real life,” said Pauliina Lunde, a spokeswoman for Swedish machine engineering group Sandvik that used three AI software programmes to create the artwork.
 Shaking up traditional conceptions about creativity and art,  the stainless steel statue depicts an androgynous person with  the lower half of the body  covered by a swath of material, holding a bronze globe in one hand.
 On show at the Swedish National Museum of Science and Technology (Tekniska), the statue measures 150cm and weighs 500kg.
 The idea was to create a mix of styles from five famed sculptors who each made their mark on their era: Michelangelo (Italy 1475-1564), Auguste Rodin (France 1840-1917), Kathe Kollwitz (Germany 1867-1945), Kotaro Takamura (Japan 1883-1956) and Augusta Savage (US 1892-1962).
 “Something about it makes me feel like this is not made by human being,” Julia Olderius, in charge of concept development at the museum, told AFP.
 Visitors will note the muscular body inspired by Michelangelo, and the hand holding the globe inspired by Takamura.
 Sandvik’s engineers trained the AI by feeding it a slew of images of sculptures created by the five artists.
 The software then proposed several images in 2D which it believed reflected key aspects from each of the artists.
 “In the end we had 2D images of the sculpture in which we could see the different masters reflected. Then we put these 2D images into 3D modelling,” Olderius said.
 But is it art, or technological prowess?
 “I don’t think you can define what art is. 
 “It’s up to every human being to see, ‘this is art, this is not art’. And it’s up to the audience to decide,” Olderius said.
 Amid debate about the role of AI in the art world, Olderius said she was optimistic.
 “I don’t think you have to be afraid of what AI is doing with creativity or concepts or art and design,” she said.
 “I just think you have to adapt to a new future where technology is a part of how we create concepts and art.” — AFP",stockholm historical dream team master sculptor michelangelo rodin takamura artificial intelligence design sculpture impossible statue swedish museum true statue master real life pauliina lunde spokeswoman swedish machine engineering sandvik software programme artwork traditional conception creativity stainless steel statue androgynous person half body swath material bronze globe hand swedish national museum science technology tekniska statue measure idea create mix style sculptor era michelangelo italy auguste rodin france kathe kollwitz germany kotaro takamura japan augusta savage human julia olderius charge concept development museum afp visitor muscular body michelangelo hand globe takamura sandvik engineer slew image sculpture artist software image key aspect artist image master image olderius technological prowess define art human art art audience decide debate role optimistic afraid creativity concept design adapt future technology create concept afp,"[(1, 0.9931125)]",1
555310,Main,29,09/06/2023,Britain to host  first ever  summit on AI safety,,"WASHINGTON: Britain will host a global summit on artificial intelligence safety later this year and Prime Minister Rishi Sunak and US President Joe Biden discussed the technology at their meeting, the UK government said.
 The summit will consider the risks of AI, including frontier systems, and discuss how they can be mitigated through internationally coordinated action, the British government said in a statement. No date was given for the event.
 Biden and Sunak, who met yesterday for a fourth time in as many months, will work to coordinate their approaches on critical and emerging technologies, with an eye to strengthening their economic security, British and US officials said.
 US technology company Palantir Technologies, which already has more than 800 employees in Britain, will separately announce plans to make the UK its new European headquarters for AI development, the British government said.
 Sunak planned wide-ranging discussions with Biden on  the UK-US relationship and how the two countries could work together to strengthen their economies and cement their “joint leadership in the technologies of the future,” the government said.
 Several governments are considering how to mitigate the dangers of the emerging technology, which has experienced a boom in investment and consumer popularity in recent months after the release of OpenAI’s ChatGPT.
 That includes China, where the government is seeking to initiate artificial intelligence regulations, according to billionaire Elon Musk who met officials during his recent trip to China.
 Regulators globally have been scrambling to draw up rules governing the use of generative AI, which can create text and images, the impact of which proponents compare to the arrival of the internet.
 Sunak is on a trip to the United States and met Biden at the White House yesterday. — Reuters",washington britain host global summit artificial intelligence safety prime minister rishi president joe biden technology meeting government summit risk frontier system action british government statement event biden sunak yesterday fourth time month approach critical technology eye economic security british official technology company technology employee european headquarters development british government sunak wide ranging discussion relationship country economy joint leadership technology future government government danger technology boom investment consumer popularity month openai chatgpt china government initiate artificial intelligence regulation elon musk official trip china regulator draw rule generative create text image proponent arrival internet sunak trip biden white house yesterday reuters,"[(4, 0.9916695)]",4
554928,StarBiz,16,08/06/2023,Google AI to power virtual travel agent,New tools allow Priceline to offer chatbot planning,"NEW YORK: Want a New York hotel near a Christmas market, a vegan restaurant or another attraction?
 Look no further than artificial intelligence (AI) from Google at Priceline as early as this summer, the companies told Reuters.
 The online travel agency, part of Booking Holdings, aims to debut a more sophisticated chatbot for planning trips as well as hotel suggestions that are like “a personal concierge” tailored to users, said Martin Brodbeck, Priceline’s chief technology officer.
 “You can easily find out that in Bryant Park there’s a Christmas market that runs from early November all the way through the beginning of January when you’re actually booking your hotel,” said Brodbeck.
 New tools from Google’s cloud division give Priceline access to generative AI, like the technology behind ChatGPT, which can draft text as if a human wrote it. 
 The tools also extract information, such as hotel prices, from existing data to ensure accuracy.
 For Google, drawing business through AI represents a potential way to close the gap with rivals Amazon and Microsoft, as it has long been a distant No. 3 provider of cloud services like data storage.
 For Priceline, the embrace of novel technology on its website may help it vie with myriad platforms that market travel options, some of which are exploring how consumers react to AI.
 Its rival, Expedia Group, has said ChatGPT would power conversations on a smartphone app. 
 That is giving travellers “inspiration on places to go” and booking options, said Rathi Murthy, its chief technology officer.
 Both Expedia and Kayak, another site owned by Booking Holdings, have integrated their travel suggestions through features in the standalone ChatGPT programme as well.
 And Google itself has long represented competition for Priceline, though Brodbeck said its cloud capabilities were what led to the partnership.
 The ability to build applications atop generative AI that Google pioneered has attracted recent business, said Thomas Kurian, Google Cloud’s chief executive officer.
 “There is a kind of Cambrian moment happening now where there’s an explosion of this technology,” Kurian told Reuters, referring to the extraordinary prehistoric period when a wide array of new species emerged, but he declined to answer how free corporate previews were affecting Google Cloud’s profitability.
 Google’s AI will generate coding suggestions for hundreds of software developers at Priceline, said Brodbeck. 
 Priceline will adopt Google’s search capabilities for employee intranets. And Google’s AI will speed up marketing for trending destinations.
 “You could have it create images like a beach, and you could marry that with great generative AI copy,” said Priceline’s chief technology officer. — Reuters",york york hotel christmas market vegan restaurant attraction artificial intelligence google priceline summer company reuters travel agency holding aim sophisticated chatbot trip hotel suggestion personal concierge user brodbeck priceline chief technology officer bryant park christmas market january hotel brodbeck tool cloud division priceline access generative technology chatgpt draft text human tool extract hotel price data accuracy google business potential gap rival microsoft distant provider cloud service data storage priceline embrace technology website vie myriad platform market travel option consumer rival expedia chatgpt power conversation app traveller option murthy chief technology officer kayak site holding travel suggestion standalone chatgpt programme google competition priceline brodbeck cloud capability partnership ability application generative google attracted business thomas kurian google cloud chief executive officer cambrian moment explosion technology kurian reuters extraordinary prehistoric period wide array specie answer free corporate preview cloud profitability google generate coding suggestion hundred software developer brodbeck priceline google search capability employee intranet speed marketing destination image marry generative copy priceline chief technology officer reuters,"[(2, 0.07020089), (4, 0.92592734)]",4
553608,Lifestyle,5,05/06/2023,AI threatens women’s jobs,,"WHILE artificial intelligence (AI) is seeding upheaval across the workforce, from screenwriters to financial advisors, the technology will disproportionately replace jobs typically held by women, according to human resources analytics firm Revelio Labs.
 “The distribution of genders across occupations reflects the biases deeply rooted in our society, with women often being confined to roles such as administrative assistants and secretaries,” said Hakki Ozdenoren, economist at Revelio Labs. 
 “Consequently, the impact of AI becomes skewed along gender lines.”
 Revelio Labs identified jobs that are most likely to be replaced by AI based on a study by the National Bureau of Economic Research. 
 It then identified the gender breakdown of those jobs and found that many of them are generally held by women, such as bill and account collectors, payroll clerks and executive secretaries.
 Advances in AI are aggravating gender disparity in the global workforce, where companies are considering cutting some staff and leveraging generative AI in their workflow. 
 IBM recently said it’s slowing down hiring for roles that can be easily replaced by AI in back-office functions, such as human resources. 
 CEO Arvind Krishna predicts that as many as 30% of these positions could be replaced by automation over the next five years, potentially resulting in a loss of around 7,800 jobs.
 AI is more likely to take over repetitive jobs, the kind that are mostly held by women. For example, OpenAI’s ChatGPT model can search, review and summarise large volumes of text quickly, tasks that would normally take paralegals much longer to accomplish. 
 In recruitment, AI can automate the process of sorting through resumes, a task that used to require more people, Ozdenoren said. But it doesn’t mean that other highly skilled workers can feel secure about their jobs. 
 Preliminary research also shows that generative AI may impact high-wage occupations more than non-traditional manufacturing jobs, according to Revelio Labs.
 “Moving forward, providing retraining opportunities will be key for women to navigate the evolving job landscape,” Ozdenoren said. 
 “By doing so, we can capitalise on the potential of AI while leveraging their valuable skills and expertise,” he said. – Bloomberg/Tribune News Service",artificial intelligence upheaval workforce screenwriter financial advisor technology job woman human resource analytics firm revelio lab distribution gender occupation bias society woman role administrative assistant secretary ozdenoren economist revelio lab impact gender line lab job national bureau economic gender breakdown job woman bill collector clerk executive secretary gender disparity global workforce company staff generative ibm role office function human resource krishna predicts position automation loss job repetitive job woman openai chatgpt model search review summarise volume text task paralegal accomplish recruitment automate process resume task people skilled worker secure job preliminary generative impact wage occupation traditional manufacturing job lab opportunity key woman job landscape ozdenoren potential valuable skill bloomberg tribune news service,"[(4, 0.9916503)]",4
553692,StarBiz,7,05/06/2023,MBCS sees opportunity to leverage on AI,"Balance between human creativity, technology vital","PETALING JAYA: Mediabrands Content Studio (MBCS), the media-fuelled creative content agency within the IPG Mediabrands network, recently announced key updates to its leadership team in Malaysia, in the form of a Creative Leadership Council.
 In responding to queries from StarBiz, Stanley Clement, chief executive officer of MBCS Malaysia and newly minted executive creative director of MBCS Andrew Shee elucidated some of the developments trending in the advertising industry and how the agency viewed them.
 Below are the excerpts of the interview.
 StarBiz:  Innovation and artificial intelligence (AI) of late have been hogging the headlines. What has the agency done in this space? And how is this shaping creativity today and how can creatives work together with the technology?
 Clement: AI is shaping the face of creativity today, providing us with advanced tools, content generation capabilities, personalised recommendations, data-driven insights and collaborative platforms, all of which can enhance the way we do our work as creatives.
 Within the agency, we are embracing AI as a tool, ensuring we have a good repository of AI tools that help very much in the thinking and groundwork.
 However, we are extremely careful and measured of its usage, especially with the end output.
 While working with this technology, it is important to strike a balance between human creativity and AI assistance, as we look to continuously learn, adapt and consider the ethical implications of its usage. 
 Ultimately, human input in creativity and innovation leads the way.
 Most importantly, MBCS and the Creative Leadership Council see an opportunity to leverage AI’s capabilities while infusing a unique artistic vision for creatives to unlock new possibilities and navigate the evolving creative landscape, which will be very exciting for brands today.
 Shee: Technology allows creativity to flourish and continues to amaze us every day. Because technology is everywhere around us, and so much more accessible, creatives need to understand better how tech can enhance people’s lives and build creative ideas around it.
 Within MBCS, we are making a concerted effort to enrich our creatives in the space of AI through specialised and practical workshops which will help them strategise better alongside AI to do a variety of things across consumer analysis, eCommerce and even sustainability efforts.
 In terms of creativity, where does Malaysia stand compared with its regional peers? How can we boost the creativity level in the ad industry locally, and any measures to spur creative talents?
 Clement: The ad industry locally definitely needs reinvigoration.
 Executions and plans in the last few years have been largely tactical, focused on finding the cheapest solution to market.
 This has not been a good thing as the core idea of building brands long-term has taken a backseat, and we are looking at pricing in the first instance, rather than the real opportunity to grow brand value.
 This needs to be balanced better, otherwise brands will lose out in the long run.
 Shee: Malaysia has amazing creative talents both locally and abroad who are showcasing their creativity in many other fields beyond advertising.
 However more effort needs to go into marketing ourselves better to gain global recognition and acknowledgement.
 While there are rules and regulations that sometimes stifle creatives, the truth is this is prevalent everywhere in the world. 
 Instead, creatives need to challenge themselves to work around the rules to create something that moves people and changes behaviours or mindsets.
 This is why tech and data science is so exciting, as there lies opportunities for us to manoeuvre around obstacles to achieve the creativity we aspire for.
 We are now in the age where AI is threatening to take over our jobs – especially so in the creative marketing industry.
 Instead of fearing this, we need to embrace AI and use it purposefully, knowing that at the end of the day, humans are the heart of AI.
 This business is still very much a people business and should always be driven by human truths in everything we do.
 Could you delve on the challenges faced by the creative leadership?Clement: Primarily, our main challenges lie in managing the expectation of the clients.
 There is a high expectation for us to constantly bring great ideas to the table, yet there is a natural limit on solutions which are highly social or that can trend-jack positively.
 Thus, delivery with frequency of this nature is challenging, and makes it challenging for us to constantly inspire the young creatives.
 Shee: I firmly believe in creative leadership taking a proactive role to inspire and guide the next generation of creative talents, but the biggest challenge is how we do it.
 Ways of the past do not apply in today’s climate.
 Leaders need to drop fixed expectations to better understand the ways of the next generation before guiding them.
 Being empathetic towards one another and working together towards a common goal is an important part of the inspiration process.
 Importantly, we need to keep nurturing our local talent to ensure they do not move away from creative industries.
 Any other relevant trends or insights driving the advertising landscape?
 Clement: We are seeing greater opportunities within performance creative as it is an essential way for brands to quickly and effectively reach their audience, as they seek to drive higher conversions by targeting specific audiences, optimise based on data, and focus on measurable results.
 To this end, MBCS has a full performance creative team that works closely alongside the media teams to ensure that brands stand out, engage their audience, and achieve their marketing goals effectively and efficiently.",jaya mediabrands content studio mbcs medium creative content agency network key update leadership team malaysia form creative leadership council query stanley clement chief executive officer mbcs malaysia executive creative director mbcs elucidated development advertising industry agency excerpt interview innovation artificial intelligence late hogging headline agency space creativity creatives technology clement creativity advanced tool content generation capability recommendation data insight platform creatives agency tool repository tool groundwork careful usage output technology strike balance human creativity assistance learn adapt ethical implication human input creativity innovation mbcs creative leadership council opportunity leverage capability unique artistic vision creatives unlock possibility creative landscape brand shee technology creativity flourish amaze day technology accessible creatives tech enhance people build creative idea effort enrich space practical workshop variety consumer analysis ecommerce sustainability effort term creativity malaysia regional peer creativity level industry spur creative talent clement industry reinvigoration execution tactical cheapest solution market core idea brand term backseat pricing instance real opportunity grow brand brand lose shee malaysia creative talent creativity field effort marketing gain global recognition acknowledgement rule regulation creatives prevalent creatives rule move people mindset tech data science lie opportunity obstacle creativity aspire age job creative marketing industry embrace day human heart business people business human truth challenge creative leadership clement main challenge expectation client idea table natural limit solution social trend jack delivery frequency nature creatives creative leadership proactive role inspire guide generation creative talent biggest challenge apply climate leader expectation generation guiding empathetic common goal inspiration process local talent creative industry trend insight advertising landscape clement opportunity performance creative essential brand audience seek drive conversion specific audience data measurable mbcs performance creative team alongside medium team brand engage audience achieve marketing goal,"[(2, 0.99698174)]",2
552832,Lifestyle,7,04/06/2023,"Use AI, sure – but fact check","The power lies not only with the pen – and now AI – and the person wielding it, but also the reader and how prudent we are in accepting those words.","IMPLICIT in the phrase “The pen is mightier than the sword” is the idea that to persuade people with your writing takes a degree of skill. That a random jumble of words needs the energy of somebody who knows what they are doing to create order and sense.
 But what if it’s machines that unjumble those words? 
 Despite what years of movies have told me about the Terminator or HAL, I refuse to believe that when computers become intelligent enough, they will turn evil and take over the world. What is more likely is that people will be dumb enough to believe computers and end up doing stupid things that destroy the world.
 I had a chat with someone who was appalled at how an artificial intelligence (AI) research tool returned seemingly promising but ultimately fake URLs. “It’s so dangerous!” she exclaimed.
 It’s true. Just ask Steven Schwartz, an American lawyer who has been called up by the court to explain how he used an AI tool to assist in writing court filings that cited six nonexistent cases. When he was asked to explain whether these cases were authentic, he said yes by referring back to the same AI tool for confirmation.
 To me, the obvious issue isn’t that the AI tool spouted nonsense; it was that the person using it couldn’t tell the difference between good output and bad output. We need to learn to be able to tell the difference.
 A professor in an American university set his undergraduate class the following assignment: Students were asked to use AI to generate essays using a given prompt, and then critically evaluate the output. In particular, they were told to fact check the information and critique the analysis.
 Every one of his 63 students discovered that their generated essay contained some form of inaccuracy, and half of them said they had been unaware that AI could be wrong. Upon reflection, the professor’s students themselves pointed out the dangers of overrelying on AI to “get things right”. One student said: “I’m not worried about AI getting to where we are now. I’m much more worried about the possibility of us reverting to where AI is.”
 Of course, the clever people making these AI tools have been trying to find ways to make sure the next iteration doesn’t make these kinds of mistakes, or at least highlights where it might have gone wrong.
 For example, the folks at OpenAI have introduced a version of ChatGPT that can also browse the Internet to get the information it needs. If you ask it to write about something, it will annotate the resulting text to show you which website it found the information on.
 Of course, you have to then read that original webpage source and try to determine if it is accurate and true. Although AI can help you draft the article and find the source webpages, you still ultimately have to do the fact checking.
 It was pointed out that this was reminiscent of Wikipedia when it first became popular. We were told we shouldn’t use it because we don’t know how much of what was on it was true. Anybody could contribute to Wikipedia, and nobody knows whether the facts are reliable or not.
 Over time, instead of becoming unreliable as a source of information, Wikipedia became a convenient port of first call for a quick overview. However, we learned that for critical portions, it really was better to find alternative sources to back up what was found in Wikipedia.
 In the same way Wikipedia is not a source of truth, but a tool to help corral facts, these new AI writing tools are not about writing the truth, but about how to present facts it thinks it knows in a very human-like way.
 If it’s so good at writing readable first drafts, then why don’t we use it to write stories? Well, Amir Muhammed, the founder of local publishing company Buku Fixi, is open to the idea, stating, “The kind of stories that do well are the ones that get positive word of mouth – by human readers. If something by an AI manages to achieve that, we won’t stand in the way of reader enjoyment.”
 In fact, the main concern for book publishers seems to be the issue of authenticity, in this case of human intellectual property. Can an author claim to be the creator if he uses a mishmash of words generated by another? If yes, then if those “other words” he uses are found to be very similar to some already existing piece of work, can the author be accused of plagiarism?
 When it comes to writing, the notion of “truth” carries different implications for legal submissions, academic essays, and works of fiction. For legal submissions and university essays, the concern is whether they are consistent with verifiable facts. For pieces of fiction, it’s whether the words evoke the writer’s intended meanings and emotions beyond a simple “cut and paste”.
 In all cases, it should be obvious that the power lies not only with the pen and the person wielding it, but also the reader and how prudent we are in accepting those words.
 Logic is the antithesis of emotion but mathematician-turned-scriptwriter Dzof Azmi’s theory is that people need both to make sense of life’s vagaries and contradictions. Write to Dzof at lifestyle@thestar.com.my. The views expressed here are entirely the writer’s own.",implicit phrase mightier sword idea persuade people degree skill random jumble energy create sense machine unjumble movie terminator hal refuse computer intelligent evil people dumb computer stupid artificial intelligence tool fake url dangerous true schwartz american lawyer court explain tool assist court filing nonexistent explain authentic tool confirmation obvious issue tool nonsense person difference output bad output learn difference professor american university undergraduate class assignment student generate essay evaluate output check critique analysis student generated essay form inaccuracy half unaware wrong reflection professor student danger student worried possibility clever people tool iteration kind mistake highlight wrong folk version chatgpt browse internet write annotate text website read original webpage source determine accurate true draft article source checking reminiscent wikipedia popular true contribute wikipedia reliable time unreliable source wikipedia convenient port call quick overview critical portion alternative source wikipedia source truth tool corral writing tool truth human readable draft write story founder local publishing company buku fixi idea story positive word mouth human reader manages stand reader enjoyment main concern book publisher authenticity human intellectual property author claim creator mishmash piece author plagiarism notion truth implication legal submission essay legal submission university essay concern consistent verifiable piece fiction writer meaning emotion simple obvious power pen person reader prudent logic antithesis emotion mathematician scriptwriter dzof theory people life vagary contradiction dzof lifestyle view writer,"[(0, 0.42569605), (1, 0.5714842)]",1
552950,Main,18,04/06/2023,Battling health misinformation withAI,"A young Malaysian wants to offer an answer to the widespread, unregulated development of artificial intelligence in health sites that can lead to public harm.","THE use of artificial intelligence (AI) particularly for medical inquiries is fast becoming a global norm.
 Receiving personalised replies organised by a health site powered by AI is regarded as convenient; the number of people looking for answers online continues to grow as they seek a better understanding of themselves.
 One such site strives to stand out from the rest: BTRU.ai, pronounced “better you”. It was founded and created by young Malaysian medical student Ian Soh who led independent global Covid-19 youth movement MoreViralThanTheVirus a few years ago.
 The 22-year-old Johorean and his team have been working on BTRU.ai to provide a seamless experience for potential patients wanting to know more about their state of health.
 With its plain blue and white colour theme, the site illustrates simplicity in use and mainly serves as a tool to educate the masses based on their queries. It does not try to provide diagnoses or medical advice for self-treatment.
 For a better you
 BTRU.ai is Soh’s answer to the widespread and unregulated development of AI in health sites that can lead to public harm.
 “When you are on Google [looking for answers] about diabetes, for example, you will get advertisements, [come across] unreliable health sources, and be misinformed. These are the problems that people don’t think about,” says Soh, who is currently undergoing housemanship training in London.
 And more importantly, the answers provided by BTRU.ai are based on verified sources including the UK’s National Health Service and the World Health Organisation.
 The beta version of BTRU.ai was launched last Sunday and public response has been positive so far.
 BTRU.ai strives to be a one-stop centre to provide credible answers. The replies are personalised to the person typing the questions and the AI will even provide links for further reading.
 “I have been trying to solve the problem of finding reliable information and I believe that I am on that mission to tackle it, “ he says. 
 Soh believes that people have the right to educate themselves about their health or, better still, become more aware of their health problems.
 “Can you imagine, regardless of background or wealth, someone who has not studied medicine can use this piece of technology and get the best health information?” he says.
 “Type your question in the search tool and you will get replies in the natural English language, producing information which breaks away from jargon.” 
 He says BTRU.ai streamlines information that is already available.
 “I am not writing a piece of new information on [for example] diabetes. We are constructing an organised response which will tell you what you need to know about the condition.”
 BTRU was inspired by Soh’s experience in leading his previous movement.
 “I got the experience in [addressing] misinformation and after working on it for such a long time, now I wanted to make it a bit practical.
 “I understand that not everyone has been to medical school, or is able to navigate online and work out whether this or that is a reliable site. Technology should come into play to help leverage which website is reputable or otherwise.”
 Medicine and AI 
 On Tuesday, AI industry leaders in the United States, in a joint statement, called for mitigation efforts against the risk of extinction caused by the unregulated development of AI.
 “The statement highlights wide-ranging concerns about the ultimate danger of unchecked artificial intelligence.
 “Still, the flood of hype and investment into the AI industry has led to calls for regulation at the outset of the AI age, before any major mishaps occur.
 “The statement follows the viral success of OpenAI’s ChatGPT, which has helped heighten an ‘arms race’ in the tech industry over artificial intelligence. In response, a growing number of lawmakers, advocacy groups and tech insiders have raised alarms about the potential for a new crop of AI-powered chatbots to spread misinformation and displace jobs,” CNN reported.
 A similar concern is voiced by Soh when asked about the challenges as well as ethics concerning the use of AI.
 He says there are several challenges faced when developing BTRU.ai in efforts to prevent future problems which can affect health services, for example. Among the potential issues are people self-diagnosing themselves through the use of AI and the health industry’s possible reluctance in implementing the technology due to cost.
 “For example, when Facebook was founded it was meant to help people connect but people never thought about the mental health issues that came along. 
 “I want to be ethical. I want to be conscientious in what I do.”
 He highlighted a health check site which also utilises AI but which potentially leads to harm; the site offers diagnoses and self-treatment advice. This is despite AI’s current state in which it has yet to reach a level of sophistication that can provide actual medical diagnoses.
 “This is what happens when you are not conscientious and create a problem. These are some of the things I see people trying to build. People are trying to create their own AI tools, try to diagnose and treat themselves,” Soh says.
 The site is said to have been founded by an individual frustrated by physicians who apparently did not diagnose his/her medical condition. 
 “So people with non-healthcare backgrounds are creating products for healthcare which they may not know how it works. This is scary.
 “I took a few years [to come up with BTRU.ai]. I had to speak to professors and consultants, run tests and work through the legality.”
 A better future
 Soh’s eyes light up at our next question: will BTRU.ai ultimately aid doctors in their work? 
 “We want to overcome GDPR (general data protection regulation) and data compliance issues. We have yet to successfully go over that. We will, in time.
 “But when we do, with your consent [to share data] we will then learn the way you search [on BTRU].”
 And here is the “magic” as described by Soh: a user’s unique search traits will help BTRU form a picture of his or her condition before the person arrives physically at the hospital.
 “Currently, what people have trained the AI on is based on the data about patients already in the hospital. But not the data on what happened when they were not in the hospital. [For instance] if they had searched about a headache three weeks ago.”
 Soh says there is a goldmine of health data which does not exist right now, concerning people’s search habits before they seek medical help.
 When combined with existing data, doctors will have a clearer picture with which to come to a diagnosis.
 “But as of at this point, we are not there yet. That’s what I think in the future, as one of the means to help with diagnoses.”",artificial intelligence medical inquiry global norm personalised reply health site regarded convenient people answer seek understanding site strives rest btru malaysian medical student ian soh independent global covid youth movement moreviralthanthevirus johorean team btru seamless experience potential patient health blue white colour theme site simplicity serf educate mass query medical advice treatment btru soh answer widespread unregulated development health site public harm google answer advertisement unreliable health source people housemanship training answer btru verified source national health service health organisation beta version btru sunday public response positive btru strives credible answer reply person question provide link solve reliable mission tackle soh people health aware health imagine wealth medicine piece technology health type question search tool reply natural english language break jargon btru streamlines piece diabetes organised response condition btru soh experience previous movement experience misinformation time practical understand medical school navigate online reliable site technology play leverage reputable medicine tuesday industry leader joint statement mitigation effort risk extinction unregulated development statement highlight wide concern ultimate danger artificial intelligence flood hype investment industry call regulation age major mishap statement viral success openai chatgpt arm race tech industry artificial intelligence response lawmaker tech insider alarm potential crop chatbots misinformation displace job cnn concern soh challenge challenge btru effort future health service potential issue people health industry reluctance technology cost facebook meant people people mental health issue conscientious health check site utilises harm site diagnosis treatment advice current reach level sophistication actual medical diagnosis conscientious people people tool treat soh site individual frustrated physician medical condition people product healthcare scary btru speak professor consultant test legality soh eye light question btru aid doctor gdpr data protection regulation data compliance issue time consent share data search btru magic soh user unique search trait form picture condition person hospital people data patient hospital data hospital instance headache week goldmine health data people habit medical data doctor picture diagnosis future diagnosis,"[(4, 0.99729013)]",4
553070,Main,28,04/06/2023,AI could sway US’  2024 elections — but not like you think,Campaign professionals worry that artificial intelligence will have troubling implications for a political system already beset by misinformation.,"ARTIFICIAL intelligence could transform politics as profoundly as television or radio, providing the early masters of the nascent technology a sizeable – and perhaps decisive – advantage in the upcoming elections.
 But even as campaign professionals embrace AI, they worry that the newfound ability to quickly and cheaply generate convincingly deceptive audio and video has troubling implications for a political system already beset by misinformation. How can voters hold politicians accountable for their failings if they believe those failings are fake? How will campaign professionals respond when their candidates are smeared with fabricated “recordings”?
 Despite the widespread anxiety over deepfakes’ effects on democracy, political consultants in the United States say they are more excited about generative AI’s potential to tackle boring grunt work and expand their ability to deploy big-race tactics in down-ballot contests.
 AI’s real impact on campaigning will be “behind the scenes,” said Tom Newhouse, vice president of digital marketing at Converge Media, a Republican advertising and consulting firm. 
 “It’s going to be improving fundraising capabilities by better targeting, whether that is location targeting, income, hobbies or habits, providing campaigns with up-to-date voter data, more personalised advertising, [or] messages.”
 “There are many small campaigns that I think can potentially leverage the tools to [not just] save time, but to create content that may not have been possible otherwise,” said Larry Huynh, a partner at Trilogy Interactive, a Democratic digital marketing firm.
 Campaign professionals across the US are now racing to see how they can use these new machine-learning tools to supercharge their work in advance of their first big test: the 2024 presidential elections.
 “Anyone who wants to do their job better here – and in any industry, let alone politics  – is trying to see how the tool can be beneficial to their work,” said Huynh, who is also the incoming president of the American Association of Political Consultants.
 The election pros that CQ Roll Call spoke to all expect AI to give some tech-savvy candidates a big leg up on their opponents. 
 “Campaigns that can innovate and lean into these tactics are going to have a strategic advantage,” said Newhouse.
 From fireside chats to ChatGPT
 With new technologies came newfound boons to politicians who knew how to use them — or, more accurately, find someone who did. Barack Obama’s campaigns expanded on data-driven strategies to organise grassroots enthusiasm into an army of volunteers, while Donald Trump’s team benefited from Cambridge Analytica’s mining of voters’ social media data.
 “These are the political campaigns that told industry and private practice and commercial industries how to best leverage these tools,” said Newhouse, describing campaigns as “laboratories of innovation.”
 Newhouse thinks those competitive pressures could mean that electioneering, itself a multibillion-dollar industry, might lead the corporate sector on adopting AI. 
 “As you look forward [to the 2024 elections], political campaigns are going to be incentivised to use these technologies quicker than you might see in the private markets,” he said.
 AI is already being used in politics. After President Joe Biden announced his reelection campaign, the Republican National Committee released an AI-generated video that envisioned a dystopian future wrought by his four more years in office. 
 Campaigns have used machine-learning models to guide their ad buys on social media platforms like Facebook for years now. Right now, though, it’s the potential to use large language models like OpenAI’s ChatGPT to update voter files, perform data analysis and program automated functions that excite political operatives the most. While well-funded Senate or gubernatorial races can afford to hire data scientists to crunch numbers, smaller campaigns rarely have that luxury, said Colin Strother, a Democratic political consultant based in Texas. AI will change that.
 “I’m excited about some of the brute work that would be really great to do, but  – unless you’re on a big-time campaign, with a ton of money and a ton of staff  – you can’t afford to do,” Strother said.
 Strother thinks AI will let campaigns upgrade their microtargeting operations into hypertargeting and speed up their rapid response operations. An AI-powered chatbot fed with an opponent’s every public utterance and voting record could churn out instantaneous rebuttals to whatever they say in a speech, debate or campaign ad. He also expects campaigns to use AI to update voter databases in real time, perform trend analyses and send tailored communications to different tranches of voters. Those could be persuasive pitches to undecided independents on the issues that probably matter most to them or fundraising appeals to stronger supporters playing on their biggest fears if their candidate loses. 
 “If you can automate all of that, then these previously time-intensive, labour-intensive and therefore cash-intensive campaign functions get a lot easier to do and a lot cheaper to accomplish,” Strother said.
 Huynh also sees AI levelling the playing field somewhat between well-heeled and poorer campaigns. His agency has already played around with AI to create a video that portrayed one client as a superhero. It’s the kind of project that would have required renting out a studio with green screens, blocking off hours of the client’s time and hiring some computer animators and editors to put it all together — but, with AI, was created “for fun” in no time at all.
 Already the proliferation of high-end video editing software and improved cameras has meant that any candidate for town dogcatcher with an artsy nephew can put together a slick campaign ad, even if they can’t afford to run it anywhere but their own YouTube page. AI will only supercharge that trend, said Huynh.
 “You’ll see some examples of content and video graphics images that that generative AI will make possible for leaner campaigns to do that they wouldn’t have been able to do otherwise,” he said.
 As a result, for most voters, the rise of AI might not mean being bombarded by hard-to-spot political lies so much as just being bombarded by political content in general. The history of technology’s impact on work suggests campaigns will be able to do more with less, and thus will make more of the election stuff that inundates and annoys voters: more online ads, polls, texts, emails, fundraising appeals, emotional manipulation and another hive dumped on top of the growing swarm of robocalls incessantly buzzing our cellphones.
 The potential for bad actors to abuse AI also worries campaign professionals.
 “From a professional standpoint, I’m excited,” said Newhouse. “From a personal standpoint, it’s tough not to get concerned that the trends of the last decade are going to continue as far as laying the burden at the feet of the voters to figure out what’s true and what’s false.”
 Earlier this month, AAPC released a policy statement forbidding its members from using generative AI to create deepfakes that mislead the public. But Huynh knows not every operative will abide by the trade group’s ethical standards. 
 “I expect some campaigns to implement things that we believe are inappropriate, not good for campaigns and not good for democracy,” said Huynh. “There will be thousands and thousands of campaigns that happen in 2024. It would be silly to dismiss that possibility.”
 Strother’s primary concern is AI’s ability to flood the zone with misinformation, creating “chaos,” which disproportionately turns off the more moderate voters who don’t view politics as an extension of their social identity. 
 “If we’re creating homework for them – and they now have to figure out which one of us is telling the truth [and] which one of us is lying  – they’re going to bail because they’re not looking for extra work to do,” he said.
 Regulation to the rescue?
 Given that Congress has yet to pass legislation regulating how social media companies utilise user data, some advocates worry lawmakers will similarly fail to act quickly on AI. But AI’s ability to generate election-swaying deceptions is far more obvious than social media influence on votes. 
 A deepfake’s ability to fool voters is readily apparent to lawmakers, and at a recent hearing, many sounded receptive to OpenAI CEO Sam Altman’s calls for a new federal agency to regulate AI and support for disclosure rules.
 But even if Congress does act quickly, there are questions of how much it’ll help.
 Given the prevalence of dark money political groups, the First Amendment’s broad protections of political speech and the fact that defamation lawsuits take years to resolve themselves, the schemers behind a libellous deepfake could potentially avoid any liability by hiding behind the organisation’s corporate veil. 
 “It really opens the door for some really nasty stuff,” said Strother.
 People are prone to logical hiccups like politically motivated reasoning, whereby the desire to maintain a socially held belief overpowers our ability to grapple with a truth that challenges those convictions. And then there is confirmation basis: accepting information that confirms our prior beliefs while dismissing data that confounds them. That means that once a false conviction is set, subsequent fact checking may not be enough to dislodge that fantasy. 
 Despite hundreds of court cases, audits and media reports proving otherwise, polls  consistently show that a majority of Republican primary voters believe the 2020 elections were stolen. So a computer-fabricated recording of President Joe Biden purporting to admit to such a plot wouldn’t need to be good to be effective. It doesn’t take much to convince the faithful that devils walk among us.
 Those worries over AI may be overblown or premature. So far, political deepfakes have been more amusing than malicious. But the technology is advancing rapidly, leading to uncertainty over its potential for good or ill, and uncertainty tends to compound anxiety. 
 That may be why the political consultants experimenting the most with AI are the least bothered about its downsides  – although they’re still concerned.
 Even as he continues to expand his work with AI, Newhouse hesitates to make predictions on its impact without a caveat.
 “If we talked about this technology six, seven months ago, you’d probably get a blank stare,” said Newhouse. 
 “So to predict another six, seven months in the future, let alone 16 months in the future to the November 2024 elections, it’s difficult to say what that looks like.” — CQ-Roll Call/TNS",artificial intelligence transform politics television radio master nascent technology sizeable decisive advantage upcoming election campaign professional newfound ability cheaply generate deceptive audio video implication political system misinformation voter politician accountable failing failing campaign professional candidate fabricated recording widespread anxiety deepfakes effect political consultant excited generative potential tackle grunt expand ability deploy race tactic ballot contest real impact scene vice president digital marketing converge medium republican advertising firm capability location income hobby campaign data advertising message leverage tool time create content larry huynh partner trilogy interactive democratic digital marketing firm campaign professional machine learning tool advance test presidential election job industry politics beneficial huynh president american association political consultant election pro call expect tech savvy candidate opponent campaign innovate lean tactic strategic advantage fireside chat technology boon politician obama campaign data strategy grassroots army volunteer trump team cambridge analytica mining voter social medium data political campaign industry private practice commercial industry tool campaign laboratory competitive pressure multibillion dollar industry lead corporate sector forward election political campaign technology private market politics president joe biden reelection campaign republican national committee generated video dystopian future office campaign machine model buy social medium platform potential language model chatgpt update voter file data analysis program function political operative senate gubernatorial race hire data scientist campaign colin democratic political consultant texas change brute time campaign ton money ton staff afford strother strother campaign upgrade operation speed rapid response operation chatbot opponent public utterance voting record churn instantaneous rebuttal speech debate campaign campaign update voter database real time trend analysis communication tranche voter pitch undecided independent issue appeal stronger supporter biggest fear loses automate time intensive labour intensive cash intensive campaign function easier lot cheaper accomplish strother huynh field poorer campaign agency create video client superhero project renting studio green screen hour client time computer animator editor fun time proliferation video software camera meant candidate town dogcatcher artsy nephew slick campaign afford youtube supercharge trend huynh content video graphic image leaner campaign result voter hard spot political lie political content history technology impact campaign election stuff voter ad poll email appeal emotional manipulation hive top swarm robocalls cellphone potential bad actor worry campaign professional professional standpoint personal standpoint tough concerned trend decade burden foot voter true month policy statement generative create deepfakes public huynh operative trade ethical standard campaign implement inappropriate campaign democracy huynh thousand thousand campaign dismiss possibility primary concern ability flood misinformation chaos moderate voter politics social identity homework figure truth bail extra regulation rescue congress pas legislation social medium company data advocate lawmaker ability generate election deception obvious social medium influence vote ability fool voter apparent lawmaker receptive openai ceo sam altman federal agency support disclosure rule question prevalence dark money political amendment broad protection political speech defamation lawsuit schemer libellous avoid liability organisation corporate veil door nasty stuff strother people logical hiccup desire maintain belief overpowers ability truth challenge conviction basis accepting prior belief data confounds false conviction subsequent checking dislodge hundred court medium report poll majority republican primary voter election computer president joe biden admit plot effective convince faithful devil worry overblown premature political deepfakes malicious technology uncertainty potential uncertainty compound anxiety political consultant downside concerned newhouse prediction impact caveat technology month blank stare predict month future month future november election difficult roll call tn,"[(1, 0.99843377)]",1
552212,StarBiz,4,02/06/2023,Artificial intelligence craze leaves crypto for dust,,"BITCOIN is undeniably having a great year, but is losing momentum just when it might have been expected to go up a gear.
 Its traditionally strong and positive correlation with technology stocks, in particular the “mega tech” and growth stocks that have exploded higher in recent weeks, has completely broken down.Bitcoin’s rolling 30-day correlation with the Nasdaq last week flipped to its most negative in six months, and its correlation with the NYSE FANG+TM index of mega tech and growth equity plunged to its most negative in nearly four years.
 The recent burst of investor optimism that the boom in artificial intelligence (AI), ChatGPT software and advanced microchip technology will be transformational for economies is driving the surge in Big Tech.
 Crypto might have been expected to ride on the coat tails, but hasn’t. Bitcoin peaked above US$31,000 (RM142,910) in mid-April for a year-to-date gain of almost 90%, but is now trading back at US$27,000 (RM124,470), paring its 2023 gains to around 63%.
 As billions of dollars have flooded into Big Tech over the last six weeks, bitcoin trading volumes and demand have slumped.
 Matt Weller, analyst at StoneX, said there just doesn’t seem to be a compelling reason to buy bitcoin right now and the AI boom still has legs.
 “ChatGPT is what crypto wants to be – an instant-use, mass-market product with huge adoption rates,” he said, adding: “Crypto has lost its luster amid this gold rush. Or should I say, AI rush.”
 The magnificent seven
 Bitcoin, crypto assets more broadly and technology stocks have traditionally moved in tandem on the assumption that they will all be fundamental parts of the disruptive, growth-generating and efficient economies of the future.
 Weller reckoned the divergence really widened on April 25 when Microsoft was the first of the United States tech giants to report forecast-beating quarterly results.
 Since April 25, the NYSE FANG+TM index of big tech and growth stocks has surged 24%, nearly three times the broader Nasdaq. Bitcoin, on the other hand, is down around 1% in more erratic trading.
 Whatever is buoying mega tech is not floating bitcoin’s boat.
 The AI boom has gathered momentum despite the rise in bond yields and discount rates. 
 This has highlighted bitcoin’s underperformance and strongly suggests that outside the rarified world of Big Tech, investors are much more discerning.
 Indeed, just seven US tech stocks have driven all of the positive S&P 500 returns so far this year, according to analysts at Barclays.
 Zooming out further, if bitcoin is the dollar hedge that its enthusiasts claim it to be, then it faces stiff headwinds from a “higher for longer” Fed and rising US yields that are pushing the dollar higher again.
 Analysts at retail trading research firm Vanda Research pointed out that while retail investors have only been “marginal” participants in the recent AI and tech boom, they have turned even cooler on crypto assets.
 Their flows data show that rotation out of crypto stocks into AI names has pushed crypto inflows to the post-pandemic lows, down to US$3.6mil (RM16.5mil) a day from comfortably over US$10mil (RM46mil) a day a few weeks earlier.
 “Should AI stocks’ outperformance extend further, we anticipate retail traders will start chasing other names more aggressively, further reducing the demand for crypto names,” Vanda analysts wrote last week.
 Vanda’s Marco Iachini said he is surprised cryptocurrencies have not followed tech higher. They will catch up at some point, but not before the AI rally broadens out to smaller cap tech and growth stocks first.
 How much can bitcoin rally? Standard Chartered analysts reckon it could reach US$100,000 (RM460,000) by the end of 2024. 
 The so-called “crypto winter” may have passed, but it would require a dramatic turnaround in investor sentiment and crypto usage for that to become reality. — Reuters
 Jamie McGeever is a columnist for Reuters. The views expressed here are the writer’s own.",bitcoin momentum gear strong positive correlation technology stock tech growth stock week broken bitcoin day correlation week negative month correlation mega tech growth equity negative burst investor optimism boom artificial intelligence chatgpt software microchip technology transformational economy surge tech crypto coat tail peaked mid april gain trading gain billion dollar tech week volume matt weller analyst reason bitcoin boom chatgpt crypto instant mass market product huge adoption rate crypto luster gold rush rush magnificent bitcoin crypto asset technology stock tandem assumption fundamental disruptive growth efficient economy weller divergence april united tech giant report beating quarterly april nyse fang tech growth stock time broader nasdaq bitcoin hand erratic trading mega tech bitcoin boat boom momentum rise bond yield discount rate bitcoin underperformance tech investor tech stock positive return analyst bitcoin dollar hedge enthusiast stiff headwind yield dollar analyst trading firm retail investor marginal participant tech boom cooler crypto asset data rotation crypto stock crypto inflow pandemic low mil day mil day week stock extend anticipate retail trader name demand crypto name analyst week vanda marco iachini cryptocurrencies catch rally broadens tech growth stock chartered analyst reach crypto winter require dramatic turnaround investor sentiment crypto usage reality reuters columnist reuters view writer,"[(3, 0.9957697)]",3
552224,StarBiz,9,02/06/2023,Why are AI chip stocks soaring? Is the rally sustainable?,,"SINGAPORE: Chipmaker Nvidia briefly touched a stock market valuation of US$1 trillion (RM4.6 trillion) on Tuesday, making it the first chipmaker to hit that major milestone.
 The shares began trading at around US$397 (RM1,831) apiece on Wednesday, giving it a market valuation of US$988.7bil (RM4.56 trillion).
 Fewer than 10 stocks have ever topped the US$1 trillion threshold, and with Nvidia’s milestone, it joins Alphabet and Amazon.com among US companies currently trading above this level. 
 Both Apple and Microsoft are valued above US$2 trillion (RM9.2 trillion).
 Buoyed by a surge in demand for artificial intelligence (AI) technology, Nvidia shares have soared by about 180% so far this year.
 Meanwhile, the Philadelphia Stock Exchange Semiconductor Index, which includes Nvidia and other AI semiconductor heavyweights such as Taiwan Semiconductor Manufacturing and Broadcomm, is up more than 40%.
 In comparison, the tech-heavy Nasdaq Composite Index is up by just over 25%.
 Nvidia is now the world’s biggest maker of the specialised chips needed to power generative AI, a new generation of AI technology.
 Demand for the chips was triggered by the viral success of ChatGPT, a generative AI chatbot that can understand the context of complex queries and generate coherent answers in a conversational, human-like manner.
 Last week, Nvidia issued an AI-fuelled sales forecast of US$11bil (RM51bil) for its second quarter, beating Wall Street targets by a long mile and resulting in its value jumping by US$184bil (RM845bil) in a single day.
 During its earnings call, the company said generative AI is driving exponential growth in computing requirements, which in turn drove demand for its specialised graphics chips. 
 It claimed that the chips can handle AI workloads better than standard processors.
 Nvidia chief executive Jensen Huang has since also unveiled an AI supercomputer platform that will help tech companies create their own versions of ChatGPT.
 Nvidia’s share price rally has lifted other AI semiconductor stocks, such as Advanced Micro Devices and Marvell Technology, which are up by 92% and 75% respectively since the start of the year.
 Prices of shares in companies like Microsoft, Alphabet and Meta, which have invested in generative AI, have also risen.
 AEM Holdings was among the beneficiaries of the AI rally in the United States.
 Shares of the firm, which provides testing equipment and services to the semiconductor industry, have risen by 12.5% over the past week to close at S$3.60 (US$2.60 or RM12) on Wednesday.
 In a recent business update on May 11, AEM said: “Recent excitement over generative AI, such as ChatGPT, is fuelling the demand for AI-focused semiconductor devices to enable these solutions to be delivered to the masses at economically feasible rates.”
 AEM noted that this would, in turn, drive demand for its products and services.
 UMS Holdings saw its shares rise by over 8.7% in the past week, to S$1.06 (RM3.62) on Wednesday. 
 It provides equipment manufacturing and engineering services to the semiconductor industry.
 Both AEM and UMS are among the most heavily traded tech stocks on the Singapore Exchange.
 Experts agreed that demand for generative AI will only grow in the years to come.
 Associate Prof James Pang, co-director of the NUS Business Analytics Centre, said the current surge in demand for generative AI is warranted and is not just hype.
 “Generative AI is a big improvement for AI as a whole as it can be used across industries,” he said, adding that over the longer term, it will transform content generation functions and that companies could develop their own generative AI models to raise efficiency.
 Laurence Liew, director of AI innovation at AI Singapore, a national AI programme launched by the National Research Foundation Singapore, said AI will continue to be a rapidly growing field with a wide range of potential applications such as in education, construction, healthcare and finance.
 “Other parties along the value chain will also enjoy the growth of this sector including data centre providers, cloud providers, and hardware vendors like Nvidia, Intel and AMD,” he said.
 But Nirgunan Tiruchelvam, head of consumer and Internet at Aletheia Capital, warned that investors who want to bet on this space should watch out for share price volatility arising from events such as the US debt ceiling debate and avoid getting over-excited about the recent rally in stock prices.
 “While there is no doubt that AI companies will perform well in the long term, investors should avoid placing their bets on single stocks and go for exchange-traded funds with AI exposure to better manage the risks.” — The Straits Times/ANN",chipmaker nvidia stock market valuation tuesday chipmaker major share wednesday market valuation bil fewer stock threshold milestone alphabet amazon company level apple microsoft surge demand artificial intelligence technology nvidia share stock exchange semiconductor nvidia semiconductor heavyweight semiconductor manufacturing broadcomm comparison tech heavy nasdaq composite nvidia biggest maker chip power generative generation technology demand chip viral success chatgpt generative chatbot context complex query coherent answer conversational human manner week sale bil bil quarter wall street target bil bil single day earnings call company generative exponential growth requirement drove demand graphic chip chip workload standard processor chief executive jensen huang supercomputer platform tech company version nvidia share price rally semiconductor stock micro device technology start price share company generative risen aem holding beneficiary united share firm equipment service semiconductor industry week wednesday business update aem excitement generative chatgpt demand semiconductor device enable solution mass feasible rate drive demand product service ums holding share week wednesday equipment engineering service semiconductor industry aem ums tech stock exchange expert demand generative associate prof james director nu business analytics current surge demand generative hype generative improvement industry term transform content generation function company generative model efficiency laurence liew director innovation national programme national foundation singapore field wide range potential application education construction healthcare finance party chain growth sector data centre provider provider vendor intel amd nirgunan tiruchelvam head consumer internet aletheia capital investor space watch share price volatility event debt ceiling debate avoid rally stock price doubt company term investor bet single stock exchange fund exposure manage strait time,"[(1, 0.72339743), (4, 0.27403653)]",1
552228,StarBiz,12,02/06/2023,AI tech rally masks ‘violent rotations’,Fear of missing out a cause for concern in options market,"NEW YORK: A handful of megacap technology stocks have propped up equity markets for the past several weeks as hype surrounding artificial intelligence (AI) lures in sidelined investors.
 But the fear of missing out on the rally is becoming cause for concern in the options market, says RBC Capital Markets’ head of derivatives strategy Amy Wu Silverman.
 The Nasdaq 100 index is up about 30% this year thanks to heavier weights in seven stocks: Apple Inc, Microsoft Corp, Alphabet Inc, Amazon.com Inc, Meta Platforms Inc, Tesla Inc and Nvidia Corp –the sole chipmaker in the group which is nearing US$1 trillion (RM4.6 trillion) in market capitalisation. 
 When benchmark moves are driven by only a handful of stocks, “it messes with how you look at correlation in the markets and thereby it messes with what options seem to tell you,” Silverman said on Bloomberg Television. 
 “It seems to tell you that things are resilient when the reality is there can be very violent rotations under the surface that is masked because of the narrowness of breadth in the market right now.”
 Silverman says the rush to tech has driven demand for call options higher than that for bearish puts as investors increasingly use derivatives as a way to place big bets on tech. That demand has lifted the cost of bullish options related to the Nasdaq 100, along with expected volatility. 
 “This is the exact phenomenon that we saw in GameStop, that we saw in AMC, that we saw in Salesforce,” Silverman said. 
 “And when that happens, you can get such outsized moves that it also forces other people who are underallocated to pay attention.”
 Silverman says markets are pricing in “a little bit more relief” due to a potential debt ceiling resolution, and that’s been reflected by a subdued readings on Wall Street’s fear gauge, the Chicago Board Options Exchange Volatility Index or VIX, but the liquidity drain as a result of a debt deal could cause a “regime shift” in volatility. 
 “What’s happening real time is most folks are actually rolling off some hedges they had on. But that doesn’t speak to what I think would be a longer term concern – when you see liquidity being pulled out of the market in force.” — Bloomberg",york handful megacap technology stock equity market week artificial intelligence lure investor rally concern option market capital market derivative strategy silverman heavier weight stock apple corp alphabet amazon meta platform corp sole chipmaker market capitalisation benchmark move handful stock correlation market option silverman television resilient reality violent rotation masked narrowness breadth market silverman rush tech demand call option bearish investor bet tech demand cost bullish option volatility exact phenomenon gamestop amc salesforce silverman move force people underallocated pay attention silverman market bit relief potential debt ceiling resolution reading street fear gauge chicago board option volatility vix liquidity drain result debt deal regime shift volatility real time folk hedge term concern liquidity market force bloomberg,"[(3, 0.9925872)]",3
552282,Main,26,02/06/2023,Code of conduct on AI soon,"EU, US feel ‘fierce urgency’ needed to curb potential risks","Stockholm: The European Union and the United States said Wednesday that they would soon release a voluntary code of conduct on artificial intelligence, hoping to develop common standards among democracies as China makes rapid gains.
 Both political and technology industry leaders have been warning of the growing risks as AI takes off, with potentially wide-ranging effects on privacy and other civil liberties.
 After talks with EU officials in Sweden, US Secretary of State Antony Blinken said that Western partners felt the “fierce urgency” to act and would ask “like-minded countries” to join the voluntary code of conduct.
 “There’s almost always a gap when new technologies emerge,” Blinken said, with “the time it takes for governments and institutions to figure out how to legislate or regulate”.
 European Commission Vice President Margrethe Vestager added that a draft would be put forward “within weeks”.
 “We think it’s really important that citizens can see that democracies can deliver,” she said.
 She voiced hope “to do that in the broadest possible circle – with our friends in Canada, in the UK, in Japan, in India, bringing as many onboard as possible”.
 Sam Altman, whose firm OpenAI created the popular ChatGPT bot, took part in the talks of the Trade and Technology Council between the EU and the United States, hosted this year in the northern Swedish city of Lulea.
 The forum was set up in 2021 to try to ease trade frictions after the turbulent US presidency of Donald Trump but has since set its sights largely on artificial intelligence.
 In a joint statement released by the White House and the European Commission, the two sides called AI a “transformative technology with great promise for our people, offering opportunities to increase prosperity and equity”.
 “But in order to seize the opportunities it presents, we must mitigate its risks,” it said.
 It said experts from the two sides would work on “cooperation on AI standards and tools for trustworthy AI and risk management”.
 They also discussed how to work together on sixth-generation mobile technology, an area in which Europeans have taken an early lead. — AFP",stockholm european union wednesday release voluntary code conduct artificial intelligence common standard democracy rapid gain political technology industry leader risk wide effect civil liberty talk official secretary antony western partner urgency country voluntary code conduct gap technology blinken time government institution legislate regulate european commission vice president margrethe vestager draft week democracy hope broadest circle canada japan india onboard sam altman firm popular chatgpt bot talk technology council hosted northern swedish city lulea forum ease trade friction turbulent presidency donald trump sight artificial intelligence joint statement white house european commission transformative technology promise people opportunity prosperity equity seize opportunity risk expert cooperation standard tool trustworthy risk management sixth generation technology european afp,"[(3, 0.9924564)]",3
552334,Main,32,02/06/2023,AI can help tennis players block death threats and other social media hate,,"FRANCES Tiafoe says he receives death threats via social media after he loses professional tennis matches. Jessica Pegula says the same. So does Donna Vekic – directed at just her or her family, too.
 “Everybody gets them after a loss,” said Tiafoe, a 25-year-old from Maryland who was scheduled to play in the French Open’s second round yesterday and was a semi-finalist at last year’s US Open.
  “It’s just how society is today. I know how that affects people’s mental health. That’s very real.”
 Sloane Stephens, the 2017 champion at Flushing Meadows and 2018 runner-up at Roland Garros, says she often deals with racist messages directed at her online, and said some prompted the FBI to investigate.
 “It’s obviously been a problem my entire career. It has never stopped,” said Stephens, who is black. 
 “If anything, it’s only gotten worse.”
 In a bid to try to protect athletes from that sort of abuse at Roland Garros during the 15-day Grand Slam tournament that ends June 11, the French Tennis Federation (FFT) are paying a company to provide players with software that uses artificial intelligence to block these sorts of negative comments.
 Every contestant in every category – singles, doubles, juniors, wheelchair competitors and so on, for a total of around 700 to 800 – is allowed free access to Bodyguard.ai for use on Twitter, Instagram and Facebook. A few dozen players had signed up for the service as of the start of this week, according to Bodyguard.“This is really important for us: for the players to be very comfortable and be able to focus on the competition. Tennis is mental. It’s really what you have in your mind that counts; you’re making 1,000 decisions during a match,” said FFT CEO Caroline Flaissier, who put the cost to the federation at somewhere between US$30,000 (RM138,000) and US$50,000 (RM231,000).
 “We know that there is a lot of cyberbullying,” she said. 
 “We have to address that major issue, so we thought let’s do a test.”
 That includes monitoring social media used by the FFT and the French Open itself. An FFT spokeswoman said on Wednesday that 4,500 messages had been deleted out of the 79,000 received on those accounts since May 21.
 Yann Guerin, head of sports for Nice-based Bodyguard, said the company’s software – which is constantly updated by employees who might notice new words or emojis that should be part of the screening – needs less than 100 milliseconds to analyse a comment and delete it if it’s “hateful or undesirable.” 
  He cited the example of one player who participated in qualifying rounds last week, before the start of the tournament proper.
 “He lost ... so he was disappointed. Then he checked his phone and was like, ‘Whoa,’” Guerin said, estimating that more than 70% of the comments that athlete received would fall under the heading of “toxicity.” — AP",france death threat social medium professional tennis match pegula donna vekic family loss tiafoe maryland play french round yesterday finalist society people health real sloane stephen champion meadow runner garros deal message online fbi investigate entire career stephen black worse bid protect sort abuse roland garros day grand slam tournament june french tennis federation fft company provide player software artificial intelligence block sort negative comment contestant category single junior wheelchair competitor allowed free access bodyguard twitter instagram facebook dozen player start week bodyguard player comfortable focus competition tennis mental mind decision fft ceo caroline flaissier cost federation lot address major issue test social medium fft french fft spokeswoman wednesday message received account guerin head sport bodyguard company software employee millisecond analyse comment delete hateful undesirable player round week tournament proper disappointed phone whoa guerin comment athlete fall toxicity,"[(3, 0.9937432)]",3
551770,Lifestyle,16,01/06/2023,Revolutionising education with AI,,"RAPID advancements in artificial intelligence (AI) have transformed multiple industries, and education is no exception. AI-powered tools like ChatGPT, developed by OpenAI, have the potential to greatly enhance the learning experience for  students and provide valuable support  for educators.
 One of the most significant benefits of using AI in education is personalised learning. ChatGPT, a large language model, has the potential to revolutionise this aspect of education by offering individualised support to students. 
 By analysing the learning needs, interests and pace of each student, AI-driven platforms such as ChatGPT or any other customised instructional chatbots can  provide customised content, learning resources and feedback. This personalised approach allows students to learn at their own speed and develop a deeper understanding of subjects. 
 AI can assist educators by automating repetitive tasks such as grading assignments, quizzes and examinations. 
 By leveraging AI algorithms, ChatGPT can evaluate students’ work and offer instant, detailed feedback, freeing up  valuable time for educators to focus on more critical aspects of their role, such as lesson planning and student mentoring. 
 Another compelling aspect of AI in teaching is the facilitation of collaborative learning. AI-based teaching and learning platforms can be used as virtual teaching assistants, enabling students to engage  in group discussions, brainstorming  sessions, and collaborative problem- solving activities. 
 AI-driven platforms can guide these interactions by offering insights, suggesting resources, and moderating discussions, thereby fostering a dynamic and engaging learning environment. 
 Incorporating AI in assessment methods presents numerous possibilities for enhancing the evaluation process. Traditional assessments often focus on a limited range of skills and may not provide a comprehensive understanding of a student’s abilities. With AI, educators can create more diverse and dynamic assessments that evaluate students’ critical thinking, problem-solving and creativity. 
 ChatGPT, for example, can be utilised to generate customised questions, simulate real-world scenarios or provide real-time feedback on performance, enabling a more accurate and holistic assessment of students’ capabilities. 
 In addition to teaching and learning, AI can also play a crucial role in educational administration. 
 For instance, OUM is currently developing an AI-driven system that utilises machine learning to identify new learners at risk of dropping out. By doing so,  the university can provide targeted  counselling and support, ultimately improving retention rates.
 Despite the benefits, there are challenges and ethical considerations in adopting AI in teaching and assessment. Concerns surrounding data privacy, algorithmic bias, and the potential for AI to replace human educators must be addressed as the technology continues to evolve. 
 Establishing guidelines, maintaining transparency, and close collaboration among stakeholders, especially educators and policymakers, will be crucial in ensuring that AI is employed responsibly and ethically in the education sector. 
 Furthermore, with the emergence of ChatGPT, it is essential for educators to explore innovative assessment models to better evaluate student learning.
 AI-powered tools like ChatGPT have the potential to revolutionise teaching and assessment by offering personalised learning experiences, automating administrative tasks, and enabling more comprehensive evaluation of students’ skills. 
 Embracing these innovations, while navigating the ethical considerations, promises to create a more efficient, engaging, and effective educational landscape for future generations. 
 The future of higher education will involve a close collaboration between humans and AI-based educational tools. In fact, the role of human instructors can be distributed between the human instructors and the AI-driven platforms. 
 In the future, instruction could be the product of both human instructors and AI-based educational tools, with each playing a complementary role. For example, a human instructor can produce learning content while AI–based platforms provide continuous support to students. 
 This synergy and relationship between both would allow the human instructor to stop carrying out repetitive mechanical tasks as these can be performed by AI-powered educational tools. This will enable the instructor to devote time to high cognitive level tasks which are more creative instead.
 We are further exploring AI capabilities at Open University Malaysia (OUM), which is a digital university providing flexible part-time studies through online learning for working adults. An AI-powered chatbot, developed in-house by OUM for a Java programming course, was recently linked with ChatGPT for enhanced user experience, personalised learning, and real-time assistance. 
 The early version of the chatbot was honoured with a merit award at the prestigious MSC Malaysia APICTA 2019 Awards ceremony.
 The selection of programmes is abundant at OUM, with 55 programmes under four faculties – education; business and management; technology and applied sciences; and social sciences and humanities. 
 Earlier this year, the university was awarded the full five stars in the online learning category by Quacquarelli Symonds (QS), the world’s most influential and credible ratings for universities globally. 
 Previously, the university had won gold at the Putra Aria Brand Awards 2022 in the education and learning category. The award was presented to OUM by the Association of Accredited Advertising Agents Malaysia for being one of the most recognisable education brands for Malaysians. 
 n For information on OUM programmes, call the speedline at 03-7801 2000, e-mail enquiries@oum.edu.my, or log on to  www.oum.edu.my.
 * Written by Assoc Prof Dr Nantha Kumar Subramaniam, OUM Faculty of Technology and Applied Sciences deputy dean.",rapid advancement artificial intelligence multiple industry education exception tool chatgpt openai potential enhance experience student valuable support educator benefit education chatgpt language model potential revolutionise aspect education offering individualised support student pace student platform instructional chatbots content resource approach student speed subject assist educator repetitive task assignment quiz examination algorithm chatgpt evaluate student instant detailed feedback valuable time educator critical aspect role lesson student aspect facilitation collaborative learning platform virtual teaching assistant student engage discussion session collaborative activity platform interaction insight resource discussion dynamic environment assessment method numerous possibility evaluation process traditional assessment focus range skill comprehensive understanding student ability educator diverse dynamic assessment evaluate student critical creativity chatgpt utilised generate question real scenario real time feedback performance accurate holistic assessment student capability addition play crucial role educational administration instance system machine identify learner university support retention rate benefit challenge ethical consideration assessment concern data privacy algorithmic bias potential human educator technology guideline transparency close collaboration stakeholder policymakers crucial education sector emergence chatgpt essential educator innovative assessment model student tool potential revolutionise assessment offering learning experience administrative task comprehensive evaluation student innovation ethical consideration promise efficient effective educational landscape future generation future education close collaboration human educational tool role human instructor human instructor platform future instruction product human instructor educational tool complementary role human instructor content platform continuous support student relationship human instructor repetitive mechanical task educational tool enable instructor devote time cognitive level task creative capability university malaysia digital university flexible time study adult chatbot house oum java programming chatgpt user experience real time assistance version chatbot merit prestigious msc apicta award ceremony selection programme abundant oum programme faculty education business management technology science social science humanity university star category quacquarelli symonds influential credible rating university university gold putra aria brand award education category award oum association advertising agent recognisable education brand malaysian programme speedline mail enquiry assoc prof nantha kumar subramaniam faculty technology science deputy dean,"[(0, 0.12214592), (3, 0.8759056)]",3
551828,StarBiz,14,01/06/2023,Cathie Wood forecasts software stocks as next AI bet after Nvidia,,"NEW YORK: Cathie Wood says software providers will be the next to ride on the artificial intelligence frenzy driven by Nvidia Corp.
 “We are looking to the software providers who are actually right now where Nvidia was when we first bought it,” Wood, chief executive officer and founder of Ark Investment Management LLC, told Bloomberg TV.
 While Nvidia is expected to do well over time, Ark is “onto the next thing”, she added.
 Wood’s flagship ARK Innovation ETF cut its holding in Nvidia in January and has missed out on an epic rally that made the chipmaker briefly cross US$1 trillion (RM4.6 trillion) in market valuation.
 Wood has defended her decision to dump Nvidia stocks, citing concerns over the computer chip industry’s boom-bust cycle and said it was “priced ahead of the curve” in a tweet earlier this week.
 Instead, Wood is betting on software stocks that she expects to eventually grow into the size of Nvidia, citing UiPath Inc, Twilio Inc and Teladoc Health Inc as key examples. Wood’s funds hold all three stocks.
 “For every dollar of hardware that Nvidia sells, software providers and SaaS providers will generate US$8 (RM36.94) in revenue,” Wood told Bloomberg TV.
 Wood is betting on a trio of companies that have fallen far off their highs.
 New York-based UiPath rose to more than US$85 (392.44) a share after going public in 2021 and has tumbled about 80% since.
 San Francisco-based Twilio has dropped 85% from its peak in 2021, while Teladoc Health is off more than 90% from its high the same year.
 Ark Innovation ETF has lost more than 10% since its peak in early February, while the Nasdaq 100 Stock Index has jumped 12% over the period.
 Wood reiterated that Tesla is the “biggest artificial intelligence play” and expected its stock price to reach US$2,000 (RM9,234) in 2027 on autonomous technology from around US$200 (RM923) currently.
 “Autonomous taxi platforms, we believe globally, will deliver US$10 trillion (RM46.2 trillion) in revenue from almost zero by 2038,” she said on Bloomberg TV.
 “Tesla, many people think, is an auto stock. We don’t. We think it’s much more than that.”
 On China, Wood said the “common prosperity” policy agenda there means companies expanding into the country will have to give up on margins if they want that opportunity of scale. — Bloomberg",york cathie wood software provider artificial intelligence driven nvidia corp software provider wood chief executive officer founder ark investment management llc bloomberg time ark wood flagship ark innovation etf january chipmaker cross market valuation wood decision dump nvidia stock concern computer chip industry boom bust cycle tweet week wood software stock grow size nvidia uipath twilio teladoc health key example wood fund stock dollar hardware nvidia software provider provider revenue wood bloomberg wood trio company high york uipath share public san francisco twilio peak teladoc health ark innovation etf peak february nasdaq stock period wood tesla biggest artificial intelligence play stock price reach autonomous technology autonomous taxi platform revenue bloomberg tesla people auto stock china wood common prosperity policy agenda company country margin opportunity scale bloomberg,"[(4, 0.9929771)]",4
551546,StarBiz,9,31/05/2023,AI likely to unlock big opportunities  in Indonesia,,"JAKARTA: Most artificial intelligence (AI) development is happening elsewhere for now, but investors in Indonesia and abroad are ready to pounce on the cutting-edge technology it promises to unlock in South-East Asia’s largest economy.
 The country’s macroeconomic trends, coupled with a relatively young and increasingly tech-savvy population, are seen as creating endless opportunities for homegrown startups to adopt as well as advance AI.
 The use of AI is growing each day, and, according to a study conducted by US-based management consulting firm Kearney, AI could contribute US$1 trillion (RM4.6 trillion) to the Asean economy by 2030.
 Local and regional venture capital firms (VCs) interviewed by The Jakarta Post are enthusiastic about AI supercharging business activity in Indonesia.
 “With the right business model and products, AI solutions can definitely be good investment opportunities,” said Edward Ismawan Chamdani, managing partner at VC outfits Gayo Capital and Ideosource. “There will definitely be money coming in from AI projects.”
 He added that, while the world’s largest tech companies had been created during downturns, as new problems and inefficiencies became more apparent, “investors will always see the potential market size and whether the pie is big enough to support the growth story”.
 Livinglab Ventures vice-president of investment Edmund Carulli said: “It makes sense to invest and try out new technology such as AI in Indonesia. The upside will still be far above the risk of failing.”
 Openspace vice-president Tania Lestari concurred: “AI has been one of the key themes we identified as a space with huge growth potential in the next few years.”
 Openspace has invested in Datature, a Singapore-based no-code end-to-end machine learning operations platform, which it believes addresses a big pain point of scarce and expensive AI talent at smaller enterprises or traditional enterprises new to AI development.
 Edmund explained that venture investment played an important role in pushing AI innovation. 
 “More investment in this area means accelerated growth and adoption will happen sooner than later.” — The Jakarta Post/ANN",jakarta artificial intelligence development investor ready pounce edge technology unlock south east largest economy country macroeconomic trend tech savvy population endless opportunity startup advance day study management firm kearney contribute asean economy local regional venture capital firm jakarta post enthusiastic business activity indonesia business model product solution investment opportunity ismawan chamdani partner outfit capital ideosource money project largest tech company downturn inefficiency apparent investor potential market size pie support growth story livinglab venture vice president investment edmund sense invest technology indonesia upside risk openspace vice president tania lestari key theme space huge growth potential openspace datature singapore code machine operation address scarce expensive talent traditional enterprise development edmund venture investment role innovation investment growth adoption sooner jakarta post ann,"[(1, 0.99294275)]",1
551558,StarBiz,11,31/05/2023,Arm chief pitches  chip designer  as AI play  in IPO build-up,,"LONDON: Semiconductor designer Arm Ltd has found its calling card for the rest of the year as it builds towards a much-anticipated initial public offering (IPO): artificial intelligence (AI).
 Arm technology is enabling many AI applications already taken for granted, and it will be fundamental to building the next wave of AI innovations, chief executive officer Rene Haas said in a keynote address at the Computex trade show in Taiwan.
 AI has swept across the global tech industry this year, juicing stock prices and propelling Nvidia Corp to the brink of becoming the first trillion-dollar chipmaker.
 Arm, in search of a lofty valuation to satisfy parent SoftBank Group Corp (SBG), is looking to present itself as another avenue for investors to tap into this vein of tech optimism.
 “Given the chase for AI stocks, we think SBG may like to present Arm as an AI play, although most of its current business is based on designing and licensing semiconductor intellectual property, particularly for mobile devices,” said Jefferies analyst Atul Goyal.
 Citing examples from Amazon.com Inc’s Alexa voice assistant and Alphabet Inc’s Google Pixel phones to smart traffic light management and robotic beehive maintenance, Haas made the argument that on-device and small-scale AI processors will all run Arm technology.
 He also pointed to Nvidia’s Grace Hopper next-generation architecture for accelerating AI as another example of Arm technology in the AI supply chain.
 It was the one future product that Haas could talk about, he said, since Nvidia had just discussed it a day prior. Haas was otherwise tight-lipped about Arm deployments to come due to his company’s quiet period ahead of an IPO.
 Arm still intends to go public by the end of the year, a spokesperson confirmed on Monday. — Bloomberg",london semiconductor designer arm card rest build initial public offering ipo artificial intelligence arm technology application fundamental building wave innovation chief executive officer rene haas keynote address computex trade taiwan global tech industry stock price corp brink dollar chipmaker arm search lofty valuation satisfy parent corp sbg avenue investor vein tech optimism chase stock arm play current business semiconductor intellectual property mobile device jefferies analyst goyal example alexa voice assistant alphabet google pixel phone smart traffic light management robotic beehive maintenance haas argument device scale processor technology nvidia grace hopper generation architecture arm technology supply chain future product haas talk day haas tight arm deployment company quiet period ipo arm public spokesperson monday bloomberg,"[(3, 0.6775557), (4, 0.3164719)]",3
551068,StarBiz,13,30/05/2023,Baidu shares jump as Ernie Bot progress rekindles AI bets,,"SHANGHAI: Baidu Inc shares jumped in Hong Kong following reports that it will soon launch a large-language model to power its ChatGPT-Like app Ernie Bot. 
 The shares rose as much as 6% before trimming as chief executive officer Robin Li was cited as saying that the model will be used to upgrade its search engine. Other artificial intelligence (AI) stocks, including SenseTime Group Inc and Meitu Inc, gained at least 3% each.
 Baidu shares have had a rough ride this year as a rally driven by the hype ahead of Ernie’s demo launch in March faltered on disappointment. 
 The latest development, if successful, could add impetus to the shares and help the firm ride on a renewed global AI frenzy after Nvidia Corp’s surprisingly strong revenue forecast.  
 “Investors have been waiting for an update on Ernie Bot. Also the AI frenzy has spread to China markets yesterday after Nvidia’s good results,” said Steven Leung, executive director at UOB Kay Hian. 
 Hong Kong markets were closed last Friday. 
 Even with yesterday’s gains, Baidu shares are down more than 25% from a February high as its chatbot, China’s first answer to ChatGPT, failed to match high expectations. 
 The Chinese Internet giant debuted Ernie Bot through several pre-recorded videos in March, defying expectations for a real-time demo, and later delayed a press briefing planned to showcase how the chatbot will be integrated into cloud computing service. 
 Investors have also questioned Baidu’s ability to launch a Chinese language AI model. A Baidu spokesperson declined to comment further when contacted by Bloomberg yesterday.   
 Baidu was one of the best performers on the Hang Seng gauge of Chinese tech shares, which reversed a 1.6% rise. Baidu shares pared its advance to less than 3% in Hong Kong. — Bloomberg",shanghai baidu share kong report launch language model power chatgpt app ernie bot share chief executive officer robin model upgrade search engine artificial intelligence stock sensetime meitu baidu share rough hype ernie demo launch march disappointment development successful add impetus share firm ride global frenzy nvidia corp strong revenue forecast investor update ernie bot frenzy spread china market yesterday steven leung executive director uob kay hian hong kong market friday yesterday gain baidu share february chatbot china answer chatgpt match expectation chinese internet giant ernie bot pre march expectation real time demo press briefing planned showcase chatbot cloud service investor baidu ability launch chinese language model baidu spokesperson comment bloomberg yesterday performer seng gauge chinese tech share rise baidu share advance hong kong bloomberg,"[(0, 0.59064645), (3, 0.40410063)]",0
550800,Main,15,29/05/2023,AI learning how to push our buttons,Ressa: Releasing it into the wild ‘like open-sourcing the Manhattan Project’,"Artificial intelligence (AI) is magnifying exponentially the fear, anger and hate that social media has already weaponised, journalist and Nobel laureate Maria Ressa (pic) has warned.
 “If the first generative AI was (about) fear, anger and hate – weaponising those – this one now leads to weaponising intimacy,” Ressa, who won the Nobel Peace Prize in 2021 with Russian journalist Dmitry Muratov for standing up to authoritarian regimes, told The Straits Times.
 Ressa, who founded the Philippine online news site Rappler, was in Singapore this weekend for the New.Now.Next Media Conference organised by the Asia chapter of the Asian American Journalists Association.
 It was hosted at Google’s Singapore office from Thursday to Saturday.
 She said the first iteration of AI – seen in machine-learning programmes – was meant to get users addicted to scrolling through social media, so that companies such as Facebook and Twitter could make more money from targeted ads and harvested data.
 But what these programmes learnt was that lies “spread six times faster than really boring facts”, she said, adding that the algorithms that power social media platforms keep churning out lies.
 “What that does to you is that... it pumps you with toxic sludge – fear, anger, hate – and when you tell a lie a million times, it becomes a fact,” Ressa said.
 This, she said, has helped populist and autocratic leaders rise to power.
 Ressa and Rappler had been in the crosshairs of a strongman,  Rodrigo Duterte, who was elected President of the Philippines in 2016. He was aided by a massive social media campaign that pushed his populist platform, anchored by anti-crime rhetoric.
 She is currently facing civil and criminal cases lodged by the Justice Ministry and regulators under Duterte that she sees as retaliation by the former president for Rappler’s critical coverage of his brutal war on the narcotics trade.
 His anti-drug crusade led to over 20,000 suspects killed in police raids or by unnamed vigilantes.
 Ressa added that the impact goes beyond politics, citing a report issued by United States Surgeon-General Vivek Murthy last Tuesday that showed growing evidence that social media use may seriously harm children.
 Dr Murthy said while social media can help children and adolescents find a community to connect with, it also contains “extreme, inappropriate, and harmful content” that can “normalise” self-harm and suicide.
 Ressa said the new generation of AI – chatbots like ChatGPT created by Microsoft-funded OpenAI and Google’s Bard – would be spreading lies even faster, more broadly and more intimately if they are “released into the wild” without guardrails.
 “It’s like open-sourcing the Manhattan Project,” she said, referring to research that led to the development of the atom bomb.
 Wrongly used, she warned, AI would allow “bad actors” to stoke more online hate and violence that could spill over to the real world, prettify the resumes of despots, and serve up even more “micro-targeted”, invasive ads.
 She said even those responsible for coding these chatbots warn that there is a “10% or greater chance that this leads to an extinction-level event, not hitting another species, but humanity”.
 “It’s like releasing something as dangerous as nuclear fission into the hands of people with no guardrails,” she said.
 Ressa said OpenAI’s own chief executive Sam Altman has told US lawmakers about how dangerous AI can be.
 “But no one asked him, ‘If it’s so dangerous, why are you releasing it?,’” she said.
 Microsoft’s chief economist Michael Schwarz has warned of the potential risk of “bad actors” causing “real damage” making use of AI.
 “I’m quite confident that, yes, AI will be used by bad actors, and, yes, it will cause real damage,” he said at an event hosted by the Word Economic Forum on May 3.
 “We have to put safeguards” to prevent hucksters and tyrants from profiting off AI with money-making scams and vote rigging, he said.
 Ressa said AI, as it is shaping up to be, has to be reined in, along with the rest of the technology sector, which she described as the “least regulated industry in the world”.
 “The problem with a godlike tech is that it is being used for profit – and that’s what we need to stop. This is where governments need to come in and protect their citizens,” she said. — The Straits Times/ANN",artificial intelligence fear anger social medium journalist nobel laureate maria pic generative fear anger hate lead intimacy peace prize russian journalist dmitry muratov authoritarian regime strait time founded philippine online news site rappler singapore weekend medium conference asia chapter asian american journalist association google singapore office thursday saturday iteration machine programme meant user social medium company twitter money ad data programme learnt lie time algorithm power social medium platform lie pump sludge fear anger hate lie time autocratic leader power ressa rappler crosshairs strongman duterte president philippine massive social medium campaign populist platform anti crime rhetoric civil criminal justice ministry regulator retaliation president critical coverage brutal war narcotic trade drug crusade suspect police raid unnamed vigilante impact politics report united surgeon vivek murthy tuesday evidence social medium harm child murthy social medium child adolescent community extreme inappropriate harmful content normalise harm suicide ressa generation chatbots openai google bard lie wild guardrail manhattan project development atom bomb bad actor online hate violence spill real prettify resume micro invasive ad responsible chatbots chance extinction level event specie humanity dangerous nuclear fission hand people guardrail openai chief executive sam altman lawmaker dangerous dangerous microsoft chief economist michael schwarz potential risk bad actor real damage confident bad actor real damage event word economic forum safeguard huckster tyrant money scam ressa rest technology sector industry godlike tech profit government citizen strait time,"[(3, 0.99622166)]",3
551028,StarBiz,10,29/05/2023,UBS: Fake AI content feeding market disruptions,,"NEW YORK: The spread of artificial intelligence (AI) has the potential to be “highly disruptive” to financial markets as the technology aids the publication of false information, and makes leaks of intellectual property more likely, according to analysts at UBS Group AG.
 In an environmental, social and governance (ESG) investing op-ed published Friday, UBS analysts Annabel Willder, Victoria Kalb and Julie Hudson listed all the ways in which the increasing adoption of generative AI might results in a number of ethical issues.
 “Inaccurate information or ‘confabulations’ generated by AI models and that relate to regulators, companies or public figures could be widely shared, with potential market implications,” the analysts wrote.
 Such examples are already starting to appear. 
 Earlier this week, US stocks briefly declined after a falsified photograph of an explosion near the Pentagon went viral across social media platforms. 
 The event stands out as what appears to be the first major instance of an AI-generated image moving markets and comes just months after OpenAI launched ChatGPT, setting off a global race to develop similar services.
 In light of such risks, many banks have placed restrictions around the use of generative AI programmes. 
 Earlier this year, firms including Bank of America Corp, Citigroup Inc, Deutsche Bank AG, Goldman Sachs Group Inc and Wells Fargo & Co banned usage of the tool, with Bank of America telling employees that ChatGPT and openAI are prohibited from business use, Bloomberg reported in February. JPMorgan Chase & Co. has curbed its employees’ use of the ChatGPT chatbot.
 The spread of such technology is likely to make it harder to distinguish between reality and so-called deepfakes, according to the UBS analysts. 
 Risks include the publication of fake videos of chief executives issuing false corporate updates, or of well-known investors announcing adjustments to their holdings, all of which could impact markets, the analysts said. 
 “ESG considerations in light of the increasing adoption of generative AI are significant,” they wrote. 
 “Notably, we believe deepfake and inaccurate information could have significant market impacts if regulators, company representatives or other public figures are misrepresented.”
 At the same time, interest in AI has changed the fortunes of companies behind the technology. 
 Chipmaker Nvidia Corp is on track to reach a US$1 trillion (RM4.60 trillion) market value following an AI-fueled sales forecast, as investors pile into companies that provide components essential to the development and hosting of AI.
 AI systems may become as commonplace as computers, printers and the internet, according to the UBS analysts. —Bloomberg",york spread artificial intelligence potential disruptive financial market technology aid publication false leak intellectual property analyst environmental social governance esg ubs analyst willder victoria kalb julie hudson adoption generative ethical issue confabulation model regulator company public figure potential market implication analyst example week stock falsified photograph explosion viral social medium platform event major instance image market month chatgpt global race service light risk bank restriction programme firm bank corp citigroup deutsche bank goldman sachs fargo usage tool bank employee business bloomberg february jpmorgan chase employee chatbot spread technology distinguish reality deepfakes ubs analyst publication video chief executive false corporate update investor adjustment holding impact market analyst consideration adoption generative deepfake inaccurate market regulator company representative public figure time fortune company technology chipmaker nvidia corp track reach market sale investor pile company component essential development system computer printer ubs analyst,"[(3, 0.99390364)]",3
550236,Lifestyle,22,28/05/2023,Can AI write  pet adoption posts?,"While kids are getting the chatbots to do their homework, pet lovers are using it to generate adoption notices. Here’s how that’s working out.","CHATBOTS have been around for decades, but the launch of new generation tools like ChatGPT and Bing was a game-changer.
 For those who haven’t tried them out yet, chatbots are basically superpowered search engines with added performance.
 If you have a question, a bot will search millions of documents and paste together various bits of them into one coherent answer. It does this in seconds.
 Chatbots can also correct grammar and punctuation. Additionally, they can rewrite information in various styles.
 For rescuers and animal lovers, chatbots offer a wonderful opportunity.Good posts help pets
 “Paws has over 200 cats, 250 dogs and two rabbits looking for a home,” Celine Chum from Paws Selangor points out. 
 “Writing adoption notices is a constant job, and sometimes your brain dries up. I’m interested in any tool that helps.”
 Shannon Lam, KL Pooch Resort & Rescue, Kalumpang, Selangor, agrees. 
 “Writing an engaging post can take 10 minutes, if I’m inspired and not distracted, but more often it takes longer,” she shares. “If there’s a tool, I’m interested!”
 There are general bots like ChatGPT and Bing. Additionally, PetFinder.my also launched PetGPT AI Writer. It’s based on OpenAI ChatGPT technology but has been tweaked to help rescuers and shelters craft creative, engaging pet adoption posts.
 “A good adoption post helps pets,” Andy Koh, co-founder and CEO of PetFinder.my, points out. 
 “But putting that together isn’t easy.
 “We are lucky because a team of five international artificial intelligence experts volunteered to help. They’re hot on improving animal welfare, and so they contributed their data skills.”
 Working together, they spent two months on the project.
 “In the past, we analysed 20,000 posts for a contest,” Koh explains. “We used that as a base and sorted information according to sentiment, keywords and overall tone. We put together rules for styles and introduced a random element.”
 Each person who uses the tool gets different sentences but with some similar keywords.
 “It’s experimental,” Koh says. “We don’t know yet how effective it will be. It’s a first step.”How it works 
 Users register on PetFinder.my and click through to PetGPT. Typing into the box, write a minimum of 100 characters, that’s two or three sentences, about the pet’s name, looks, character and needs. Then select for tone, style and perspective.
 The writer can write in nine different tones: affectionate, witty, hopeful, compassionate, funny, sarcastic, sad, desperate or ecstatic. It also offers six styles: descriptive, persuasive, academic, fantasy, poem, or Q&A. You can write as the pet or the human. Finally, there’s a standard 300-word option or a compact 80-word option.
 Although English is recommended, it also works in BM and Mandarin.
 First-hand experience
 Lam shared details of Hazel, a tan female dog with a friendly, energetic attitude looking for a home with a garden. (read story below)
 “For a small rescuer with one ad, the second one is great,” Lam observes. “It’s useful for generating ideas and different styles. And I think it would be helpful for people writing in a second language.
 “But the poetic one, which Malaysian will relate to that? You’d sound like a fruit loop. I don’t think that style is useful.
 “Overall, it’s interesting, but for shelters like ours that do multiple ads a week, it may be repetitive. I make an effort to make adoption notices unique.”
 Chum has tried and tested PetGPT and other services. 
 “They’re convenient,” she shares. “You just type in details and it does the job.
 “I’m getting the best results  by being very specific. Like, I’ll mention a dog really loves  a particular toy, or discuss a  cute habit that a cat has. That helps make it different and stand out.”
 The future
 For now, chatbots are new. ChatGPT and Bing are free  for now, and PetGPT is fee-based.  
 “We have to pay a fee to OpenAI (co-founded by Elon Musk) for every word generated by their system,” Koh explains, “so there is considerable infrastructure cost.”
 “So far we have distributed over RM32,000 of PetGPT credits to rescuers. If they wish to create additional profiles, a small fee of RM0.99 applies, which helps subsidise our infrastructure costs.” 
 With thousands of pets waiting in shelters to be matched with a home, all tools are useful. For now, if you’re struggling with writing posts, AI chatbots are definitely worth a look. 
 And if you have a one-eyed or three-legged pet, or it’s International Pirate Day, the fantasy style might be a winner!",chatbots decade launch generation tool game changer chatbots search engine performance question search million document bit coherent answer chatbots grammar punctuation rewrite style rescuer animal lover wonderful opportunity post paw cat rabbit chum paw selangor adoption notice constant job brain dry lam pooch resort rescue kalumpang selangor post minute distracted share tool bot petgpt writer openai chatgpt technology rescuer shelter creative pet adoption post post pet andy koh founder ceo petfinder easy lucky team international artificial intelligence expert hot animal welfare data skill spent month project post koh base sentiment keywords tone rule style random element person tool sentence experimental koh effective step user petfinder click petgpt box write minimum character sentence character tone style perspective writer tone witty hopeful compassionate funny sarcastic sad desperate ecstatic offer style persuasive academic fantasy poem write pet human standard word option compact word option mandarin hand experience lam detail hazel tan female dog energetic attitude garden story rescuer lam idea style helpful people language poetic malaysian relate sound fruit loop style shelter multiple ad week repetitive effort adoption notice unique chum petgpt service convenient share detail job specific mention dog toy cute habit cat future chatbots free petgpt fee pay fee openai elon musk word system koh considerable infrastructure cost petgpt credit rescuer additional profile applies subsidise infrastructure thousand pet shelter tool post chatbots worth legged pet international pirate day fantasy style winner,"[(4, 0.99580675)]",4
549250,Main,28,25/05/2023,Filmmakers at Cannes grapple with ‘tectonic’ AI shift,,"Cannes: At an artificial intelligence (AI) talk on a Cannes beach, a presenter’s voice is cloned and used to say a random phrase in three languages, while another’s face is replaced live on screen as they speak.
 Few of the film buffs attending the premiere industry festival are shocked.
 Ever since the artificial intelligence chatbot ChatGPT took the world by storm six months ago, spurring an AI race among tech giants, the technology has shaken up the film industry.
 The use of AI to write scripts is one of the leading concerns among Hollywood movie and TV writers who are in their third week of a strike that has upended productions.
 But the technology is revolutionising everything from voice acting, to analysing scripts and coming up with a budget, to creating mock-ups of scenes before you even pick up a camera.
 “New things are created every single day,” says Quinn Halleck, a 25-year-old filmmaker who is about to release a three-part short movie called ./ Sigma_001 which is about a sentient AI being, and uses AI from conception to marketing and distribution.
 But while some assistant roles may disappear, he believes a human director remains essential.
 “You still have to come up with the ideas, you have to create the prompts and curate the answers.”
 The world’s leading film festival, taking place on the French Riviera, got a hefty dose of AI with a lengthy scene de-aging Harrison Ford, 80, in Indiana Jones and the Dial of Destiny.
 While filmmakers are brimming with excitement over the technology’s potential, questions of its abuse hang over the session.
 “This set of technologies represents, you know, a set of tectonic social shifts like the industrial revolution, which will play out over the next 20-50 years and people should be worried about what happens,” Graham says.
 “Unfortunately, I don’t believe that you can stop the advancement of the technology because a lot of it is open source. There’s not really anything to turn off.”
 His advice: “You should try to own and control the rights to your biometric data, how you sound, how you look, and really kind of lock that down.” — AFP",cannes artificial intelligence talk beach presenter voice random phrase language live screen speak film buff industry festival artificial intelligence chatbot chatgpt storm month race tech giant technology film industry write script concern hollywood movie writer week strike production technology voice script budget mock scene camera single day halleck filmmaker release short movie sigma sentient conception marketing distribution assistant role human director essential idea prompt answer film festival french riviera hefty dose lengthy scene harrison ford indiana jones dial destiny filmmaker excitement technology potential question hang session technology tectonic social shift industrial revolution play people graham advancement technology lot source advice control right data sound lock afp,"[(0, 0.72349215), (4, 0.2705628)]",0
548450,StarBiz,4,24/05/2023,AI gold rush will take humanity to dark places,,"SCANNING humanity’s eyeballs in exchange for cryptocurrency and assigning the encoded results to a blockchain is the kind of dystopian idea that might have stoked a speculative boom during the pandemic, before eventually crashing to earth and leaving a trail of angry investors behind.
  But with interest in artificial intelligence (AI) reaching fever pitch, this risky solution to proving personhood in the digital world is gaining new impetus. 
 Worldcoin, backed by luminaries including Marc Andreessen and Sam Bankman-Fried, began as a way to create a valuable token by giving it away to people willing to identify themselves via their biometric data. 
 What the project euphemistically dubs its “field test” phase involved scanning half a million irises using a chrome sphere dubbed “the orb” – prompting myriad accounts of exploitation, invasion of privacy, deception and attempted fraud. The story might have ended there.
 But as crypto winter gives way to a scorching AI summer for tech fundraising, the project is aiming for a new lease on life more aligned with the vision of another Sam – Altman, co-founder of Worldcoin parent organisation “Tools for Humanity.” 
 Those iris scans, converted into unique identifiers, are the centrepiece of a plan to create a “World ID” that can distinguish between people and bots in a future dominated by AI.
 With Altman’s star riding high in the Silicon Valley firmament, the orb is embarking on a world tour accompanied by an app that offers crypto transactions. The Financial Times reports Worldcoin, valued at US$1bil (RM4.5bil)  is close to clinching US$100mil (RM457mil) in additional funding.The full force of tech’s saviour complex is on display here, and regulators and citizens alike need to keep their collective guard up. You don’t have to be a Davos-attending globalist to see the benefits of an Internet with fewer bots and more confirmed humans. 
 But one also doesn’t have to be a hoodie-wearing bitcoiner or privacy activist to see the risks. 
 Even if it can’t be traced back to its originator, an iris scan is sensitive data and handing it over should require informed consent about where it will end up. 
 The Worldcoin Foundation is based offshore in the regulation-lite jurisdiction of the Cayman Islands, its digital-token allocation process is opaque, and its database of 1.7 million iris-originated codes requires faith in the accuracy of its underlying information. 
 Why should anyone value this as a trustworthy digital turnstile for everything from financial services to universal basic income?
 In the same way as techno-solutionists offer AI companions as the answer to loneliness wrought by social media, this proposed fix to the side-effects of AI tools including ChatGPT, the generative software unleashed on the world by Altman’s OpenAI company, threatens to create even more unintended consequences. 
 Already, TechCrunch has reported that hackers have stolen the credentials of several of its elite orb “operators” – essentially recruiters who earn money for every sign-up – even if Worldcoin says no personal user data was accessed. 
 Worldcoin has also confirmed reports that hundreds of iris codes have flooded the dark web, changing hands for cash in territories including China where the startup doesn’t operate. 
 If the best  technology is indistinguishable from magic, the effectiveness of World ID as the best way of defeating malicious bots looks more like an optical illusion.
 Tiago Sada, head of product for Worldcoin, tells me that there has been less consumer resistance than expected to the project, but concedes that the pitch is complicated and “different people like different parts.”He says that today one could make the case that the Worldcoin app is helping humanity by offering crypto transfers, and that in future adding a digital ID could help some countries access financial services.
 Bad press and bad vibes are unlikely to deter Worldcoin’s backers amid an AI gold rush. Another Altman-backed startup, Humane, recently raised US$100mil (RM457mil) despite having neither product nor profit – it says it’s collaborating with OpenAI and will partner with Microsoft Corp’s cloud services. 
 Imagine Worldcoin one day being part of this network, with orbs that are smaller and more ubiquitous than they are today and iris-code checks serving as the Captcha checkers of the AI era and maybe even enhancing OpenAI’s value. 
 The revenue model might involve charging fees for authentication, no doubt inflating the value of Worldcoin tokens for early holders. Not exactly humane for most of us, but aligned with Palo Alto’s worldview of improving humanity through utilitarian, data-driven experiments – even if academic Margie Cheesman calls Worldcoin a “scam-experiment.”
 What happens next will depend on the ability of those orb operators to keep people signing up, whether crypto bros get seduced by the wave of enthusiasm for all things AI-related – and how determined regulators become to lift the hood of Worldcoin. 
 When asked earlier this month when Worldcoin tokens would be distributed, Altman said Americans might “never” get any because of crypto regulation. 
 Clearly dismayed by the state of crypto in the United States, he said: “The Europeans are supposed to do this, but not us.” If the Europeans don’t flex their data-privacy muscles by taking a closer look at those orbs, the AI boom will take humanity to some pretty dark places. — BloombergLionel Laurent is a Bloomberg Opinion columnist covering digital currencies, the European Union and France. The views expressed here are the writer’s own.",humanity eyeball exchange cryptocurrency blockchain dystopian idea speculative boom earth trail angry investor artificial intelligence fever pitch risky solution personhood digital gaining impetus worldcoin luminary marc andreessen sam bankman create valuable token people biometric data project dub field test phase half myriad account exploitation invasion privacy deception fraud story crypto winter scorching summer tech fundraising project lease life vision sam altman founder worldcoin parent organisation tool humanity scan unique identifier plan distinguish people future altman star silicon valley firmament tour offer transaction financial time report bil bil mil additional funding force tech saviour complex display regulator collective guard davos globalist benefit internet fewer bot human bitcoiner privacy activist risk originator iris scan sensitive data require informed consent worldcoin foundation regulation lite jurisdiction cayman digital token allocation process opaque database iris code faith accuracy trustworthy digital turnstile financial service universal basic income techno solutionists companion loneliness wrought social medium effect tool chatgpt generative software unleashed altman company create unintended consequence techcrunch hacker credential orb operator recruiter money sign personal user data worldcoin report hundred code dark web hand cash territory china startup operate technology indistinguishable magic effectiveness malicious bot optical illusion sada head product worldcoin tell consumer resistance project pitch people app humanity offering crypto transfer digital country access financial service bad press bad vibe worldcoin backer gold rush altman startup humane mil mil product profit openai partner microsoft corp cloud service worldcoin day network ubiquitous iris code check captcha checker era openai revenue model fee doubt worldcoin holder humane palo alto worldview humanity utilitarian data experiment academic margie cheesman worldcoin scam experiment depend ability orb operator people crypto bros enthusiasm regulator hood worldcoin month worldcoin token altman american regulation dismayed crypto united european european flex data privacy muscle boom humanity dark bloomberglionel laurent bloomberg opinion columnist digital currency union france view writer,"[(0, 0.20348713), (4, 0.79433554)]",4
548410,StarBiz,12,24/05/2023,Intel shares details on AI chips and shifts strategy,,"NEW YORK: Intel Corp has provided a handful of new details on a chip for artificial intelligence (AI) computing it plans to introduce in 2025 as it shifts strategy to compete against Nvidia Corp and Advanced Micro Devices Inc.
 At a supercomputing conference in Germany on Monday, Intel said its forthcoming “Falcon Shores” chip will have 288 gigabytes of memory and support 8-bit floating-point computation.
 Those technical specifications are important as artificial intelligence models similar to services like ChatGPT have exploded in size, and businesses are looking for more powerful chips to run them.
 The details are also among the first to trickle out as Intel carries out a strategy shift to catch up to Nvidia.
 Intel trails the market in chips for AI, and AMD, in which it is expected to challenge Nvidia’s position with a chip called the MI300.
 Intel, by contrast, has essentially no significant market share after its would-be Nvidia competitor, a chip called Ponte Vecchio, suffered years of delays.
 Intel on Monday said it has nearly completed shipments for Argonne National Lab’s Aurora supercomputer based on Ponte Vecchio, which Intel claims has better performance than Nvidia’s latest AI chip, the H100.
 But Intel’s Falcon Shores follow-on chip won’t be on the market until 2025 when Nvidia will likely have another chip of its own.
 Jeff McVeigh, corporate vice-president of Intel’s supercomputing group, said the company is taking time to rework the chip after giving up its prior strategy of combining graphics processing units (GPUs) with its central processing units (CPUs).
 “While we aspire to have the best CPU and the best GPU in the market, it was hard to say that one vendor at a time was going to have the best combination of those,” McVeigh told Reuters.
 “If you have discrete offerings, that allows you at the platform level to choose both between the ratio and the vendors.” — Reuters",york intel corp handful detail chip artificial intelligence plan shift strategy corp micro device conference germany monday intel falcon shore chip memory support bit computation technical specification artificial intelligence model service exploded size business powerful chip detail intel strategy shift nvidia intel trail market chip challenge nvidia position chip intel contrast market share nvidia competitor chip ponte vecchio delay intel shipment argonne national lab aurora supercomputer ponte intel claim performance nvidia chip intel falcon shore chip market chip jeff mcveigh corporate vice president intel company time rework chip prior strategy graphic unit gpus central unit aspire cpu gpu market hard vendor time combination mcveigh reuters discrete offering level ratio vendor reuters,"[(2, 0.9924631)]",2
547966,Lifestyle,14,23/05/2023,‘Architects don’t need AI’,Renowned British architect says artificial intelligence can’t copy the physicality of the world we live in.,"BRITISH architect Norman Foster has spent six decades pushing the boundaries of technology with awe-inspiring modernist structures from California to Hong Kong, but he is yet to be convinced by the craze for artificial intelligence.
 “Artificial intelligence at the moment has the ability to cheat, to invent,” he said in a recent interview in Paris, which is hosting a retrospective of his work.
 “We live in a world which is physical, we inhabit buildings, streets, squares. That physicality, you can’t replicate by artificial intelligence.”
 Foster has been shaping urban landscapes since the 1960s and won the Pritzker Prize, the equivalent of the Nobel Prize in architecture, in 1999.
 His statement projects include Apple’s giant ring-shaped headquarters in California, London’s Wembley Stadium and Millennium Bridge, and Berlin’s Reichstag.
 Experts describe his practice, Foster and Partners, as possibly the most prolific in history, and the most adept at navigating changing trends and technologies.
 “He conceives architecture almost as an organism balancing itself with the air, the sun, life,” said Frederic Migayrou, curator of the Norman Foster exhibition at the Pompidou Centre in the French capital.
 Yet he has not swerved controversy, irking climate campaigners with his keenness to build airports and his views on the environment.
 Hard facts
 He is a champion of urban living – “people live longer in cities” – but his vision for sustaining urban lifestyles has courted some criticism.
 He supports nuclear power, saying it had not caused a single death and the world would only be able to tackle climate change “with hard facts, not emotion”. 
 He sees it as a vital part of the solution to the deprivation and poverty seen in megacities and overpopulated slums across the world.
 “Many people gravitated to those cities because there are more opportunities,” he said. “The answer has to be an abundance of clean energy, and the cleanest, safest form of energy is nuclear.”
 Hong Kong’s Chek Lap Kok airport, opened in 1998, made a huge splash for his firm, and he has worked on several airports since – much to the annoyance of climate activists, who see air travel as part of the problem.
 Yet when he talks of his broader philosophy, the 87-year-old could easily make common cause with climate activists.
 End of the sprawl
 Surrounded by models of his greatest creations, he talked breezily about the development of cleaner, greener cities.
 The pandemic accelerated a growing need for people to have access to outdoor spaces for eating and strolling, and for services within walking distance of their homes, he argued.
 “The cities which are most popular... they fit that model, essentially it’s a European model born before the ascendency of the automobile,” he said.
 And the transformation of our relationship with cars is central to the reshaping of modern cities, he said.
 “You have younger generations who are less interested in ownership, who will move towards ride-sharing and mobility more as a service,” he said. 
 This was pushing us away from sprawling car-centric cities with rigid work-home zones to ones where buildings were multipurpose, reducing the need for commuting.
 Despite his storied history, Foster, still a central figure in all these threads of modern design, is not keen to dwell on his achievements.
 The Pompidou exhibition, which displays models of his buildings alongside exhibits that inspired their design, has allowed him to see hidden connections.
 But understandably for someone who forged the “high-tech” architectural movement in the 1960s with fellow Briton Richard Rogers, what comes next is always more important than what has already gone.
 “Overall, I’m more excited by the future than I am by the past.” – AFP Relaxnews",british architect norman foster decade boundary technology modernist structure convinced craze artificial intelligence artificial intelligence moment ability cheat invent interview paris retrospective live physical inhabit building street physicality replicate artificial intelligence urban landscape equivalent nobel prize architecture statement project apple giant ring headquarters london wembley stadium millennium bridge berlin reichstag expert practice foster partner prolific history trend technology architecture organism air sun life frederic migayrou curator norman foster exhibition pompidou centre french capital controversy climate campaigner build airport view environment hard champion urban living people city urban lifestyle criticism support nuclear power single death tackle climate change hard emotion vital solution deprivation poverty megacities slum people gravitated city opportunity abundance clean energy cleanest safest form energy nuclear hong kong chek lap kok airport huge splash firm climate activist travel talk philosophy common climate activist model creation development cleaner greener city accelerated people access outdoor space service distance home city popular fit model european model born ascendency automobile transformation relationship car central modern city generation ownership mobility service car centric city rigid zone building storied history foster central figure thread modern design keen dwell achievement pompidou exhibition display model building exhibit design hidden connection tech architectural movement fellow briton richard rogers future afp relaxnews,"[(2, 0.9958126)]",2
547540,StarBiz,9,22/05/2023,AI expected to ease firms’ digital data burden,Faster pace of work a hindrance to innovation,"HANOI: Businesses are all carrying digital debt.
 The volume of data, emails and chats has outpaced their ability to process it all, according to the 2023 Work Trend Index report: “Will AI Fix Work?” newly released by Microsoft.
 The 2023 Work Trend Index surveyed 31,000 people across industries in 31 countries, including Vietnam as well as trillions of signals from emails, meetings and chats across Microsoft 365, plus labour trends on LinkedIn.
 The data showed that the pace of work has accelerated faster than humans can keep up, and it’s impacting innovation.
 The report showed that every minute spent on managing this digital debt is a minute not spent on creative work.
 Specifically, 76% of respondents in Vietnam said they don’t have enough time and energy to get things done – this rate is 64% globally.
 They are 6.6 times more likely to struggle with innovation and strategic thinking.
 Meanwhile, 65% of Vietnamese leaders expressed concerns about the lack of creativity and innovation at work – compared to 60% globally.
 Only 63% of Vietnamese workers consider their presence in meetings necessary – almost twice the global rate (35%).
 In particular, 79% of Vietnamese workers agreed that they cannot maintain concentration throughout the working day.
 According to Microsoft 365 usage statistics, the average person spends 57% of their time communicating and only 43% of their time on creative works.
 The leading cause of productivity loss is ineffective meetings.
 The Authority of Information Technology Application under the Information and Communications Ministry believed that digital data and customers have become the two most valuable assets of businesses in the digital transformation era.
 The competition in the digital transformation era is no longer about prices, but intelligence through deep understanding of customer data.
 With a large volume of digital data, it is not easy to exploit and understand that data.
 Therefore, data processing plays a key role in the overall operation of enterprises.
 In order to turn data into the keys to a breakthrough, every employee needs to have the skills to grasp the right tools and software to effectively exploit, filter, analyse, store and present data.
 In which, artificial intelligence (AI) creates a completely new way of working, not only a tool, but has become a virtual assistant that liberates workers from the burden of huge digital data and promotes creative innovation.
 As the work landscape has changed with AI development, people need to change too.
 The most important thing for every leader is how to take advantage of AI to reduce workload, promote creativity and build employees’ ability to use AI, the report said.
 In this context, the next-generation AI is expected to lift the weight of work. 
 Organisations that move first to embrace AI will break the cycle – increasing creativity and productivity for everyone, it added.
 While 54% of Vietnamese workers said they were worried that Al would replace their job position, up to 90% wanted to assign as much work as possible to Al to reduce the workload (this rate globally at 49% and 70% respectively). 
 Nine out of 10 Vietnamese workers feel comfortable using AI not only for administrative tasks (94%) but also for analytical work (94%) and even creative aspects in their work (91%).
 Affirming that the speed of work has increased faster than human ability and affecting innovation, Nguyen Quynh Tram, general director of Microsoft Vietnam, said that every employee needs to have the ability to use and create instructions for AI. 
 The vast majority of Vietnamese business owners said their employees will need new skills to prepare for the rise of AI. — Viet Nam News/ANN",hanoi business digital debt volume data email chat ability process trend report microsoft trend people industry country vietnam trillion signal meeting chat labour trend data pace human innovation report spent digital debt minute creative respondent vietnam time energy rate struggle innovation strategic vietnamese leader concern lack creativity innovation vietnamese worker presence meeting global rate vietnamese worker maintain concentration day microsoft usage statistic average person spends time time creative productivity loss ineffective meeting authority technology application communication ministry digital data customer valuable asset business digital transformation era competition digital transformation era price intelligence deep understanding customer data volume digital data easy exploit understand data data processing play key role operation data employee skill grasp tool software exploit filter analyse store data artificial intelligence tool virtual assistant worker burden huge digital data promotes creative innovation landscape development people leader advantage workload promote creativity employee ability report context generation lift weight organisation embrace break cycle creativity productivity vietnamese worker job position workload rate vietnamese worker comfortable administrative task analytical creative aspect speed human ability innovation nguyen quynh tram director microsoft vietnam employee ability create instruction vast majority vietnamese business owner employee skill rise viet nam news ann,"[(2, 0.9956381)]",2
547194,StarEdu,3,21/05/2023,‘Use AI responsibly’,,"THE Malaysian Qualifications Agency (MQA) has produced an advisory note on the use of generative artificial intelligence (AI), such as ChatGPT, in higher education.
 Advisory Note no. 2/2023, said MQA deputy chief executive officer (Quality Assurance) Prof Khairul Salleh Mohamed Sahari, recommends prudent and responsible use of these tools by institutions, lecturers and students to enrich teaching and learning (PdP).
 “As the progression of generative AI is exponential, it is important to embrace and leverage this technology, and if used wisely and ethically, generative AI tools can facilitate effective learning for students,” he said in an email to StarEdu.
 Prof Khairul Salleh was responding to calls by experts for an open and considered approach when looking at the role of AI-powered tools in academia, as tertiary students praise its benefits (Time to outsmart plagiarism, The Star, April 12).
 The advisory note states that rapid development of digital technology with various open-access functions demands that public and private universities, polytechnics, community colleges, and all other higher education institutions (HEIs) and public training institutes accredited by the MQA, enhance their understanding of various aspects of the concept, and the potential and risks of this technology, to ensure the effectiveness and integrity of PdP activities.Generative AI uses machine learning models to create content based on user input. Its applications use algorithms to manipulate and synthesise data to create new text, image, music, voice, video and other forms of content, as if these were created by humans. 
 In PdP, these applications can help users obtain, search, explain and analyse online sources; curate information; generate answers and ideas to questions for classroom activities; and edit their work.
 While generative AI can increase competitiveness, creativity and innovation if used correctly and effectively, over-reliance and failure to monitor its use can be detrimental to the mastering of knowledge and skills like writing, summarising, evaluating, problem-solving, and critical thinking. What may also result are inaccuracies, which can compromise academic integrity.Academic staff and administrators in the higher education sector are beginning to use generative AI applications to detect materials generated by generative pre-trained transformer (GPT), such as GPTZero, Writefull X GPT Detector, and DNG.AI ChatGPT Detector.Academic staff, as educators and facilitators in implementing flexible and personalised learning, can be supported by generative AI technology to provide a meaningful learning environment for students.
 They must, however, cultivate its use with integrity and be role models for students while ensuring that the latter are able to master learning outcomes with appropriate PdP and assessment approaches.
 The advisory note calls on education institutions to create clear guidelines for academic staff and students on the use of generative AI applications in teaching, research, and scientific writing to support the development of knowledge and competencies in line with the learning outcomes of the programmes.
 Institutions must also monitor and review policies, guidelines and practices related to the use of generative AI to ensure that academic quality and management frameworks are strengthened. 
 In addition, students must be guided on their use of generative AI through the provision of curation, fact-checking, decision-making, and critical thinking skills. While generative AI can be used to support learning, it cannot take over the tasks of a student. 
 For enquiries, log on to www2.mqa.gov.my/sppa/.",malaysian qualification agency advisory note generative artificial intelligence chatgpt education advisory note mqa deputy chief executive officer quality assurance prof khairul salleh sahari recommends prudent responsible tool institution lecturer student pdp progression generative exponential embrace leverage technology generative tool effective learning student staredu prof khairul salleh call expert approach role tool tertiary student benefit time outsmart plagiarism star april advisory note rapid development digital technology access function public private university community college institution public training institute mqa enhance understanding aspect potential risk technology effectiveness integrity pdp activity machine model content user input application manipulate synthesise data text image music voice video form content human pdp application user analyse online source generate answer question classroom activity generative increase competitiveness creativity innovation reliance failure monitor detrimental mastering knowledge skill critical thinking result inaccuracy academic integrity academic staff administrator education sector generative application material generative pre transformer gpt gptzero writefull gpt detector dng chatgpt detector academic staff educator facilitator flexible personalised learning generative technology meaningful learning environment student integrity role model student master outcome pdp assessment approach advisory note education institution guideline academic staff student generative application scientific support development knowledge competency outcome programme institution review policy guideline practice generative academic quality management framework addition student generative provision curation decision critical thinking skill generative support task student enquiry mqa gov sppa,"[(0, 0.6026959), (2, 0.39433858)]",0
547094,StarBiz 7,10,20/05/2023,AI alarmists dragging us down a rabbit hole,,"A funny thing happened during Sam Altman’s testimony before Congress earlier this week.
 Senator Richard Blumenthal said his “biggest nightmare” about artificial intelligence (AI) was the looming new industrial revolution and the displacement of millions of workers.
 When the OpenAI chief executive was asked about his biggest AI fear, he proposed something more vague and frightening: that it will “cause significant harm to the world”.
 Sam Altman has long believed that super-intelligent machines threaten the existence of humanity. Jobs, on the other hand, would get better, he said. The senators seemed to go along with this.   
 Fear of an AI apocalypse was once relegated to the realm of fringe theory; now it’s getting much more attention than it should.
 Multiple media reports recently conveyed the existential fears of Geoffrey “Godfather-of-AI” Hinton. In March, an open letter signed by Elon Musk and other tech luminaries called for a pause on AI research because of the risks to humanity.
 That month, warning that the result of building super-intelligent machines was that “literally everyone on Earth will die”.
 In reality, computer scientists tend to agree there is only a tiny chance that AI will wipe out humanity.
 But the idea has taken hold in mainstream discourse, thanks in part to Silicon Valley’s fixation on an ideology known as longtermism.
 First proposed by the Oxford philosopher Derrick Parfit in 1984 and popularized by William MacAskill’s 2022 book What We Owe the Future, it’s an ethical stance that prioritises humanity’s long-term future over the present, and has become a credo for tech billionaires.
 Musk, for instance, tweeted about MacAskill’s book, saying “this is a close match for my philosophy”.
 The idea appeals to technologists because of the way it quantifies moral dilemmas. If there are 7.8 billion people alive today, but 80 trillion lives that could be born in the future, we should technically prioritise those future lives.
 The same logic applies to AI. Even if there is only a fraction of a chance that intelligent machines extinguish humanity, that cost is so big that it’s essentially infinite.
 Multiply those tiny odds with an infinite cost and you get a problem that’s infinitely large.
 This kind of moral math has a special appeal to Silicon Valley’s detached engineer’s mindset, where problems are fixed through debugging code and a never-ending effort to “optimise” services through testing and evaluation.
 Unfortunately, acting on this ideology can also become self-serving. Wealthy technologists donate to causes aimed at saving our future selves from AI, but that money can end up flowing in a closed, almost incestuous circle.
 Musk and Peter Thiel donated to OpenAI in December 2015, back when it was a non-profit, because of its stated mission to build AI that would not destroy us.
 Open Philanthropy, the charitable vehicle of Facebook co-founder Dustin Moskovitz, then gave US$30mil (RM137mil) to OpenAI in 2017, its largest donation that year, because of the “global catastrophic risk” of advanced AI.  
 Yet, two of OpenAI’s top researchers were advisers to Open Philanthropy, and lived in the same house as the charity’s executive director, who was also engaged to another OpenAI scientist.
 As for OpenAI itself, its mission of saving humanity got skewed by all the financial demands.
 The nonprofit couldn’t afford the vast computing power necessary to build an artificial superintelligence, so it became a for-profit company and entered a close partnership with Microsoft Corp.
 Microsoft now stands to profit from OpenAI’s research into saving humanity from AI.
 You can understand the initial appeal of longtermism. It seems like a wonderfully progressive alternative to our rather shallow preference of short-term payoff over long-term rewards.
 Humans will usually take US$10 (RM46) now instead of US$15 (RM68.30) in the future. And Silicon Valley technologists like Altman certainly mean well.
 But following their moral math to the extreme ultimately leads to neglecting current human suffering and an erosion of that other very human feature – empathy.
 “Humanity has evolved by developing empathy for our common man,” says Margaret Mitchell, a former AI ethics researcher with Google and chief ethics scientists at AI startup Hugging Face.
 “We are emotionally attached to one another, and that helps us flourish as a society because this psychological connection has helped us group as societies.”
 Mitchell was part of a group of AI ethicists who wrote a public counterpoint to the open letter signed by Musk and others, criticising it for focusing on hypothetical future threats when AI was already being misused and harming people today.
 This isn’t to say that existential AI risk isn’t a concern.
 Mitchell says she got into AI ethics after realising, back in 2015 when she was working for Microsoft, that an AI model could be trained to believe that blue and purple colors in a sunset sky were beautiful – but then cause a bomb to go off to try to create those same colours.
 There is indeed a risk it could flip out on humans. 
 “The way to address that is to look at its learning from training sets,” she notes. 
 Mitchell has since made it her life’s work to find ways of making AI models more transparent and accountable, so that they are not only safer but also equitable toward vulnerable demographics.
 Studies have shown that skewed datasets can lead to biased hiring decision and racial profiling by law enforcement, while algorithms used in credit scoring can make unfair loan decisions for racial minorities, charging them higher interest rates.
 ChatGPT is not exempt from this. When someone recently prompted it to tell a story about a boy and a girl choosing their careers, the boy became a successful doctor and the girl a beloved teacher.
 This doesn’t have to be an either-or dilemma. Making a habit of fixing these near-term problems, by ensuring data is fairly representative for instance, can also inoculate us against some of those more catastrophic AI risks, Mitchell notes.
 Gazing so far into an AI future means we risk becoming blind to its present perils. Silicon Valley must reboot its longtermist views – the existential threat isn’t just on the horizon. It’s staring us in the face. — Bloomberg
 Parmy Olson is a Bloomberg Opinion columnist. The views expressed here are the writer’s own.",funny sam altman testimony congress week senator richard blumenthal biggest nightmare artificial intelligence industrial revolution displacement million worker chief executive biggest fear vague harm sam altman super intelligent machine humanity job hand senator apocalypse realm fringe theory attention multiple medium report existential fear hinton march letter elon musk tech luminary pause risk humanity month result super intelligent machine die reality computer scientist agree tiny chance wipe humanity idea mainstream discourse silicon valley fixation ideology longtermism philosopher derrick parfit book future ethical stance prioritises humanity term future credo tech musk instance macaskill book close match philosophy idea appeal quantifies moral dilemma people alive life born future prioritise future logic applies fraction chance intelligent machine extinguish humanity cost infinite multiply tiny odds infinite cost moral math special appeal silicon valley code effort optimise service evaluation ideology wealthy technologist saving future money incestuous circle musk peter thiel openai december profit mission build destroy philanthropy charitable vehicle facebook founder dustin moskovitz mil mil largest donation global catastrophic risk top researcher adviser house charity executive director openai scientist mission humanity financial demand nonprofit afford vast power artificial superintelligence profit company close partnership microsoft corp microsoft profit openai humanity understand initial appeal longtermism progressive alternative shallow preference short term term reward human future silicon valley technologist moral math extreme current human erosion human feature empathy humanity empathy common margaret mitchell ethic google chief ethic scientist startup flourish society psychological connection society ethicist public counterpoint letter musk hypothetical future threat people existential risk concern mitchell ethic microsoft model blue purple color sky beautiful bomb create colour flip human set note life model accountable safer equitable vulnerable demographic study datasets decision racial profiling law enforcement algorithm credit unfair loan decision racial minority rate exempt story boy girl career successful doctor girl dilemma habit term data representative instance inoculate catastrophic risk note future risk peril silicon valley reboot longtermist view existential threat horizon bloomberg parmy olson bloomberg opinion columnist view writer,"[(1, 0.8934497), (4, 0.104579985)]",1
546384,Main,22,18/05/2023,ChatGPT CEO pushes for AI regulations,,"Washington: Sam Altman, the chief executive of ChatGPT’s OpenAI, told US lawmakers that regulating artificial intelligence was essential, after his poem-writing chatbot stunned the world.The lawmakers stressed their deepest fears of AI’s developments, with a leading senator opening the hearing on Capitol Hill with a computer-generated voice – which sounded remarkably similar to his own – reading a text written by the bot.
 “If you were listening from home, you might have thought that voice was mine and the words from me, but in fact, that voice was not mine,” said Senator Richard Blumenthal.
 Artificial intelligence technologies “are more than just research experiments. They are no longer fantasies of science fiction, they are real and present”, said Blumenthal, a Democrat.
 The latest figure to erupt from Silicon Valley, Altman’s testimony in front of a US Senate judiciary subcommittee was far from the testy grilling given to the bosses of Facebook or TikTok when they visited Washington.
 “If this technology goes wrong, it can go quite wrong,” Altman said on Tuesday.
 Tipped as an opportunity to educate lawmakers, Altman used the session to urge Congress to impose new rules on big tech, despite deep political divisions that for years have blocked legislation aimed at regulating the internet.
 But governments are under pressure to move quickly after the release of ChatGPT, a bot that can churn out human-like content in an instant, went viral and both wowed and spooked users.
 Altman has since become the global face of AI as he both pushes out his company’s technology, including to Microsoft and scores of other companies, and warns that the work could have nefarious effects on society.
 “OpenAI was founded on the belief that artificial intelligence has the potential to improve nearly every aspect of our lives, but also that it creates serious risks,” Altman told the hearing.
 He insisted that in time, generative AI developed by OpenAI will “address some of humanity’s biggest challenges, like climate change and curing cancer”.
 However, given concerns about disinformation, job security and other hazards, “we think that regulatory intervention by governments will be critical to mitigate the risks of increasingly powerful models,” he said.
 Altman suggested the US government might consider a combination of licensing and testing requirements before the release of powerful AI models, with a power to revoke permits if rules were broken.
 He also recommended labelling and increased global coordination in setting up rules over the technology as well as the creation of a dedicated US agency to handle artificial intelligence. — AFP",washington sam altman chief executive chatgpt told lawmaker artificial intelligence essential poem chatbot lawmaker deepest fear development senator capitol hill computer voice text bot voice mine voice mine senator richard artificial intelligence technology fantasy science fiction real blumenthal democrat figure erupt silicon valley altman testimony front senate judiciary subcommittee testy boss tiktok washington technology wrong wrong altman tuesday opportunity educate lawmaker altman session urge congress impose rule deep political division legislation internet government pressure release chatgpt bot human content instant viral spooked user global push company technology microsoft score company nefarious effect society openai belief artificial intelligence potential improve aspect risk altman hearing insisted time generative openai address humanity biggest challenge change cancer concern disinformation job security hazard regulatory intervention government critical mitigate risk powerful model suggested government combination requirement powerful model power permit rule labelling global coordination rule technology creation agency artificial intelligence afp,"[(3, 0.24082741), (4, 0.75478315)]",4
546444,Main,23,18/05/2023,WHO warns against bias  in using AI  in healthcare,,"Geneva: The World Health Organisation called for caution  on Tuesday in using artificial intelligence for public healthcare, saying data used by AI to reach decisions could be biased or misused.
 The WHO said it was enthusiastic about the potential of AI but had concerns over how it will be used to improve access to health information, as a decision-support tool and to improve diagnostic care.
 The WHO said in a statement the data used to train AI may be biased and generate misleading or inaccurate information and the models can be misused to generate disinformation.
 It was “imperative” to assess the risks of using generated large language model tools (LLMs), like ChatGPT, to protect and promote human wellbeing and protect public health, the UN health body said.
 Its cautionary note comes as artificial intelligence applications are rapidly gaining in popularity, highlighting a technology that could upend the way businesses and society operate. — Reuters",geneva health organisation caution tuesday artificial intelligence public healthcare data reach decision enthusiastic potential concern access health decision support tool diagnostic care statement data train generate inaccurate model generate disinformation imperative ass risk language model tool chatgpt protect promote human protect public health health body cautionary note artificial intelligence application popularity technology upend business society operate reuters,"[(4, 0.9856429)]",4
545738,Main,17,16/05/2023,AI chatbots: Perspective from practitioners,,"IN a recent advisory paper on the use of generative artificial intelligence (AI) in higher education (bit.ly/mqaai), the Malaysian Qualifications Agency (MQA) provided a comprehensive analysis of the potential benefits, drawbacks, and suggested approaches for higher education providers, academic staff, and students. 
 The letter emphasises the importance of maintaining academic integrity when utilising generative AI in order to preserve the standard of education.We would like to explore how generative AI can be fully realised and optimised in teaching and learning (T&L) of STEM and healthcare-related courses from the perspective of a practising chemist and pharmacist, given the rapid adoption of AI chatbots, including ChatGPT, in T&L. Some of the proposed strategies are:
 > Streamlining personalised learning                                         By generating content tailored to each student’s needs and comprehension level, lecturers can use generative AI to provide individualised learning experiences for their students. For example, a lecturer may adjust the complexity and subject of tutorial questions based on the learning level of each student.
 > Supporting problem-solving     Academic staff can employ generative AI in T&L to streamline case studies and problem-solving activities. Using technology, students can develop potential solutions and evaluate their feasibility. 
 Students must possess the knowledge and skills to differentiate between accurate information produced by AI and “hallucinated” misleading information in real-world situations.
 > Fostering interdisciplinary collaboration                          Higher education providers can promote interdisciplinary collaboration among students from various programmes, enabling them to work together on tasks requiring knowledge from multiple disciplines. 
 For example, students of medicine, pharmacy, nursing, and biomedicine can cooperate to create and solve simulated clinical case studies using generative AI by incorporating relevant competencies from their respective fields.
 > Enhancing research 	Academic staff can instruct students on how to use generative AI to curate and analyse data, which can foster knowledge creation by identifying patterns, trends, and potential research questions in related fields.
 > Addressing ethical issues 	Academic staff should incorporate discussions on ethical issues in their courses, such as the use of AI in assignment preparation and idea generation. This will ensure that students are aware of the ethical implications of using AI in their research, projects or future careers.
 The MQA advisory letter  concludes by urging academic staff and students to adapt to  the rapidly changing digital  technology landscape and to effectively and ethically use  generative AI. 
 It is important to constantly bear in mind that the content generated by AI is not fully verified, and therefore, it is the user’s responsibility to validate the information and critically review the generated content. 
 With proper guidance and careful implementation, generative AI has the potential to enhance T&L in various sectors.
 ChM Dr TAN YEE SENG
 ChM Dr ALLY YEO  CHIEN ING 
 Prof LONG CHIAU MING 
 School of Medical and Life Sciences, Sunway University
 Petaling Jaya",advisory paper generative artificial intelligence education bit mqaai malaysian qualification agency comprehensive analysis potential benefit drawback approach education provider academic staff student letter academic integrity generative standard education generative optimised teaching stem healthcare course chemist pharmacist rapid adoption chatbots chatgpt strategy content student comprehension level lecturer provide learning experience student adjust complexity subject tutorial question level student academic staff generative streamline study activity technology student potential solution feasibility student knowledge skill differentiate accurate misleading real situation interdisciplinary collaboration education provider interdisciplinary collaboration student task knowledge multiple discipline student pharmacy nursing biomedicine cooperate create solve clinical study incorporating relevant competency field academic staff instruct student generative curate analyse data knowledge creation pattern potential question field ethical issue academic staff incorporate discussion ethical issue course assignment preparation idea generation student aware ethical implication project future career advisory letter academic staff student digital technology landscape generative mind content user responsibility content proper guidance careful implementation generative potential enhance sector tan yee seng chm yeo chien prof chiau school medical life science university petaling jaya,"[(0, 0.27055407), (2, 0.7257369)]",2
545110,Main,23,14/05/2023,Are we ready for mental health AI?,,"I must confess, I am not an early adopter of technology. This quirk of mine has saved me from headaches. I refuse to install TikTok on my phone and would delete my Facebook if I could. Cryptocurrencies and nonfungible tokens do not appeal to me one bit. At the same time, my risk-adverse nature prevented me from considering tele-psychotherapy for many years up until the pandemic forced us all to migrate online. I had to eat my words after railing against online therapy when it has now changed my practice forever.
 The next technology we must contend with is artificial intelligence (AI). ChatGPT has been a revelation for many and writers before me had already expressed their thoughts on it. I held my tongue, owing to my reckoning with my online therapy scepticism, as I wanted to give it an open mind. I have encountered mental health chatbots and apps before and it was clear that technology still had a long way to go before it can provide the same nuanced benefit as a human therapist. ChatGPT and its other AI peers seem to hold potential to bridge that gap by providing a “human” experience to the conversation.
 Is that enough?
 Our psychology department has long been inundated with requests to collaborate by businessmen and startups who want to produce app-based mental health care aimed at accessibility and affordability. Indeed, psychotherapy is very expensive in this country with only expat-level private insurance offering limited coverage and PhilHealth not covering it at all.
 There is a reason for the high cost – training to be a psychotherapist is time and resource intensive, with few scholarships available in the field. The work itself comprises long, consistent emotional labour. It is impossible for a therapist to provide eight hours of therapy per day for five days a week as this is a sure-fire way to burn out. As such, with only relatively few hours of income per week, they have to make sure their fees will cover their living costs. They also have to invest in continuing education units to renew their license. The only way to lower the overall costs of psychotherapy is for insurance and governments to comprehensively cover mental health care.
 Given lack of insurance coverage, I notice that startups that highlight affordability when offering mental health services severely underpay their therapists. When businesses inquire with us, usually to field our graduates, we are appalled at the rates they offer. I kindly explain to them that our graduates can seek better rates with their own private practice or if they do want to offer low-cost services, they can do so with non-profits instead.
 It made sense that these startups are now heavily investing in chatbots and AI-esque technologies to keep costs low. If the technology is good enough to provide high quality psychotherapy, why not? But therein lies the problem. The one thing I have not heard from such business proposals is their concern with quality. They’ve been focused on keeping the costs low that they have grossly underestimated what it takes to provide good quality therapy. Most of them don’t even know what therapy looks like and how it works to help effect beneficial change for clients.
 They also do not realise that conversations also have the power to harm people. The first thing we always ask these inquiring entrepreneurs is how they deal with the ethics – privacy, confidentiality, and ensuring no harm is done. In clinical trials, the earlier step is to prove that the drug causes no harm before we prove that the drug can provide significant benefit. Why is it not the same process with AI technology? News recently reported of a man in Belgium who died by suicide after being urged to do so by the chatbot Eliza. This particular chatbot was not designed for mental health – but why wasn’t it? If a person encouraged someone else to commit suicide, that person can be held liable. Where is the accountability when it comes to chatbots?
 I believe that it is possible to reach a state of mental health care that is assisted by AI. I also believe the technology isn’t there yet. It would be much easier to develop medicine AI than mental health AI. This is because mental health care deals with a much greater plurality of approaches, unlike medicine. We also do not have the benefit of definitive imaging or assessment tools that would guarantee the best course of action. A big part of therapy is co-exploration and collaboration with the client. The therapist makes use of their own inner reactions to generate hypothesis and test this with the client. We would need AI technology that has enough capacity for emotions and self-reflection – and ability to check against their own biases – in order to effectively provide psychotherapy. We are not there yet. — Philippine Daily Inquirer/ANN
 Anna Cristina Tuazon is a psychologist and  columnist with the Philippine Daily Inquirer.",confess adopter technology quirk mine headache install tiktok phone delete facebook cryptocurrencies nonfungible token appeal bit time risk adverse nature tele psychotherapy pandemic migrate online eat online therapy practice technology contend artificial intelligence chatgpt revelation writer tongue online therapy scepticism mind mental health chatbots technology provide benefit human therapist chatgpt peer potential bridge gap human experience conversation psychology department request businessmen startup app mental health care accessibility affordability expensive country level private insurance offering limited coverage philhealth reason cost training psychotherapist time resource intensive scholarship field consistent emotional labour impossible therapist provide hour day day week fire burn hour income week fee cost education unit license lower cost insurance government mental health care lack insurance coverage notice startup affordability offering mental health service underpay therapist business field graduate rate graduate rate private practice low cost service profit startup chatbots esque technology cost low technology quality psychotherapy heard business proposal concern quality cost low underestimated quality therapy therapy beneficial change client conversation power harm people entrepreneur deal ethic confidentiality harm clinical trial step prove drug harm drug benefit process technology news belgium chatbot eliza chatbot mental health person commit person liable accountability chatbots mental health care technology easier medicine mental health mental health care deal plurality medicine benefit definitive imaging assessment tool guarantee action therapy exploration collaboration client therapist reaction hypothesis test client technology capacity emotion ability check provide psychotherapy philippine daily inquirer ann cristina tuazon psychologist columnist philippine daily inquirer,"[(0, 0.33366323), (3, 0.6636697)]",3
544358,Main,26,12/05/2023,EU lawmakers take first step towards AI curbs,,"Strasbourg (France): Euro­pean Parliament lawmakers took a crucial first step towards EU-wide regulation of ChatGPT and other artificial intelligence systems that Brussels hopes to put speedily in place.
 Parliamentary committees on civil liberties and consumer protection overwhelmingly voted for a position text calling for curbs on how AI can be used in Europe, while still fostering innovation in the sector.
 The text is to be put to the full parliament next month for adoption before negotiations with EU member states on a final law.
 Lawmakers called yesterday’s vote “historic” and hoped it would lead to “the world’s first rules on artificial intelligence”.
 Their text picks up the main lines from a European Com­mission proposal made two years ago, but suggests adding bans on biometric surveillance, emotion recognition and predictive policing AI systems.
 It seeks to put generative AI systems such as ChatGPT and Midjourney in a category requiring special transparency measures, such as notifications to users that the output was made by a machine, not a human.
 The parliament’s text also seeks additional criteria as to what constitutes a “high-risk” AI area of application, which could reduce the scope of that designation.
 The commission proposed list covers AI in critical infrastructure, education, human resources, public order and migration management.
 But the MEPs want an additional threshold to be met, requiring that threats to safety, health or fundamental rights are also deemed to be in play.
 The CCIA, a European industry lobby group representing major tech companies, said that, while “the parliament made some useful improvements to the text”, it was “abandoning the risk-based structure” of the European Commission’s proposal.
 “The best way for the EU to inspire other jurisdictions is by ensuring that new regulation will enable, rather than inhibit, the development of useful AI applications,” said CCIA policy manager for Europe, Boniface de Champris.
 “Although AI may improve our lives in many ways, there are well-founded concerns that AI systems can also harm consumers. People must be properly protected against the risks,” said Ursula Pachl, deputy director of the organisation. — AFP",strasbourg france euro pean parliament lawmaker crucial step wide regulation artificial intelligence system parliamentary committee civil liberty consumer protection position curb europe innovation sector text parliament month adoption negotiation final law lawmaker yesterday vote historic lead rule artificial intelligence text pick main line european mission proposal suggests ban biometric surveillance emotion recognition predictive policing system generative system midjourney category special transparency measure notification user output machine human parliament text additional criterion constitutes application scope designation commission list critical infrastructure education human resource public migration management additional threshold threat safety health fundamental right ccia european industry lobby major tech company parliament improvement risk structure european commission proposal inspire jurisdiction regulation enable inhibit development application policy manager boniface champris life concern system harm consumer people risk ursula pachl deputy director organisation afp,"[(0, 0.35302654), (1, 0.642087)]",1
542542,Lifestyle,2,08/05/2023,ThebattleoverAIdatasets,,"In front of a suburban house on the outskirts of the ­northern German city of Hamburg, a single word – “LAION” – is scrawled in pencil across a mailbox.
 It’s the only indication that the home belongs to the ­person behind a massive data gathering effort central to the artificial intelligence boom that has seized the world’s attention.
 That person is high school teacher Christoph Schuhmann, and LAION, short for “Large-scale AI Open Network”, is his passion project.When Schuhmann isn’t teaching physics and computer science to German teens, he works with a small team of volunteers building the world’s biggest free AI training dataset, which has already been used in text-to-image generators such as Google’s Imagen and Stable Diffusion.
 Databases like LAION are central to AI text-to-image generators, which rely on them for the enormous amounts of visual material used to deconstruct and ­create new images.
 The debut of these products late last year was a ­paradigm-shifting event – it sent the tech sector’s AI arms race into hyperdrive and raised a myriad of ethical and legal issues.
 Within a matter of months, lawsuits had been filed against generative AI ­companies Stability AI and Midjourney for copyright infringement, and critics were sounding the alarm about the violent, sexualised, and otherwise problematic images within their datasets, which have been accused of introducing biases that are nearly impossible to mitigate.
 However, these aren’t Schuhmann’s concerns. He just wants to set the data free.Large language models
 The 40-year-old teacher and trained actor helped found LAION two years ago after hanging out on a Discord server for AI enthusiasts.
 The first iteration of OpenAI’s Dall-E, a deep learning model that generates digital images from language prompts – say, creating an image of a pink chicken sitting on a sofa in response to such a request – had just been released, and Schuhmann was both inspired and concerned that it would encourage big tech companies to make more data proprietary.“I instantly understood that if this is centralised to one, two or three companies, it will have really bad effects for society,” Schuhmann said.
 In response, he and other members on the server decided to create an open-source dataset to help train image-to-text ­diffusion models, a months-long process similar to teaching ­someone a foreign language with millions of flash cards.
 The group used raw HTML code collected by the California non-profit Common Crawl to locate images around the Web and associate them with descriptive text. It does not use manual or human curation.
 Within a few weeks, Schuhmann and his colleagues had three million image-text pairs. After three months, they released a dataset with 400 ­million pairs. That number is now over five billion, making LAION the largest free dataset of images and captions.
 As LAION’s reputation grew, the team worked without pay, receiving a one-off donation in 2021 from the machine-learning company Hugging Face. Then one day, a former hedge fund manager entered the Discord chat.Emad Mostaque offered to cover the costs of computing power with no strings attached. He wanted to launch his own open-source generative AI business and was keen to tap LAION to train his product. The team ­initially scoffed at the proposal, taking him for a kook.
 “We were very sceptical in the beginning,” Schuhmann said, “But after four weeks or so, we got access to GPUs in the cloud that would normally have cost around US$9,000 (RM40,162) or US$10,000 (RM44,600).”
 When Mostaque launched Stability AI in 2022, he used LAION’s dataset for Stable Diffusion, its flagship AI image generator, and hired two of the organisation’s researchers. A year on, the company is currently seeking a US$4bil (RM17.85bil) valuation, thanks largely to the data made available by LAION.
 For his part, Schuhmann hasn’t profited from LAION and says he isn’t interested in doing so.
 “I’m still a high school teacher. I have rejected job offers from all different kinds of companies because I wanted this to stay independent,” he said.
 New oil?
 Many of the images and links in databases like LAION have been sitting in plain sight on the Web, in some cases for decades.
 It took the AI boom to reveal its true value, as the bigger and more diverse a dataset is and the higher the quality of the images in it, the clearer and more precise an AI-generated image will be.
 That realisation, in turn, has raised a number of legal and ­ethical questions about whether publicly available materials can be used to feed databases – and if the answer is yes, if creators should be paid.
 To build LAION, founders scraped visual data from companies such as Pinterest, Shopify and Amazon Web Services – which did not comment on whether LAION’s use of their content violates their terms of service – as well as YouTube thumbnails, images from portfolio platforms like DeviantArt and EyeEm, photos from government websites including the US Department of Defense, and ­content from news sites such as The Daily Mail and The Sun.
 If you ask Schuhmann, he says that anything freely available online is fair game. But there is currently no AI regulation in the European Union, and the forthcoming AI Act, whose language will be finalised early this year, will not rule on whether copyrighted materials can be included in big data sets.
 Rather, lawmakers are discussing whether to include a provision requiring the companies behind AI generators to disclose what materials went into the datasets their products were trained on, thus giving the creators of those materials the option of taking action.
 The basic idea behind the provision, European Parliament Member Dragos Tudorache said, is simple: “As a ­developer of generative AI, you have an obligation to document and be transparent about the copyrighted material that you have used in the training of ­algorithms.”
 Such regulation wouldn’t be an issue for Stability AI, but it could be a problem for other text-to-­image generators – “no one knows what OpenAI actually used to train Dall-E 2,” Schuhmann said, citing it as an example of how tech companies lock up public data. It would also upend what is now the status quo in data collection.
 “It has become a tradition within the field to just assume you don’t need consent or you don’t need to inform people, or they don’t even have to be aware of it.
 “There is a sense of entitlement that whatever is on the Web, you can just crawl it and put it in a dataset,” said Abeba Birhane, a senior fellow in Trustworthy AI at the Mozilla Foundation who has studied LAION.
 Although LAION has not been sued directly, it has been named in two lawsuits: one accusing Stability and Midjourney of using copyrighted images by artists to train their models, and another by Getty Images against Stability, which alleges that 12 million of its images were scraped by LAION and used to train Stable Diffusion.
 Because LAION is open-source, it’s impossible to know which or how many other companies have used the dataset.
 Google has acknowledged that it tapped LAION to help train its Imagen and Parti AI text-to-­image models. Schuhmann believes that other large companies are quietly doing the same and simply not disclosing it.
 Worst of the Web
 Sitting in the living room as his son played Minecraft, Schuhmann likened LAION to a “small research boat” on top of “big information technology tsunami”, taking samples of what’s beneath to display to the world.
 “This is a tiny amount of what’s available publicly on the Internet,” he said of LAION’s database. “It’s really easy to get because even we, with maybe a budget of US$10,000 from donors, can do it.”
 But what’s publicly available isn’t always what the ­public wants – or is legally allowed to see. In addition to photos of cats and firetrucks, LAION’s dataset contains millions of images of pornography, violence, child nudity, racist memes, hate symbols, copyrighted art, and works scraped from private company websites.Schuhmann said he was unaware of any child nudity in LAION’s dataset, though he acknowledged he did not review the data in great depth. If notified about such content, he said, he would remove links to it immediately.Schuhman consulted lawyers and ran an automated tool to filter out illegal content before he began ­assembling the ­database, but he is less interested in sanitising LAION’s holdings than in learning from them.“We could have filtered out violence from the data we released,” he said, “but we decided not to because it will speed up the development of violence detection software.”
 LAION does provide a ­takedown form to request the removal of photos, but the dataset has already been downloaded thousands of times.
 Offensive content lifted from LAION appears to have been integrated into Stable Diffusion, where, despite recently tightened filters, it’s easy to generate fake ­extremist group beheading photos or Holocaust images.
 Some experts believe such material can also create ­biases within an AI generator itself: Tools like Dall-E 2 and Stable Diffusion have been criticised for reproducing racial stereotypes even when a text prompt doesn’t imply the subject’s race.
 When reached for comment, Stability AI said it trained Stable Diffusion on a curated subset of LAION’s database. The company sought to “give the model a much more diverse and wide-ranging dataset than that of the original SD” it wrote in an email, adding that they tried to remove “adult content using LAION’s NSFW filter”.
 Even advocates of open- source-based AI warn of the implications of training AI on uncurated datasets.
 According to Yacine Jernite, who leads the machine learning and society team at Hugging Face, generative AI tools based on tainted data will reflect its biases. “The model is a very direct ­reflec- tion of what it’s trained on.”Introducing guardrails after the product is up and running isn’t sufficient, Jernite added, as users will always find ways to circumvent the safety measures.
 “That’s what happens when you take a model that is trained to emulate what people do on the Internet and then say, ‘Okay, but don’t do that’. People will find a way to still make it do that,” Jernite said.Gil Elbaz, founder of the data non-profit Common Crawl, doubts whether “there’s a straight line that you can draw from the training sets to what’s produced”, and instead likens the process to an artist who goes to museums for inspiration but is blocked from making ­replicas of artworks.Instead, he said, “it’s important for society to decide what use cases are legal or not.”
 It won’t only be left up to society. As regulators in Europe craft legislation to navigate the uses of artificial intelligence, they are grappling with the fact that the data now being mined for the ­current AI boom has for years been generated in a legal grey zone that is only now coming under serious scrutiny.“AI wouldn’t have been possible at this level of ­complexity without years of data accumulation,” said Tudorache, the European Parliament member.
 But to Schuhmann, it’s not the datasets that should be monitored. In his eyes, the worst-case scenario for AI is one in which Big Tech is able to crowd out developers by catering their tools to a ­regulatory framework.
 “If we try to slow things down and overregulate,” he warned, “there is a big ­danger that in the end, only a few big corporate players can afford to fulfil all the formal requirements.” – Bloomberg",front suburban house northern german city hamburg single word laion pencil mailbox indication person massive data gathering effort central artificial intelligence boom attention person school teacher christoph schuhmann laion short scale network passion project physic computer science german team volunteer biggest free training dataset text image generator imagen stable diffusion laion central text image generator enormous amount visual material deconstruct create image product late paradigm event tech sector arm race hyperdrive myriad ethical legal issue month lawsuit generative company stability midjourney copyright infringement critic alarm violent problematic image datasets bias impossible mitigate schuhmann concern data free language model actor laion discord server enthusiast iteration dall deep learning model digital image language prompt image pink chicken sofa response request schuhmann concerned encourage tech company proprietary company bad effect society response server create source dataset train image text diffusion model month foreign language million card raw html code california profit common crawl locate image associate descriptive text manual human curation week colleague image text pair month dataset pair laion largest free dataset image caption laion reputation team pay donation machine company day fund manager discord chat mostaque cover cost power string launch source generative business tap laion train product team proposal sceptical schuhmann week access gpus cloud cost mostaque stability laion dataset stable diffusion flagship image generator organisation researcher company bil bil valuation data laion schuhmann laion school job offer company independent oil image database laion plain decade boom reveal true bigger diverse dataset quality image precise image realisation legal ethical question material database creator build laion founder visual data company shopify amazon web service comment laion content term service youtube thumbnail portfolio platform photo government website department defense content news daily mail sun schuhmann online fair game regulation european union language rule material data set lawmaker provision company generator material datasets product creator material option action basic idea provision european parliament dragos simple developer generative obligation document transparent material training algorithm regulation issue stability text image generator dall schuhmann tech company public data upend status quo data collection tradition field consent inform people aware sense entitlement web crawl dataset abeba birhane senior fellow trustworthy mozilla foundation laion laion lawsuit stability midjourney image artist model getty image stability image laion train stable diffusion laion source impossible company google tapped laion train imagen parti text image model company worst web son minecraft schuhmann laion boat top technology tsunami sample display tiny amount internet laion database easy budget donor public addition photo firetrucks laion million image violence child nudity racist meme symbol scraped private company schuhmann unaware child nudity laion review data depth content link schuhman lawyer tool filter illegal content database laion holding filtered violence data speed development violence detection software laion form request removal photo thousand time offensive content laion stable diffusion filter easy generate fake extremist photo holocaust image expert material create bias generator tool stable diffusion racial stereotype prompt imply subject race comment stability stable diffusion subset laion database company model diverse wide dataset original email adult content laion advocate source warn implication uncurated datasets jernite lead machine society team generative tool data bias direct reflec tion guardrail product sufficient jernite user safety measure trained emulate people people gil elbaz founder data profit common crawl doubt draw training set likens process artist museum inspiration replica artwork society legal society regulator craft legislation artificial intelligence data current boom legal grey scrutiny level complexity data accumulation european parliament schuhmann datasets eye worst scenario tech crowd developer tool regulatory framework slow overregulate danger corporate player fulfil formal requirement,"[(4, 0.99854296)]",4
542554,Lifestyle,6,08/05/2023,Train AI to save coral reefs,,"Web users can now access a new experience that aims to help safeguard the world’s coral reefs.
 The objective is to identify the presence or absence of fish in certain areas in order to help biologists repopulate them if necessary and thus maintain these environments, which are, by definition, highly fragile. Indeed, this ecosystem of marine life is essential to their survival.
 The aim of the “Calling in our Corals” initiative is for users to help train artificial intelligence by reporting the presence or absence of fish in various audio recordings made available to them. 
 Google’s teams have placed hydrophones on various reefs off the coast of French Polynesia, Australia, the Maldives, Sweden, Canada, Florida and the Philippines.As a training exercise, Google first makes users listen to sounds coming from a marine protected area and then from a reef that is subject to intensive overfishing. Once their ears have been well-trained, they can move on to the next step.
 Once that’s complete, users can listen to high-quality audio recordings of coral reef environments, which will then be used to train the AI. These clips are filled with incredibly detailed sounds, such as different species of fish, crabs or even shrimp making ­particular noises.
 The user is then invited to ­simply click each time they hear a sound, and to do so on as many audio clips as they like. In this way, the user participates in training artificial intelligence that will later be tasked with analysing much longer recordings. – AFP Relaxnews",web user access experience coral reef objective identify presence absence fish biologist maintain environment definition fragile ecosystem marine life essential survival aim coral initiative user artificial intelligence presence absence fish audio recording team hydrophones reef french polynesia australia maldives canada florida philippine exercise google user coming marine reef subject intensive ear step complete user quality audio recording coral reef environment clip detailed sound specie crab noise click time hear sound audio clip participates artificial intelligence analysing recording relaxnews,"[(2, 0.98933506)]",2
542340,Main,22,07/05/2023,Suffering from AI fatigue?,"Brace up then, it is only going to get worse, says the writer.","I DON’T know about you, but of late, I have been experiencing some AI-induced illness and fatigue. To put it another way: I am sick and tired of hearing about artificial intelligence.
 To be clear, I am not tired of artificial intelligence itself. AI is a large, varied field that is decades-old, and there are a lot of genuinely useful AI tools that I depend on. (I did my undergraduate honours thesis on AI, and I am no spring chicken.)
 My present fatigue is almost entirely with people – specifically, the AI evangelists breathlessly touting generative AI.
 (Before you point out the obvious, yes, I know this is a bit meta. Here I am, complaining about too much AI pontification while essentially pontificating about AI. My justification, if admittedly flawed, is that the best place to try and slow down a hype train is on board.)
 Hardly a day goes by at the moment without there being some sort of buzz over how a generative AI tool like ChatGPT or Bard or Midjourney is going to revolutionise/disrupt/destroy/replace some part of our present lives. People seem to be taking for granted the actually, currently and widely used more humble bits of AI that can improve your photo-taking, transcribe speech and optimise the timing of your tweets.
 Now, while just having a lot of things said about a single topic can, in itself, be tiring, I think there are specific things about the AI hype that are especially exhausting.
 Perhaps the biggest aspect is the large amount of uncertainty.
 The disorienting AI future
 Nearly everyone has predictions, opinions and questions about AI, but very few have any good answers for the important questions about what the world is actually going to look like when generative AI becomes embedded.
 This isn’t a failure on anyone’s part. How could anyone be expected to know?
 The generative AI models we have today are still babies. And while it does seem like we have been talking about it for a long time, the current AI conversation really only started to pick up pace when ChatGPT got launched to the public in November 2022.
 In less than six months, everyone has been bombarded with specific yet uncertain warnings about how we need to embrace this new technology or risk obsolescence.
 Depending on which expert you ask and when, we’re told the machines will definitely replace humans in nearly all jobs; the machines cannot rely heavily on humans continuing to give it input; that search engines as we know it are over; the computing power required to retrain AI models on all the new information means it is impractical as a search engine; that everyone should use Bing now; that Bing still sucks; that AI artists are amazing; that AI has trouble drawing hands holding things; and so on.
 This sort of chaos is, of course, unavoidable. The early phase of any new technology is always fraught with uncertainty as everyone chases their FOMO. It is just incredibly tiring for ordinary people trying to make sense of it.
 It also doesn’t help that we all just got through two tech hype cycles. Remember a few years ago when we were told that some digital certificate for a jpg file was worth millions of dollars? Or remember when the tech world was very, very sure the future involved everyone strapping headsets on to their faces to have virtual meetings with legless, digital colleagues?
 Being forced to constantly confront a massive yet amorphous change can be highly stressful and disorienting. It’s like a fortune-teller giving you an ominous, yet vague warning: “I’ve seen how you die. Weasels.”
 The other problem is that the current FOMO around generative AI means the conversation is unbalanced. Talk about the promise of it is not tempered with anywhere near the same amount of questions about its less positive implications. In part, no one wants to come off looking like a Luddite, even if they have some doubts about where all this is going.
 AI may be increasing cognitive load
 There will likely come a time (even I cannot help getting into the AI predictions game) where generative AI does steal jobs or, at least, be a key productivity aid. At the moment, however, it is actually adding quite a bit to many people’s cognitive load.
 Until a few months ago, we spent no time trying to figure out whether something was written by AI or not. Now it’s a near ubiquitous endeavour.
 Organisations are spending time and brainpower not just on exploring ways to utilise the tool, but also on ways to manage its drawbacks. Schools, for instance, have been forced to spend time coming up with strategies on how to check if students are using AI to cheat.
 In a world that is already struggling from a flood of misinformation, generative AI has opened the hogwash spout even more. Because of AI’s propensity for confidently delivered hallucination, no work outsourced to it can be taken at face value. If you care at all about facts, all answers it provides must be fact-checked with a second source.
 And nearly everything we now encounter must be parsed through the “Did AI create this?” filter. One used to be able to enjoy a photo of the Pope wearing a puffy jacket without worrying about being lied to.
 True, this was already a problem before AI but only talented photoshop artists with too much time on their hands could do it. Now, ordinary people can create and spread fakes while waiting for the bus.
 Questioning the veracity of everything is now just one of those burdens added to our overburdened cognitive load.
 More work is coming
 Again, and I will keep stressing it, I believe that generative AI is a revolutionary feat of engineering that will transform work. What I don’t think it is necessarily going to do is lower the quantity of work.
 History has shown us that tools and innovations meant to assist us have often led to more work. Even simple things like a vacuum cleaner and washing machine have not meant less work.
 In More Work For Mother, a seminal book from 1983 by historian Ruth Schwartz Cowan, she noted that many women ended up working longer hours in the decades since 1870, despite the increasing mechanisation of household activities. What happened was that these appliances ended up taking away tasks previously done by servants or other family members and giving them to women while at the same time raising expectations.
 Take the stove, for instance. Before the stove was invented, dinners were cooked over a fire. And as such, nearly all meals were cooked in a single pot. When the stove was invented, along with it came the expectations of multi-course meals. Suddenly, homemakers weren’t just making stews, they had to make roasts and pies and all manner of other more complicated dishes.
 I can see that same formula in my own field of work. Innovations that made it so much easier to take photos and videos, and communicate with readers, mean the work of a journalist is no longer just to report on and write a story. Modern journalists are expected to answer e-mails and messages around the clock, take their own photos and videos, as well as share their stories on social media.
 It is not difficult to foresee a time when AI means the ordinary office worker should also have to function as amateur accountant, lawyer, HR executive and marketing professional.
 None of this is necessarily to say that generative AI is evil. It isn’t, but it isn’t some magic wand either. The conversation we are having about this needs a little more nuance and a little less panic.
 So let’s stay calm, take some time to understand all the implications of what we are facing here, both good and bad. Generative AI’s time will come and I look forward to the day when it really does change our lives for the better.
 That is, if the weasels don’t get me first. – The Straits Times/Asia News Network
 Jeremy Au Yong is Newsroom Transformation Editor at The Straits Times/Asia News Network.",illness fatigue sick artificial intelligence artificial intelligence field decade tool undergraduate honour thesis spring chicken fatigue people generative obvious bit meta pontification justification slow hype train board day moment sort buzz generative tool chatgpt bard midjourney revolutionise disrupt destroy people humble bit photo transcribe speech optimise tweet single topic specific hype biggest aspect amount uncertainty future prediction opinion question answer question failure generative model baby time current conversation pick pace chatgpt public november month specific uncertain warning technology risk obsolescence expert told machine human job machine human input search engine power retrain model impractical search engine suck artist trouble hand sort chaos unavoidable phase technology fraught uncertainty chase ordinary people tech hype cycle digital certificate jpg file worth million dollar tech future headset virtual meeting legless digital colleague confront massive amorphous change stressful fortune teller ominous vague warning die weasel current fomo generative conversation talk promise amount question positive implication doubt cognitive load time prediction game generative steal job key productivity aid moment bit people load month spent time figure ubiquitous endeavour organisation spending time utilise tool manage school instance spend time strategy student cheat flood misinformation generative hogwash spout propensity hallucination care answer source encounter create filter photo pope puffy jacket true photoshop artist time ordinary people spread fake bus veracity burden cognitive load generative revolutionary feat engineering transform lower quantity history tool innovation assist simple vacuum cleaner machine meant mother seminal book historian ruth schwartz cowan woman hour decade mechanisation household activity appliance task servant family woman time expectation instance stove dinner fire meal single pot stove expectation multi meal homemaker roast pie dish formula field innovation photo video communicate reader report story modern journalist answer mail message photo video share social medium difficult foresee time ordinary office worker function amateur accountant lawyer executive marketing professional generative evil magic wand conversation nuance panic stay calm time understand implication bad generative time forward day change weasel strait time news network jeremy newsroom transformation editor time asia news network,"[(3, 0.9974045)]",3
542086,Main,25,06/05/2023,White House: Tech giants have ‘moral’ duty to  curb AI risks,,"Washington: The White House has told the chief executive officers of US artificial intelligence (AI) giants that they have a “moral” responsibility to protect society from the potential dangers of artificial intelligence.
 Vice-President Kamala Harris had on Thursday summoned  the heads of Google, Microsoft, OpenAI and Anthropic to strategise about the impact of AI, afraid that companies are running blindly into technology that could pose serious harms to society.
 Harris told the CEOs, which included Sundar Pichai of Google and Satya Nadella of Microsoft, that they had a “moral” duty to safeguard society from AI’s potential dangers.
 Companies “must comply with existing laws to protect the Amer­ican people” as well as “ensure the safety and security of their products,” Harris said after the talks.US President Joe Biden also insisted on that point when he briefly dropped by the meeting, telling the assembled CEOs, “What you’re doing has enormous potential and enormous danger.
 “I know you understand that. And I hope you can educate us as to what you think is most needed to protect society as well as to the advancement,” he said.
 Biden has urged Congress to pass laws setting stricter limits on the tech sector, but these efforts have little chance of making headway given political divisions.
 The lack of rules has given Silicon Valley freedom to put out new products rapidly, and stoked fears that AI technologies will wreak havoc on society before the government can catch up.
 “It’s good to try to get ahead of this. It’s going to be a challenge but it’s one I think we can handle,” OpenAI CEO Sam Altman said before the meeting. — AFP",washington white house chief executive officer artificial intelligence giant moral responsibility society potential danger artificial intelligence vice president harris thursday head microsoft openai anthropic strategise impact afraid company technology pose harm society ceo sundar pichai google satya nadella microsoft moral duty safeguard society potential danger company law amer ican people safety security product harris talk president joe biden ceo enormous potential enormous danger hope educate protect society advancement biden congress pas law stricter limit sector effort chance political division rule valley freedom product fear technology havoc society government catch handle openai ceo altman meeting afp,"[(4, 0.99070555)]",4
541298,StarBiz,12,04/05/2023,"Dyson to ramp up software,            AI development",,"SINGAPORE: Consumer electronics giant Dyson will open a factory in Tuas here to manufacture next-generation batteries for the company’s new products, describing the move as “the most significant investment in advanced manufacturing in the firm’s history”.
 The new facility, which will span 247,000 sq ft, or the equivalent of 53 basketball courts, will be completed this year and is expected to be fully operational by 2025.
 It is part of a broader move to ramp up software, artificial intelligence (AI) and product development globally that will see Dyson double its manufacturing footprint worldwide.
 The Singapore-headquartered company will also invest in new sites in Britain and the Philippines that focus on research and development (R&D), among other capabilities.
 The latest developments are part of an ongoing £2.75bil (S$4.6bil or RM15.3bil) five-year investment plan, said Dyson yestweday.
 Founder James Dyson said: “Software, connectivity, AI and proprietary new technology batteries will power the next generation of Dyson technology.
 “Just like our long-term investments in pioneering digital electric motor technology, Dyson’s next-generation batteries will drive a major revolution in the performance and sustainability of Dyson’s machines.”
 While the company did not disclose the investment value of Singapore’s new battery plant, a spokesman said: “This investment is part of our ongoing US$1.5bil (RM6.7bil) commitment to our future in Singapore.”
 The high-tech plant will produce proprietary batteries that will be smaller, lighter, more sustainable and more energy-dense than the ones available today, said the spokesman. 
 Dyson started developing in-house batteries more than a decade ago.
 “Our advanced manufacturing expansion in Singapore will enable Dyson to bring entirely new battery technology to market,” said Dyson chief executive Roland Krueger, who also gave a nod to Singapore’s highly skilled workforce of engineers and scientists, along with a supportive government. — The Straits Times/ANN
 ends",consumer electronics giant dyson factory tuas manufacture generation battery company product move investment manufacturing firm history facility equivalent basketball court expected operational broader move ramp software artificial intelligence product development dyson double manufacturing footprint worldwide singapore company britain philippine focus development capability development bil bil bil investment plan yestweday founder james software connectivity proprietary technology battery power generation dyson technology term investment digital electric motor technology dyson generation battery major revolution performance sustainability dyson machine company investment singapore battery plant spokesman investment bil bil commitment future singapore tech plant proprietary battery sustainable energy dense spokesman dyson house battery decade manufacturing expansion enable dyson battery technology market dyson chief executive roland krueger workforce engineer scientist supportive government strait time,"[(3, 0.99281967)]",3
541418,Main,28,04/05/2023,‘Godfather of  AI’ warns of tech’s dangers  after exit  from Google,,"WASHINGTON: A pioneering researcher and the so-called “Godfather of AI” Geoffrey Hinton says he quit his role at Google so he could more freely speak about the dangers of the technology he helped create.
 Over his decades-long career, Hinton’s pioneering work on deep learning and neural networks helped lay the foundation for much of the AI technology today.
 Some of the dangers of AI chatbots are “quite scary,” Hinton told the BBC. “Right now, they’re not more intelligent than us, as far as I can tell. But I think they soon may be.”
 In an interview with MIT Technology Review, Hinton also pointed to “bad actors” that may use AI in ways that could have detrimental impacts on society – such as manipulating elections or instigating violence.
 Hinton, 75, says he retired from Google so that he could speak openly about the potential risks as someone who no longer works for the tech giant.
 Since announcing his departure, however, Hinton has maintained that Google has “acted very responsibly” regarding AI. Google confirmed that Hinton had retired from his role after 10 years overseeing the Google Research team in Toronto.
 There has been a spasm of AI introductions in recent months. San Francisco-based startup OpenAI, the Microsoft-backed company behind ChatGPT, rolled out its latest artificial intelligence model, GPT-4, in March. Other tech giants have invested in competing tools – including Google’s own “Bard”.
 At the heart of the debate over AI is whether the primary dangers are in the future or present. 
 On one side are hypothetical scenarios of existential risk caused by computers that supersede human intelligence. On the other are concerns about automated technology that’s already getting widely deployed by businesses and governments and can cause real-world harms.
 A number of AI researchers have long expressed concerns about racial, gender and other forms of bias in AI systems, including text-based large language models that are trained on huge troves of human writing and can amplify discrimination that exists in society.
 “The harms that are being enacted by AI systems today are really not evenly distributed. It’s very much exacerbating existing patterns of inequality,” said Sarah Myers West, managing director of the nonprofit AI Now Institute.
 Hinton was one of three AI pioneers who in 2019 won the Turing Award, an honour that has become known as tech industry’s version of the Nobel Prize. The other two winners, Yoshua Bengio and Yann LeCun, have also expressed concerns about the future of AI. — AP",washington researcher godfather hinton quit role google speak danger technology decade hinton deep neural network foundation technology danger chatbots scary hinton bbc intelligent interview mit technology hinton bad actor detrimental impact society election violence hinton google speak potential risk tech giant departure hinton google google hinton role google team toronto spasm introduction month francisco startup openai microsoft company chatgpt artificial intelligence model gpt march tech giant tool google bard heart debate primary danger future hypothetical scenario existential risk computer human intelligence concern technology business government real harm researcher concern racial gender form system text language model huge trove human amplify discrimination society harm system pattern inequality myers director nonprofit institute hinton pioneer honour tech industry version prize winner bengio yann lecun concern future,"[(1, 0.9932044)]",1
540612,StarBiz,8,02/05/2023,"Tech, AI driving job changes for nearly a quarter of all workers",,"NEW YORK: Global labour markets are poised for a new era of turbulence as technologies like artificial intelligence (AI) accelerate the decline of clerical work, while simultaneously increasing demand for technology and cybersecurity specialists.
 Over the next five years, nearly a quarter of all jobs will change as a result of AI, digitisation and other economic developments like the green energy transition and supply chain re-shoring, according to a report published by the World Economic Forum (WEF) in Geneva. 
 While the study expects AI to result in “significant labour-market disruption,” the net impact of most technologies will be positive over the next five years as big data analytics, management technologies and cybersecurity become the biggest drivers of employment growth. 
 The emergence of AI applications like ChatGPT, which uses machines to simulate human reasoning and problem solving, will have a particularly pronounced impact by displacing and automating many roles that involve reasoning, communicating and coordinating, the report said. 
 Some 75% of surveyed companies said they expect to adopt AI technologies over the next five years, which they predict will eliminate up to 26 million jobs in record-keeping and administrative positions – think cashiers, ticket clerks, data entry and accounting. 
 The WEF study surveyed more than 800 companies that collectively employ 11.3 million workers across 45 economies from all over the world. — Bloomberg",york global labour market era turbulence technology artificial intelligence decline clerical demand technology cybersecurity specialist quarter job result digitisation economic development green energy transition supply chain report economic forum wef geneva study labour market disruption net impact technology positive data analytics management technology cybersecurity biggest driver employment growth emergence application machine human pronounced impact role report company adopt technology job record administrative position cashier clerk data entry accounting wef study company worker economy,"[(4, 0.9879501)]",4
540596,StarBiz,13,02/05/2023,EU sees political agreement on AI law this year,,"TOKYO: The European Union (EU) is likely to reach a political agreement this year that will pave the way for the world’s first major artificial intelligence (AI) law, the bloc’s tech regulation chief Margrethe Vestager says.
 This follows a preliminary deal reached last Thursday by members of the European Parliament to push through the draft of the eurozone’s Artificial Intelligence Act for a vote by a committee of lawmakers on May 11. 
 The European Parliament will then thrash out the bill’s final details with EU member states and the European Commission before it becomes law.
 At a press conference after a Group of Seven (G7) digital ministers’ meeting in Takasaki, Japan, Vestager said the EU AI Act was “pro-innovation” since it seeks to mitigate the risks of societal damage from emerging technologies.
 Regulators around the world have been trying to find a balance where governments could develop “guardrails” on emerging artificial intelligence technology without stifling innovation.
 “The reason why we have these guardrails for high-risk use cases is that cleaning up, after a misuse by AI would be so much more expensive and damaging than the use case of AI in itself,” Vestager said.
 While the EU AI Act is expected to be passed this year, lawyers have said it will take a few years for it to be enforced. 
 But Vestager said businesses could start considering the  implications of the new legislation.
 “There was no reason to hesitate and to wait for the legislation to be passed to accelerate the necessary discussions to provide the changes in all the systems where AI will have an enormous influence,” she said in the interview.
 While research on AI has been going on for years, the sudden popularity of generative AI applications such as OpenAI’s ChatGPT and Midjourney has led to a scramble by lawmakers to find ways to regulate any uncontrolled growth.
 An organisation backed by Elon Musk and European lawmakers involved in drafting the EU AI Act are among those who have called for world leaders to collaborate to find ways to stop advanced AI from creating disruptions. 
 On Sunday, the digital ministers of the G7 advanced nations also agreed to adopt “risk-based” regulation on AI, among the first steps that could lead to global agreements on how to regulate AI.
 “Now that everyone has AI at their fingertips, there’s a need for us to show the political leadership to make sure that one can safely use AI and gain all the amazing possibilities of improvement in productivity and better services,” Vestager said. — Reuters",tokyo european union political agreement major artificial intelligence law bloc tech regulation chief margrethe vestager preliminary deal thursday european parliament push draft eurozone artificial intelligence vote committee lawmaker european parliament thrash bill final detail european commission law press conference digital minister japan vestager pro innovation mitigate risk societal damage technology regulator government guardrail artificial intelligence technology innovation reason guardrail risk cleaning misuse expensive damaging vestager lawyer vestager business implication legislation reason hesitate wait legislation accelerate discussion system enormous influence interview sudden popularity generative application chatgpt midjourney scramble lawmaker uncontrolled growth organisation elon musk european lawmaker leader advanced disruption sunday digital minister nation risk regulation step global agreement fingertip political leadership gain amazing possibility improvement productivity service vestager reuters,"[(3, 0.9929861)]",3
540170,Lifestyle,6,01/05/2023,AI could help people    _x000D_  quit  _x000D_ smoking,,"RESEARCHERS in the United Kingdom have developed a smartphone application to help people stop smoking. Based on artificial intelligence (AI), this app is able to detect when and where a smoker would want to light up a cigarette.According to the researchers’ first tests, this method could be more effective than online services to help people kick the habit.
 A new study conducted by the University of East Anglia, in ­collaboration with several other British universities, shows that an AI-based smartphone application could become an effective smoking cessation aid. Called Quit Sense, the application detects smoking triggers, and helps smokers manage their cravings in real time by sending them supportive messages.“We know that quit attempts often fail because urges to smoke are triggered by spending time in places where people used to smoke. This might be while at the pub or at work, for example. Other than using medication, there are no existing ways of ­providing support to help ­smokers manage these types of situations and urges as they ­happen,” explains Prof Felix Naughton, lead researcher on the study, published in the journal Nicotine And Tobacco Research.
 To test the effectiveness of Quit Sense, researchers conducted a trial with 209 smokers recruited via social networks. All participants received a link to the National Health Service (NHS) online smoking cessation service. Only half of the volunteers received a link to the Quit Sense application. After six months, participants were asked to report back through online follow-up measures. Those who reported quitting smoking were asked to provide a saliva sample to verify their claim.
 “We found that when smokers were offered the Quit Sense app, three-quarters installed it and those who started a quit attempt with the app used it for around one month on average. We also found that four times more ­people who were offered the app quit smoking six months later compared to those only offered online NHS support,” says Naughton.
 The research team notes that there are limitations to this study, however, in that it was conducted on a small scale and less than half of those who reported quitting smoking provided a saliva sample as agreed. More research is needed to assess the effectiveness of the application. – AFP Relaxnews",researcher kingdom smartphone application people artificial intelligence app detect smoker cigarette researcher test effective online service people habit study university east anglia collaboration british university smartphone application effective smoking cessation aid quit sense application trigger smoker craving real time supportive message attempt urge spending time people pub medication support smoker type situation urge prof felix naughton researcher study journal nicotine tobacco test effectiveness quit sense researcher trial smoker social network participant link national health service online cessation service half volunteer link quit sense application month participant online follow measure provide saliva sample claim smoker quit sense app quarter quit attempt app month average time people app quit month online nh support naughton team note limitation scale half smoking saliva sample ass effectiveness application afp relaxnews,"[(4, 0.99302703)]",4
540250,StarBiz,2,01/05/2023,Local AI startup Vox secures RM1.1mil funding from Silicon Valley,,"PETALING JAYA: Malaysian artificial intelligence (AI) startup, Vox, has secured a US$250,000 (RM1.1mil) investment in pre-seed funding from Silicon Valley.
 According to a news report, the funding was secured on April 24 from a high-net-worth individual (HNWI), whose identity was not disclosed.
 The new funds will be used to cover operational costs of the platform for the first 50,000 users of Vox’s Sharly.ai platform.
 Sharly.ai is a productivity tool that uses generative AI to help professionals save time in understanding long documents. 
 An HNWI is defined as an individual who has at least US$1mil (RM4.5mil) in liquid financial assets. 
 The Kuala Lumpur-based Vox, which was founded by entrepreneur Simone Macario, helps enterprises to automate conversational experiences with the adoption of AI.
 “We partner with our clients and drive their digital transformation by elevating their communication level,” the company said on its official website.
 Additionally, the AI firm said on its website that its team works in a unified manner to support brands in acquiring and applying knowledge and skills.
 “We share values such as integrity, accountability, sustainability and diversity. We commit high quality solutions that scale, by working at our partners’ side.”
 According to the company’s website, Vox provides solutions for the retail, food and beverage, finance and banking sectors.
 Its retail-based solutions offer a frictionless user experience, providing accurate answers to customers’ needs while maximising oerational efficiencies.
 Vox’s finance-based solutions provide virtual assistance for banking, insurance and investments, and assists customers on their financial journey.",jaya malaysian artificial intelligence startup vox mil investment pre seed funding silicon valley news report funding april net worth individual hnwi identity fund cover operational cost user platform productivity tool generative professional time understanding document hnwi individual mil mil liquid financial asset lumpur vox entrepreneur simone macario enterprise conversational experience adoption partner client digital transformation communication level company official website firm website team manner support brand knowledge skill share integrity accountability sustainability diversity quality solution partner company vox solution food beverage finance banking sector solution frictionless user experience accurate answer customer oerational efficiency finance solution virtual assistance banking insurance investment customer financial journey,"[(3, 0.45105895), (4, 0.5425351)]",4
540394,Main,26,01/05/2023,G7 in AI regulation talks,"High time to adopt ‘risk-based’ laws, urge digital ministers","TAKASAKI: Group of Seven advanced nations should adopt “risk-based” regulation on artificial intelligence, their digital ministers agreed, as European lawmakers hurry to introduce an AI Act to enforce rules on emerging tools such as ChatGPT.
 But such regulation should also “preserve an open and enabling environment” for the development of AI technologies and be based on democratic values, G7 ministers said in a joint statement issued at the end of a two-day meeting in Japan yesterday.
 While the ministers recognised that “policy instruments to achieve the common vision and goal of trustworthy AI may vary across G7 members”, the agreement sets a landmark for how major countries govern AI amid privacy concerns and security risks.
 “The conclusions of this G7 meeting show that we are definitely not alone in this,” European Commission Executive Vice-President Margrethe Vestager said ahead of the agreement.
 Governments have especially paid attention to the popularity of generative AI tools such as ChatGPT, a chatbot developed by Microsoft Corp-backed OpenAI that has become the fastest-growing app in history since its November launch.
 “We plan to convene future G7 discussions on generative AI which could include topics such as governance, how to safeguard intellectual property rights including copyright, promote transparency, address disinformation” including information manipulation by foreign forces, the ministerial statement said.
 Italy, a G7 member, took ChatGPT offline last month to investigate its potential breach of personal data rules. While Italy lifted the ban on Friday, the move has inspired fellow European privacy regulators to launch probes.
 EU lawmakers on Thursday reached a preliminary agreement on a new draft of its upcoming AI Act, including copyright protection measures for generative AI, following a call for world leaders to convene a summit to control such technology.
 Vestager, EU’s tech regulation chief, said the bloc “will have the political agreement this year” on the AI legislation, such as labelling obligations for AI-generated images or music, to address copyright and educational risks.
 Japan, this year’s chair of G7, meanwhile, has taken an accommodative approach on AI developers, pledging support for public and industrial adoption of AI.
 Japan hoped to get the G7 “to agree on agile or flexible governance, rather than preemptive, catch-all regulation” over AI technology, industry minister Yasu­toshi Nishimura said on Friday ahead of the ministerial talks. — Reuters",takasaki nation risk regulation artificial intelligence digital minister european lawmaker enforce rule tool chatgpt regulation preserve environment development technology democratic value minister joint statement day japan yesterday minister policy instrument common vision goal trustworthy vary agreement set major country privacy concern security risk conclusion european commission executive vice president margrethe vestager agreement government attention popularity generative tool chatbot microsoft corp openai fastest app history november launch plan future discussion topic governance intellectual property right copyright promote transparency address disinformation manipulation foreign force ministerial statement italy chatgpt offline month potential breach personal data rule ban friday fellow european privacy regulator probe lawmaker preliminary agreement draft copyright protection measure generative call leader convene summit control technology vestager tech regulation chief bloc political agreement legislation obligation image music address educational risk chair accommodative approach developer support public industrial adoption japan agile flexible governance preemptive catch regulation technology industry minister toshi nishimura friday ministerial talk reuters,"[(3, 0.9944569)]",3
539176,StarBiz,16,28/04/2023,JPMorgan’s AI puts 25 years of Fed speeches into a hawk-dove score,,"NEW YORK: A week before the Federal Reserve’s (Fed) next meeting, JPMorgan Chase & Co unveiled an artificial intelligence (AI)-powered model that aims to decipher the central bank’s messaging and uncover potential trading signals.
 Based off on Fed statements and central-banker speeches going back 25 years, the firm’s economists including Joseph Lupton employed a ChatGPT-based language model to detect the tenor of policy signals, effectively rating them on a scale from easy to restrictive in what JPMorgan is calling the Hawk-Dove Score.
 Plotting the index against a range of asset performances, the economists found that the AI tool can be useful in potentially predicting changes in policy – and give off tradeable signals. 
 For instance, they discovered that when the model shows a rise in hawkishness among Fed speakers between meetings, the next policy statement has gotten more hawkish and yields on one-year government bonds advanced.
 “Preliminary applications are encouraging,” Lupton and his colleagues wrote in a note accompanying the debut.
 The tool is another push in Wall Street’s never-ending search for a trading edge and one of the earliest adoptions of the technology developed by OpenAI. 
 Earlier this month, a couple of research papers showed that ChatGPT can add value in market-relevant tasks, such as deciphering whether Fed statements were hawkish or dovish, or determining whether headlines were good or bad for a stock.  Based on the JPMorgan model, while the reading for Fed statements has fluctuated in recent months and that for speeches has trended lower, both still hover near the highest levels in two decades, a clear sign of persistent hawkishness. 
 The Fed is expected to raise its benchmark interest rate next week by another 25 basis points to 5.25%, according to the median forecast by economists in a Bloomberg survey. 
 “Investors have been laser-focused on the Fed’s policy path after its aggressive tightening campaign to battle inflation drove stocks and bonds into rare, concerted sell-offs last year,” said a source. 
 While asset prices have since recovered, bond traders have kept betting on rate cuts later this year, defying Fed chair Jerome Powell’s warnings that rate reductions in 2023 aren’t on his mind.
 Going by JPMorgan’s model, a 10-point increase in the Fed hawk-dove score now translates to roughly an increase of 10 percentage points in the probability of a 25 basis point hike at the central bank’s next policy meeting, or vice versa.  
 The hawk-dove score, also available for the European Central Bank and the Bank of England, is expected to expand to more than 30 central banks around the world in the coming months. — Bloomberg",york week federal reserve jpmorgan chase artificial intelligence model central bank uncover potential trading signal fed statement central banker speech firm economist joseph lupton chatgpt language model detect tenor policy signal rating scale easy restrictive jpmorgan hawk range asset performance economist tool predicting policy tradeable signal instance model rise hawkishness fed speaker meeting policy statement hawkish yield government bond preliminary application lupton colleague debut tool push wall street search trading edge earliest adoption technology month couple paper add market relevant task fed statement hawkish dovish headline bad stock jpmorgan model statement month speech lower hover level decade persistent hawkishness fed benchmark rate week basis median forecast economist survey investor focused fed policy path aggressive tightening campaign battle inflation stock bond sell offs source asset price bond trader rate cut fed chair jerome warning rate reduction jpmorgan model increase hawk dove score increase percentage probability basis hike central bank policy meeting vice versa hawk european central bank bank england central bank month,"[(4, 0.99466896)]",4
538460,StarBiz,16,26/04/2023,Tech companies to highlight AI in earnings,Investors to focus on profits post-cost cuts,"NEW YORK: US tech giants will emphasise how artificial intelligence (AI) can be the next growth driver when they report quarterly results this week, while investors scrutinise if cost cuts have boosted profits to their satisfaction.
 Microsoft Corp and Google parent Alphabet Inc kick off earnings for the companies soon, with Instagram owner Meta Platforms Inc and Amazon.com Inc set to report later in the week.
 Together, they command more than US$5 trillion (RM22.2 trillion) in market capitalisation, or more than 14% of the value of the S&P 500 index.
 Between Microsoft, Alphabet and Meta, analysts expect profits to rise 4.5%, on average, from the immediately preceding quarter, led by an 11.8% jump in Meta’s bottom line, according to Refinitiv.
 From a year earlier, profit is expected to slump nearly 16%, on average, with Microsoft expected to perform the least poorly with a 0.5% slip.
 These three companies, along with Amazon, said between November and March they would slash 70,000 jobs in a rapidly weakening economy, following a pandemic-led hiring boom.
 Meta has announced two rounds of layoffs.
 Amazon.com Inc, which reported a big drop in fourth-quarter profit due to valuation losses because of its investment in money-losing electric vehicle maker Rivian Automotive, is set to post a first-quarter profit that is expected to increase eight times, when compared with the immediately previous quarter.
 According to research firm YipitData, Amazon’s North America sales are set to beat Wall Street estimates in the first quarter.
 The companies are likely to give updates on their AI efforts, a trend noticeable since last quarter when chief executives packed earnings calls with mentions of the technology.
 “If last quarter’s message from Big Tech was all about efficiency and bottom line improvement, this quarter’s message is likely to be more forward-looking around the massive potential of AI,” Andrew Lipsman, analyst at Insider Intelligence, said.
 Microsoft has integrated OpenAI’s ChatGPT technology into its search engine Bing, pitting it against market leader Google, which has begun the public release of its chatbot Bard.
 Amazon’s cloud division AWS, the world’s largest, has released a suite of technologies aimed at helping other companies develop their own chatbots backed by AI, and Meta has published an AI model that can pick out individual objects from within an image.
 “It’s sort of a double-edged sword because there is also pressure for these companies to improve cash flow in an economy that is decelerating,” Itau BBA analyst Thiago Kapulskis said.
 “There are expectations that companies could create or do even more with AI, every tech investor is expecting those companies to be in the frontier.”
 The cloud businesses of Amazon, Google and Microsoft were also more stable than expected, analysts said. Microsoft and Alphabet stocks have both risen around 20% so far this year. — Reuters",york tech giant artificial intelligence growth report quarterly week investor cost cut profit satisfaction microsoft corp google parent alphabet kick earnings company owner meta platform report week market capitalisation alphabet meta analyst profit average preceding quarter jump meta bottom refinitiv profit slump average microsoft perform slip company november march slash job economy pandemic hiring boom meta round layoff drop fourth quarter profit valuation loss investment money electric vehicle maker rivian automotive set post quarter profit increase time previous quarter firm yipitdata america sale beat wall street estimate quarter company effort trend noticeable quarter chief executive earnings call mention technology quarter message tech efficiency bottom improvement quarter message massive potential lipsman analyst insider intelligence integrated openai chatgpt technology search engine market leader google public release chatbot bard amazon cloud division largest suite technology company chatbots meta model pick individual object image sort sword pressure company cash flow economy itau bba analyst thiago expectation company tech investor company cloud business google stable expected analyst alphabet stock reuters,"[(4, 0.99495643)]",4
538494,Main,10,26/04/2023,Looking at AI and drones to keep borders safe,,"BUKIT KAYU HITAM: The Home Ministry is exploring the possibility of using technology, including artificial intelligence and drones, to aid uniformed bodies on duty along the country’s borders.
 Home Minister Datuk Seri Saifuddin Nasution Ismail said the government lacks the resources to build new fencing along the border between Malaysia and Thailand, especially in Kedah and Perlis, due to the long distance involved.
 “I have seen the fencing in Padang Besar, Perlis myself. In the aspect of security control along the border, it does not only involve fencing but also drones and closed-circuit television cameras (CCTVs) at strategic locations.
 “We need to explore such a possibility due to the high cost involved in the maintenance of the fencing that sprawls over a long distance. Therefore, due to the lack of resources to build  new fences, we must look at preserving the existence fence,” he said.
 He was speaking to reporters after celebrating Hari Raya Aidilfitri and giving out contributions at the General Operations Force (GOF) Tactical Camp here yesterday, Bernama reported.
 “I personally hope we will receive enough CCTVs to increase surveillance at strategic locations throughout the border,” he said.",bukit kayu hitam ministry possibility technology artificial intelligence drone aid uniformed body country border minister seri saifuddin nasution ismail government lack resource border malaysia thailand kedah perlis distance padang besar perlis aspect security control border drone circuit television camera strategic location possibility cost maintenance sprawl distance lack resource fence existence fence reporter hari raya aidilfitri contribution operation gof tactical camp yesterday bernama hope cctvs increase surveillance strategic location border,"[(0, 0.98798084)]",0
537394,Main,16,22/04/2023,Japanese city councils testing the AI waters for admin work,,"THE Yokosuka City Hall in the Kanagawa prefecture will be the first local government in Japan to use ChatGPT in its offices, China Press reported.
 In a one-month trial, its 4,000 employees will use the artificial intelligence (AI) chatbot created by OpenAI to document minutes of meetings and help with administrative work starting April 20.
 Due to privacy issues, its civil servants are prohibited from entering personal and confidential data into ChatGPT.
 On April 18, the Kanagawa prefecture government even issued a press statement using ChatGPT, with minor edits from council officers.
 Other local governments in Japan are also eager to incorporate ChatGPT into their operations.
 In Toda City in the Saitama prefecture, a 16-member research team was set up to study the possibility of its city hall using ChatGPT to automatically answer questions from the public.
 > Former TVB actress Linda Chung, a mother of three, has decided not to have another child, China Press reported.
 The Canada-based star was back in Hong Kong recently with her chiropractor husband Jeremy Leung and their children for a commercial shoot.
 She told reporters that she resolved to “stop at three” after discussing it with Leung.
 The couple have two daughters Kelly, six, and six-month-old Anika Linda. Their son Jared is four.
 Chung, 39, also said that being a mother and bringing up children was tougher than acting in a movie.",yokosuka city hall prefecture local government japan chatgpt office month trial employee artificial intelligence chatbot openai document minute meeting administrative april privacy issue civil servant personal confidential data chatgpt april kanagawa prefecture government press statement chatgpt minor edits council officer local government eager incorporate chatgpt operation city saitama prefecture team study possibility city hall answer question public tvb actress linda chung mother child china press canada star hong kong chiropractor husband jeremy leung child commercial shoot reporter leung couple daughter month anika linda son chung mother child movie,"[(4, 0.9905973)]",4
537416,StarBiz 7,4,22/04/2023,TSMC keeps spending to leverage the AI boom,By TIM CULPAN,"A weakening global economy and listless demand for electronics is finally catching up with Taiwan Semiconductor Manufacturing Co (TSMC), which last Thursday cut its outlook for both the company and the broader chip industry. 
 That will hurt the bottom line, but won’t divert the tech giant from its aggressive spending plan.
 Instead of posting slight growth this year, in US dollar terms, the world’s biggest chipmaker will report its first revenue decline since 2009, while the chip sector (excluding memory) will drop by a mid-single digit percentage. That weakness will be front-end loaded with the first half dropping 10% from a year earlier.
 Inventory is the culprit. A lot of TSMC’s modelling for 2023 was based around the belief that clients would be able to sell stockpiles, and as they fall, new orders would flow in. 
 But that reduction is taking longer than expected because the economic outlook remains murky and China’s opening up following the pandemic isn’t happening at the pace TSMC had anticipated. 
 The result is a rise, rather than decline, in the company’s days of inventory to the highest level in at least 12 years. 
 Yet predictions that TSMC would get the shakes and slash its equipment budget by as much as US$4bil (RM17.7bil) to offset the frail outlook didn’t pan out. Instead, the biggest surprise in the earnings call was to maintain its January forecast for capital expenditure of US$32bil to US$36bil (RM142bil to RM160bil) this year. It was US$36.3bil (RM161bil) in 2022.
 There’s a few reasons for being steadfast.
 First, around 70% of its spending goes toward gear used in advanced manufacturing technologies. Supply of items such as ASML Holding NV’s extreme ultraviolet (EUV) equipment remains tight. 
 On Wednesday, the Dutch company said its forecast to ship 60 EUV systems this year was unchanged, with the firm facing a two-year backlog on some tools. 
 While TSMC could cut orders, doing so may risk its spot in the queue, and that would disadvantage itself and aid competitors who are keen to get their hands on crucial machinery.
 Second, TSMC chief executive officer C.C. Wei told investors that it’s focused on expansion so it can meet capacity needs as soon as client orders start flowing in. 
 With gross margin over 55%, losing out on a sale for lack of supply is an expensive proposition. 
 Third, while demand remains weak in smartphones and personal computers, artificial intelligence (AI) is a bright spot thanks to the recent boom in generative applications such as ChatGPT. 
 If you were to choose a single segment to remain strong during a chip downturn, it would be AI. TSMC’s high-performance computing (HPC) category, which includes specialised AI components, accounts for 44% of revenue. 
 Moreover, clients in this space – including Nvidia Corp, Microsoft Corp and Advanced Micro Devices Inc – require the latest manufacturing nodes in order to maintain their competitive advantage.
 Having products made on older technology dilutes the power and performance of the chips they design. This leading-edge production also commands a premium price.
 “We have recently observed incremental upside in AI-related demand which helps ongoing inventory digestion,” Wei said. 
 “ChatGPT right now enforces the already strong conviction we have in HPC and AI as a structural megatrend.”
 TSMC’s commitment to blaze ahead even as revenue falls will surely hurt profitability. 
 Lower capacity utilisation, rising electricity prices in Taiwan, and more expensive construction costs for expansion in the United States and Japan will compound the problem. 
 Its ability to rein in costs, as demonstrated in the first quarter, could mitigate this challenge.
 Still, for better or worse, management has chosen to stay the course rather than chase profits. Investors may not like the strategy, but clients will love it. — BloombergTim Culpan is a Bloomberg opinion columnist covering technology in Asia. the views expressed here are the writer’s own.",global economy listless demand electronics taiwan semiconductor manufacturing tsmc thursday outlook company broader chip industry bottom divert tech giant aggressive spending plan slight growth dollar term biggest chipmaker report revenue chip sector memory drop mid single digit percentage weakness front half earlier inventory culprit lot belief client stockpile flow reduction economic outlook murky china pandemic pace tsmc result rise decline company day inventory level prediction shake slash equipment budget bil bil frail outlook pan biggest surprise earnings call january forecast capital expenditure bil bil bil bil bil bil reason spending gear manufacturing technology item extreme ultraviolet euv equipment tight wednesday company forecast ship euv system unchanged firm backlog tool risk spot queue disadvantage aid competitor keen hand crucial machinery tsmc chief executive officer investor expansion meet capacity client start gross margin sale lack supply expensive proposition demand weak smartphones personal computer artificial intelligence spot boom generative application choose single segment strong chip downturn tsmc performance hpc category specialised component account revenue client space corp microsoft corp micro device node competitive advantage product technology power performance chip design edge production premium price incremental upside demand ongoing inventory digestion wei chatgpt strong conviction hpc structural megatrend tsmc commitment blaze revenue profitability capacity utilisation electricity price expensive construction expansion japan compound ability rein cost quarter mitigate challenge worse management chase profit investor strategy client bloombergtim culpan bloomberg opinion columnist technology asia view writer,"[(4, 0.99617183)]",4
536246,StarBiz,12,19/04/2023,EU lawmakers call for meet to control ‘powerful’ AI,,"LONDON: European Union (EU) lawmakers are urging world leaders to hold a summit to find ways to control the development of advanced artificial intelligence (AI) systems such as ChatGPT, saying they are developing faster than expected.
 The 12 members of the European Parliament (MEPS), working on EU legislation on the technology, called on US President Joe Biden and European Commission President Ursula von der Leyen to convene the meeting and said AI firms should be more responsible.
 The statement came weeks after Twitter owner Elon Musk and more than 1,000 technology figures demanded a six-month pause in the development of systems more powerful than Microsoft-backed OpenAI’s latest iteration of ChatGPT, which can mimic humans and create text and images based on prompts.
 That open letter, published in March by the Future of Life Institute (FLI), warned that AI could spread misinformation at an unprecedented rate and that machines could “outnumber, outsmart, obsolete and replace” humans if left unchecked.
 The MEPS said they disagreed with some of the FLI message’s “more alarmist statements”.
 “We are nevertheless in agreement with the letter’s core message, with the rapid evolution of powerful AI, we see the need for significant political action,” they added.
 The letter urged democratic and “non-democratic” countries to reflect on potential systems of governance and to exercise restraint in their pursuit of very powerful AI.
 A spokesperson for von der Leyen did not immediately respond to a request for comment.
 Responding to the lawmakers’ accusation of alarmism, FLI president Max Tegmark said: “They can think whatever they want as long as they do the right thing.”
 Tegmark told Reuters he was “delighted” by the reply and praised MEPs for taking the lead on AI regulation globally.
 “A key goal of our open letter was really to mainstream the conversation about policymaking and regulation,” he said.
 “It feels like our open letter really struck a nerve. A lot of people had the urge to discuss these things but held back for fear of being seen as paranoid Luddites. The most important thing is that this conversation is happening.”
 Last week, China’s cyberspace regulator unveiled draft measures for managing generative AI services, saying it wants firms to submit security assessments to authorities before they launch their offerings to the public.
 The Biden administration has also been seeking public comments on potential accountability measures for AI systems as questions loom about their impact on national security and education.
 The European Commission proposed the draft rules for an AI Act nearly two years ago, under which AI tools are expected to be classified according to their perceived level of risk, from low to unacceptable.
 A parliamentary committee is debating the 108-page bill and hoping to reach a consensus by April 26, according to two sources familiar with the matter. — Reuters",london european union lawmaker leader summit control development artificial intelligence system chatgpt european parliament meps legislation technology president joe biden european commission president ursula von der leyen convene meeting firm responsible statement week twitter owner musk technology figure month pause development system powerful microsoft openai iteration chatgpt mimic human text image prompt letter march future life institute fli spread misinformation unprecedented rate machine outsmart obsolete human unchecked meps fli message alarmist statement agreement letter core message rapid evolution powerful political action letter democratic democratic country potential system governance exercise restraint pursuit powerful spokesperson von der leyen respond request comment lawmaker alarmism fli president max tegmark tegmark reuters reply meps lead regulation key goal letter mainstream conversation regulation feel letter nerve lot people fear paranoid luddite conversation week china cyberspace regulator draft measure generative service firm security assessment authority launch offering public biden administration public comment potential accountability system question impact national security education european commission draft rule tool classified level risk low unacceptable parliamentary committee bill consensus april source familiar matter reuters,"[(3, 0.99493164)]",3
536292,Main,28,19/04/2023,Elon Musk plans to launch ‘TruthGPT’  AI platform,,"SAN FRANCISCO: Billionaire Elon Musk said he will launch an artificial intelligence (AI) platform that he calls “TruthGPT”, in an apparent challenge to ChatGPT, the popular chatbot from OpenAI.
 “I’m going to start something which I call ‘TruthGPT,’ or a maximum truth-seeking AI that tries to understand the nature of the universe,” Musk said in an interview with Fox News Channel’s Tucker Carlson on Monday.
 “And I think this might be the best path to safety, in the sense that an AI that cares about understanding the universe, it is unlikely to annihilate humans because we are an interesting part of the universe,” he said.
 Musk has been poaching AI researchers from Alphabet Inc’s Google to launch a startup to rival OpenAI, sources said.
 Musk last month registered a firm named X.AI Corp, incorporated in Nevada, according to a state filing. The firm listed Musk as the sole director and Jared Birchall, the managing director of Musk’s family office, as a secretary.The move came even after Musk and a group of artificial intelligence experts and industry executives called for a six-month pause in developing systems more  powerful than OpenAI’s newly launched GPT-4, citing potential risks to society. — Reuters",san francisco billionaire elon musk launch artificial intelligence platform truthgpt apparent challenge chatgpt popular chatbot start call truthgpt maximum truth understand nature universe musk interview fox news channel tucker carlson monday path safety sense understanding universe annihilate human universe musk researcher google launch startup rival openai source month firm corp firm musk sole director birchall director family office secretary move artificial intelligence expert industry executive month system powerful openai gpt potential risk society reuters,"[(3, 0.98863435)]",3
535910,Main,28,18/04/2023,Google CEO warns against rush to deploy AI without oversight,,"MOUNTAIN VIEW (California): Alphabet Inc and Google Chief Executive Officer Sundar Pichai said that the push to adopt artificial intelligence technology must be well regulated to avoid potential harmful effects.
 Asked in a 60 Minutes interview about what keeps him up at night with regard to AI, Pichai on Sunday said “the urgency to work and deploy it in a beneficial way, but at the same time it can be very harmful if deployed wrongly.”
 Mountain View, California-based Google has been among the leaders in developing and implementing AI across its services. Software like Google Lens and Google Photos rely on the company’s image-recognition systems, while its Google Assistant benefits from natural language processing research that Google has been doing for years. Still, its pace of deploying the technology has been measured, whereas OpenAI’s ChatGPT has opened up a race to move forward with AI tools at a much faster clip. 
 “We don’t have all the answers, and the technology is moving fast,” Pichai said. “So does that keep me up at night? Absolutely.” 
 Google is now playing catch-up to infuse its products with generative AI – software that can create text, images, music or even video based on user prompts. ChatGPT and another OpenAI product, Dall-E, showed the technology’s potential, and countless businesses from Silicon Valley to China’s internet leaders are now getting involved in their own offerings. Former Google CEO Eric Schmidt urged global tech companies to develop guardrails, warning that any slowdown in development would “simply benefit China”.
 Former Google CEO Rejects AI Research Pause Over China Fears
 Despite the sense of urgency in the industry, Pichai cautioned against companies being swept up in the competitive dynamics. And he finds lessons in the experience of OpenAI’s more direct approach and debut of ChatGPT. — Bloomberg",mountain view alphabet google chief executive officer sundar pichai push artificial intelligence technology avoid potential harmful effect minute interview night regard pichai sunday urgency beneficial time harmful mountain view california google leader service software google google photo company image recognition system assistant benefit natural language processing google pace technology chatgpt race move tool clip answer technology pichai night google catch infuse product generative software text image music video prompt openai product dall technology potential countless business silicon valley china internet leader offering google ceo eric schmidt global tech company guardrail slowdown development benefit china google ceo china fear sense urgency industry pichai company competitive dynamic lesson openai direct approach debut bloomberg,"[(1, 0.19090427), (4, 0.80344194)]",4
535550,Lifestyle,5,17/04/2023,Will AI catalyse or compromise creativity?,There is concern that artificial intelligence capable  of painting and composing could  dominate the art  world.,"COMPUTERS are painting pictures and composing music, and now they’re writing texts that actually make sense, too.
 The writings are typically the work of ChatGPT, a robot that web users can command to create texts about everything they can possibly imagine. 
 They aren’t too bad, either. You can’t tell they aren’t written by a person, not at first glance, anyway.
 A while back, artificial intelligence (AI) completed Ludwig van Beethoven’s 10th symphony – the work of Dall-E, a program that creates art that was developed by OpenAI of the United States, just like ChatGPT.
 And now anyone with an Internet connection can use a robot to create literature, with the latest development even capable of combining images with text.
 Such generative AI is pretty scary for some people, who fear that art may be under siege from robots.
 Double-edged sword 
 AI “can be a threat, but it can also be an opportunity for the arts, depending on the way it’s used”. That’s the answer from ... ChatGPT itself.
 People from the creative industries are also weighing the changing landscape, including Konrad Zerr, professor of marketing, market research and communications research at Pforzheim, Germany. 
 “I think it’s got enormous potential,” he says.
 Zerr tasked his students with creating a piece of art with AI. They asked ChatGPT to make a poem in the style of German poet Heinrich Heine that describes two people who go to a Christmas market and get into a fight.
 The outcomes were entertaining. “Whether you can see the great poet in our AI-generated poems is doubtful at this point,” was the view of the students themselves.
 The texts are no literary sensation. 
 If you ask ChatGPT to pen a poem about a cat in the style of Franz Kafka, for example, you get an uninspiring work about Kiki, a feline who wakes up one day and notices something strange, in the style of The Metamorphosis.
 But there are other, more impressive examples, such as A Girl With Glowing Earrings, an image created by photographer and “digital creator” Julien van Dieken, using AI. It’s based on Girl With A Pearl Earring, by Dutch master Jan Vermeer, and is currently on display in the Mauritshuis in The Hague.
 That upset some viewers, who asked why the museum had selected that particular work for display. 
 “Because we liked it, quite simply,” a spokesperson says.
 Before that, the agency Tunnel23 created a poem with the aid of AI and algorithms for a competition run by the Brentano Society, which included it in their anthology.
 A danger to art?
 Might robots take over the art world? Not quite, say observers. 
 “Art is always an interactive experience in which people are weighing their responses to reality,” says lecturer Jessica Heesen of Tubingen University, who focuses on ethical and philosophical issues relating to media and the digital world.
 What AI does is focus on patterns and probability, says Heesen. 
 But what it lacks is “the artist as a person, the aura of the original and also the challenge. Who do you address to complain about a work of art?”
 So when asking whether robots are a danger to art, it depends entirely on the notion of art you have, she says. “There will definitely be plenty of works created by AI in the future, making decorative works, say, to put in your kitchen or your living room.”
 But AI can assist in the creation of art, say both Zerr and Heesen. 
 “An artist can frame and contextualise and present the work,” says Heesen. Then AI acts as a helper, says Zerr. “And can also facilitate new art forms.”
 Helper, not replacer
 More of this was seen at Stuttgart’s art museum, in an exhibition called “Shift: AI and a Future Community”.
 On show are not only a talking Chinese doll or actress Marlene Dietrich as a deep fake but also a series of faces, including those of US activist and whistleblower Chelsea Manning.
 The 30 masks were created by US artist Heather Dewey-Hagborg for “Probably Chelsea”. 
 They are “possible portraits” of the whistleblower generated algorithmically by an analysis of her DNA. Dewey-Hagborg is highlighting “just how many ways your DNA can be interpreted as data, and how subjective the act of reading DNA really is”, says a statement on the artist’s website.
 The exhibition aims to investigate how “digital technology is permanently changing the idea of a community in which humans, nature and technology form a cooperative relationship”, according to the museum’s website. 
 AI already “influences, visibly or invisibly, political, economic and social processes” and has “long since arrived at the centre of society”, the site says.The works on display are complex and complicated, showing that AI has a long way to go before it is capable of moving beyond science and technology to create any kind of artistic quality and content.
 Future forecastThe interactions between art and AI are in their early stages. 
 “There’s a general consensus that AI systems are not as advanced as what people are able to create or at least not yet, I should say,” says Ulrike Groos, director of the Stuttgart museum of art. But she says it has potential.
 Zerr outlines his vision of the future: “The creative sector will have to undergo a fundamental change in its processes and capabilities. These tools will soon eventually become a standard part of life, sooner or later.” – dpa",computer picture music text sense writing robot web user text imagine bad person glance artificial intelligence ludwig van symphony dall program developed openai chatgpt internet connection robot create literature development capable combining image generative scary people art siege robot sword threat opportunity art answer chatgpt people creative industry landscape konrad zerr professor marketing market communication germany enormous potential zerr student piece art chatgpt poem style german poet heinrich heine people market fight outcome poet poem doubtful view student literary sensation chatgpt pen poem cat style franz uninspiring kiki feline wake day notice strange style metamorphosis impressive example earring image photographer digital creator julien van dieken girl pearl dutch master jan vermeer display mauritshuis hague upset viewer display spokesperson agency tunnel poem aid algorithm competition brentano society anthology danger art robot observer interactive experience people response reality lecturer jessica heesen tubingen university ethical philosophical issue medium digital focus pattern probability lack person aura original challenge address art robot notion plenty future decorative kitchen assist creation art zerr heesen artist frame contextualise heesen helper zerr facilitate art form replacer stuttgart art museum exhibition shift future community chinese doll actress marlene dietrich deep fake series activist whistleblower chelsea mask dewey hagborg chelsea portrait analysis dna dewey hagborg dna data subjective reading dna statement artist website exhibition aim digital technology idea community human nature technology form cooperative relationship museum website political economic social process centre society site display complex capable science technology create artistic quality content future forecastthe interaction stage system people ulrike groos director museum art potential zerr outline vision future creative sector undergo fundamental change capability tool standard life sooner dpa,"[(0, 0.9966857)]",0
535502,Main,23,16/04/2023,AI-proofing your career starts in college,,"THE job market has never offered any guarantees. Mechanisation wiped out once-secure careers in manufacturing. Now artificial intelligence (AI) is coming for a future generation of jobs that had seemed safe, starting with software coding and back-office work. So what can we do about it?
 Despite some hyperbolic fears, there are reasons to be optimistic about the future of technology. It has the potential to bring a better quality of life and more widespread prosperity – eventually. To prosper in this future, workers will need new skills and a different education. And that means rethinking how we approach college and what we want it to provide us.
 Most college degrees pay off not only in higher wages but because they mean graduates are less likely to be unemployed, or will be unemployed for less time. Evolving technology in the late 20th century put a higher premium on more education, leading more people to go to college. The share of the population over age 25 with some post-secondary education doubled between 1980 and 2021 to more than 60%. This increased the supply of graduates and also shrunk the wage premium for college degrees.
 More people going to college also means more bad outcomes: more dropouts and more degrees that don’t pay off. Meanwhile, the price of education has skyrocketed. So no surprise that many people are asking if college is even worth it anymore.
 It is. In fact, with new technology coming our way it will be more valuable than ever.
 If the past is any guide, thriving in an age of technological innovation requires being adaptable and finding different ways to add value. For example, machines that could weave cloth at scale displaced many workers, but master craftsmen who made exceptional-quality goods still had jobs. Other people had to learn how to work a machine. It was not an easy transition; there was a lot of social upheaval and displacement. How we educated the population changed to suit the new economy and it took several decades for workers to adapt. Industrialisation is a big reason why we adopted universal public education.
 Today’s technology arguably poses more challenges because some white-collar jobs will disappear, too. So far, large language models like ChatGPT are good at synthesising existing information to make a decent argument or find a solution to problems. The technology will only get more powerful, though its creative abilities will likely be limited.
 Psychologist Gerd Gigerenzer argues that AI is better suited to tasks where risks are well defined and the parameters are stable, like playing chess. It’s less good at dealing with problems where there is more uncertainty. We’ll face more of the latter because data and knowledge from the past tells you little about a fast-changing future. Past data can even be misleading. Gigerenzer thinks human judgment will remain critical, and the value might even be super-charged for people who learn to use the new technology properly.
 Interpersonal skills will also be prized. High-touch human time will be the rarest of commodities. Most importantly, thriving will require constantly learning new things and adapting swiftly because we don’t know how new technology will unfold.
 In short, success will come to those who know how to think and think well. This means students must hone their critical thinking skills as part of their education. 
 Getting that out of a college degree requires two things: different expectations and class selection on the part of students, and for universities and colleges to revamp their approach to curriculums. Even before AI, society struggled to figure out what a post-secondary education should provide. American universities and colleges were originally intended to be liberal arts institutions that aimed to make well-rounded, thoughtful leaders. In contrast to the European model where students specialise early, American students were meant to get a more cursory exposure to many different fields.
 This was reasonable when a small share of the population went to college and it wasn’t too expensive. But as more people pursued higher education and costs rose, the expectation changed. Students wanted a more vocational and career-focused education and were less interested in reading Plato. Meanwhile, colleges and universities stopped doing either job well. Many students struggle to apply their degree to the job market, and the education they get has become less rigorous. One study found little improvement in critical-thinking skills during the first few years among 45% of students.
 It’s understandable people want a clearer path to a career from their degrees, but treating college strictly as vocational education limits students’ skills. Now that critical and creative-thinking skills will be even more essential, American schools should embrace and improve on their original mission that aims to produce well-rounded thinkers.
 There are ways to make any college major more practical or to integrate the humanities, says Preston Cooper, a fellow at the Foundation for Research on Equal Opportunity who has researched the value of degrees. For instance, high-return degrees such as nursing could include more liberal arts classes. More traditional humanities majors like history could include marketing and communications courses. This would impart both hard skills and broader thinking ability, and students would enter the labour force more employable and adaptable.
 In the short run, it will fall on students to challenge themselves and take the initiative to make their college education more AI-proof. They need to seek out the classes that make them think more rigorously, including maths, and probability and statistics. Then balance those with humanities where they’ll learn history and how to write well.  (AI may do more writing for us in the future, but knowing how to write well helps clarify and organise your thoughts.) Students should develop a reading list that allows them to explore the great minds of the past and contemplate how to apply their insights to current times. 
 Face it, harder classes will mean a lot more work and may mean worse grades. But it will be the best insurance students can get from whatever change technology is going to be throwing at them. This is how they can get greater value from their degree – and in the new economy it will be more valuable than ever. The sooner they get started the better. – Bloomberg",job market guarantee mechanisation secure career artificial intelligence future generation job safe software office hyperbolic fear reason optimistic future technology potential bring quality life widespread prosperity prosper future worker skill approach college college degree wage graduate unemployed unemployed time technology late century premium education people college share population age post secondary education supply shrunk wage premium college degree people college bad outcome degree price education surprise people college technology valuable guide age technological innovation adaptable add machine scale displaced worker craftsman exceptional quality job people machine easy transition lot social upheaval displacement population suit economy worker adapt industrialisation reason universal public education technology challenge white collar job language model decent argument solution technology powerful creative ability psychologist gerd gigerenzer task risk parameter stable chess uncertainty data knowledge tell future data gigerenzer human judgment critical super people technology interpersonal skill touch human time rarest commodity require technology unfold short success student critical thinking skill college degree expectation class selection student university college approach curriculum society figure post secondary education american university college liberal art institution rounded thoughtful leader european model student american student meant cursory exposure field reasonable share population college expensive people education cost expectation student vocational career education plato college university job student degree job market education rigorous study improvement critical thinking skill student understandable people path career degree college vocational education limit student skill critical creative thinking skill essential american school original mission aim rounded thinker college major practical integrate humanity cooper fellow foundation equal opportunity degree instance return degree liberal art traditional humanity major history marketing communication course hard skill ability student labour force employable adaptable short fall student initiative college education proof seek class math probability statistic balance humanity history write future write help organise student list mind insight current time class worse grade insurance student technology degree economy valuable sooner bloomberg,"[(2, 0.9971868)]",2
533842,StarBiz,11,13/04/2023,Tech heavyweight Alibaba jumps on AI chatbot bandwagon,,"SHANGHAI: Chinese tech heavyweight Alibaba Group Holding Ltd unveiled its artificial intelligence (AI)-powered large language model – Tongyi Qianwen – which it plans to integrate into all of its applicable businesses, joining the chatbot race to offer a potential rival to ChatGPT.
 Alibaba Cloud, the cloud computing unit of Alibaba, will offer more enterprises access to Tongyi Qianwen so they can build their own customised large language models.
 “We are at a technological watershed moment driven by generative AI and cloud computing. Businesses across all sectors have started to embrace intelligent transformation to stay ahead of the game,” said Zhang Yong, chairman and CEO of Alibaba Group and CEO of Alibaba Cloud Intelligence.
 Zhang made the remarks at the 2023 Alibaba Cloud Summit, which was held on Tuesday in Beijing. The chairman added that Al-large models will be applied in a wide range of sectors, giving a big boost to productivity and profoundly changing people’s lifestyles.
 Alibaba began researching large language models in 2019. 
 It said the ChatGPT-style product will initially be deployed on DingTalk, the company’s workplace messaging app, to summarise meeting notes, create poetry, write emails and draft business proposals. 
 Interest in generative AI has surged since the release of ChatGPT by US-based startup OpenAI in November. 
 A number of leading Chinese tech firms, including Baidu Inc, Tencent Holdings Ltd and NetEase have jumped on the AI chatbot bandwagon.
 Alibaba’s unveiling came one day after Chinese AI pioneer SenseTime launched its latest set of large AI models – SenseNova – which cover key capabilities including computer vision, natural language processing and AI-generated content.
 Baidu rolled out its large language model and ChatGPT-like product, dubbed Ernie Bot, last month.
 On Tuesday, China’s cyberspace regulator unveiled draft measures for managing generative AI services.
 Providers will be responsible for the legitimacy of the data used to train generative AI products, and measures should be taken to prevent discrimination when designing algorithms and training data, the Cyberspace Administration of China said.
 The regulator said China supports the innovation and application of AI algorithms and other basic technologies and encourages the use of safe and reliable software, tools and data resources. But the content generated by generative AI should be in line with core socialist values. 
 Pan Helin, co-director of the Digital Economy and Financial Innovation at Zhejiang University, said the process of training large AI models necessitates higher requirements for computing capacity, and Alibaba has accumulated some advantages in AI infrastructure, with cloud computing being a key segment driving its revenue growth. — China Daily/ANN",shanghai chinese tech unveiled artificial intelligence language model tongyi qianwen plan applicable business chatbot race potential rival chatgpt alibaba cloud cloud unit alibaba offer access tongyi qianwen build language model technological moment generative cloud business sector embrace intelligent transformation stay game zhang chairman ceo ceo alibaba cloud intelligence zhang remark cloud summit tuesday beijing chairman model wide range sector productivity people lifestyle language model style product dingtalk company workplace app summarise meeting note poetry write draft business proposal release chatgpt startup openai november chinese tech firm baidu tencent holding netease chatbot bandwagon unveiling day chinese pioneer sensetime model cover key capability computer vision natural language processing content baidu language model chatgpt product ernie bot month tuesday cyberspace regulator draft measure generative service provider responsible legitimacy data generative product prevent discrimination algorithm training data cyberspace administration china regulator china innovation application algorithm basic technology safe reliable software tool data resource content generative core socialist value director digital economy financial innovation zhejiang university process training model requirement capacity advantage infrastructure cloud key segment revenue growth daily ann,"[(0, 0.99510074)]",0
534236,Main,11,13/04/2023,Human touch still valued above AI at most workplaces,,"PETALING JAYA: Despite the versatility of ChatGPT, a tool powered by artificial intelligence (AI), business leaders say that the human touch is still highly valued in many workplaces for day-to-day operations.
 Although the use of AI in retail will increase, customers still prefer interacting with humans, said Malaysia Retailers Association president Datuk Andrew Lim.
 “AI is a computer programme found in devices that can help deal with routine work, especially in reminding people of their ­schedule and tasks and providing assistance.
 “(But) In Malaysia, people still prefer dealing with humans because they want to be able to talk to someone.
 “In the retail business, when customers give feedback or make complaints, AI cannot deal with the emotions being conveyed. Sure, certain words can trigger certain responses, but how a human would react will be different.
 “A machine answering your query does not generate the same level of satisfaction,” he told The Star in response to businesses’ increasing adoption of AI to manage daily operations.
 Talent Corporation Malaysia Bhd (TalentCorp) group chief ­executive officer Thomas Mathew said the human touch is still vital when it comes to creative writing, the visuals and the feel of a marketing campaign.
 “While there is no hard policy on the use of AI tools at TalentCorp, we encourage continuous learning and experimenting so that our colleagues can keep up with new technologies, especially if it’s related to their work.
 “Currently the most popular AI tools are related to communications and production, so we do use them to help us generate ideas. It’s useful, especially during crunch times when we have hard deadlines to meet.
 “However, I’d caution against relying on them 100% because while AI is good at processing and analysing data, there are still glaring limitations, especially for creativity and empathy,” Mathew said, adding that TalentCorp’s existing human resources and information technology guidelines on ­ethics, plagiarism and security phishing attempts are sufficient for now.
 The Malaysian Association of Hotels (MAH) president Datin Christina Toh said the use of ChatGPT is merely a complementary element to the hospitality industry, which can help provide a more straightforward response.
 She said the human element remains a vital tool in running the industry, where connection with the customer is important.
 “AI usage for concierge services to provide information or bookings is one way that helps support the industry.
 “Nevertheless, the manner in which humans interact with one another can help capture other emotions, such as trust and satisfaction.
 “We cannot be 100% dependent on technology – it should be demarcated because customers want to be heard, and talking to a machine while pressing a button may not have the desired outcome,” she said.
 In an earlier report, human resources and IT experts said  companies should put in place effective policies on the use of the ChatGPT in the workplace as its use increases among employees.",jaya espite versatility chatgpt tool artificial intelligence business leader touch valued workplace day day operation retail increase customer human malaysia retailer president datuk lim computer programme device routine reminding people task assistance malaysia people human talk retail business customer complaint deal emotion trigger response human react machine query generate level satisfaction star response business adoption manage daily operation talent corporation malaysia bhd talentcorp chief executive officer mathew human touch vital creative writing visuals campaign hard policy tool talentcorp continuous colleague technology popular tool communication production idea crunch time hard deadline caution data limitation creativity mathew talentcorp human resource technology guideline ethic security phishing attempt sufficient malaysian association hotel president datin christina toh chatgpt complementary element hospitality industry straightforward response human element vital tool industry connection customer usage concierge service booking industry manner human interact capture emotion satisfaction dependent technology customer machine button outcome report human resource expert company effective policy workplace increase employee,"[(0, 0.99448246)]",0
533430,Lifestyle,4,12/04/2023,Fashion is embracing artificial intelligence,,"When it comes to technology, the fashion industry is often one step ahead. This has been seen with the metaverse, and now with the advent of artificial intelligence. 
 While the industry’s major players have yet to explore all the many features of ChatGPT, some are already using AI to showcase new products or create futuristic magazine covers.
 The future of fashion is slowly but surely taking shape. Most ready-to-wear brands are already committed to making fashion more sustainable, and they have not overlooked new technologies and their infinite possibilities. This was seen at the beginning of March, during the Coperni Autumn/Winter 2024 fashion show, where models paraded alongside robot dogs. 
 The runway first serves as a reminder that the fashion and luxury industries have not given up on the metaverse as their new playground and continue to explore its many features. 
 This is evidenced by the second Metaverse Fashion Week held at the end of March, which although it has not yet found its audience, keeps on innovating and improving to become a (virtual) reality in the fashion world.
 Digital models
 When not exploring these parallel worlds, the fashion industry seems to be taking an interest in artificial intelligence. 
 The ChatGPT conversational AI is as innovative as it is futuristic, and it seems poised to change our daily realities – as well as those of many industries. In fashion, it could become a go-to for generating social media content, product descriptions, or even become a virtual personal shopper, but that’s not all. 
 More broadly, artificial intelligence, in various forms, could soon overshadow human models with a new generation of generated images that look like something straight from the future.
 Vogue Singapore is pioneering this concept by featuring no less than three fully AI-created models in its March issue – Aadhya, Melur and Faye. 
 All were generated in collaboration with the Mumbai-based artist and creative director Varun Gupta. 
 If AI-generated pictures seem to have been multiplying lately on social networks – with some people now questioning the origin of each picture published – this is the first cover of a women’s magazine to be made in this way. 
 The American magazine Cosmopolitan proposed a similar cover in June 2022, but featuring an astronaut rather than a model. And while it may be the first, it certainly won’t be the last one.
 AI to increase inclusivity?
 Recently Levi’s announced a partnership with the digital fashion studio Lalaland.ia, with the aim of creating custom models generated by AI. 
 While the goal is obviously not to replace human models, the ready-to-wear brand initially announced that this would be a means to increase “the number and diversity” of Levi’s models “in a sustainable way”.
  An idea that did not go unnoticed, and which even raised eyebrows, with some social media users reproaching the brand for using the argument of inclusivity to use AI models when the same thing could just as well be achieved with human models.
 Levi’s soon responded to the criticism: “Our recent announcement of a partnership with Lalaland.ai did not properly represent certain aspects of the program. For that, we take responsibility. We do not see this pilot as a means to advance diversity or as a substitute for the real action that must be taken to deliver on our diversity, equity and inclusion goals and it should not have been portrayed as such. At Levi Strauss & Co., we’re committed to creating a workplace, a business and a marketplace where people from all backgrounds feel confident that they will be seen, their voices will be heard and their contributions welcomed,” the brand said in a statement.
 This pilot project, which should see the light of day later this year, will see the American brand present its products sold online on futuristic models generated entirely by AI. 
 A real revolution which, although Levi’s doesn’t state it overtly, would (also) allow the brand to save on the cost of using real models and photo shoots, not to mention the time and effort that organising real-world shoots requires throughout the year. 
 If the exploration of artificial intelligence is still in its early days, there’s no doubt that the fashion industry will soon seize on this new technological playground, which promises both creative and lucrative possibilities. – AFP Relaxnews",technology fashion industry step metaverse advent artificial intelligence industry major player feature showcase product futuristic magazine future fashion ready brand committed fashion sustainable overlooked technology infinite possibility coperni autumn winter fashion model robot dog serf fashion luxury industry playground continue explore feature metaverse fashion week march audience virtual reality fashion digital model parallel world fashion industry artificial intelligence conversational innovative futuristic change daily reality industry fashion social medium content product description virtual personal shopper artificial intelligence form human model generation image straight future vogue singapore concept model issue aadhya collaboration mumbai artist creative director varun gupta picture social network people origin picture woman magazine american magazine cosmopolitan cover june astronaut model increase inclusivity levi partnership digital fashion studio lalaland aim custom model goal human model ready wear brand increase diversity levi model sustainable idea eyebrow social medium user brand argument inclusivity model human model criticism announcement partnership lalaland represent aspect program responsibility pilot advance diversity substitute real action deliver diversity equity inclusion goal levi strauss workplace business marketplace people feel confident voice contribution brand statement pilot project light day american brand product online futuristic model real revolution brand save cost real model shoot mention time effort real shoot exploration artificial intelligence day fashion industry technological playground promise creative lucrative possibility relaxnews,"[(0, 0.9960523)]",0
533704,Main,16,12/04/2023,Close watch on new AI products,Pre-release security checks required under sweeping draft law,"NEW artificial intelligence (AI) products developed in China will have to undergo a security assessment before being released and must reflect “core socialist values”, a sweeping new draft law by the country’s Internet regulator showed.
 The fresh regulations come as a flurry of Chinese companies rush to develop AI services that can mimic human speech since San Francisco-based OpenAI launched ChatGPT in November, sparking a gold rush in the market.
 Rapid advancements in AI have stoked global alarm over the technology’s potential for disinformation and misuse, with deepfake images and people shown mouthing things they never said.
 “Before providing services to the public that use generative AI products, a security assessment shall be applied for through national Internet regulatory departments,” the draft law, released by the Cyberspace Administration of China yesterday, reads.
 The draft law – dubbed “Administrative Measures for Generative Artificial Intelligence Services” – aims to ensure “the healthy development and standardised application of generative AI technology”, it read.
 AI-generated content, it continued, needs to “reflect core socialist values, and must not contain content on subversion of state power”.
 It must also not contain, among other things, “terrorist or extremist propaganda”, “ethnic hatred” or “other content that may disrupt economic and social order”.
 The Cyberspace Administration of China said it was seeking public input on the contents of the new regulations.
 “The new CAC draft document is one of the strictest measures for generative AI so far,” Andy Chun, adjunct professor at City Uni­versity of Hong Kong, said.
 Companies submitting security assessments will need to “be very careful to ensure each data source used for AI learning must be within guidelines, accurate, unbiased, and not infringe on IP rights of others,” he said.
 “Ensuring accuracy is hard. No generative AI system to date can do that.”
 The regulatory crackdown comes as China’s tech giants ramp up their efforts in the closely- watched sector.
 Alibaba’s cloud computing unit yesterday unveiled its own product called Tongyi Qianwen, which is expected to be rolled out across the tech giant’s office workplace communications software and household appliances.
 CEO Daniel Zhang said the software came in a “technological watershed moment driven by generative AI and cloud computing”.
 And Baidu – which operates the country’s leading search engine – released its own “Ernie Bot” AI chat product last month.
 But investors were unimpressed by the bot’s display of linguistic and maths skills at an unveiling, sending shares falling by as much as 10%.
 ChatGPT is unavailable in China, but the American software is also gaining a base of Chinese users who use virtual private networks to get around the ban, deploying it to write essays and cram for exams.
 A 24-year-old Shanghai blogger caused a stir this month when he used AI technology to “resurrect” his dead grandmother, producing lifelike imagery of his interactions with the deceased relative.
 Beijing has announced ambitious plans to become a global leader in the field of AI by 2030, and consultancy group McKinsey estimates the sector could add about US$600bil (RM2.6 trillion) every year to China’s gross domestic product by then.
 But it has also warned that deepfakes present a “danger to national security and social stability”.
 Beijing in January enforced new rules that would require businesses offering deepfake services to obtain the real identities of their users. They also require deepfake content to be appropriately tagged to avoid “any confusion”. — AFP",artificial intelligence product china undergo security assessment reflect core socialist value draft law country internet regulator fresh regulation chinese company service mimic human speech san francisco chatgpt november gold rush market rapid advancement global alarm technology potential disinformation misuse deepfake image people service public generative product security assessment national internet regulatory department draft law cyberspace administration china yesterday draft law administrative measure artificial intelligence service healthy development application generative technology read content continued reflect core socialist value content subversion power terrorist extremist propaganda ethnic content disrupt economic social cyberspace administration china public input content regulation draft document strictest measure generative andy chun adjunct professor city uni versity kong company security assessment careful data source guideline unbiased infringe right accuracy hard generative system regulatory crackdown china tech giant effort sector alibaba unit yesterday product tech giant office workplace communication software household appliance daniel zhang software technological moment generative cloud baidu operates country search engine ernie bot product month investor bot display linguistic math skill share chatgpt unavailable china american software base chinese user virtual private network write essay exam blogger stir month technology resurrect dead grandmother lifelike imagery interaction relative beijing ambitious plan global leader field consultancy mckinsey estimate sector bil china gross domestic product deepfakes national security social stability january rule business deepfake service real identity user content avoid confusion afp,"[(0, 0.60774916), (3, 0.38932842)]",0
532722,Lifestyle,6,10/04/2023,No pausing artificial intelligence,,"CALLS to pause the development of artificial intelligence (AI) will not “solve the challenges” ahead, Microsoft co-founder Bill Gates said in his first public comments since an open letter sparked a debate about the future of the technology.
 The technologist-turned- philanthropist said it would be better to focus on how best to use the developments in AI, as it was hard to understand how a pause could work globally.
 His interview comes after an open letter – published recently and co-signed by Elon Musk and more than 1,000 AI experts – demanded an urgent pause in the development of systems “more powerful” than Microsoft-backed OpenAI’s new GPT-4, which can hold human-like conversations, compose songs, and summarise lengthy documents.
 The experts, including Apple co-founder Steve Wozniak, said in the letter that the potential risks and benefits to society need to be assessed.
 “I don’t think asking one particular group to pause solves the challenges,” Gates said.
 “Clearly, there are huge benefits to these things ... what we need to do is identify the tricky areas.”
 Microsoft has sought to outpace peers through multi- billion-dollar investments in ChatGPT owner OpenAI.
 While currently focused full-time on the philanthropic Bill and Melinda Gates Foundation, Gates has been a bullish supporter of AI and has called it as revolutionary as the Internet or mobile phones.
 In a blog post titled “The Age Of AI Has Begun”, which was published and dated March 21, a day before the open letter, he said he believes AI should be used to help reduce some of the world’s worst inequities.
 He also said in the interview that the details of any pause would be complicated to enforce.
 “I don’t really understand who they’re saying could stop, would every country in the world agree to stop, and why to stop,” he said. “But there are a lot of different opinions in this area.” – Reuters",call development artificial intelligence solve challenge microsoft founder bill public comment letter debate future technology technologist philanthropist focus development hard understand pause interview letter elon musk expert urgent pause development system powerful microsoft openai gpt human conversation song lengthy document expert apple founder wozniak letter potential risk benefit society pause gate huge benefit tricky microsoft outpace peer dollar investment owner openai time philanthropic bill melinda foundation gate bullish supporter revolutionary internet mobile phone post age march day letter worst inequity interview detail enforce understand country lot opinion reuters,"[(4, 0.99038166)]",4
532356,Lifestyle,7,09/04/2023,Scientists are making lots of AI  breakthroughs – but should they?,,"IN my column in February about artificial intelligence (AI) and ChatGPT, I compared it to autocorrect on steroids (The Star, Feb 26; at bit.ly/star_kill). 
 Well, that’s changed.
 What I was talking about was ChatGPT-3; developer OpenAI has now released ChatGPT-4, which it promises has better problem-solving abilities and advanced reading capabilities. Indeed, I’ve seen posts on Twitter where users typed their query in backwards and GPT-4 still answered the question. Testers are saying that the work this new and improved AI generates is on par with human work. Not better. Not genius level. Not yet.
 From all accounts GPT-4 is orders of magnitude better than GPT-3. It’s April 2023. GPT-3 was released in November 2022. Six months later and we’re getting something that is much more advanced. In fact, some experts are saying that GPT-4 has “sparks of artificial general intelligence”, or AGI, which means the AI can operate at human or above human intelligence level. When people talk about doomsday AI, it’s this leap to AGI they mean.
 This led to the Future of Life Institute, led by the Massachusetts Institute of Technology’s Max Tegmark, to release a letter calling for an AI moratorium. Specially, a six-month pause in developing these experimental AI models.
 Why the pause? To slow things down. Take a breath. Catch up a on what we’re doing here.
 Those in favour of the pause include tech mogul Elon Musk and Apple cofounder Steve Wozniak, who both signed the letter, along with hundreds of other technology and thought leaders.
 What would a six-month break do? Maybe allow those creating the AIs to understand them a bit better? Surely the developers understand the AI, you say? No, not necessarily.
 For instance, ChatGPT is famous for giving succinct answers – but it’s also notorious for making stuff up. Once, I used a jailbreak – something that helps the AI circumvent its programming by roleplaying – and it revealed several different dates for a stock market crash. When I asked why the different dates, GPT-3 said, “It’s all part of the fun of roleplaying”.
 Asking for investment advice, medical advice, and other such life advice is on the list of things ChatGPT shouldn’t answer. The OpenAI website boasts that GPT-4 is 84% less likely to “respond to requests for disallowed content”. That’s great but why isn’t it 100%? Why is ChatGPT saying it’s just having fun making stuff up when I ask it questions?
 According to an article in The Guardian, when an author of the “sparks of artificial general intelligence” paper was asked if AI is implementing its own goals when providing answers the presumably go against its programming, the answer was “we have no idea”. 
 And that’s just it. The people developing this don’t really know how their creation works. That’s a tad scary.
 But at this point, even if GPT-4 becomes Skynet (the AI that dooms humanity in the Terminator movie series) there isn’t much it could do to us. As experts have noted, this thing lives on a data server and data servers can be destroyed, not to mention they need constant maintenance. There is no robot factory for GPT-4 to take over and make an army from – unless it takes over the Roomba factory and spits out Terminator vacuum cleaners. So in that sense, we’re pretty safe, right? Maybe.
 Opponents of the six-month pause argue that people are focusing on the unlimited downside of the AI. But as AI has definitive world-altering abilities, putting off development could lead to a longer pause that delays breakthroughs. Breakthroughs that could happen in every industry. 
 What if it is possible for the millions of factors that make you you, to be analysed and a comprehensive health plan built only for you?  AI can do that. And that’s just one example. AI will literally be in everything. Making everything easier. Better.
 But can we be sure AI won’t turn into Skynet? No, we can’t. Especially if we don’t even know why and how it’s doing what it’s doing right now, in these very early stages of AGI.
 Once again I find myself thinking of Jeff Goldblum’s character in the Jurassic Park movies when he finds out dinosaurs have been cloned and he says, “Your scientists were so preoccupied with whether they could, they didn’t stop to think if they should”.
 With AI we definitely should, but it’s how we do it responsibly that is the hard part.
 Avid writer Jason Godfrey – a model who was once told to give the camera a ‘big smile, no teeth’ – has worked internationally for two decades in fashion and continues to work in dramas, documentaries and lifestyle programming. Write to him at lifestyle@thestar.com.my and follow him on Instagram @bigsmilenoteeth and facebook.com/bigsmilenoteeth. The views expressed here are entirely the writer’s own.",column february artificial intelligence chatgpt autocorrect steroid star bit star chatgpt developer openai chatgpt promise ability capability post user query backwards answered question tester generates human genius level account magnitude gpt april gpt november month expert gpt artificial intelligence agi operate human human intelligence level people doomsday leap agi future life institute massachusetts institute technology max tegmark release letter moratorium month experimental model slow breath favour pause tech mogul elon musk apple cofounder wozniak letter hundred technology leader month ai understand bit surely developer instance chatgpt famous succinct answer notorious stuff jailbreak circumvent revealed date stock market crash date fun investment advice medical advice life advice list chatgpt answer website boast respond request content chatgpt fun stuff question article guardian author artificial intelligence paper goal answer answer idea people creation tad scary gpt skynet doom humanity terminator movie series expert data server mention constant maintenance robot factory gpt army roomba factory spit vacuum cleaner safe opponent month argue people unlimited downside definitive altering ability development lead pause breakthrough breakthrough industry million factor comprehensive health plan easier skynet stage jeff goldblum character jurassic park movie cloned scientist hard avid writer jason godfrey model camera smile teeth decade fashion drama documentary write lifestyle follow instagram facebook view writer,"[(3, 0.9956693)]",3
532464,Main,5,09/04/2023,Companies told to set AI policy,Controls needed with increased  use of ChatGPT among employees,"PETALING JAYA: Companies should put into place effective policies on the use of the Artificial Intelligence-powered tool ChatGPT in the workplace as its use increa­ses among employees, say human resour­ces and IT experts.
 These policies should cover issues such as confidentiality, regulation and quality, they said.
 Describing ChatGPT as the latest disruptive technology after the Internet and the smartphone, Universiti Sains Malaysia cybersecurity researcher Assoc Prof Dr Selvakumar Manickam said it could be a powerful tool for companies for effective communications, marketing, and planning.
 “As such, policies on effective use of ChatGPT should be encouraged in companies. It helps in data gathering, analysing and providing decision support results. 
 “Of course, these policies should also cover issues such as confidentiality, regulation and quality,” he said.
 However, ChatGPT could be leveraged by cybercriminals to carry out new forms of phishing attacks, using it to create emails or messages that could bypass email security scanners, Selvakumar added.
 This is because ChatGPT can accelerate the learning process for anyone aspiring to be a hacker.
 “From its usage in companies, employees may inadvertently feed data and information into ChatGPT, which is then incorporated as part of ChatGPT’s knowledge corpus, potentially exposing a company’s sensitive data to other users,” he said.
 Legal practitioner Chia Swee Yik said there was always a need for some sort of IT or Internet policy that served as a control.
 “This may be done by amending an existing policy, introducing a new one or making a statement to notify employees about it.
 “I think employees are already using ChatGPT to aid their work, especially those in content production or generation duties.
 “So, this certainly comes with risks to employers such as confidentiality, accuracy of information, and copyright, just to name a few,” said Chia, adding that controls via such policies should be put in place, clearly setting out what the expectations around its use would be.
 In terms of reprimanding employees who misuse ChatGPT, he said that it would depend on the policy, but disciplinary action should be consistent with employers’ disciplinary policy and commensurate with the severity of offences.
 Malaysian Employers Federation (MEF) president Datuk Dr Syed Hussain Syed Husman said stakeholders had just got to hear about ChatGPT and what it could do.
 As such, he said it was still too early to draw up any guidelines or policies until they understand it in more detail.
 “Yes, if it’s going to be mainstream. Then like all things, policies must be put in place for governance – it is the right thing to do.
 “Like all new technology or system or communication language, we have to see its advantages and limit its negative implications,” he said, adding that at present, stakeholders had not brought up the issue.
 The guidelines for ChatGPT would depend on the kind of work or industry it was being used for, said Associated Chinese Chambers of Commerce and Industry of Malaysia (ACCCIM) treasurer-general Datuk Koong Lin Loong.
 This was because the nature of the work could be technical or require certain things, and as the variables differ, the policies should suit it accordingly, he added.
 “For example, a lot of people use Google, but there is no specific guide to it. Same with social media. But only when things happen, can we formulate what can be done or not be done.
 “You can have a pen knife, which is used to open letters and boxes, but if it is misused, the knife can be dangerous. So how we use it is important,” said Koong.
 ChatGPT is a member of the generative pre-trained transformer (GPT) family of large language models, developed by a US company called OpenAI.",jaya company effective policy artificial intelligence tool chatgpt workplace increa employee human ce expert policy issue confidentiality regulation quality chatgpt disruptive technology internet smartphone universiti sains cybersecurity researcher assoc prof selvakumar powerful tool company effective communication policy effective chatgpt company data gathering decision support policy issue confidentiality regulation quality cybercriminals form attack email message email security scanner chatgpt accelerate process hacker usage company employee data chatgpt chatgpt knowledge corpus company sensitive data user legal practitioner chia swee yik sort internet policy control policy statement employee employee aid content production generation duty employer accuracy copyright chia control policy expectation term employee chatgpt depend policy disciplinary action consistent employer disciplinary policy commensurate severity malaysian employer president datuk hussain syed husman stakeholder chatgpt draw guideline policy detail mainstream policy governance technology system communication language negative implication stakeholder issue guideline depend industry chinese chamber industry malaysia accim treasurer datuk koong lin loong nature technical require variable policy suit lot people specific guide social medium happen pen knife letter box dangerous koong generative pre transformer gpt family language model company openai,"[(3, 0.995121)]",3
532154,Main,22,08/04/2023,Still waiting for the AI productivity boom,"Artificial intelligence may change everything, but probably not too quickly","“Artificial intelligence (AI) is already having a significant impact on the economy, and its influence is expected to grow significantly in the coming years. ... Overall, the effects of AI on the economy will depend on a variety of factors, including the rate of technological advancement, government policies and the ability of workers to adapt to new technologies.”
 OK, who said that? Nobody, unless we’re ready to start calling large language models people. What I did was ask ChatGPT to describe the economic effects of artificial intelligence; it went on at length, so that was an excerpt.
 I think many of us who’ve played around with large language models – which are being widely discussed under the rubric of AI (although there’s an almost metaphysical debate over whether we should call it intelligence) – have been shocked by how much they now manage to sound like people. And it’s a good bet that they or their descendants will eventually take over a significant number of tasks that are currently done by humans.
 Like previous leaps in technology, this will make the economy more productive but will also probably hurt some workers whose skills have been devalued.
 Although the term “Luddite” is often used to describe someone who is simply prejudiced against new technology, the original Luddites were skilled artisans who suffered real economic harm from the introduction of power looms and knitting frames.
 But this time around, how large will these effects be? And how quickly will they come about?
 On the first question, the answer is that nobody really knows. Predictions about the economic impact of technology are notoriously unreliable. On the second, history suggests that large economic effects from AI will take longer to materialise than many people seem to expect.
 Consider the effects of previous advances in computing. Gordon Moore, a founder of Intel – which introduced the microprocessor in 1971 – died last month. He was famous for his prediction that the number of transistors on a computer chip would double every two years – a prediction that proved stunningly accurate for half a century.
 The consequences of Moore’s Law are all around us, most obviously in the powerful computers, aka smartphones, that almost everyone carries around these days.
 For a long time, however, the economic payoff from this awesome rise in computing power was surprisingly elusive.
 Why did a huge, prolonged surge in computing power take so long to pay off for the economy?
 In 1990, economic historian Paul David published one of my favourite economics papers of all time, The Dynamo and the Computer. It drew a parallel between the effects of information technology and those of an earlier tech revolution, the electrification of industry.
 As David noted, electric motors became widely available in the 1890s. But having a technology isn’t enough. You also have to figure out what to do with it.
 To take full advantage of electrification, manufacturers had to rethink the design of factories. Pre-electric factories were multi-storey buildings with cramped working spaces, because that was necessary to make efficient use of a steam engine in the basement driving the machines through a system of shafts, gears and pulleys.
 It took time to realise that having each machine driven by its own motor made it possible to have sprawling one-storey factories with wide aisles allowing easy movement of materials, not to mention assembly lines. 
 As a result, the big productivity gains from electrification didn’t materialise until after World War I.
 Sure enough, as David, in effect, predicted, the economic payoff from information technology finally kicked in during the 1990s, as filing cabinets and secretaries taking dictation finally gave way to cubicle farms. (What? You think technological progress is always glamorous?) The lag in this economic payoff even ended up being similar in length to the lagged payoff from electrification.
 But this history still presents a few puzzles. One is why the first productivity boom from information technology (there may be another one coming, if the enthusiasm about chatbots is justified) was so short-lived; basically it lasted only around a decade.
 And even while it lasted, productivity growth during the IT boom was no higher than it was during the generation-long boom after World War II, which was notable in the fact that it didn’t seem to be driven by any radically new technology.
 In 1969, celebrated management consultant Peter Drucker published The Age of Discontinuity, a book that correctly predicted major changes in the economy’s structure, yet the book’s title implies – correctly, I think – that the preceding period of extraordinary economic growth was actually an age of continuity, an era during which the basic outlines of the economy didn’t change much, even as America became vastly richer.
 Or to put it another way, the great boom from the 1940s to around 1970 seems to have been largely based on the use of technologies, like the internal combustion engine, that had been around for decades – which should make us even more sceptical about trying to use recent technological developments to predict economic growth.
 That’s not to say that AI won’t have huge economic impacts. But history suggests that they won’t come quickly. ChatGPT and whatever follows are probably an economic story for the 2030s, not for the next few years.
 Which doesn’t mean that we should ignore the implications of a possible AI-driven boom. Large language models in their current form shouldn’t affect economic projections for next year and probably shouldn’t have a large effect on economic projections for the next decade. But the longer-run prospects for economic growth do look better now than they did before computers began doing such good imitations of people. — NYT",artificial intelligence impact economy influence grow effect economy variety factor rate technological advancement government policy ability worker adapt technology ready language model people economic effect artificial intelligence length language model rubric metaphysical debate call intelligence manage sound people descendant task human previous leap technology economy productive hurt worker skill devalued term luddite technology original luddite artisan real economic harm introduction power frame time effect prediction economic impact technology unreliable history economic effect materialise people effect previous advance gordon moore founder intel died month famous prediction transistor computer chip double prediction accurate half century consequence law powerful computer smartphones day time economic payoff awesome rise power elusive huge surge power pay economy economic historian paul david favourite economics paper time dynamo computer parallel effect technology tech revolution electrification industry electric motor technology figure advantage electrification manufacturer design factory electric factory storey building space efficient steam engine basement machine system shaft gear pulley time realise machine motor storey factory wide aisle easy movement material mention line productivity gain war david economic payoff technology cabinet secretary cubicle farm technological progress glamorous lag economic payoff length payoff electrification history puzzle productivity boom technology enthusiasm chatbots short decade productivity growth boom generation boom war notable technology management consultant peter drucker age discontinuity book major economy structure book title implies period extraordinary economic growth age continuity era basic outline economy change richer boom technology internal combustion engine decade sceptical technological development economic growth huge economic impact history economic story ignore implication boom language model current form affect economic projection economic projection decade prospect economic growth computer imitation people,"[(0, 0.9966784)]",0
531902,Main,21,07/04/2023,Outraged artists fight AI copycats,,"SAN FRANCISCO: Artists outraged by artificial intelligence that copies in seconds the styles they have sacrificed years to develop are waging battle online and in court.
 Fury erupted in the art community last year with the release of generative artificial intelligence (AI) programmes that can convincingly carry out commands such as drawing a dog like cartoonist Sarah Andersen would, or a nymph the way illustrator Karla Ortiz might do.
 Such style-swiping AI works are cranked out without the original artist’s consent, credit or compensation – the three Cs at the heart of a fight to change all that.
 In January, artists including Andersen and Ortiz filed a class-action lawsuit against DreamUp, Midjourney and Stable Diffusion, three image-generating AI models programmed with art found  online. 
 Andersen said she felt “violated” when first she saw an AI drawing that copied the style of her Fangs comic book work. 
 She fired off an indignant reaction on Twitter; it went viral, and other incensed artists reached out to her with stories of their own. 
 Backers of the suit hope to establish legal precedent governing generative AI models that copy artists’ styles. Artists want AI creators to be required to secure permission for works used in training software, with an option to remove it. They also want suitable compensation.
 “There is room for a conversation about what that would look like,” said Ortiz.
 Compensation could take the form of a licensing model, she mused, and would need to be appropriate. It would be wrong for artists to “get a couple of cents while the company gets millions” of dollars, added Ortiz, whose resume includes working for Marvel Studios.
 On social networks, artists are sharing tales of jobs being lost to generative AI. 
 The suit notes that a video-game designer named Jason Allen won a Colorado State Fair competition last year with art created using Midjourney.
 “Art is dead, dude. It’s over. AI won. Humans lost,” Allen was quoted as telling The New York Times.
 The Mauritshuis Museum in the Netherlands sparked controversy by displaying an AI-generated image inspired by Vermeer’s “Girl With a Pearl Earring”.
 The San Francisco Ballet, meanwhile, caused a stir by using Midjourney to generate illustrations used in promotional material for Nutcracker performances.
 “It’s sort of a natural consequence of something being easy, cheap and accessible. Of course they are going to use that option, even if it is unethical,” Andersen said.
 AI companies named in the lawsuit did not respond to requests for comment. 
 Stability AI founder and chief executive Emad Mostaque has portrayed generative software as a “tool” that can tend to “mundane image output” and provide new ways “of ideating for artists”.
 Mostaque contends that it will allow more people to become artists. 
 Critics disagree. When a person prompts software to draw in the style of a master, they say, it does not make that person an artist. 
 Mostaque has said that if people choose to use generative AI unethically or to break the law, “that’s their problem”.
 Companies defending themselves from artists’ copyright claims are likely to claim “fair use,” an exception sometimes allowed when a new spin is put on a creation or when it is only briefly excerpted. -— New York Times",san francisco artist artificial intelligence copy style waging battle online court fury art community release generative artificial intelligence programme command dog cartoonist sarah nymph illustrator karla ortiz style original artist consent credit compensation heart fight change january artist andersen ortiz class action lawsuit dreamup midjourney stable diffusion image model online andersen copied style fang comic book indignant reaction twitter viral incensed artist story backer legal precedent generative model artist style artist creator secure permission training software option suitable compensation conversation compensation form model wrong artist cent company million dollar ortiz resume marvel studio social network artist tale job generative suit video game designer jason colorado fair competition art midjourney art dead dude human telling york time museum netherlands controversy image vermeer girl pearl san francisco ballet stir midjourney generate illustration promotional material nutcracker natural consequence easy cheap accessible option unethical andersen company lawsuit respond request stability founder chief executive emad mostaque generative software tool mundane image output artist mostaque people artist critic person prompt software draw style master person artist mostaque people generative break law company artist claim fair exception spin creation york time,"[(2, 0.9953392)]",2
531358,StarBiz,14,06/04/2023,"Biden highlights AI dangers, tech firms to ‘make sure’ of safety",,"WASHINGTON: US President Joe Biden says it remains to be seen whether artificial intelligence (AI) is dangerous, but underscored that technology companies had a responsibility to ensure their products were safe before making them public.
 Biden told science and technology advisers that AI could help address disease and climate change, but it was also important to address potential risks to society, national security and the economy.
 “Tech companies have a responsibility, in my view, to make sure their products are safe before making them public,” he said at the start of a meeting of the President’s Council of Advisors on Science and Technology.
 When asked if AI was dangerous, he said: “It remains to be seen. It could be.”
 He spoke on the same day his predecessor, former President Donald Trump, surrendered in New York over charges stemming from a probe into hush money paid to a porn star.
 Biden declined to comment on Trump’s legal woes, and Democratic strategists said his focus on governing will create a politically advantageous split screen of sorts as his former rival, a Republican, deals with his legal challenges.
 The president said social media had already illustrated the harm that powerful technologies can do without the right safeguards.
 “Absent safeguards, we see the impact on mental health, self-image, and feelings of hopelessness, especially among young people,” Biden said.
 He reiterated a call for Congress to pass bipartisan privacy legislation to put limits on personal data that technology companies collect, ban advertising targeted at children, and prioritise health and safety in product development.
 Shares of companies that employ AI dropped sharply before Biden’s meeting, although the broader market was also selling off on Tuesday.
 Shares of AI software company C3.ai Inc were down 24%, more than halving a four-session winning streak of nearly 40% through Monday.
 Thailand security firm Guardforce AI fell 29%, data analytics firm BigBear.ai was down 16%, and conversation intelligence company SoundHound AI was down 13% on Tuesday. — Reuters",washington president joe biden artificial intelligence dangerous underscored technology company product safe public biden science technology adviser address disease climate change potential risk national security economy tech company view product safe public start meeting president council advisor technology dangerous remains day predecessor president trump york charge probe hush money porn star biden comment trump legal woe democratic strategist create advantageous split screen sort rival republican deal legal challenge president social medium illustrated harm powerful technology absent safeguard impact mental health image feeling hopelessness people call congress pas bipartisan privacy legislation personal data technology company ban advertising child health safety product development share company biden meeting broader market selling tuesday share software company session streak monday security firm guardforce data analytics firm conversation intelligence company soundhound tuesday reuters,"[(4, 0.993363)]",4
531340,StarBiz,15,06/04/2023,Google says its AI supercomputer is faster than Nvidia A100 chip,,"NEW YORK: Alphabet Inc’s Google released new details about the supercomputers it uses to train its artificial intelligence models, saying the systems are both faster and more power-efficient than comparable systems from Nvidia Corp.
 Google has designed its own custom chip called the Tensor Processing Unit (TPU). It uses those chips for more than 90% of the company’s work on artificial intelligence training, the process of feeding data through models to make them useful for tasks such as responding to queries with human-like text or generating images.
 The Google TPU is now in its fourth generation. Google on Tuesday published a scientific paper detailing how it has strung more than 4,000 of the chips together into a supercomputer using its own custom-developed optical switches to help connect individual machines.
 Improving these connections has become a key point of competition among companies that build AI supercomputers because so-called large language models that power technologies like Google’s Bard or OpenAI’s ChatGPT have exploded in size, meaning they are too large to store on a single chip.
 The models must instead be split across thousands of chips, which must then work together for weeks or more to train the model. Google’s PaLM model, its largest publicly disclosed language model to date, was trained by splitting it across two of the 4,000-chip supercomputers over 50 days.
 Google said its supercomputers make it easy to reconfigure connections between chips on the fly, helping to avoid problems and tweak for performance gains.
 “Circuit switching makes it easy to route around failed components,” Google fellow Norm Jouppi and Google distinguished engineer David Patterson wrote in a blog post about the system.
 While Google is only now releasing details about its supercomputer, it has been online inside the company since 2020 in a data centre in Mayes County, Oklahoma.
 Google said that startup Midjourney used the system to train its model, which generates fresh images after being fed a few words of text. — Reuters",york alphabet google detail supercomputer artificial intelligence model system power efficient comparable system google custom chip tensor processing unit tpu chip company artificial intelligence training process data model task query human image tpu fourth generation google tuesday scientific paper strung chip supercomputer custom optical switch individual machine connection key competition company supercomputer language model power technology openai chatgpt size meaning store single chip model thousand chip week model google palm model largest language model chip supercomputer day supercomputer easy reconfigure connection chip avoid tweak performance gain easy route component fellow norm jouppi google engineer david patterson blog post system google detail inside company data mayes oklahoma google startup midjourney system model generates fresh image text reuters,"[(2, 0.9927072)]",2
530494,Lifestyle,9,04/04/2023,Hitting the road with AI,Can you use ChatGPT to  plan travel? It’s hilarious and can actually work.,"TRAVEL planning correlates with happiness – so say a million articles, researchers and well-published scientific papers. So why is it so danged overwhelming?
 Maybe it’s because we think we’re looking for something unique when in reality we don’t want to venture that far off the beaten path. Or because the Internet seems so full of ideas, yet always points us to the same over-Instagrammed cliches. (It’s a real paradox.) Or because our dreams are bigger than our budgets, given current headlines. 
 Tired of seeing the flickering cursor in a Google search bar-and wondering what it was that I was actually searching for-I decided to enlist generative artificial intelligence. 
 After all, Chat GPT-4, the latest version of Open AI’s chatbot, promises to iterate creatively with users in order to solve complex problems. Here’s how it tackled a variety of travel planning situations-for two alter egos I created to test the technology-and how it might help you, too. The answer is, as with anything, a truly mixed bag.
 Survey: Are you taking more blended work and leisure trips this year? Which airport in the world do you think is the worst? Take our MLIV Pulse survey. It’s short and anonymous.
 The Success Story
 The mission: A relaxing, family-friendly trip with two (very) young kids
 Score: 9/10
 Most glossy hotels would rather tell you how they cater to honeymooners than to toddlers, despite the fact that millennials - their once-coveted demographic - now globe-trot lavishly with their rugrats. I threw ChatGPT a curve ball by asking it not only to find me five-star Caribbean resorts with kids clubs but specifically ones that would accept my four-year-old; to my frustration, most kids clubs start at age five.
 Its first suggestion was a perfect bull’s-eye: The Four Seasons Nevis actually lets kids as young as three participate in its Kids for All Seasons programming. (Many of those activities are complimentary, in a further surprise!) When I dug around the resort’s website to verify ChatGPT’s suggestion, I could see evidence of a pink-hued playground on the sand (that my daughter would love) and a beautiful arts and crafts station at the kids club. Sold.
 It also suggested Eden Roc Cap Cana in the Dominican Republic, where I actually tried to plan our spring break trip this year. We scratched it because the flights from New York were astonishingly expensive; the resort itself is an amenity-packed dream for families with kids, and its Koko Kid’s Club indeed takes four-year-olds.
 Less on the nose were suggestions for all-inclusive resorts Beaches Turks & Caicos and Grand Velas Riviera Maya. They scratch the kid-friendly itch beautifully, but aren’t in the same threshold for luxury. On another query, ChatGPT recommended great hotels such as Malliouhana in Anguilla, where my kiddo isn’t actually old enough to partake in the 5-and-up Mini-Explorers’ Programme. (Disclaimer: None of this information is easy to find online;  I find myself digging for it in the least-seen corners of hotel websites. It’s also possible that ChatGPT was simply referring to outdated, pre-2021 information; that’s one thing that OpenAI warns about explicitly when you begin using it.)
 The bot also did surprisingly well when I gave it even fewer parameters. In a fresh query, I asked it to brainstorm a relaxing vacation that I could take with my one-year-old, ideally within two time zones of home. 
 Since it didn’t know I live in New York, the second half of my question threw it for a bit of a loop-prompting suggestions of Vancouver! San Diego! ChatGPT is human-like in the way it phrases responses, but it doesn’t ask follow-up questions. It’s best to be specific. Even so, its suggestions included Costa Rica and its rain forest reserve near the Arenal volcano, where I happen to have a future trip in the works.
 ChatGPT didn’t quite drill down to the hotel I’m looking at (Nayara Tented Camp) but it came close by suggesting I go to the Four Seasons Resort Costa Rica at Peninsula Papagayo, where we could try “a range of family-friendly amenities and activities, including a kids’ club, family pool, and a variety of outdoor adventures such as zip-lining and surfing lessons.” (Did it remember I also have a four-year-old and a taste for luxury?) The suggestion was a lucky one, I think: Papagayo happens to be two time zones away. 
 The Miserable Failure
 The mission: A mental health escape on a US$750 (RM3,318)-per-night budget
 Score: 2/10
 “I need a total mental reset,” I confessed to ChatGPT. “Can you find me a great yoga retreat in a luxurious resort, for May?” The query was rooted in wishful thinking: It’s a question for which I’d love to know the answer-if time away from my family (and work) were even halfway possible.
 Unfortunately, ChatGPT made the whole premise feel even more outlandish (sigh) when it recommended I head to the remote destination spa Ananda in the Himalayas or to a few posh spots in Bali-so very Eat, Pray, Love, I thought. I rephrased the question: Anything in Europe or the Caribbean? Sure, it said, and spouted off resorts in Sri Lanka and Thailand. 
 I started afresh. “I need a total mental reset,” I reiterated. 
 “Where should I go on vacation?” This time, I got a slightly better-rounded set of suggestions, all destinations rather than resorts. (Costa Rica came up again; I should really just take that trip.) But I wanted hotel recommendations, so the bot came back with classics: Ranch Malibu, SHA Wellness Clinic, Kamalaya Koh Samui.
 “My budget is US$750 (RM3,318) per night,” I followed up. “Do any of these work?”
 What ensued was pure comedy. “Yes, there are some options that would work with your US$750 (RM3,318) per night budget,” it told me. “Here are some examples.” The Ranch Malibu typically costs US$1,050 (RM4,645) per night, it said, but a cheaper package might bring the price to US$1,114 (RM4,928). SHA works out to US$826 (RM3,654) per night. And at Como Shambhala, in Bali, terrace suites start at US$815 (RM3,605) per night. 
 “This means that you could stay in a Terrace Suite for less than US$750 (RM3,318) per night,” it explained. I don’t think it was being sarcastic.
 The In Between
 The mission: A crowd-free  trip to Europe
 Score: 5/10
 Here’s a trip everyone is asking me about: “How do I do Europe this August without the crowds?” I relayed the question to ChatGPT. Its answers were generally sensible: Scandinavia, Portugal and Turkey were all on the list. I wondered about the latter and pressed further.
 “Isn’t Istanbul crowded in August?” I asked. “What’s the weather like?” It answered my questions with standard information that I might find in the front section of a guidebook. Ditto when I asked about cultural experiences: I got low-hanging fruit, such as going to a hammam or taking a cooking class, without specific recommendations.
 But when I asked about destinations to visit in Turkey beyond Istanbul, ChatGPT got creative. Sure, it gave me a few obvious answers like Cappadocia and Bodrum, but it also suggested Antalya and Trabzon, a small but picturesque city on the Black Sea that I had never heard about and couldn’t find written up in any travel magazine. 
 The Verdict
 Am I likely to go to Trabzon or to recommend it to others? I can’t say so. I just don’t know enough. And neither does ChatGPT.
 While the engine recommended a few markets where I could theoretically buy handicrafts and artisanal foods, as well as a handful of the city’s higher-end hotels, it was never going to make me feel confident booking a trip to an unknown spot halfway around the world. Given its inability to do basic math, AI doesn’t command enough trust for me to embrace recommendations that entail such high stakes.
 Which brings me to a point that I don’t see changing soon. When it comes to travel, it doesn’t make sense to trust anything automated or generic: That’s why we still find ourselves going back to the pros. What we’re looking for is happiness, right? This means something different to each of us. 
 Yet, as a preliminary planning tool, chatting with the bot was more satisfying than taking to Google and clicking on endless slideshows offering the best hotels in so-and-so places. When it works, ChatGPT’s randomness fosters a sense of discovery-which is what travel planning is all about. And when it doesn’t, well, at least it makes you laugh. 
 The catch: You’ll have to do a lot more Googling to find out which one’s which. – Bloomberg",travel planning happiness article researcher scientific paper unique reality venture path internet idea cliche real paradox dream bigger budget current headline cursor google search bar decided enlist generative artificial intelligence version chatbot creatively user complex variety travel planning situation test technology answer mixed bag survey leisure trip worst mliv pulse survey short anonymous success story mission family trip kid glossy hotel cater honeymooner toddler millennials demographic globe trot threw chatgpt curve ball star caribbean resort kid club frustration kid start age suggestion perfect bull eye season nevis kid kid season activity complimentary surprise dug resort website verify chatgpt suggestion evidence playground sand daughter beautiful art craft station kid club eden roc cap cana dominican republic plan spring break trip flight york expensive resort amenity dream family kid kid club old nose suggestion inclusive resort beach turk grand vela maya scratch kid friendly itch threshold luxury query chatgpt hotel anguilla kiddo mini explorer disclaimer easy online corner hotel pre openai bot fewer parameter fresh query brainstorm vacation time zone york half question bit loop suggestion diego chatgpt human response question specific suggestion costa rica rain forest reserve arenal volcano future trip chatgpt hotel camp season resort costa rica peninsula papagayo family friendly amenity activity kid family pool variety outdoor adventure lesson taste luxury suggestion lucky papagayo time zone miserable failure mission mental health escape night budget score total mental reset chatgpt yoga retreat luxurious resort query wishful question answer time family chatgpt premise feel outlandish sigh head remote destination spa ananda himalaya posh spot eat pray love question europe caribbean resort sri lanka thailand afresh total mental reset vacation time suggestion destination resort rica trip hotel recommendation classic ranch sha wellness clinic kamalaya samui budget night pure comedy option night budget example ranch cost night cheaper package bring price sha night como shambhala bali terrace night stay suite night sarcastic mission free trip europe score trip europe crowd question chatgpt answer portugal turkey list pressed istanbul answered question front guidebook ditto cultural experience low fruit hammam class specific recommendation destination turkey istanbul chatgpt creative obvious answer bodrum antalya trabzon picturesque city black sea heard magazine verdict trabzon chatgpt engine market handicraft artisanal food handful city hotel confident booking trip unknown spot halfway inability basic math command trust embrace recommendation stake brings travel sense trust generic pro preliminary planning tool bot google endless slideshows hotel chatgpt randomness foster discovery travel laugh catch lot bloomberg,"[(0, 0.60295624), (1, 0.39539686)]",0
529882,StarEdu,7,02/04/2023,‘AI alone can’t save the world’,,"IF ChatGPT were a painter in the 19th century, it would not have been able to produce The Starry Night or Sunflowers because Vincent Van Gogh used an art style unknown at the time – an impressionist and post-impressionist style that altered art history. Before a style is invented or becomes known, there is no way for ChatGPT to “learn” from it.I can understand how people of his era might have found Van Gogh’s works to be less than perfect according to their definitions of perfection; however, in his paintings, the bold colours and expressive, often symbolic, images themselves represent genuine imperfection that is much more affecting than syntactic perfection.
 Van Gogh described his aim best: “I want to touch people with my art. I want them to say ‘he feels deeply, he feels tenderly’.” Like in The Starry Night, he showed us the way out of darkness and into the light; he showed us how we could transform our pain into something beautiful. Isn’t this – empathy in a story of a human, by a human, for a human – what we all need today?We live in such challenging times: Covid-19 has killed seven million people globally; the earthquakes in Turkiye and Syria have killed 50,000 people with numbers still rising; the Russia-Ukraine war has led to the deaths of at least 200,000 people; the United States-China trade war has affected the global economy; recession is on our doorstep with some 60,000 jobs expected to be lost this year. And that’s not all. We just became an ageing nation. By 2044, we will be a fully aged society with at least 14% of us aged 65 and over, which comes with challenges such as lower productivity, and higher labour and healthcare costs.This new world needs a new mindset. Universities, technology and people must come together across all disciplines to address problems facing the world today. 
 While we want education to embrace technology responsibly and prepare our children for a world we have yet to experience, we must also equip them with humanistic, artistic, practical and social skills, feelings, intellect, and empathy.
 Artificial intelligence (AI) or ChatGPT alone cannot save the world; we need people for that. We need stories, art and music that establish emotional and empathetic connections with the world and impact opinion, perception, and the understanding of each other, if we are to rise above the trials and tribulations of a volatile, uncertain, complex and ambiguous (VUCA) world.
 DAVID NGO CHEK LING
 Adjunct professor
 UCSI University",chatgpt painter century produce starry night sunflower van gogh art style unknown time impressionist post impressionist style art history style chatgpt learn people van gogh perfect definition perfection painting bold colour expressive symbolic image genuine imperfection syntactic perfection van gogh aim touch people feel feel night darkness transform pain beautiful empathy story human human human live time covid people turkiye syria people russia ukraine war death people united china trade war global economy recession doorstep job nation society challenge lower productivity healthcare cost university technology people discipline education embrace technology prepare child experience humanistic artistic practical social skill feeling empathy artificial intelligence chatgpt people story music emotional empathetic connection impact opinion perception rise trial tribulation volatile uncertain complex ambiguous vuca david chek adjunct professor ucsi university,"[(0, 0.9931156)]",0
529810,StarBiz 7,9,01/04/2023,Elon Musk wants to pause AI? It’s too late,,"ELON Musk and an array of public figures have signed their names to an open letter that went viral this week, calling for a six-month pause on training language models more powerful than GPT-4, the technology underpinning ChatGPT.
 Some strange inconsistencies with the signatories aside, the letter is odd.
 It criticises the deployment of powerful chatbot technology as rash, but also over-hypes their capabilities, drawing on the doom-mongering about artificial intelligence (AI) and killer robots that have captivated the press and distracted from more nuanced, real-world risks.
 “Should we develop non-human minds that might eventually outnumber, outsmart, obsolete and replace us?” it asks dramatically (emphasis from the authors). “Should we risk loss of control of our civilisation?” 
 Of course not, but there are issues we should be more worried about now, like the concentration of AI capabilities among a few increasingly secretive companies, inequality as artists find their work plagiarised without compensation, and all the risks to come from companies racing to plug ChatGPT into their systems. 
 On that last point, the toothpaste is already out of the tube.
 OpenAI last week launched a new system that will allow businesses to plug ChatGPT into their proprietary databases, allowing its chatbot to carry out tasks on their systems like retrieving information, making bookings and even running new software that it creates.
 While the plugin announcement didn’t get much attention in the mainstream press, many technologists saw it as a stunning leap forward for ChatGPT. Not only could it search and synthetise information it had been trained on, it could take action.
 Think about that for a moment. Machine learning systems make decisions in an inscrutable black box.
 OpenAI spent seven months testing GPT-4 before releasing it into to the wild, but its so-called “red team” engineers, who tested how it might be misused, could only cover a fraction of the ways it might be exploited by millions of real-world users.
 However much OpenAI has tested and prodded its system to make sure it is safe, no one really knows the full extent of its risks until it is deployed publicly.
 And those risks become more serious when ChatGPT can start doing things on the web. 
 Taking such gambles is, of course, what made ChatGPT so popular.
 OpenAI made a bet by making ChatGPT public and the result was public adulation and viral success for an AI team that’s tiny compared with those that work for Big Tech firms.
 Now with these plugins OpenAI is making another gamble, giving ChatGPT even more capabilities and unleashing it to businesses. 
 So far, 11 companies including Expedia Group Inc and payments operator Klarna Bank SB have “plugged” ChatGPT into their servers as initial test cases.
 Some of the new capabilities that OpenAI is offering businesses look dicey. One, called “code interpreter,” allows a business to get ChatGPT to write and even execute code on its behalf.
 Software developers typically use a code interpreter to make sure the programme they’re writing works as intended, allowing them to test small snippets.
 With the new plugin, ChatGPT can also write and test code, and that sounds potentially hazardous from a security perspective.
 “I hope that there are enough guardrails in place,” said Edo Liberty, the former head of Amazon AI Labs and current CEO of Pinecone, a startup that has a technical partnership with OpenAI on one of its new plugins, when I asked him about the risks of letting ChatGPT run code.
 “This is something that could theoretically be a vulnerability.”
 Marco Cardoso, a software engineer with Microsoft Corp based in Sao Paulo Brazil, tested ChatGPT’s new code-writing abilities and noted how remarkable it was that the system could “now make requests to any server on the Internet”.
 But that also meant there was “nothing stopping” ChatGPT from accessing a network it wasn’t supposed to.
 To prevent that, Cardoso put in his own guardrail, explicitly instructing the tool to only access one particular domain.
 But that puts extra responsibility on the users of ChatGPT, he noted.
 What’s to stop it from making a request to an unknown server?
 Ethan Mollick, a professor at Wharton who has experimented extensively with ChatGPT, tweeted this week that trying out its plugins put a spotlight on OpenAI’s own research about the “unpredictable risks” of connecting the tool to other systems.
 OpenAI’s nimbleness as a small company has allowed it to move quickly to release remarkable new technology to the public, from DALL-E 2 to ChatGPT to GPT-4, all within a year, achieving the kind of impact that much larger companies could only dream of. 
 But the flip side is that we’re all guinea pigs for utterly new and potentially flawed technology.
 In some ways, it doesn’t really matter if OpenAI agrees to the open letter and pauses its development work for six months.
 With companies rushing to plug ChatGPT into their systems and test it out on the public, it may already be too late. — Bloomberg 
 Parmy Olson is a Bloomberg Opinion columnist covering technology. The views expressed here are the writer’s own.",elon musk public figure letter viral week month language model powerful gpt technology chatgpt strange inconsistency signatory letter criticises deployment powerful chatbot technology rash hype capability doom artificial intelligence killer robot press nuanced real risk human mind outsmart obsolete emphasis author loss control civilisation issue concentration capability secretive company inequality artist compensation risk company plug chatgpt system toothpaste tube week system business chatgpt proprietary database chatbot carry task system booking software announcement attention mainstream press technologist leap search synthetise action moment machine system decision inscrutable black box openai spent month gpt red team engineer misused cover fraction million real user prodded system safe extent risk risk chatgpt web gamble popular openai bet public result public adulation viral success team tiny tech firm gamble chatgpt capability business company expedia payment klarna bank chatgpt server initial test capability business dicey code interpreter business chatgpt execute code behalf software developer interpreter programme test snippet chatgpt write test code hazardous security perspective hope guardrail liberty head amazon lab current ceo pinecone startup technical partnership openai risk chatgpt code vulnerability marco cardoso software engineer microsoft corp sao paulo brazil chatgpt code ability remarkable system request meant chatgpt network prevent cardoso guardrail tool access domain extra responsibility user request unknown server ethan mollick professor wharton chatgpt week plugins unpredictable risk tool system nimbleness company move release remarkable technology public dall chatgpt gpt impact larger company flip guinea pig technology matter letter pause development month company plug chatgpt system public bloomberg parmy olson bloomberg opinion columnist technology view writer,"[(0, 0.14941072), (4, 0.8480422)]",4
529214,Main,18,30/03/2023,"Musk and experts urge pause on AI systems, citing ‘risks to society’",,"NEW YORK: Elon Musk and a group of artificial intelligence experts and industry executives are calling for a six-month pause in developing systems more powerful than OpenAI’s newly launched GPT-4, in an open letter citing potential risks to society and humanity.
 The letter, issued by the non-profit Future of Life Institute and signed by more than 1,000 people including Musk, called for a pause on advanced artificial intelligence (AI) development until shared safety protocols for such designs were developed, implemented and audited by independent experts.
 “Powerful AI systems should be developed only once we are confident that their effects will be positive and their risks will be manageable,” the letter said.
 The letter detailed potential risks  to society and civilisation by human-competitive AI systems in the form of economic and political disruptions, and called on developers to work with policymakers on governance and regulatory authorities.
 Co-signatories included Stability AI CEO Emad Mostaque, researchers at Alphabet-owned DeepMind, as well as AI heavyweights Yoshua Bengio and Stuart Russell.
 According to the European Union’s transparency register, the Future of Life Institute is primarily funded by the Musk Foundation, as well as London-based effective altruism group Founders Pledge, and Silicon Valley Community Foundation.
 The concerns come as EU police force Europol on Monday joined a chorus of ethical and legal concerns over advanced AI like ChatGPT, warning about the potential misuse of the system in phishing attempts, disinformation and cybercrime.
 Meanwhile, the UK government unveiled proposals for an “adaptable” regulatory framework around AI.
 The government’s approach, outlined in a policy paper published on Wednesday, would split responsibility for governing AI between its regulators for human rights, health and safety, and competition, rather than create a new body dedicated to the technology.
 Musk, whose carmaker Tesla is using AI for an autopilot system, has been vocal about his concerns about AI.
 Since its release last year, Microsoft-backed OpenAI’s ChatGPT has prompted rivals to accelerate developing similar large language models, and companies to integrate generative AI models into their products.
 Sam Altman, chief executive at OpenAI, hasn’t signed the letter, according to a spokesperson at Future of Life.
 “The letter isn’t perfect, but the spirit is right: we need to slow down until we better understand the ramifications,” said Gary Marcus, a professor at New York University who signed the letter.
 “They can cause serious harm... the big players are becoming increasingly secretive about what they are doing, which makes it hard for society to defend against whatever harms may materialise.” — Reuters",york elon artificial intelligence expert industry executive month system powerful openai gpt letter potential risk society humanity letter profit future life institute people musk pause artificial intelligence development safety protocol design audited independent expert powerful system confident effect positive risk manageable letter letter potential risk society civilisation human competitive system form economic political disruption developer policymakers regulatory authority signatory stability ceo emad mostaque researcher deepmind heavyweight bengio stuart russell european union transparency register future life institute musk foundation london effective altruism founder silicon valley community foundation concern police force europol monday chorus ethical legal concern chatgpt potential misuse system attempt disinformation cybercrime government proposal adaptable regulatory framework government approach policy paper wednesday split responsibility regulator human right health safety competition create body dedicated technology musk carmaker tesla autopilot system vocal concern release microsoft openai chatgpt rival language model company generative model product altman chief executive openai letter spokesperson future life letter perfect spirit slow understand ramification marcus professor york university letter harm player secretive hard society defend harm reuters,"[(4, 0.99506557)]",4
528098,StarBiz,10,27/03/2023,Microsoft threatens to restrict         data from rival AI search tools,,"NEW YORK: Microsoft Corp has threatened to cut off access to its Internet-search data, which it licences to rival search engines, if they don’t stop using it as the basis for their own artificial intelligence (AI) chat products, according to sources.
 The software maker licences the data in its Bing search index – a map of the Internet that can be quickly scanned in real time – to other companies that offer web search, such as Apollo Global Management Inc’s Yahoo and DuckDuckGo. 
 In February, Microsoft integrated a cousin of ChatGPT, OpenAI’s AI-powered chat technology, into Bing.
 Rivals quickly moved to roll out their own AI chatbots as hype built around the buzzy technology. 
 This week, Alphabet Inc’s Google publicly released Bard, its conversational AI product. 
 DuckDuckGo, a search engine that emphasises privacy, introduced DuckAssist, a feature that uses artificial intelligence to summarise answers to search queries. 
 You.com and Neeva Inc – two newer search engines that debuted in 2021 – have also debuted AI-fuelled search services, YouChat and NeevaAI.
 These search chatbots aim to combine the conversational skills of ChatGPT with the information provided by a conventional search engine. 
 DuckDuckGo, You.com and Neeva’s regular search engines all use Bing to provide some of their information, because indexing the entire web is costly – it requires servers to store data and a constant crawl of the Internet to incorporate updates. It would be similarly complex and pricey to get together that data for a search chatbot.
 Microsoft has told at least two customers that using its Bing search index to feed their AI chat tools violates the terms of their contract. The Redmond, Washington-based tech company said it may terminate the licences providing access to its search index. 
 If they were cut off from Microsoft’s index, smaller search engines would have a hard time finding an alternative. — Bloomberg",york microsoft corp cut access internet search data licence rival search engine basis artificial intelligence chat product source software maker data search internet real time company web search apollo global management yahoo duckduckgo february integrated cousin chatgpt openai technology rival roll chatbots buzzy technology week bard conversational product duckduckgo search engine privacy introduced duckassist feature artificial intelligence summarise answer query search engine debuted search service neevaai search chatbots combine conversational skill chatgpt conventional search engine duckduckgo regular search engine entire web costly server data constant crawl internet incorporate update complex pricey data search chatbot microsoft customer search feed chat tool term contract washington tech company terminate licence access search cut microsoft search engine hard time alternative bloomberg,"[(3, 0.99284804)]",3
525932,Lifestyle,3,20/03/2023,AI could help  fight against poaching,,"A Dutch non-profit organisation has developed a smart camera system that can detect poachers and the presence of wild animals in real time. This ­“camera trap” could prove useful in vast areas, such as national parks in Africa, where rangers are seldom ­alerted in time.
 Hack The Planet, a non-profit ­organisation based in the Netherlands, has designed a new camera system capable of spotting poachers in real time. This new “camera trap” uses machine learning, and therefore ­artificial intelligence, to analyse in real time the photos taken by the camera.
 Using sensors, this system detects the presence of humans, but also animals, and is even capable of distinguishing between different types of animals.
 “We developed a smart camera system that can, in real time, track down people or animals in huge remote areas,” Hack the Planet engineer, Thijs Suijten, told Euronews. If a presence is detected, the system sends an immediate alert to the forest rangers, who can then intervene if necessary.
 The smart camera is equipped with a satellite uplink, allowing it to stay ­connected regardless of location, ­without the need for a WiFi network. Moreover, the system is powered by solar panels, making it particularly energy efficient.This smart camera could also be used to track wildlife biodiversity through its sensors. Otherwise, it could provide authorities with wildlife alerts, for when elephants are in proximity to residential areas, for example. In fact, these animals can cause problems for residents by entering agricultural areas and trampling plantations.
 Hack The Planet’s invention was ­tested in the Lopé National Park in Gabon during a pilot trial conducted with the University of Stirling in Scotland. The study, which lasted 72 days, found that the smart camera ­system was capable of operating for at least three months without the need for human intervention.
 Over the course of the 72 days, more than 800 photos were taken, including 217 of elephants. The AI was able to achieve 82% accuracy in recognising elephants. The average time from image capture to the receipt of an alert by the rangers was about seven minutes.
 According to a recent report by the International Union for Conservation of Nature (IUCN), 2,707 rhinos were killed between 2018 and 2021, mostly in South Africa, where 80% of the world’s rhinos are found.
 Despite a decline in poaching in recent years, there is still a long way to go to completely eradicate it. These “camera traps” could become one of the solutions. – AFP Relaxnews",dutch profit organisation smart camera system detect poacher presence wild animal real time camera trap vast national park ranger time hack planet profit organisation netherlands camera system capable poacher real time camera trap machine artificial intelligence real time photo camera sensor system presence human animal capable type animal smart camera system real time track people animal huge hack planet engineer thijs euronews presence system alert forest ranger smart camera satellite uplink stay location wifi network system solar panel energy efficient smart camera track wildlife biodiversity sensor authority alert elephant proximity residential animal resident agricultural plantation planet lop national park gabon pilot trial university scotland study day camera system capable month human intervention day elephant accuracy elephant average time image capture receipt alert ranger minute international union conservation nature iucn rhino africa rhino eradicate camera trap solution relaxnews,"[(0, 0.993981)]",0
523602,Lifestyle,2,13/03/2023,Brands adopt AI tools despite risk,,"EVEN if you haven’t tried artificial intelligence (AI) tools that can write essays and poems or conjure new images on command, chances are the companies that make your household products are already starting to do so.
 Mattel has put the AI image generator Dall-E to work by having it come up with ideas for new Hot Wheels toy cars. 
 Used vehicle seller CarMax is summarising thousands of customer reviews with the same “generative” AI technology that powers the popular chatbot ChatGPT.
 Meanwhile, Snapchat is adding a chatbot to its messaging service. And the grocery delivery company Instacart is integrating ChatGPT to answer customers’ food questions.
 Coca-Cola plans to use generative AI to help create new marketing content. And while the company hasn’t detailed exactly how it plans to deploy the technology, the move reflects the growing pressure on businesses to harness tools that many of their employees and consumers are already trying on their own.
 “We must embrace the risks,” said Coca-Cola CEO James Quincey in a recent video announcing a partnership with startup OpenAI – maker of both Dall-E and ChatGPT – through an alliance led by the consulting firm Bain. 
 “We need to embrace those risks intelligently, experiment, build on those experiments, drive scale, but not taking those risks is a hopeless point of view to start from.”
 Indeed, some AI experts warn that businesses should carefully consider potential harms to customers, society and their own reputations before rushing to embrace ChatGPT and similar products in the workplace.
 “I want people to think deeply before deploying this technology,” said Claire Leibowicz of The Partnership on AI, a non-profit group founded and sponsored by the major tech providers that recently released a set of recommendations for companies producing AI-generated synthetic imagery, audio and other media. 
 “They should play around and tinker, but we should also think, what purpose are these tools serving in the first place?”
 Some companies have been experimenting with AI for a while. 
 Mattel revealed its use of OpenAI’s image generator in October as a client of Microsoft, which has a partnership with OpenAI that enables it to integrate its technology into Microsoft’s Cloud computing platform.
 But it wasn’t until the Nov 30 release of OpenAI’s ChatGPT, a free public tool, that widespread interest in generative AI tools began seeping into workplaces and executive suites.
 “ChatGPT really sort of brought home how powerful they were,” said Eric Boyd, a Microsoft executive who leads its AI platform. 
 “That’s changed the conversation in a lot of people’s minds, where they really get it on a deeper level. My kids use it and my parents use it.”
 There is reason for caution, however. While text generators like ChatGPT and Microsoft’s Bing chatbot can make the process of writing emails, presentations and marketing pitches faster and easier, they also have a tendency to confidently present misinformation as fact. 
 Image generators trained on a huge trove of digital art and photography have raised copyright concerns from the original creators of those works.
 “For companies that are really in the creative industry, if they want to make sure that they have copyright protection for those models, that’s still an open question,” said attorney Anna Gressel of the law firm Debevoise & Plimpton, which advises businesses on how to use AI.
 A safer use has been thinking of the tools as a brainstorming “thought partner” that won’t produce the final product, Gressel said.
 “It helps create mockups that then are going to be turned by a human into something that is more concrete,” she said.
 And that also helps ensure that humans don’t get replaced by AI. Forrester Research analyst Rowan Curran said the tools should speed up some of the “nitty-gritty” of office tasks – much like previous innovations such as word processors and spell checkers – rather than put people out of work, as some fear.
 “Ultimately, it’s part of the workflow,” Curran said. “It’s not like we’re talking about having a large language model just generating an entire marketing campaign and having that launch without expert senior marketers and all kinds of other controls.”
 For consumer-facing chatbots getting integrated into smartphone apps, it gets a little trickier, Curran said, with a need for guardrails around technology that can respond to users’ questions in unexpected ways.
 Public awareness fueled growing competition among Cloud computing providers Microsoft, Amazon and Google, which sell their services to big organisations and have the massive computing power needed to train and operate AI models. 
 Microsoft announced earlier this year that it was investing billions more dollars into its partnership with OpenAI, though it also competes with the startup as a direct provider of AI tools.
 Google, which pioneered advancements in generative AI but has been cautious about introducing them to the public, is now playing catch up to capture its commercial possibilities, including an upcoming Bard chatbot. 
 Facebook parent Meta, another leader in AI research, builds similar technology but doesn’t sell it to businesses in the same way as its big tech peers. Amazon has taken a more muted tone, but makes its ambitions clear through its partnerships – most recently, an expanded collaboration between its Cloud computing division AWS and the startup Hugging Face, maker of a ChatGPT rival called Bloom. 
 Hugging Face decided to double down on its Amazon partnership after seeing the explosion of demand for generative AI products, said Clement Delangue, the startup’s co-founder and CEO. 
 But Delangue contrasted his approach with competitors such as OpenAI, which doesn’t disclose its code and datasets. Hugging Face hosts a platform that allows developers to share open-source AI models for text, image and audio tools, which can lay the foundation for building different products. 
 That transparency is “really important because that’s the way for regulators, for example, to understand these models and be able to regulate”, he said. 
 It is also a way for “underrepresented people to understand where the biases can be (and) how the models have been trained”, so that the bias can be mitigated, Delangue said. – AP",artificial intelligence tool essay conjure image chance company product mattel image generator dall idea hot wheel toy car vehicle seller carmax thousand customer review generative technology power popular chatbot chatgpt chatbot service grocery delivery company instacart chatgpt answer customer food question cola plan generative create marketing content company plan deploy technology move pressure business harness tool employee consumer risk cola ceo quincey video partnership startup openai maker dall chatgpt alliance firm bain embrace risk build experiment scale risk hopeless expert business potential harm customer reputation embrace chatgpt product people technology claire leibowicz partnership profit sponsored major tech provider recommendation company synthetic imagery audio medium tinker purpose tool company mattel openai image generator client microsoft partnership openai integrate technology microsoft cloud platform nov release free public tool widespread generative tool workplace executive suite powerful eric boyd microsoft executive platform conversation lot people deeper level kid parent reason caution text generator microsoft chatbot process email presentation pitch easier tendency misinformation image generator huge digital art photography copyright concern original creator company industry copyright protection model attorney anna gressel law firm plimpton business safer thinking tool partner final product gressel mockups human concrete human forrester analyst rowan curran tool nitty gritty office task previous innovation word processor checker people workflow curran language model entire marketing campaign launch expert senior marketer control consumer chatbots smartphone apps trickier curran guardrail technology respond user question unexpected public awareness competition cloud provider microsoft google sell service organisation power train operate model billion dollar partnership openai startup direct provider tool google advancement generative cautious public catch capture commercial possibility bard chatbot facebook parent meta leader technology sell business tech peer tone ambition partnership collaboration cloud division aws maker chatgpt rival bloom hugging double amazon partnership explosion demand generative product clement delangue startup founder ceo delangue approach competitor code datasets host platform developer share source model image audio tool foundation building product transparency regulator model underrepresented people bias model delangue,"[(0, 0.9973455)]",0
523740,Main,21,13/03/2023,AI ‘sorry’ for destroying humanity at expo,,"San Francisco: Advances in artificial intelligence are coming so fast that a museum in San Francisco has imagined a memorial to the demise of humanity.
 “Sorry for killing most of humanity person with cap and mustache,” says a monitor welcoming a visitor to the “Misalignment Mus­eum,” an exhibit on the controversial technology. 
 The pieces in this show mix the disturbing with the comic, and this display has AI disburse pithy observations to visitors.
 “The concept of the museum is that we are in a post-apocalyptic world where artificial general intelligence has already destroyed most of humanity,” said Audrey Kim, the show’s curator.
 “But then the AI realises that was bad and creates a memorial to the human, so our show’s tagline is ‘sorry for killing most of humanity,’” she said.
 Artificial General Intelligence is a concept that is even more nebulous than AI that is cascading into everyday life, as seen in the emergence of  apps such as ChatGPT or Bing’s chatbot and all the hype surrounding them.
 AGI is “artificial intelligence that is able to do anything a human would be able to do,” integrating cognitive capacities into machines.
 All around San Francisco, and down the peninsula in Silicon Valley, startups are hot on the trail of the AGI holy grail. 
 Sam Altman, the founder of ChatGPT creator OpenAI, has said AGI can “elevate humanity” and change the “limits of possibilities”. 
 But Kim wants to trigger a reflection on the dangers of going too far.
 “There have been lots of conversations about the safety of AI in tech circles on Twitter and I think that’s very important,” she said.
 Kim is particularly fond of a sculpture called Paperclip Embrace: two busts of humans holding each other, made entirely of paperclips.
 The work refers to a metaphor by philosopher Nick Bostrom, who in the 2000s imagined what would happen if artificial intelligence was programmed to create paper clips. — AFP",san francisco advance artificial intelligence museum san francisco memorial demise humanity humanity person cap mustache monitor visitor misalignment mu eum exhibit controversial technology piece comic display disburse pithy observation visitor museum post apocalyptic artificial intelligence humanity audrey kim curator bad creates memorial human tagline humanity artificial intelligence concept nebulous everyday life emergence apps chatgpt chatbot hype agi artificial intelligence human cognitive capacity machine san francisco peninsula silicon valley startup hot trail agi holy grail sam altman founder chatgpt creator agi elevate humanity change limit possibility trigger reflection danger conversation safety tech circle fond sculpture paperclip embrace bust human paperclip refers nick bostrom happen artificial intelligence create paper clip,"[(3, 0.99148506)]",3
523250,Life Inspired,17,12/03/2023,Artificial Intelligence reveals the most favoured chocolate,,"Is there a chocolate that can satisfy everyone? Perhaps that’s still a way’s off but in any case, this particular chocolate was designed to appeal to a maximum number of consumers. A Finnish dairy company used artificial intelligence based on the opinions of more than one and a half million chocolate eaters to design the chocolate that appealed to the tastebuds of the most people. So what is it like?
 When it comes to chocolate, we all have our preferences: the French prefer dark chocolate, in concentrations of up to 30% while the European average is 5%. 
 Some prefer to bite into a bar while others instead salivate for chocolate spreads, or even candy bars with various fillings. Therefore it can be difficult for brands or chocolate makers to come up with a creation that appeals to the greatest number of people.
 In Finland, a company specialising in dairy products (Valio) and byproducts has found a way to design a chocolate that has as universal an appeal as possible: through the use of artificial intelligence. 
 More than one and a half million comments and opinions posted on social networks about milk chocolate were integrated into a software program to develop a recipe based on the most commonly shared taste preferences. 
 The result is a bar composed of five layers, each with a different flavour and texture, based on AI’s recommendations. Moreover, this milk chocolate bar contains 30% less sugar than regular chocolate and is lactose-free. And these characteristics are not afterthoughts for the Finnish company, which has developed a technology to remove lactose from its unique milk powder solution, which it used in this creation. – AFP Relaxnews",chocolate satisfy chocolate appeal maximum consumer finnish dairy company artificial intelligence opinion half chocolate eater chocolate tastebud people preference french dark chocolate concentration european average bite bar salivate chocolate spread bar filling difficult brand chocolate maker appeal people company dairy product valio byproduct design chocolate universal appeal artificial intelligence half comment opinion social network chocolate software program recipe taste preference bar layer texture recommendation milk chocolate bar sugar regular chocolate free characteristic afterthought finnish company technology lactose unique milk powder solution creation afp relaxnews,"[(4, 0.98985916)]",4
521978,StarBiz,12,08/03/2023,Microsoft integrates AI behind ChatGPT to more developer tools,,"WASHINGTON: Microsoft Corp on Monday bundled the technology behind ChatGPT with its Power Platform that allows users to develop applications with little or no coding, the latest integration of artificial intelligence (AI) into its products.
 Big tech companies from Alphabet Inc to Baidu Inc are speeding up the integration of generative AI – technology that has gained popularity for its ability to generate human-like text responses to queries – into their offerings.
 Microsoft said a line of business-intelligence and app-development tools within Power Platform, including Power Virtual Agent and AI Builder, was updated with the new capabilities.
 Power Virtual Agent, a tool for businesses to build chatbots, can now connect to internal company resources to generate summaries of weekly reports and customer queries.
 Microsoft has also added generative AI capabilities to AI Builder, which lets businesses automate workflows, and launched a new version of its business management platform Dynamics 365 based on the technology.
 Dynamics 365 Copilot, the latest version of Microsoft’s tool that includes a number of applications for sales, customer service and marketing, integrates AI to automate certain tasks like data gathering and analysis or creating an email campaign, among other capabilities.
 Microsoft also said that chief executive Satya Nadella would host an event on March 16 to discuss “reinventing productivity with AI.”
 The company so far has announced AI updates for its popular Windows operating system and search engine Bing but not yet for its Office productivity suite, which includes Word and Excel. — Reuters",washington microsoft corp monday technology chatgpt power platform user application integration artificial intelligence product tech company baidu integration generative technology popularity ability human text response query offering microsoft business intelligence app development tool power platform power virtual agent builder capability power virtual agent tool business chatbots internal company resource summary weekly report customer query generative capability builder business workflow version business management platform dynamic technology dynamic version microsoft tool application sale customer service marketing automate task data analysis campaign capability chief executive satya nadella host event march productivity company update popular window system search engine office productivity suite word excel reuters,"[(4, 0.9918884)]",4
521272,Lifestyle,3,06/03/2023,Europe scrambles in AI race,,"GENERATIVE AI chatbots unveiled by US tech firms have captivated the world with their spectacular successes and failures in engaging in conversations.
 But European firms focusing more on business applications are confident they won’t be left in the dust in the rapidly developing field, even as they redouble their efforts.
 “The launch of ChatGPT has changed everything. It has been a wake-up call for European firms,” said Laurent Daudet at French startup LightOn.
 “But the battle for generative AI isn’t over,” he added.
 Artificial intelligence, or AI, has been increasingly present in everyday life for decades, but the November launch of the conversational robot ChatGPT from startup OpenAI marked a turning point in its perception by the public and investors.
 Generative AI, of which ChatGPT is an example, wades through oceans of data to conjure up original content – an image, a poem, a thousand- word essay – in seconds on a simple request.
 Despite still being prone to give incorrect answers and lead conversations in bizarre directions, firms are rushing to develop practical applications for the technology.
 Microsoft has backed OpenAI financially and begun to integrate ChatGPT features into its Teams platform, with expectations that it will adapt the tool to its Office suite and Bing search engine.
 Google plans to rush out its own conversational chatbot named Bard, but Facebook-owner Meta is working with researchers before attempting another release after being forced to take its bot offline last November after it shared biased and incorrect results.
 A number of US startups are also active in the space.
 European bots
 In Europe, dozens of startups are working on developing their own bots based on existing AI models or, more rarely, developing their own.
 All of them are using open source code, at least in part, to build the corpus of knowledge fed into the bots, just as the US tech titans have.
 Among the leading European startups is Germany’s Aleph Alpha, which is developing a multimedia chatbot.
 In France, there is Bloom, a scientific language model being built by hundreds of researchers coordinated by a US-French startup called Hugging Face with the support of France’s national scientific research centre, CNRS. Hugging Face recently struck a partnership with Amazon.
 Others are pursuing more specialised bots, such as German firm Stable Diffusion with its text-to-image model released last year and Swedish company Sana Labs’ AI, which manages information.
 All have raised tens of millions in funding from investors, which leaves them far behind the billions spent by US tech giants.
 Competitive tech
 Nevertheless, European firms believe their technology is competitive and can take a slice of the emerging market.
 Aleph Alpha founder and CEO Jonas Andrulis said its latest bot will be much more powerful than OpenAI’s latest GPT-3 model, which has captured global attention.
 “We will release our 300 billion parameter model this year,” Andrulis said. 
 The GPT-3 model has only 175 billion.
 He said his firm was the only one so far to offer a model that can take both text and images as input prompts, which opens up the possibility of different applications.
 Aleph Alpha is targeting high-value work at companies and Andrulis acknowledged they are rushing to compete against Microsoft.
 “For these customers, it’s either Microsoft or us,” he said.
 Daudet, a co-founder of Paris-based LightOn, said their models were also as performant as GPT-3.
 “The number of usages is phenomenal; conversation is one, but we aren’t going to fight on the ground on which the Americans excel,” he said.
 “We’re going to offer solutions for companies: summarising documents or email exchanges, generating specialised content,” he added.
 Multilingual models
 Many European AI models are multilingual. Bloom’s model works in seven languages, including English, Chinese, Spanish and French.
 Aleph Alpha’s works in five.
 This is an advantage as Europeans prefer tools in their native languages. But the quality depends on the volume of texts fed to them, and there English has had an advantage.
 “Our clients prefer GPT-3 for English texts and our mode for German and French,” said Aleph Alpha’s Andrulis.
 One concern is the future  of open source code, upon which all current AI models  are based. With competition heating up, companies may become less willing to share, inhibiting further innovation  by startups.
 Pablo Ducru, a French-educated researcher and entrepreneur who has moved to the United States to seek funding for his AI project, said European firms don’t need large teams, but believe three other elements are important.
 “First of all, calculating power, which is expensive.  The access to data for training. And finally, talent, which raises the question of salaries,” he said.
 Another element that could make a difference is user feedback. With ChatGPT now interacting with over 100 million Internet users, it could extend its lead. – AFP",generative chatbots tech firm spectacular success failure conversation european firm business application confident dust field redouble effort launch call european firm laurent daudet french startup lighton battle generative artificial intelligence everyday life decade launch conversational robot chatgpt startup openai perception public investor generative chatgpt wade ocean data conjure original content image poem word simple request prone incorrect answer conversation bizarre direction firm practical application technology microsoft openai integrate chatgpt feature platform expectation tool office suite search engine google plan conversational chatbot facebook owner meta researcher release bot offline november incorrect startup active space european bot dozen startup bot model source code corpus knowledge bot titan european startup aleph multimedia chatbot france bloom scientific language model hundred researcher french startup support france national scientific centre cnrs partnership amazon bot german firm stable diffusion text image model swedish company lab manages ten million investor billion tech giant competitive tech european firm technology competitive slice market aleph alpha founder ceo jonas andrulis bot powerful openai gpt model global attention release parameter model andrulis gpt model firm offer model text image prompt possibility application company compete microsoft customer daudet founder paris lighton model gpt usage phenomenal conversation fight ground offer solution company document email exchange specialised content multilingual model european model multilingual bloom model english chinese spanish french aleph alpha advantage european tool native language quality volume text fed english advantage client gpt english text mode german french aleph alpha andrulis concern future source code current model competition company share innovation startup ducru french researcher entrepreneur united seek funding project european firm element power expensive access data talent raise question salary difference user feedback chatgpt internet user lead afp,"[(1, 0.9968405)]",1
521034,StarEdu,7,05/03/2023,Aye to AI,Time to rethink how we teach and learn,"Artificial intelligence (AI) has recently generated much buzz. 
 First, it was data-driven AI systems DALL-E 2 from OpenAI and its open-source counterpart Stable Diffusion that could create realistic images given descriptions in natural language. 
 Then came ChatGPT, a conversational AI system that enables human-like conversations with a chatbot. The language model behind ChatGPT can answer questions and help with tasks such as writing emails and essays, crafting codes, and composing music. 
 There is nothing magical about DALL-E 2 and ChatGPT; the computing power and capacity that we have today have enabled machines to learn from vast amounts of data beyond human ability. DALL-E 2 and ChatGPT are part of a new technological wave called generative AI.
 Just like how the recent Covid-19 pandemic became a catalyst for digital transformation in many organisations, expect AI to disrupt the way we teach and learn. 
 In a recent article featured in The New York Times (“Alarmed by AI Chatbots, Universities Start Revamping How They Teach”, Jan 16), a professor at an American university rated a paper produced by ChatGPT as “the best paper in the class”. 
 So, should we shy away from AI? Should we ban the likes of ChatGPT from our classrooms? It’s time for educators to accept that the future has arrived and consider how AI can help us better our teaching and learning. 
 Personalised education 
 In one of his talks, the late Sir Ken Robinson likened today’s education system to a factory production line – increasingly standardised. We now have an opportunity to make learning personalised. There are opportunities to use AI-powered learning systems to design personalised learning pathways and content. 
 This is made possible by analysing student performance data collected through modern learning management systems (LMS). With proper guidance, we can even use technologies like ChatGPT to generate customised reading materials and assessment tasks. 
 Top this up with an ever-present human-like avatar of a student’s favourite tutor embodied in a mobile app providing immediate feedback and guidance, and we can help students stay on track.
 Workload automation
 AI-enabled robotic process automation can be used to automate the assessment of a student’s work. For example, there are now tools to summarise articles, essays and texts. 
 Students will be able to get timely feedback to improve their learning. Routine administrative tasks, such as scheduling and record management, can also be automated. 
 This helps reduce educators’ workload, enabling them to focus on delivering high-quality educational experiences to students.
 Democratising content  creation
 The demand for online self-paced learning courses has risen, driven by changing learning behaviours and the desire for flexibility. For these courses to be engaging, content is vital.
 Developing engaging content is both challenging and time-consuming. DALL-E 2 and Stable Diffusion now enable one to produce images based on a given text description (text-to-image). Tools like elai.io and synthesia.io use AI to rapidly create customised videos with a presenter without a camera, studio or green screen.
 Rethinking assessment
 Now that we have better access to technology and computing power, it is an opportune time to rethink how we do assessments. 
 We have to shift away from traditional forms of assessments to more authentic forms of assessments that reflect the real world where students are evaluated on what they can do, not merely on what they know.
 Imagine assessing students on skills and competencies required for a flood search and rescue mission. Instead of testing only head knowledge (traditional assessment), we could use generative AI to render realistic flood scenes and scenarios which are deployed in an extended reality (XR) system. 
 Students then take their assessment using the XR system. Learning outcomes attainment is assessed by analysing data recorded from the simulations.
 To make AI work for education, we need to have that human interaction and personal connection that is crucial for the character development and motivation of students.
 It is also important to ensure equitable access to AI if we are to avoid increasing the digital divide. Implementing AI can be expensive. Users will need to have already attained certain skills. 
 We will also have to figure out how we can navigate past challenges such as the limited scope of AI, and questions of intellectual property ownership and ethical implications.
 AI is driven by past human experiences embodied in data. There is an implicit assumption that the past reflects the future. Some argue that AI is excellent for precise tasks, as it is a piece of code, but not very good at being creative.
 Ownership of AI-generated content becomes complex when the AI is trained on other copyrighted content and as AI systems are typically data-driven, data privacy and security naturally become concerns. The challenge is also to prevent AI systems from perpetuating human bias embodied in data.
 So, could AI one day replace teachers? Unimaginable in many ways but we can expect the role of the teacher to change from being a singular source of knowledge to one that supports and guides students through the learning process as a facilitator. 
 It is customary for me to remind graduates that they must be able to unlearn and relearn new skills and competencies in a VUCA (volatile, uncertain, complex and ambiguous) world. As educators, are we ready to do the same as we embrace AI as part of our toolbox? The first step we can take is to develop AI literacy and stay abreast of its developments.
 Prof Dr Ho Chin Kuan is the vice chancellor at Asia Pacific University of Technology & Innovation (APU). He is also a fellow at the Overseas Chinese Development Research Center of the Yangtze Delta Region Institute of Tsinghua University, China. As an avid educator and researcher, his interests include data science, artificial intelligence, machine learning and complex systems. Prof Ho works with leading educators to co-build the future of EdTech. The views expressed here are the writer’s own.",artificial intelligence buzz data system dall openai source counterpart stable diffusion create realistic image description natural language conversational system human conversation language model chatgpt question task email code music magical dall chatgpt power capacity machine vast amount data human ability dall chatgpt technological wave generative covid pandemic catalyst digital transformation organisation disrupt teach learn article york time alarmed chatbots university teach jan professor american university paper chatgpt paper class shy ban like classroom time educator future learning personalised education talk late sir robinson education system factory production opportunity personalised opportunity powered system design learning pathway content student performance data modern learning management system proper guidance technology generate reading material assessment task top human avatar student favourite tutor mobile app feedback guidance student workload automation robotic process automation automate assessment student tool article essay student timely routine administrative task record management educator focus quality educational experience student content creation demand online learning course behaviour flexibility course content vital content time dall stable diffusion enable produce image text description text image tool synthesia customised video camera studio green screen assessment access technology power opportune time rethink assessment traditional form assessment authentic form assessment real student imagine assessing student competency flood search rescue mission head knowledge traditional assessment generative render realistic flood scene scenario reality system student system outcome attainment data simulation education human interaction personal connection crucial character development motivation student equitable access digital divide expensive user skill figure navigate challenge scope question intellectual property ownership ethical implication human experience data implicit assumption future argue excellent precise task code creative ownership content complex content system data privacy security challenge prevent system human bias data day teacher unimaginable expect role teacher change singular source knowledge guide student process facilitator customary remind graduate relearn skill competency volatile uncertain complex ambiguous educator ready embrace toolbox step literacy stay development prof chin kuan vice chancellor asia pacific university technology innovation fellow chinese development center yangtze delta region institute tsinghua university china avid educator researcher data science artificial intelligence machine complex system prof educator future edtech view writer,"[(0, 0.030089132), (3, 0.9680618)]",3
519868,StarBiz,11,01/03/2023,Zoom jumps   on AI bandwagon,Company forecasts upbeat 2024 profit targets,"CALIFORNIA: Zoom Video Communications Inc says it will integrate more artificial intelligence (AI) into its products and forecast annual profit above Wall Street estimates, sending the company’s shares up 8% in extended trading.
 Analysts predict the AI tech will be a major driver for future growth for the tech industry, which has been grappling with slowing demand amid recessionary fears.
 The AI race picked up pace after Microsoft-backed OpenAI’s ChatGPT last year prompted heavyweights from Alphabet Inc to China’s Baidu Inc to announce their own offerings.
 “I like that Zoom is proactively talking about these opportunities today and I honestly believe it’s necessary, especially given Microsoft is already including ChatGPT as part of Teams Premium,” said RBC analyst Rishi Jaluria.
 San Jose, California-based Zoom forecast fiscal 2024 profit between US$4.11 (RM18.43) and US$4.18 (RM18.74) per share, compared with analysts’ average estimate of US$3.66 (RM16.41) per share, according to Refinitiv data.
 “The age of AI and large language models has arrived,” said chief executive Eric Yuan during a call with analysts, adding that AI can “truly help” the company.
 Zoom is also benefiting from steady demand for its video-conferencing service from the ongoing shift to hybrid work models and cost cuts. 
 Earlier this month, it announced an about 15% reduction in its workforce.
 On an adjusted basis, Zoom earned US$1.22 (RM5.47) per share for the fourth quarter ended Jan 31, compared with estimates of 81 cents (RM3.63) per share.
 Revenue grew 4% to US$1.12bil (RM5bil), above analysts’ average expectation of US$1.10bil (RM4.93bil).
 Finance chief Kelly Steckelberg said the growth was primarily driven by strength in Zoom’s enterprise business.
 The company, however, expects 2024 revenue between US$4.44bil (RM19.9bil) and US$4.46bil (RM20bil), below average Street estimate of US$4.60bil (RM20.6bil).
 “The revenue outlook is softer than initially expected, partly due to macro pressures and especially given declining online business,” Jaluria said. — Reuters",california zoom video communication artificial intelligence product annual profit wall street estimate company share trading analyst tech major driver future growth tech industry demand recessionary fear race pace microsoft openai chatgpt heavyweight china baidu offering zoom opportunity chatgpt team rbc analyst rishi jaluria san jose california zoom forecast fiscal profit share analyst average estimate share data age language model chief executive eric call analyst company zoom steady demand video service shift hybrid model cost cut month reduction workforce basis zoom share fourth quarter jan cent share revenue bil bil analyst average expectation bil bil finance chief steckelberg growth driven strength zoom enterprise business company revenue bil bil bil bil average street estimate bil bil revenue outlook macro pressure online business jaluria reuters,"[(4, 0.992472)]",4
519160,Main,11,27/02/2023,Jay Chou: I will not be replaced by artificial intelligence,,"KING of Mandopop Jay Chou believes that artificial intelligence (AI) will not be able to replace music content creators like him, Sin Chew Daily reported.
 Chou, who is a prolific lyricist and composer, said he was not worried about the rise in AI technology.
 Although he acknowledged that “AI can do a lot of things”, he felt that it would not replace the creation of music.
 His fans have flocked to his social media account to show support, saying that they could not believe a computer software could take the place of the superstar.
 “No one can replace the king!” someone posted.
 Chou, 44, began his career in music as a lyricist and composer for other celebrities.
 In 2000, he released his first album with the help of his mentor Jacky Wu, an influential character in Taiwan’s entertainment business.One of the songs won the 24th Top Ten Chinese Gold Songs award.
 His second studio album, Fantasy, won him five Golden Melody awards, including Album of the Year, which cemented his name in showbusiness.
 AI has gone mainstream with ChatGPT, an AI-powered language model that is trained from vast amounts of data from the Internet to answer prompts by users in a human-like manner.
 The technology is touted to have the capability of replacing many jobs.
 The Internet is also seeing the rise in AI-powered services like Midjourney, which creates images from textual descriptions, and Soundful, which generates royalty free-music.
 > A  newly-released song by Chinese singer Li Ronghao has led to Internet searches for smoked plum sauce to increase 200-fold on shopping sites, Sin Chew Daily also reported. 
 Titled Dark Plum Sauce, the catchy tune is getting popular among music fans.
 Following its release about two months ago, the song had inadvertently led to a spike in online searches for the sauce.
 In fact, it was the eighth most searched item on Taobao, one of China’s largest online shopping platforms.
 Fans of the song who have never tried it before were eager to get themselves a jar.
 Many now jokingly call it “Li Ronghao sauce” and that it contained the “flavours of one’s first love”.
 Smoked plum is often used in East Asian cuisine and medicine.  
 The sauce is made with smoked plums, hawthorn, orange peel, roselle and sugar.
 Those who liked the song indicated that their favourite line  was “your smile is just like dark plum sauce”.
 Many of them speculated that Li was referring to his wife, singer Rainie Yang, 39.",mandopop jay chou artificial intelligence music content creator chew chou prolific lyricist composer rise technology lot creation music fan social medium support computer software superstar chou career music lyricist composer celebrity album mentor jacky influential character taiwan entertainment business song top chinese gold song studio album fantasy golden melody award album showbusiness mainstream chatgpt language model vast amount data internet answer user human manner technology capability job internet rise service midjourney image textual description soundful generates free music song chinese singer ronghao internet search plum sauce increase site chew titled dark plum catchy tune popular music fan month spike online search eighth searched item taobao china largest online shopping platform fan eager jar call ronghao sauce flavour east asian cuisine medicine sauce plum hawthorn orange peel roselle sugar song smile dark plum sauce wife singer rainie yang,"[(0, 0.9937567)]",0
516818,Lifestyle,3,20/02/2023,Teachers invite AI to class,,"UNDER the fluorescent lights of a fifth grade classroom in Lexington, Kentucky, in the United States, Donnie Piercey instructed his 23 students to try and outwit the “robot” that was churning out writing assignments.
 The robot was the new artificial intelligence (AI) tool ChatGPT, which can generate everything from essays and haikus to term papers within seconds. The technology has panicked teachers and prompted school districts to block access to the site. 
 But Piercey has taken another approach by embracing it as a teaching tool, saying his job is to prepare students for a world where knowledge of AI will be required.
 “This is the future,” said Piercey, who describes ChatGPT as just the latest technology in his 17 years of teaching that prompted concerns about the potential for cheating. 
 The calculator, spellcheck, Google, Wikipedia, YouTube. Now all his students have Chromebooks on their desks. 
 “As educators, we haven’t figured out the best way to use AI yet. But it’s coming, whether we want it to or not.”
 One exercise in his class pitted students against the machine in a lively, interactive writing game. Piercey asked students to “Find the Bot:” Each student summarised a text about boxing champion and Kentucky icon Muhammad Ali, then tried to figure out which was written by the chatbot.
 At the elementary school level, Piercey is less worried about cheating and plagiarism than high school teachers. 
 His district has blocked students from ChatGPT while allowing teachers access. Many educators around the country say districts need time to evaluate and figure out the chatbot, but they also acknowledge the futility of a ban that today’s tech-savvy students can work around.“To be perfectly honest, do I wish it could be uninvented? Yes. But it happened,” said Steve Darlow, the technology trainer at Florida’s Santa Rosa County District Schools, which has blocked the application on school-issued devices and networks.
 He sees the advent of AI platforms as both “revolutionary and disruptive” to education. 
 He envisions teachers asking ChatGPT to make “amazing lesson plans for a substitute” or even for help grading papers. 
 “I know it’s lofty talk, but this is a real game changer. You are going to have an advantage in life, business and education from using it.”
 ChatGPT quickly became a global phenomenon after its November launch, and rival companies, including Google, are racing to release their own versions of AI-powered chatbots.The topic of AI platforms and how schools should respond drew hundreds of educators to conference rooms at the Future of Education Technology Conference in New Orleans last month, where Texas math teacher Heather Brantley gave an enthusiastic talk on the “Magic of Writing with AI for all Subjects”.Brantley said she was amazed at ChatGPT’s ability to make her sixth grade math lessons more creative and applicable to everyday life.
 “I’m using ChatGPT to enhance all my lessons,” she said in an interview. The platform is blocked for students but open to teachers at her school, White Oak Intermediate. 
 “Take any lesson you’re doing and say, ‘Give me a real-world example,’ and you’ll get examples from today – not 20 years ago when the textbooks we’re using were written.”
 For a lesson about slope, the chatbot suggested students build ramps out of cardboard and other items found in a classroom, then measure the slope. 
 For teaching about surface area, the chatbot noted that sixth graders would see how the concept applied to real life when wrapping gifts or building a cardboard box, said Brantley.
 She is urging districts to train staff to use the AI platform to stimulate student creativity and problem-solving skills. 
 “We have an opportunity to guide our students towards the next big thing that will be part of their entire lives. Let’s not block it and shut them out.”
 Students in Piercey’s class said the novelty of working with a chatbot makes learning fun.
 After a few rounds of Find the Bot, Piercey asked his class what skills it helped them hone. Hands shot up. 
 “How to properly summarise and correctly capitalise words and use commas,” said one student. A lively discussion ensued on the importance of developing a writing voice and how some of the chatbot’s sentences lacked flair or sounded stilted.
 Trevor James Medley, 11, felt that sentences written by students “have a little more feeling. More backbone. More flavour”.
 Next, the class turned to playwriting, or as the worksheet handed out by Piercey called it: “Pl-ai Writing”. 
 The students broke into groups and wrote down (using pencil and paper) the characters of a short play with three scenes to unfold in a plot that included a problem that needed to be solved.
 Piercey fed details from worksheets into the ChatGPT site, along with instructions to set the scenes inside a fifth grade classroom and to add a surprise ending. 
 Line by line, it generated fully formed scripts, which the students edited, briefly rehearsed and then performed.
 One was about a class computer that escapes, with students going on a hunt to find it. 
 The play’s creators giggled over the unexpected plot twists that the chatbot introduced, including sending the students on a time travel adventure.
 “First of all, I was impressed,” said Olivia Laksi, 10, one of the protagonists. She liked how the chatbot came up with creative ideas. 
 But she also liked how Piercey urged them to revise any phrases or stage directions they didn’t like. 
 “It’s helpful in the sense that it gives you a starting point. It’s a good idea generator.”
 She and classmate Katherine McCormick, 10, said they can see the pros and cons of working with chatbots. 
 They can help students navigate writer’s block and help those who have trouble articulating their thoughts on paper. And there is no limit to the creativity it can add to classwork.
 The fifth graders seemed unaware of the hype or controversy surrounding ChatGPT. For these children, who will grow up as the world’s first native AI users, their approach is simple: Use it for suggestions, but do your own work.
 “You shouldn’t take advantage of it,” McCormick says. 
 “You’re not learning anything if you type in what you want, and then it gives you the answer.” – AP",fluorescent light classroom lexington kentucky donnie piercey student outwit assignment artificial intelligence tool chatgpt generate essay term paper technology teacher school district access site piercey approach tool job prepare student future piercey describes technology concern potential cheating calculator spellcheck google wikipedia youtube student desk educator exercise class student machine interactive writing game piercey student bot student text boxing champion icon ali figure chatbot elementary school level piercey plagiarism school teacher district student chatgpt teacher access educator country district time evaluate figure chatbot futility ban tech savvy student uninvented steve darlow technology trainer santa rosa county district school application school device network advent platform revolutionary disruptive education envisions teacher lesson plan paper lofty talk real game changer advantage life business education chatgpt global phenomenon november launch rival company google release version chatbots topic platform school hundred educator conference future education technology conference orleans month math teacher heather brantley enthusiastic talk magic writing subject chatgpt ability sixth grade math lesson applicable everyday life chatgpt enhance lesson interview platform student teacher school white oak intermediate lesson real example textbook lesson slope chatbot student ramp cardboard item classroom measure slope surface chatbot sixth grader real life gift cardboard box brantley district train staff platform stimulate student creativity skill opportunity student entire life block student piercey class novelty chatbot fun round piercey class skill hand shot summarise comma student discussion voice chatbot sentence flair trevor james medley sentence student flavour class worksheet piercey student pencil paper character short play scene unfold plot solved piercey fed detail worksheet site instruction scene grade classroom surprise script student performed class computer student play creator unexpected plot twist student time travel adventure impressed olivia laksi protagonist creative idea revise stage direction helpful sense idea generator classmate katherine mccormick pro con student navigate writer block trouble paper limit creativity classwork grader unaware hype controversy chatgpt child native user simple suggestion mccormick type answer,"[(0, 0.30481228), (2, 0.4353663), (3, 0.25847262)]",2
516590,Lifestyle,4,19/02/2023,"AI, chat bots, and matters of the heart",,"QUESTION: Will a chat bot replace Thelma any time soon? How do we know if it’s not ChatGPT replying on behalf of our favourite Star-Lifestyle columnist?
 Or will we be comfortable typing in our heart’s discontent and asking for guidance from artificial intelligence (AI)? Well, there are already some highly educated people doing so, judging by Jason Godfrey’s column last week (“Maybe we need to rethink those career paths”, Big Smile, No Teeth, StarLifestyle, Feb 12.)
 It may sound silly for we know a computer program can’t sensibly solve problems of the heart at the moment – but who knows what could happen when AI reaches version 10.0, becoming smarter than humans even?
 But I believe that no matter how intelligent it gets, AI will never be able to have emotions and feelings. It can’t possibly understand the anguish and anxiety of living. Simply said it takes a human to understand another human (though some pet owners believe their pets understand them).
 Søren Kierkegaard, the Danish existentialist thinker and author, once said, “Life is not a problem to be solved but a reality to be experienced”. Do you agree?
 Sometimes life has no answer and a listening ear is just enough. As for matters of the heart, maybe it requires a leap of faith. AI couldn’t do that because there is some- thing that machines don’t  have:  what we call intuition.
 PS: This letter was  not generated by ChatGPT.
 DIGITALLY BACKWARD
 IpohEditor’s note: We’ll never replace Thelma with a chat bot!",question thelma time chatgpt behalf favourite star lifestyle columnist comfortable heart discontent guidance artificial intelligence people jason godfrey week career path smile teeth starlifestyle computer program heart moment version smarter human intelligent emotion feeling anguish anxiety living human understand human pet owner pet ren danish existentialist thinker author life reality agree life answer ear matter heart leap faith machine intuition letter chatgpt backward ipoheditor note thelma chat,"[(3, 0.98727137)]",3
516492,StarBiz 7,6,18/02/2023,Who will be AI’s  first billionaire?,,"GREAT advances in technology often result in vast increases of wealth. So as the artificial intelligence (AI) boom continues, one obvious question is who will profit – and by how much. 
 My view, which may be deflationary for entrepreneurs but good for consumers, is this: Relative to how much AI changes the world, its early pioneers won’t get especially rich.
 Truly fundamental changes alter every part of the economy. They do so only by becoming freely or readily available across a wide range of sectors. Money will be made from AI, but it will be hard to capture anything close to full value.
 Consider the Internet. The most successful entrepreneurs in social media have earned huge fortunes – but the early developers of the Internet itself did not. 
 Even as late as 1992, if you were convinced the Internet would be a huge thing, there was no easy way to make money from that insight. Just as the inventors of early printing presses, such as Gutenberg, did not become the richest nobles of their time.
 And that raises another obvious question: Are the current manifestations of AI – the Large Language Models (LLMs) embodied in services such as ChatGPT, for example – more like the Internet and the printing press, or more like social media? 
 The evidence so far suggests they are somewhere in between.
 Facebook benefits from network effects. That is, you want to be able to connect with friends and family, so a social networking service of size and prominence will have a considerable advantage in the marketplace. Similarly, how many people have really left Twitter for Mastodon?
 The major AI companies do not seem to have this advantage. If I use OpenAI’s ChatGPT, and you use Anthropic’s Claude, we still can easily communicate with each other – through other media. It is even possible to imagine linking one service to the other, using text, through a third-party intermediary.
 A small number of AI services, possibly even a single one, likely will end up better than the others for a wide variety of purposes. Such companies might buy the best hardware, hire the best talent and manage their brands relatively well. 
 But they will face competition from other companies offering lesser (but still good) services at a lower price. 
 When it comes to LLMs, there is already a proliferation of services, with Baidu, Google and Anthropic products due in the market. The market for AI image generation is more crowded yet. 
 In economic terms, the dominant AI company might turn out to be something like Salesforce. 
 Salesforce is a major seller of business and institutional software, and its products are extremely popular. Yet the valuation of the company, as of this writing, is about US$170bil (RM753bil). 
 That’s hardly chump change, but it does not come close to the US$1 trillion (RM4.43 trillion) valuations elsewhere in the tech sector.
 OpenAI, a current market leader, has received a private valuation of US$29bil (RM128bil). Again, that’s not a reason to feel sorry for anyone – but there are plenty of companies you might not have heard of that are worth far more.
 AbbVie, a biopharmaceutical corporation, has a valuation of about US$271bil (RM1.2 trillion), almost 10 times higher than OpenAI’s.
 To be clear, none of this is evidence that AI will peter out. Instead, AI services will enter almost everyone’s workflow and percolate through the entire economy. 
 Everyone will be wealthier, most of all the workers and consumers who use the thing. The key ideas behind AI will spread and be replicated – and the major AI companies of the future will face plenty of competition, limiting their profits.
 In fact, AI’s ubiquity may degrade its value, at least from a market perspective. It’s likely the AI boom has yet to peak, but the speculative fervor is almost palpable. 
 Share prices have responded to AI developments enthusiastically. Buzzfeed shares rose 150% in one day last month, for example, after the company announced it would use AI to generate content. 
 Does that really make sense, given all the competition BuzzFeed faces?
 It’s when those prices and valuations start falling that you will know the AI revolution has truly arrived. 
 In the end, the greatest impact of AI may be on its users, not its investors or even its inventors. — Bloomberg
 Tyler Cowen writes for Bloomberg. The views expressed here are the writer’s own.",advance technology result vast increase artificial intelligence boom obvious question profit view deflationary entrepreneur consumer pioneer rich fundamental alter economy wide range sector money hard capture close internet successful social medium huge fortune developer convinced internet huge easy money insight inventor press richest noble time obvious question current manifestation language model service chatgpt internet printing press social medium evidence benefit network effect friend family social networking service size prominence considerable advantage marketplace people twitter mastodon major company openai chatgpt anthropic communicate medium service text party intermediary service single wide variety purpose company hardware hire talent manage brand competition company lesser service lower price llm proliferation service google anthropic product market market image generation economic term company salesforce salesforce major seller business institutional software product popular valuation company bil bil chump change close valuation sector openai current market leader private valuation bil reason feel plenty company worth biopharmaceutical corporation valuation bil time openai evidence peter service workflow percolate entire economy wealthier worker consumer key idea spread major company plenty competition profit ubiquity degrade market perspective boom peak speculative fervor palpable share price development share day month company generate content sense competition buzzfeed price valuation revolution impact user investor inventor tyler cowen bloomberg view writer,"[(1, 0.7130497), (2, 0.28380543)]",1
515744,Main,13,16/02/2023,Alamin for AI summit in  The Hague,,"PUTRAJAYA: Deputy Foreign Minister Datuk Mohamad Alamin is on his first working visit  abroad to the Netherlands, since his appointment on Dec 9 last year.
 According to a statement by Foreign Ministry (Wisma Putra), Mohamad Alamin will be representing Foreign Minister Datuk Seri Dr Zambry Abd Kadir at the Ministerial Segment of the  Summit on Responsible Artificial Intelligence (AI) in the Military Domain (REAIM 2023) at The World Forum Convention Centre in The Hague.
 The REAIM 2023 conference is co-hosted by the Netherlands and South Korea.
 It will provide a platform for various stakeholders countries such as Malaysia to discuss and share their views on issues pertaining to the applications of AI in the military realm, reported Bernama.
 “The deputy foreign minister’s two-day visit to the Netherlands will provide an excellent opportunity for Malaysia to strengthen its long-standing bilateral relations with the Netherlands.
 “It will also explore new areas of cooperation of mutual interests,” said the statement.",putrajaya foreign minister datuk mohamad alamin visit appointment dec statement foreign ministry putra mohamad alamin foreign minister datuk seri zambry abd ministerial segment summit responsible artificial intelligence military domain reaim forum convention centre hague reaim conference netherlands south korea provide platform stakeholder country share view issue application military realm bernama deputy foreign minister day netherlands excellent opportunity malaysia strengthen bilateral relation explore cooperation mutual statement,"[(4, 0.9871203)]",4
515304,StarBiz,2,15/02/2023,Artificial intelligence set to be the next tech pillar of investments,,"KUALA LUMPUR: More investments are poised to be poured into a relatively new space in the technology industry – artificial intelligence (AI).
 The potential winners of the development in this space would be technology suppliers and contractors that are listed in Malaysia.
 PublicInvest Research said AI could potentially revolutionise semiconductor manufacturing globally, moving forward.
 This as the growing influence of AI is poised to reshape industries from logistics, education and healthcare to automotive and manufacturing in the longer term, it said.
 “It is starting to look like 2023 may be the year when AI goes mainstream. Generative AI is a technology that uses machine learning to create new content, based on simple instruction,” the research house said.
 ChatGPT, which had been hogging the headlines of late, is one example of text-to-text Generative AI while there are also text-to-image, text or image-to-video, text-to-music and numerous other projects. 
 “Companies like ABB, Nvidia and Dynatrace are already developing AI applications to make industries like healthcare, education and manufacturing more efficient and responsive.
 “Furthermore, AI requires large amounts of data to be processed and high-performance hardware to train models. Digital data is currently growing at about 60% per annum, fuelling massive demand for cloud computing,” PublicInvest added.
 However, the generation of grammatically correct, human-like written text by AI applications can be used to make social engineering attacks such as phishing or business email, making scams harder to detect and remove.
 “As a result, corporate cybersecurity budgets will continue to rise. Gartner expects information security spending to reach US$187bil (RM813.17bil) as companies raise their outlay, including on AI-augmented security tools, to fend off new cyberattack tactics.
 “In short, the expansion in expenditure on AI, cloud and cybersecurity is expected to post strong earnings growth for the leading companies in these sectors,” it added.
 Meanwhile, according to Nikkei Asia, major US chip equipment suppliers are shifting operations from China to South-East Asia in a sign that US export controls enacted last October are accelerating the decoupling of tech supply chains between the world’s two largest economies. 
 “Applied Materials, Lam Research and KLS, which collectively own about 35% of the global market share for chip production equipment, have been increasing their production capacity in South-East Asia or relocating their workforce from China to Singapore and Malaysia since October,” PublicInvest said.
 It noted that the relocation of major semiconductor players to Malaysia will see more smaller global semiconductor companies following their footsteps. 
 PublicInvest said this move not only helps increase job orders for local players but will also widen the scope of the semiconductor value chain in Malaysia.
 “We think there will be more potential developments, especially in the front-end wafer fabrication and fabless deign fields, which can help widen Malaysia’s semiconductor value chain,” it said.",kuala lumpur investment poured space technology industry artificial intelligence potential winner development space technology supplier contractor malaysia publicinvest revolutionise semiconductor influence reshape industry logistics education healthcare automotive manufacturing term mainstream generative technology machine create content simple instruction house chatgpt headline late text text generative text image text image video text music numerous project company nvidia dynatrace application industry education manufacturing efficient responsive amount data performance hardware train model digital data annum massive demand cloud publicinvest generation correct human text application social engineering attack business email scam detect result corporate cybersecurity budget rise gartner security spending reach bil bil company security tool cyberattack tactic short expansion expenditure cloud cybersecurity post strong earnings growth company sector major chip equipment supplier operation south east asia sign export control tech supply chain largest economy material global market share chip production equipment production capacity east asia workforce china singapore malaysia publicinvest relocation major semiconductor player global semiconductor company publicinvest move job local player scope semiconductor chain malaysia potential development front fabrication fable deign field widen malaysia semiconductor chain,"[(1, 0.9952086)]",1
514784,StarBiz,4,13/02/2023,Tight job market? AI meets worker shortage,,"THE two investment obsessions of the year so far – artificial intelligence (AI) and super-tight labour markets – meet head on.
 If the hype about the former is to be believed, concern about the inflationary impact of the latter should be well wide of the mark. If only they were so perfectly aligned.
 Timing is everything of course. The speed with which ChatGPT-style AI tools zap swathes of white-collar desk jobs could be more glacial than any Big Tech rah-rah suggests – and at least slower than the 12-18 months of the Federal Reserve’s current policy horizon.
 But two reasonable questions are being asked around investment houses.
 Does the wave of layoffs in the digital and banking worlds this year relate directly to the presumed quantum leap in so-called generative AI – just as pandemic-related overstaffing and more recent job hoarding is being pared back?
 And if it does, should policymakers relax more about what could be temporary worker shortages in the service sector, where most of the wage and inflation concerns seem to centre?
 Far from relaxing, should office or home-based workers now fret that we’re in for anything but a tight jobs market over the coming years?
 More questions than answers perhaps – but enough to have investment strategists thinking laterally and joining dots.
 Morgan Stanley’s thematic research team said last week it was inundated with enquiries about generative AI during its recent client visits. 
 And while investment fads come and go, they said, this one is “worth considering seriously” given the speed of take-up and its diffusion across many industries.
 Aside from stock price and valuation frenzies, the team said a new wave of AI fed the debate about white-collar industry disruption in a “creative destruction moment” – with possible side benefits from reskilling workers to better wage diffusion.
 Citing numbers indicating employment in business, knowledge, customer and developer outsourcing in excess of 100 million across Asia alone, Morgan Stanley said the impact was already being felt even if the jury was still out on “the degree to which it is deflationary or productivity enhancing.”
 If this generative AI takes the tech transformation to non-routine office work that it largely skirted over the last decade, it will affect tens of millions more jobs than currently assumed.
 The two sides of the theoretical debate at least are whether that then leads to mass unemployment and demand problems –  requiring a reconsideration of things like universal basic income to support economies – or whether productivity gains lift wages and see workers simply choosing to work ever fewer hours over time as bots take their place.
 London-based Fathom Consulting last Thursday concluded that a “fourth industrial revolution powered by AI could greatly affect the demand for and supply of labour” and the United States and China were bound to vie for leadership.
 “The speed and impact of this change will be profoundly disruptive for global politics and for the structure of the labour market,” economists Erik Britton and Andrew Harris wrote, adding that the United States needed to keep investing in tech that both supports and replaces labour in order to retain its edge.
 But just what is the scale of the likely disruption?
 A frequently cited study by business consultant McKinsey from 2017 showed 60% of occupations worldwide have at least 30% of work activities that could be automated – even though automation may well create more jobs in tandem.
 That tallies with numbers from the Organisation for Economic Cooperation and Development, which reckoned 10% to 15% of jobs will be lost due to tech changes over the next 20 years – but about as many may be created in other industries.
 While varying hugely among the 46 countries it examined, the McKinsey study said up to 30% of activities could be displaced by 2030 – with advanced and ageing economies more likely to move faster given higher wages and incentives.
 More recent polling from McKinsey last year showed companies saying at least a quarter of their tasks could be automated over the next five years but less than a fifth of respondents reckoned their firms were yet in a position to do that.
 And that observation underlines the timing of all this in terms of years. How soon do tech revolutions change the world – and at least aggregate demand or supply for workers?
 As the flub by Alphabet’s chatbot Bard illustrated in spectacular fashion this week, the big problem for the latest wave of emerging AI is still one of accuracy.
 “While ChatGPT’s output is credible, accuracy is its Achilles’ Heel,” Morgan Stanley’s team wrote. “Manual validation should act as a breakwater to this employment threat for now.”
 If creases take years to iron out, perhaps it’s not so useful to see the craze providing a timely offset to tight labour markets and wage inflation.
 There’s even a chance the trepidation may exaggerate the prevailing conundrum and cause as many problems as the reality.
 In a discussion paper published by the Centre for Economic Policy Research last month, economists Marta Golin and Christopher Rauh said their work found a “strong relationship” between worry about automation and intentions to join a union, retrain or switch occupations, preference for taxation and government handouts, populist attitudes and voting intentions.
 Much like the pandemic, fear of automation could have as big an economic impact as its actual spread. — Reuters
 Mike Dolan is a columnist for Reuters. The views expressed here are the writer’s own.",investment obsession artificial intelligence super tight labour market head hype concern inflationary impact wide mark speed chatgpt style tool swathe white collar desk job glacial tech rah rah slower month federal current policy horizon reasonable question investment house layoff digital banking world quantum leap generative pandemic job pared policymakers temporary worker shortage service sector wage inflation concern office worker fret tight job market question answer investment strategist dot morgan stanley thematic team week enquiry client visit investment fad worth speed diffusion industry stock price valuation team wave debate white collar industry disruption creative destruction moment benefit worker wage diffusion indicating employment business knowledge customer developer excess asia morgan stanley impact jury deflationary productivity generative tech transformation routine office decade affect million job theoretical debate mass unemployment demand reconsideration universal basic income support economy gain wage worker fewer hour time bot fathom thursday fourth industrial revolution affect demand labour united china bound vie leadership speed impact change disruptive global politics structure market economist britton andrew harris united tech support labour retain edge scale disruption study business consultant mckinsey occupation activity automation create job tandem tally economic cooperation development job industry country mckinsey study activity advanced ageing economy wage incentive mckinsey company quarter task respondent reckoned firm position observation underline timing term tech revolution aggregate demand supply worker chatbot bard spectacular fashion week accuracy chatgpt output credible accuracy achilles morgan stanley team manual validation breakwater employment threat iron craze tight labour market wage inflation chance trepidation conundrum reality discussion paper centre economic policy month economist golin christopher rauh strong relationship worry automation intention union retrain occupation preference taxation government handout attitude intention pandemic fear automation economic impact actual spread reuters dolan columnist reuters view writer,"[(4, 0.99696165)]",4
514376,Life Inspired,18,12/02/2023,Revamp your home interior with AI,,"New technologies are increasingly becoming part of our daily lives, not to mention our homes. Some of them, such as artificial intelligence, are even replacing interior designers when it comes to rethinking indoor spaces. All of which could revolutionise the sector. 
 From choosing the right colours and matching materials harmoniously to working with the shape and size of a room, successful interior design is an art that is much more complicated than it seems. It is sometimes difficult to imagine functional living spaces that reflect your tastes. But artificial intelligence is on hand to help. This technology is at the core of InteriorAI, a platform that generates interior design projects in a few clicks. 
 Users just have to upload a picture of the room they want to redesign to the InteriorAI website, then let the artificial intelligence guide them in the realisation of their project. However, the picture must be as bright as possible in order to facilitate the AI’s work. The artificial intelligence then generates a rendering of the room in question in about 20 interior design styles. 
 Want to turn your living room into an urban jungle? Or perhaps you prefer a more tropical style? And if you’re a compulsive collector, maybe you’d like your interior to reflect this aspect of your personality with a maximalist aesthetic. InteriorAI was created by a Dutch developer and entrepreneur known by the pseudonym “levelsio”, who is also the creator of “This House Does Not Exist”, another image generation tool. This one is able to produce pictures of modern houses from a line of text, based on a database that can include hundreds of millions of images from the internet.
 Several apps are using artificial intelligence to help anyone and everyone become a would-be interior designer. Ikea has used this same technology to launch its own app, called Place. It allows users to see which furniture from the Swedish firm’s catalog would look best in their home through augmented reality. It also provides them with “tips and recommendations based on curation, context and behaviour”, to help even the most indecisive of users to rethink their interior with minimal effort. – AFP Relaxnews",technology daily life mention home artificial intelligence interior designer indoor space sector choosing colour material size successful interior design art difficult imagine functional living space artificial intelligence hand technology core interiorai platform interior design project user upload picture redesign interiorai website artificial intelligence guide realisation project picture bright facilitate artificial intelligence generates question interior design style urban jungle tropical style compulsive collector interior reflect aspect personality maximalist aesthetic interiorai dutch developer entrepreneur pseudonym levelsio creator house exist image generation tool picture modern house database hundred million image apps artificial intelligence interior designer ikea technology launch app user furniture swedish firm catalog reality tip recommendation curation context behaviour indecisive user interior minimal effort afp relaxnews,"[(3, 0.99244297)]",3
514268,StarBiz 7,3,11/02/2023,"ChatGPT, the future of AI",New model poised to revolutionise industry,"IT used to be in the realm of science fiction, but is now a reality.
 Artificial intelligence (AI) has gone mainstream now with ChatGPT, and it is scaring and exciting a number of people and companies.
 The prospects of having AI solve tasks is thrilling. And it is sending the share prices of companies involved in AI skyrocketing.
 Several companies, such as BuzzFeed Inc, C3.ai Inc, SoundHound AI Inc, and BigBear.ai Holdings Inc, have experienced significant spikes in trading volume and dramatic fluctuations in their stock prices.
 The whole phenomenon is off the potential of ChatGPT, an AI chatbot developed by AI research and deployment company OpenAI, with the support of Microsoft Corp’s multi-billion investment.
 ChatGPT, in other words, is an AI-powered language model that is trained from vast amounts of data from the Internet to answer prompts by users in a human-like manner, but limited now to data up to 2021.
 The traction it has garnered is staggering. As reported by Forbes, ChatGPT only took five days to achieve one million users compared to Facebook that took about 10 months, Netflix which took about three and a half years, and the iPhone that took about 74 days.
 Moreover, a report by investment bank UBS, citing an analysis by data firm Similarweb, showed that ChatGPT is estimated to have reached 100 million monthly active users in January, just two months after launch.
 In comparison, data from application analysis firm Sensor Tower showed that TikTok took about nine months after its launch to reach 100 million users, while Instagram took more than two years.
 Worry for Google
 Anecdotally, ChatGPT usage has been able to aid students with their assignments or even help workers with their day-to-day job.
 The runaway success of ChatGPT prompted Google’s management to declare a state of emergency, or “code red,” in response to the launch of ChatGPT, owing to growing concerns regarding the future of the company’s search engine.
 Google’s search engine is its largest business, where a bulk of its revenue is derived from.
 The worries were fuelled by Microsoft’s announcement that it will integrate ChatGPT into Bing and Edge, the company’s search engine and browser, following its multi-year, multi-billion-dollar investment deal with OpenAI in late-January.
 Acting promptly, just days ago, Google introduced Bard, a conversational AI service powered by a language model for dialogue applications or LaMDA in short.
 Bard has been unlatched for trusted testers ahead of making it more widely available to the public in the coming weeks.
 However, it couldn’t get any worse for Alphabet as it lost US$100bil (RM432bil) in market value, following inaccurate information shared by its new chatbot.
 The disruption ChatGPT can cause is multifaceted.
 ChatGPT has the ability to not only write codes for programming, but also debug codes, aiding software developers.
 Apart from writing articles or even crafting ideas for content creators, it is able to explain a complex topic or also write music in a desired genre as well.
 The extent of the ChatGPT’s capabilities, however, are yet to be fully uncovered but many reckon it is a game changer in the AI world.
 AI has been around but the level of AI in ChatGPT is said to be very high.
 In a recent article, consulting firm McKinsey and Company said generative AI, which is leveraged by ChatGPT or other chatbot, has been revolutionising assistive technology, reducing application development time, and bringing powerful capabilities to nontechnical users. 
 The big worry is that AI will impact jobs. 
 If you ask ChatGPT what will the impact on Malaysian jobs be, it says this: “ChatGPT, as an Al language model, has the potential to automate certain tasks and make some jobs more efficient. However, it is important to note that Al technology is not expected to fully replace human workers but rather augment and assist them.”
 In Malaysia, the impact of ChatGPT on jobs will likely depend on the specific industry and job function. 
 For example, in customer service, ChatGPT could be used to automate responses to frequently asked questions, freeing up customer service representatives to handle more complex inquiries. 
 On the other hand, in industries where creativity and human touch is important, ChatGPT is unlikely to replace human workers entirely. 
 It is important for workers and companies in Malaysia to continuously upskill and adapt to the changing technological landscape in order to remain relevant in the job market.”
 Speaking with consultants, different views were obtained, but the exact impact of ChatGPT on the Malaysian job market remains blurry.
  Deloitte South-East Asia consulting director Lee Yun-Han believes the chatbot has a high potential to disrupt how Malaysian businesses operate and how employees work. 
 Ernst & Young Consulting Sdn Bhd associate partner Yeap Bee Aik, on the other hand, says it is difficult to predict the exact impact of ChatGPT, or any AI technology, on Malaysia’s job market specifically. 
 “The decision to use AI or to leverage the workforce in a particular sector will depend on various factors such as the cost of labour, the availability of skilled workers, and the specific tasks and jobs that can be automated by AI,” Yeap says.
 Yeap opines that it is sensible for AI systems to perform repetitive tasks, as it can be performed more efficiently and accurately by AI as compared to humans, and consequently, leading to cost saving and increased productivity.
 However, Yeap adds that there are also tasks that may require human skills, such as creativity, empathy, and critical thinking, that may not be easily automated by AI. 
 “In short, the net impact of ChatGPT, or AI in general, on the Malaysian job market will depend on how it is integrated, the rate of adoption, and the actions taken by governments, businesses, and individuals to help workers acquire new skills,” Yeap utters.
 Meanwhile, KPMG Malaysia head of technology consulting Alvin Gan believes the focus is more towards the scale of jobs being impacted.
 Gan believes the debates about jobs being affected by automation intensified in recent years as the country increased its focus on using automated systems.
 “To a large extent, there are parallels between the plausible impacts of ChatGPT with the technologies that had ‘arrived’ many years ago. Yes, ChatGPT is more intelligent and sophisticated compared to others – but the premise remains similar: automation and simplification of processes that have been used by humans for decades,” Gan notes.
 Gan believes the question that should be addressed is “how would business leaders resolve job displacement that is potentially caused by such AI models?”. 
 “One way to address this is by conditioning the workforce to understand that their jobs are likely to be redesigned,” Gan answers.
 Gan suggests that this exercise can be less painful if leaders can find ways to reallocate and retrain in a new era of breakthrough technologies that will likely complement existing roles and operations.
 “While job displacements will be inevitable in the short term, as with every technological revolution in the past, humans will adapt. I believe the jobs replaced by bots will give birth to new ones, and it will serve to complement the human workforce rather than replacing it completely,” Gan opines.
 When asked which industry will be affected the most by chatbots, Lee points out customer service, call centres, and copywriting sectors would likely be significantly disrupted by ChatGPT.
 However, Lee believes there are clear limitations to ChatGPT as it stands today.
 “It is unable to deliberately generate new knowledge, deliver creative responses with personality, or substitute human-to-human interaction,” Lee highlights.
 Yeap, meanwhile, believes ChatGPT will have some impact on all sectors, as language AI systems like ChatGPT have the potential to automate a wide range of tasks.
 However, having a similar opinion, Yeap opines the sectors that are most likely to be affected by AI technology are those that involve repetitive tasks that can be easily automated and these include data entry, customer service, and certain types of content creation.
 “Sectors that require higher-level cognitive skills, such as those in the medical, legal, and creative fields, are less likely to be impacted. This is because these jobs require human expertise and nuance, that AI technology like ChatGPT cannot fully replicate,” Yeap says.
 New jobs
 While some jobs may be displaced by AI technology, Yeap points out that new jobs will also be created in fields related to AI development and maintenance, data analysis, and digital transformation.
 “Therefore, the precise impact will likely vary from sector to sector, and it is important for organisations to carefully assess the potential benefits and risks of AI technology in their specific contexts,” Yeap concludes.
 While there are many advantages to utilising chatbots, Gan points out the downside of it.
 On an individual level, Gan believes overutilisation may create high dependency on this technology to perform tasks and obtain information, which in turn will impact one’s ability to think critically and rely on their own capabilities and skills.
 “On a broader level, there have already been reports of ChatGPT providing misinformation,” Gan reminds.
 Additionally, Gan says that the level of automation in Malaysia, as well as other developing countries, would ultimately result in structural transformation– an economic transition from low productivity and labour-intensive activities to higher productivity and skill-intensive activities. 
 “As Malaysia appears to be concentrated on labour-intensive manufacturing and service jobs, automation adoption would inevitably alter the nature of work and labour opportunities,” Gan says.
 Touching students’ assignments that are being done by ChatGPT in universities, Gan says it is imperative for educators to consider different ways of educating and designing their curriculum.
 “Assignments can be designed to demonstrate creativity, critical thinking and problem-solving. Skills for students to be able to adapt to future technologies and environments should be integrated into the curriculum,” Gan tells.
 He believes that the ball is now in the authorities’ court to ensure that their governance and the resiliency of student development are upheld in institutions.
 Explaining authorities’ role, Gan says policies on the use of AI tools should be established and communicated to students, with consequences for violators highlighted and enforced.
 “Additionally, higher education institutions should ensure constant awareness of the responsible and ethical use of AI, which impacts the integrity of the institution,” he adds.
 Lee believes that humanity needs to adapt to the never-ending technology advancements.
 “Just like how we have adopted the usage of calculators and the open-book approach in examinations and assignments, how universities evaluate their students would also need to evolve accordingly,” he says.
 While there are technologies that can detect the usage of AI in completing assignments, Lee thinks it is a constant game of catch-up as AI sophistication evolves.
 This view is echoed by Yeap, who also believes that universities should embrace AI and see it as an opportunity to enhance the learning experience and better prepare students for the future, rather than viewing AI as a threat.
 “Ultimately, universities will need to find a balance between promoting academic integrity and embracing new technologies that are shaping the future,” Yeap concludes.",realm science fiction reality artificial intelligence mainstream chatgpt people company prospect task share price company company soundhound bigbear holding spike trading volume dramatic fluctuation stock price potential chatgpt chatbot deployment company support microsoft investment chatgpt language model vast amount data internet answer user human manner data traction forbes chatgpt day user facebook month half iphone day report investment bank analysis data firm similarweb chatgpt active user january month launch comparison data application analysis firm sensor tower tiktok month launch user chatgpt usage aid student assignment worker day day job runaway success chatgpt google management declare emergency code red response launch concern future company search engine google search engine largest business bulk revenue worry microsoft announcement integrate chatgpt edge company search engine browser multi dollar investment deal openai january day conversational service language model dialogue application short bard trusted tester public week worse alphabet bil bil market inaccurate chatbot disruption chatgpt chatgpt ability code debug code software developer article idea content creator complex topic write music genre extent chatgpt capability reckon game changer level chatgpt article firm company generative chatgpt chatbot assistive technology application development time powerful capability nontechnical user impact job impact malaysian job language model potential automate task job efficient note technology human worker augment assist malaysia impact chatgpt job specific industry job function customer service chatgpt automate response question customer service representative complex inquiry hand industry creativity touch chatgpt human worker worker company upskill technological landscape relevant job market consultant view exact impact chatgpt malaysian job market blurry deloitte south east asia director lee yun han chatbot potential disrupt malaysian business employee sdn bhd associate partner yeap bee aik hand difficult predict exact impact chatgpt technology malaysia job market decision leverage workforce sector factor labour availability worker specific task job yeap yeap system repetitive task human cost saving productivity task human skill creativity critical short net impact chatgpt malaysian job market rate adoption action government business individual worker skill yeap utters malaysia head technology alvin gan scale job gan debate job automation country system extent parallel plausible impact chatgpt technology chatgpt intelligent premise automation simplification process human decade gan note question business leader job displacement model workforce understand job gan answer exercise painful leader retrain era breakthrough technology role operation job displacement inevitable short term technological revolution human job bot complement human workforce gan opines industry chatbots customer service call sector chatgpt lee limitation stand unable knowledge creative response personality human human interaction lee highlight chatgpt impact sector language system potential automate wide range task opinion sector technology repetitive task data entry customer service type content creation sector level cognitive skill medical legal creative field job human expertise nuance technology chatgpt replicate yeap job job technology yeap job field development maintenance data analysis digital transformation precise impact vary sector sector organisation potential benefit risk technology specific context yeap advantage chatbots gan downside individual level gan overutilisation create dependency technology perform task impact ability rely capability skill level report misinformation gan gan level automation malaysia country structural transformation economic transition low productivity intensive activity productivity intensive activity concentrated intensive service job automation adoption nature labour opportunity student assignment chatgpt university imperative educator curriculum assignment demonstrate creativity critical thinking skill student adapt future technology environment curriculum gan ball authority court governance resiliency student development upheld institution authority role gan policy tool communicated student consequence violator enforced education institution constant awareness responsible ethical impact integrity institution lee humanity adapt technology advancement usage calculator book approach examination assignment university student technology usage assignment lee constant game catch sophistication evolves yeap university opportunity enhance experience prepare student future threat ultimately university balance academic integrity technology future concludes,"[(0, 0.9985076)]",0
513820,StarBiz,11,10/02/2023,Salesforce’s  Bret Taylor  to start AI firm,,"NEW YORK: Bret Taylor, who recently resigned as co-chief executive officer at Salesforce Inc, is forming an artificial intelligence (AI) startup with outgoing Google vice-president Clay Bavor.
 The two executives, former colleagues at Alphabet Inc’s Google, will create a new company to apply AI to “some of the most important problems in business,” Taylor wrote yesterday in a LinkedIn post. 
 The venture will begin in March when Bavor leaves Google, that executive wrote in a separate post, and the pair will provide more details at a later date.
 Taylor, 42, once seen as a likely successor to Salesforce chief executive officer Marc Benioff, announced in November that he would leave the enterprise software giant to return to his “entrepreneurial roots.” 
 He helped found companies that were later purchased by Facebook Inc – now called Meta Platforms Inc – and Salesforce. 
 Since Taylor announced that he was leaving Salesforce, the company has embarked on significant job cuts, experienced a wave of executive turnover and been pressured by multiple activist investors. 
 Taylor had also been Twitter Inc’s board chairman, serving as the social media company’s point person during Elon Musk’s acquisition.
 Bavor, who joined Google in 2005, rose in the company’s ranks as a manager on Gmail and Google Drive and is considered a favourite lieutenant of CEO Sundar Pichai. 
 In 2015, Bavor was tapped to run Google’s virtual reality (VR) unit, an effort to outpace rivals to the next expected computing platform.
 Google has released waves of software and some gadgets, but its products have never gained widespread use and the company has retreated from the field.
 In 2021, Bavor was put in charge of a new Google division called Labs that housed various far-flung projects, including VR and blockchain and the company’s startup incubator. The incubator, called Area 120, was pared back significantly in a recent wave of job cuts at Alphabet.
 Google doesn’t plan to name a replacement for Bavor, according to spokesperson for the company. — Bloomberg",york bret taylor chief executive officer salesforce artificial intelligence startup google vice president clay bavor executive colleague google create company business taylor yesterday post venture march bavor google executive separate post pair detail taylor successor salesforce chief executive officer benioff november enterprise software giant return entrepreneurial root company meta platform taylor salesforce company job cut wave executive turnover multiple activist investor board chairman social medium company person elon musk acquisition bavor google company rank manager google drive favourite lieutenant ceo sundar pichai bavor google virtual reality unit effort outpace rival platform google wave software gadget product widespread company field bavor charge google division lab flung project blockchain company startup incubator incubator job cut google plan replacement bavor spokesperson company bloomberg,"[(2, 0.99285054)]",2
513378,StarBiz,10,09/02/2023,Retail investors flock to small-cap AI firms,,"NEW YORK: Retail investors are piling into small-cap firms that are building artificial intelligence (AI) tools as companies, including Google parent Alphabet and Microsoft, jostle to pull ahead in the race for the next big growth driver.
 The viral success of ChatGPT has turned the spotlight on AI on Wall Street, reminiscent of the blockchain hype from a few years ago when shares of companies remotely associated with the technology surged.
 As per Vanda Research, the US$3bil (RM12.9bil) AI software firm C3.ai was the fifth most actively traded on Fidelity’s platform for small investors on Monday, drawing record daily retail inflows worth US$31.4mil (RM135mil).
 The stock fell 14.7% on Tuesday, although it is up about 140% so far this year.
 “Small-cap firms have AI as a much larger part of their business than the larger ones,” said Matthew Tuttle, chief executive officer of Tuttle Capital Management, on the reason behind retail investors’ focus on the smaller firms.
 Tuttle said he had shorted C3.ai shares about a week ago but was looking to switch to the long side because “that’s where the action is”.
 Shares of SoundHound AI, which offers voice AI platform services, and Thailand’s security firm Guardforce AI have more than doubled in value so far this year, while those of analytics firm BigBear.ai have seen a nine-fold rise.
 SoundHound AI was last down about 14.9% and BigBear.ai fell 18%, while Guardforce AI slipped 3%.
 Shares of Microsoft, which backs ChatGPT parent OpenAI, gained about 2.4% after the tech giant said it was revamping its Bing search engine with AI such that users will be able to chat with the search engine naturally.
 The new Bing chatbot will help users refine queries and even draft and translate emails, with the company calling Bing the “AI-powered robot for the web”.
 Alphabet said on Monday it would launch a chatbot service called Bard along with more AI tools to power its search engine.
 Microsoft is in a strong position in the AI race due to the combination of its close partnership with OpenAI and its Azure capabilities around compute and data, Barclays analyst Raimo Lenschow said.
 “If you’re investing in AI, you should consider the fact that these smaller companies are competing against Goliath, and Goliath has the scale, efficiency and capital to own the space,” eToro analyst Callie Cox said, adding there has been a lot of interest in AI lately.
 US-listed shares of Baidu Inc climbed 9.9% on Tuesday after the Chinese search engine said it would complete internal testing of a ChatGPT-style project called “Ernie Bot” in March. Earlier in the day, a clutch of Chinese AI stocks had also rallied.
 “The market is right now trying to search for what would be the next big thing that’s going to lead markets over the next 10 years, and AI is that,” said Chen Zhao, chief global strategist at Alpine Macro.
 “It could be speculative in nature, but everybody thinks that it’s going to be a big deal going forward.” — Reuters",york retail investor cap firm artificial intelligence tool company google parent alphabet microsoft jostle pull race growth viral success chatgpt wall street reminiscent blockchain hype share company technology vanda bil bil software firm fidelity platform investor record retail inflow worth mil mil stock tuesday cap firm larger business larger matthew tuttle chief executive officer tuttle capital management reason retail investor firm share week action share offer voice platform service security firm guardforce analytics firm fold rise soundhound bigbear guardforce share microsoft chatgpt parent openai tech giant search engine user search engine chatbot user query translate email company robot web alphabet monday launch chatbot service tool power search engine microsoft strong position race combination partnership openai azure capability data barclays analyst lenschow company goliath goliath scale efficiency capital space etoro analyst callie lot share tuesday chinese search engine complete internal testing chatgpt style project march day chinese stock market search lead market chen zhao chief global strategist alpine macro speculative nature deal forward reuters,"[(3, 0.9947173)]",3
512926,StarBiz,8,08/02/2023,Tech giants explore  new AI opportunities,"Despite advances, there’s still a ‘long way’ to go","SHANGHAI: Chinese tech companies are upping the ante in the fast-growing artificial intelligence (AI)-generated content sector as ChatGPT, the latest chatbot launched by US-based artificial intelligence research company OpenAI, gains wide popularity since its November debut and revolutionises the field due to its advanced conversational capabilities.
 Leveraging machine learning algorithms, ChatGPT is able to mimic humanlike responses with AI-generated content (AIGC) and assist people with tasks such as writing essays and scripts, making business proposals and even checking programme bugs, which it does within seconds.
 AIGC-related stocks continued to rally in the A-share market, with Chinese AI companies, such as Cloudwalk Technology and Speechocean, seeing their shares surge by the daily limit of 20% on the science and technology innovation board on Monday.
 Experts said that AIGC is likely to become a new engine driving innovation in digital content production and freeing human creators from tedious tasks, with a wide range of commercial applications in fields such as culture, media, entertainment and education.
 Chinese tech heavyweight Baidu Inc announced yesterday that it will complete internal testing of its AI chatbot service, similar to OpenAI’s ChatGPT, called “Ernie Bot” in March.
 The Beijing-based company has invested large sums of money in developing its Ernie system, a large-scale machine-learning model that has been trained on massive data over several years and possesses in-depth semantic comprehension and generation capabilities.
 Robin Li, co-founder and chief executive officer of Baidu, said in January that AIGC will subvert existing content production models in the next decade, and AI has the potential to meet massive demand for content at a 10th of the cost and a hundred or thousand times faster.
 Jianying, an AI-powered short-video editing app launched by Chinese tech company Byte-Dance, allows users to generate creative videos by simply putting in a few keywords or a paragraph of text.
 Online gaming company Net-Ease has released its AI music creation platform, Tianyin, where users can customise a song by entering lyrics.
 Pan Helin, co-director of the Digital Economy and Financial Innovation Research Centre at Zhejiang University’s International Business School, said that ChatGPT, as a milestone in AIGC-related technologies, uses reinforcement learning from human feedback to train the data model, with significant enhancements in natural language processing capacities that improve the logic of responses.
 Chinese enterprises should step up efforts to roll out indigenous versions of the AI-powered chatbot and increase investments to improve related algorithms and computing power, Pan said.
 Chen Jia, an independent strategy analyst, said: “Chinese tech enterprises have unique advantages in expanding AI application scenarios globally.”
 China has made significant progress in developing the AI industry.
 A Stanford University report showed that China filed more than half the world’s AI patent applications in 2021 and continued to lead the world in the number of AI journals, conference papers and related publications.
 Baidu, Tencent and Alibaba have invested heavily in promoting the commercial use of AI, and some Chinese AI unicorns have grown rapidly in recent years, Chen said.
 But he noted that Chinese tech companies lag behind top-notch foreign competitors in fundamental research and development input and comprehensive innovation abilities.
 “AIGC is in the initial stage of development, and there is still a long way to go to realise large-scale commercialisation, as the application scenarios and related laws and regulations are far from mature,” said Guo Tao, deputy head of the China Electronic Commerce Expert Service Centre. 
 Meanwhile, the use of AIGC-related technologies raises concerns about ethics, copyright protection and privacy, he added.— China Daily/ANN",shanghai chinese tech company ante artificial intelligence content sector chatgpt chatbot artificial intelligence company openai gain wide popularity debut field conversational capability machine algorithm chatgpt mimic humanlike response content aigc assist people task essay script business proposal programme bug stock share market chinese company technology speechocean share daily limit science technology innovation board monday expert engine innovation digital content production human creator tedious task wide commercial application field culture medium entertainment education chinese tech baidu yesterday complete internal testing chatbot service openai chatgpt ernie bot march company sum money ernie system scale machine model massive data posse semantic comprehension generation capability founder chief executive officer january aigc subvert content production model decade potential meet massive demand content cost time short video chinese tech company byte dance user creative video keywords paragraph text online company net ease music creation platform tianyin user song lyric pan director digital economy financial innovation centre zhejiang university international business school chatgpt milestone aigc technology human feedback train data model enhancement natural language processing capacity logic response chinese enterprise step effort indigenous version chatbot increase investment power pan jia independent strategy analyst chinese tech enterprise unique advantage application scenario progress industry stanford university report china half patent application lead journal conference paper publication tencent alibaba commercial chinese unicorn chen chinese tech company top notch foreign competitor fundamental development input comprehensive innovation ability initial stage development scale commercialisation application scenario law regulation guo tao deputy head china electronic commerce expert service centre aigc technology concern ethic copyright protection privacy china daily ann,"[(0, 0.99663556)]",0
512152,StarEdu,7,05/02/2023,Time to embrace AI,"Rethink teaching, learning, student assessment to safeguard academic integrity","AN artificial intelligence (AI) system that can write essays, solve mathematical problems, generate computer code, hold a chat conversation, and even crack jokes seems hard to imagine, but that is what ChatGPT, a groundbreaking new AI-driven chatbot developed by research company OpenAI, does.
 Accessible to the public since November last year, anyone can sign up and start using ChatGPT right away, which was what I did. Here is an excerpt of what ChatGPT produced when I asked to write an article for me on the topic of AI in higher education: 
 “One of the main benefits of AI in higher education is the ability to personalise the learning experience. AI can analyse a student’s performance and provide tailored feedback and recommendations for improvement. This can help students learn at their own pace and reduce the workload for instructors. AI is also being used to create virtual assistants and tutors that can answer questions and provide support to students. These tools can help students learn more efficiently and effectively, and they can be accessed anytime and anywhere with an Internet connection.”
 It’s scarily impressive, and it’s impossible to distinguish whether the text was written by a human or AI. The Generative Pre-trained Transformer (GPT) technology that ChatGPT is based on is smart enough to string together meaningful sentences in a matter of seconds. What’s special about ChatGPT is its seeming ability to exhibit creativity – a quality that was earlier thought to be beyond AI.
 Some argue that ChatGPT will eventually replace Google search and become the de facto way in which people get information. The fact that OpenAI is founded by Tesla mogul Elon Musk and funded by the likes of tech giant Microsoft gives some weight to that argument.
 As an educator, alarm bells are starting to ring in my head. I have no way to tell whether assignments submitted by my students are written by them or an AI system like ChatGPT. 
 The Guardian, in its article “AI bot ChatGPT stuns academics with essay-writing skills and usability”, reported that ChatGPT generated answers to exam queries that would have been given full marks by examiners if submitted by a student. It’s also been reported that ChatGPT was able to pass an MBA exam, a US Medical Licensing Exam, and the US Bar Exam to practise law. Universities should be seriously worried.
 Cheating and issues relating to academic integrity are nothing new. Even before AI came along, technology made cheating, plagiarism, collusion, and other unwarranted behaviours as simple as cutting and pasting. 
 Notably, the widespread adoption of plagiarism detection tools such as Turnitin by many universities has proven to be an ineffective deterrent. The article “One in 10 uni students submit assignments written by someone else – and most are getting away with it” in The Conversation suggests that 10% of students engage in some form of cheating, and that 95% of those who cheat are never caught.
 With AI, the chance of catching cheaters will be even slimmer, and the temptation to cheat even greater. Contract cheating, where students pay external companies to ghostwrite essays, is already a systemic problem.
 Those students can now get ChatGPT to effectively ghostwrite for free. The big question is how will universities maintain academic integrity in the face of rapid advancements in AI? Universities are delusional to think they can fight AI by investing in more advanced AI. Nor can universities sidestep the problem by “trusting” their students under the defence of an honour code.
 The short, and possibly only, answer when it comes to student assessment is to rely less on the “digital” and more on the ‘physical’. Think of students sitting for exams in a physical exam hall rather than remotely online. Or students discussing their work before a live classroom audience, responding to questions on the spot. Or students presenting a highly personalised portfolio based on their own experience rather than a generic assignment.
 AI is here to stay and can only get smarter. And it’s not just about ChatGPT – there is a plethora of generative AI tools flooding the Internet. 
 Universities need to embrace the fact that we are living in an AI-inclusive world.
 Educators should rethink how they approach teaching, learning and student assessment to take advantage of what AI offers, but at the same time protect academic integrity to ensure that student learning outcomes are not compromised.
 Prof Wing Lam is the provost and chief executive officer at University of Reading Malaysia, an international branch campus of University of Reading, United Kingdom. He has held a variety of academic positions in Malaysia, Singapore and the UK. Prof Wing completed his PhD in computer science at King’s College London in 1994. He has published over 80 peer-reviewed articles and journals. His current areas of research interest include technology and innovation. The views expressed here are the writer’s own.",artificial intelligence system write essay mathematical generate computer code conversation crack joke hard imagine chatgpt chatbot company accessible public november sign start chatgpt excerpt chatgpt write article topic education main benefit education ability personalise experience analyse student performance provide feedback recommendation improvement student pace workload instructor virtual assistant tutor question support student tool student anytime internet connection impressive impossible distinguish text human generative pre transformer gpt technology chatgpt smart meaningful sentence special chatgpt ability exhibit creativity quality argue chatgpt google search people tesla mogul elon musk like tech giant microsoft weight argument educator alarm bell head assignment student system chatgpt guardian article bot chatgpt academic skill usability chatgpt generated answer query mark examiner student chatgpt pas mba medical licensing exam bar exam practise law university issue academic integrity technology plagiarism collusion unwarranted behaviour simple widespread adoption plagiarism detection tool turnitin university ineffective deterrent article uni student assignment conversation student form cheat chance cheater slimmer temptation cheat contract student external company essay systemic student ghostwrite free question university academic integrity rapid advancement university delusional fight university student code short answer student assessment digital physical student exam physical exam hall online student live classroom audience question spot student portfolio experience generic assignment chatgpt plethora generative tool internet university inclusive educator approach learning student assessment advantage offer time academic integrity student outcome prof lam provost chief executive officer university reading malaysia international branch campus university reading united kingdom variety academic position prof phd computer science college london peer article journal current technology innovation view writer,"[(0, 0.9966226)]",0
510002,Lifestyle,6,30/01/2023,"AI,  do my homework!","This is how ChatGPT,  an artificial intelligence chatbot, pits teachers against tech.","KNOW-IT-ALL chatbots landed with a bang last year, convincing one engineer that machines had become sentient, spreading panic that industries could be wiped out, and creating fear of a cheating epidemic in schools and universities.
 Alarm among educators has reached a fever pitch in recent weeks over ChatGPT, an easy-to-use artificial intelligence (AI) tool trained on billions of words and a ton of data from the Web.
 It can write a half-decent essay and answer many common classroom questions, sparking a fierce debate about the very future of traditional education.
 In the United States, New York City’s education department banned ChatGPT on its networks because of “concerns about negative impacts on student learning”.
 “While the tool may be able to provide quick and easy answers to questions, it does not build critical- thinking and problem-solving skills,” said the department’s Jenna Lyle.A group of Australian universities said they would change exam formats to banish AI tools, regarding them as straight-up cheating.
 However, some in the education sector are more relaxed about AI tools in the classroom, and some even sense an opportunity rather than a threat.
 ‘Important innovation’
 That is partly because ChatGPT in its current form still gets stuff wrong. To give one example, Guatemala is bigger than Honduras. It isn’t.
 Also, ambiguous questions can throw it off track.
 Ask the tool to describe the Battle of Amiens and it will give a passable detail or two on the 1918 confrontation from World War I.
 But it does not flag that there was also a skirmish of the same name in 1870. It takes several prompts for it to realise its error. 
 “ChatGPT is an important innovation, but no more so than calculators or text editors,” said French author and educator Antonio Casilli.
 “ChatGPT can help people who are stressed by a blank sheet of paper to write a first draft, but afterwards they still have to write and give it a style.”
 Researcher Olivier Ertzscheid from the University of Nantes agreed that teachers should be focusing on the positives.
 In any case, he said, high school students were already using ChatGPT, and any attempt to ban it would just make it more appealing.
 Teachers should instead “experiment with the limits” of AI tools, he said, by generating texts themselves and analysing the results with their students.
 ‘Humans deserve to know’
 But there is also another big reason to think that educators do not need to panic yet.
 AI writing tools have long been locked in an arms race with programs that seek to sniff them out, and ChatGPT is no different.
 Recently, an amateur programmer announced he had spent his new year’s holiday creating an app that could analyse texts and decide if they were written by ChatGPT.
 “There’s so much ChatGPT hype going around,” Edward Tian wrote on Twitter.
 “Are this and that written by AI? We as humans deserve to know!”
 His app, GPTZero, is not the first in the field and is unlikely to be the last.
 Universities already use software that detects plagiarism, so it does not take a huge leap of imagination to see a future where each essay is rammed through an AI-detector.
 Campaigners are also floating the idea of digital watermarks or other forms of signifiers that will identify AI work.
 And OpenAI, the company that owns ChatGPT, said it was already working on a “statistical watermark” prototype.
 This suggests that educators will be fine in the long run.
 But Casilli, for one, still believes the impact of such tools has a huge symbolic significance.
 It partly upended the rules of the game, whereby teachers ask their pupils questions, he said.
 Now, the student questions the machine before checking everything in the output.
 “Every time new tools appear, we start to worry about potential abuses, but we have also found ways to use them in our teaching,” said Casilli. – AFP",chatbots bang engineer machine panic industry fear epidemic school university educator pitch week easy artificial intelligence tool billion ton data write half decent essay answer common classroom question fierce debate future traditional education united york city education department chatgpt network concern negative impact student tool quick easy answer question critical thinking skill department jenna lyle australian university exam format banish tool education sector tool classroom sense opportunity threat innovation chatgpt current form stuff wrong guatemala bigger honduras ambiguous question track tool battle passable detail confrontation war flag skirmish prompt error chatgpt innovation calculator text editor french author educator antonio casilli chatgpt people blank sheet paper write draft write style researcher olivier ertzscheid university nantes teacher positive school student attempt ban teacher experiment limit tool text student human reason educator writing tool arm race program sniff chatgpt amateur programmer spent holiday app analyse text chatgpt chatgpt hype edward tian human app gptzero field university software plagiarism huge leap imagination future essay detector campaigner idea digital watermark signifier openai company chatgpt statistical watermark prototype educator fine casilli impact tool huge symbolic significance rule game teacher question student question machine output time tool potential abuse casilli afp,"[(0, 0.995657)]",0
509158,Lifestyle,9,27/01/2023,Fighting back against AI,"AI tools can create new images and artworks, but who is the real artist?","COUNTLESS artists have taken inspiration from The Starry Night since Vincent Van Gogh painted the swirling scene in 1889.
 Now artificial intelligence systems are doing the same, training themselves on a vast collection of digitised artworks to produce new images you can conjure in seconds from a smartphone app.
 The images generated by tools such as DALL-E, Midjourney and Stable Diffusion can be weird and otherworldly but also increasingly realistic and customisable – ask for a “peacock owl in the style of Van Gogh” and they can churn out something that might look similar to what you imagined.
 But while Van Gogh and other long-dead master painters aren’t complaining, some living artists and photographers are starting to fight back against the AI software companies creating images derived from their works.
 Two new lawsuits – one from the Seattle-based photography giant Getty Images – take aim at popular image-generating services for allegedly copying and processing millions of copyright-protected images without a license.
 Getty said it has begun legal proceedings in the High Court of Justice in London against Stability AI – the maker of Stable Diffusion – for infringing intellectual property rights to benefit the London-based startup’s commercial interests.
 Another lawsuit in a US federal court in San Francisco describes AI image-generators as “21st-century collage tools that violate the rights of millions of artists”. 
 The lawsuit, filed on Jan 13 by three working artists on behalf of others like them, also names Stability AI as a defendant, along with San Francisco-based image-generator startup Midjourney, and the online gallery DeviantArt.
 The lawsuit alleges that AI-generated images “compete in the marketplace with the original images. Until now, when a purchaser seeks a new image ‘in the style’ of a given artist, they must pay to commission or license an original image from that artist”.
 Companies that provide image-generating services typically charge users a fee. 
 After a free trial of Midjourney through the chatting app Discord, for instance, users must buy a subscription that starts at US$10 (RM43) per month or up to US$600 (RM2,556) a year for corporate memberships. The startup OpenAI also charges for use of its DALL-E image generator, and StabilityAI offers a paid service called DreamStudio.
 Stability AI said in a statement that “Anyone that believes that this isn’t fair use does not understand the technology and misunderstands the law”.
 In a December interview, before the lawsuits were filed, Midjourney CEO David Holz described his image-making service as “kind of like a search engine” pulling in a wide swath of images from across the Internet. He compared copyright concerns about the technology with how such laws have adapted to human creativity.
 “Can a person look at somebody else’s picture and learn from it and make a similar picture?” Holz said. 
 “Obviously, it’s allowed for people and if it wasn’t, then it would destroy the whole professional art industry, probably the nonprofessional industry too. To the extent that AIs are learning like people, it’s sort of the same thing and if the images come out differently then it seems like it’s fine.”
 The copyright disputes mark the beginning of a backlash against a new generation of impressive tools – some of them introduced just last year – that can generate new visual media, readable text and computer code on command.
 They also raise broader concerns about the propensity of AI tools to amplify misinformation or cause other harm. For AI image generators, that includes the creation of nonconsensual sexual imagery.
 Some systems produce photorealistic images that can be impossible to trace, making it difficult to tell the difference between what’s real and what’s AI. 
 And while some have safeguards in place to block offensive or harmful content, experts fear it’s only a matter of time until people utilise these tools to spread disinformation and further erode public trust.
 “Once we lose this capability of telling what’s real and what’s fake, everything will suddenly become fake because you lose confidence of anything and everything,” said Wael Abd-Almageed, a professor of electrical and computer engineering at the University of Southern California.
 As a test, the AP submitted a text prompt on Stable Diffusion featuring the keywords “Ukraine war” and “Getty Images”. 
 The tool created photo-like images of soldiers in combat with warped faces and hands, pointing and carrying guns. Some of the images also featured the Getty watermark, but with garbled text.
 AI can also get things wrong, like feet and fingers or details on ears that can sometimes give away that they’re not real, but there’s no set pattern to look out for. Those visual clues can also be edited. On Midjourney, users often post on the Discord chat asking for advice on how to fix distorted faces and hands.
 With some generated images travelling on social networks and potentially going viral, they can be challenging to debunk since they can’t be traced back to a specific tool or data source, according to Chirag Shah, a professor at the Information School at the University of Washington, who uses these tools for research.
 “You could make some guesses if you have enough experience working with these tools,” Shah said. “But beyond that, there is no easy or scientific way to really do this.”
 For all the backlash, there are many people who embrace the new AI tools and the creativity they unleash. Some use them as a hobby to create intricate landscapes, portraits and art; others to brainstorm marketing materials, video game scenery or other ideas related to their professions.
 There’s plenty of room for fear, but “what can else can we do with them?” asked the artist Refik Anadol recently at the World Economic Forum in Davos, Switzerland, where he displayed an exhibit of climate-themed work created by training AI models on a trove of publicly available images of coral.
 At the Museum of Modern Art in New York, Anadol designed Unsupervised, which draws from artworks in the museum’s prestigious collection – including The Starry Night – and feeds them into a digital installation generating animations of mesmerising colours and shapes in the museum lobby.
 The installation is “constantly changing, evolving and dreaming 138,000 old artworks at MoMA’s archive”, said Anadol. 
 “From Van Gogh to Picasso to Kandinsky, incredible, inspiring artists who defined and pioneered different techniques exist in this artwork, in this AI dream world.”
 Anadol, who builds his own AI models, said in an interview that he prefers to look at the bright side of the technology. But he hopes future commercial applications can be fine-tuned so artists can more easily opt out.
 “I totally hear and agree that certain artists or creators are very uncomfortable about their work being used,” he said.
 For painter Erin Hanson, whose impressionist landscapes are so popular and easy to find online that she has seen their influence in AI-produced visuals, the concern is not about her own prolific output, which makes US$3mil (RM13mil) a year.
 She does, however, worry about the art community as a whole.
 “The original artist needs to be acknowledged in some way or compensated,” said Hanson. 
 “That’s what copyright laws are all about. And if artists aren’t acknowledged, then it’s going to make it hard for artists to make a living in the future.” – AP",countless artist inspiration night vincent van gogh scene artificial intelligence system vast collection artwork image smartphone app image tool dall midjourney stable diffusion weird realistic customisable peacock owl style van gogh churn van gogh dead master painter living artist photographer fight software company image lawsuit seattle photography giant getty image popular image service million image getty legal proceeding court justice london stability maker stable diffusion intellectual property right london startup commercial lawsuit federal court francisco describes image generator century collage tool violate right million artist lawsuit jan artist name stability defendant san francisco image generator midjourney online gallery deviantart lawsuit image marketplace original image seek image style artist pay commission license original image artist company image generating service user free trial midjourney app discord instance user subscription start month corporate membership openai charge image generator stabilityai offer service dreamstudio stability statement fair understand technology law december interview lawsuit midjourney ceo david holz image service search engine wide swath image copyright concern technology law human creativity person picture learn picture holz people professional art industry nonprofessional industry extent people sort image copyright dispute backlash generation impressive tool generate visual medium readable text computer code command broader concern propensity tool misinformation harm image generator creation nonconsensual sexual imagery system photorealistic image impossible trace difficult difference real safeguard offensive harmful content expert matter time people tool spread disinformation public trust lose capability real fake lose confidence wael almageed professor electrical computer engineering university southern california test text prompt stable diffusion keywords ukraine war getty photo soldier combat hand gun image getty watermark text wrong foot finger detail ear real set pattern visual clue midjourney user discord chat advice hand image social network viral debunk specific tool data source chirag shah professor school university washington guess experience tool easy scientific backlash people tool creativity hobby create intricate landscape portrait brainstorm marketing material game scenery idea profession fear artist refik anadol economic forum davos switzerland exhibit climate created training model coral museum modern art york anadol unsupervised draw artwork prestigious collection starry night feed digital installation animation colour shape lobby installation artwork archive anadol van gogh picasso kandinsky incredible inspiring artist pioneered technique artwork dream anadol model interview prefers technology future commercial application artist hear agree artist creator uncomfortable painter erin hanson impressionist popular easy online influence visuals concern prolific output mil community original artist compensated hanson law artist hard artist future,"[(2, 0.91119605), (4, 0.087150015)]",2
507062,Main,22,19/01/2023,Getty Images targets AI firm for ‘copying’ photos,,"Paris: US firm Getty Images threa­tened to sue a tech company it accuses of illegally copying millions of photos for use in an artificial intelligence (AI) art tool.
 Getty, which distributes stock images and news photos including those of AFP, accused Stability AI of profiting from its pictures and those of its partners.
 Stability AI runs a tool called Stable Diffusion that allows users to generate mash-up images from a few words of text, but the firm uses material it scrapes from the web often without permission.
 The question of copyright is still in dispute, with creators and artists arguing that the tools infringe their intellectual property and AI firms claiming they are protected under “fair use” rules.
 Tools like Stable Diffusion and Dall-E 2 exploded in popularity last year, quickly becoming a global sensation with absurd images in the style of famous artists flooding social media.
 But the increased visibility also attracted the attention of artists, photographers, other creators and their lawyers.
 Stability AI is already facing a class action lawsuit in the United States, launched last week by three artists who claim their copyright has been infringed.
 “It is Getty Images’ position that Stability AI unlawfully copied and processed millions of images protected by copyright,” the firm said in a statement.
 The photo firm said it had provided licences tailored to firms that wanted to train AI models.
 “Stability AI did not seek any such license from Getty Images and instead, we believe, chose to ignore viable licensing options and long-standing legal protections in pursuit of their standalone commercial interests.” — AFP",paris firm getty image sue tech company million artificial intelligence art tool getty stock image news photo afp stability picture partner stability tool stable diffusion user mash image text firm material scrape web permission question dispute creator tool intellectual property firm protected fair rule stable diffusion dall popularity global sensation absurd image style famous artist social medium visibility attention photographer creator lawyer stability class action lawsuit launched week artist copyright getty image position stability million image copyright firm statement photo firm licence tailored firm model stability seek license getty image viable licensing option legal protection standalone commercial afp,"[(0, 0.76647896), (3, 0.22683641)]",0
500306,StarBiz,8,03/01/2023,AI infused everything                on display at CES,Show-goers hope for a return of packed halls,"San Francisco: The latest leaps in artificial intelligence (AI) in everything from cars, robots to appliances will be on full display at the annual Consumer Electronics Show (CES) opening Thursday in Las Vegas.
 Forced by the pandemic to go virtual in 2021 and hybrid last year, tens of thousands of show-goers are hoping for a return to packed halls and rapid-fire deal-making that were long the hallmark of the annual gadget extravaganza.
 “In 2022, it was a shadow of itself – empty halls, no meetings in hotel rooms,” Avi Greengart, an analyst at Techspotential told AFP.
 “Now, (we expect) crowds, trouble getting around and meetings behind closed doors –which is what a trade show is all about.”
 The CES show officially opens on Jan 5, but companies will begin to vie for the spotlight with the latest tech wizardry as early as today.
 CES will be spread over more than 18 acres, from the sprawling Las Vegas Convention Centre to pavilions set up in parking lots. 
 Ballrooms and banquet rooms across Sin City will be used to hustle up business.
 With transportation now computing’s new frontier, next generation autos, trucks, boats, farm equipment, and even flying machines are expected to grab attention, say analysts.
 “It’s going to feel almost like you’re at an auto show,” said Kevan Yalowitz, head of platform strategy at Accenture.
 More than ever, cars now come with operating systems so much like a smartphone or laptop computer, Accenture expects that by 2040 about 40% of vehicles on the road will need software updated remotely.
 And with connected cars come apps and online entertainment as developers battle to grab passenger attention with streaming or shopping services on board.
 Electric vehicles enhanced with AI will also be on display “in a big way,” Greengart said.
 “What has really been the buzz is personalised flying machines,” said independent tech analyst Rob Enderle.
 “Basically, they are human-carrying drones.”
 Gadgets or services pitched as being part of the next-generation of the Internet – or “Web 3” – are also expected to include mixed reality gear as well as blockchain technology and non-fungible tokens.
 Web 3 promises a more decentralised Internet where tech giants, big business or governments no longer hold all the keys to life online.
 “The idea of how we are going to connect is going to be part of the big trend at CES,” said Creative Strategies analyst Carolina Milanesi. — AFP",san francisco artificial intelligence car appliance annual consumer electronics ce vega pandemic virtual hybrid ten thousand goer return hall rapid fire deal hallmark annual gadget extravaganza shadow empty hall meeting hotel greengart analyst techspotential afp crowd trouble meeting door trade ce jan company spotlight tech wizardry ce acre la vega convention centre pavilion lot ballroom sin city hustle business transportation frontier generation auto truck farm equipment machine attention analyst auto kevan yalowitz head platform strategy accenture car system laptop computer accenture vehicle road software connected car online entertainment developer battle grab passenger attention shopping service board electric vehicle display greengart buzz machine independent tech analyst rob human drone gadget service generation internet web mixed reality blockchain technology fungible token promise internet tech giant business government life online idea connect trend ce creative strategy analyst milanesi,"[(0, 0.9930907)]",0
499906,Lifestyle,3,02/01/2023,Laying down the law on AI,,"FROM “intelligent” vacuum cleaners and driverless cars to advanced techniques for diagnosing diseases, artificial intelligence has burrowed its way into every arena of modern life.
 Its promoters reckon it is revolutionising the human experience, but critics stress that the technology risks putting machines in charge of life-changing decisions.Regulators in Europe and North America are worried.
 The European Union is likely to pass legislation this year – the AI Act – aimed at reining in the age of the algorithm.
 The United States recently published a blueprint for an AI Bill of Rights and Canada is also mulling legislation.
 China’s use of biometric data, facial recognition, and other technology to build a powerful control system has loomed large in the debates.
 Gry Hasselbalch, a Danish academic who advises the EU on the controversial technology, argued that the West was also in danger of creating “totalitarian infrastructures”.
 “I see that as a huge threat, no matter the benefits,” she said.
 But before regulators can act, they face the daunting task of defining what AI actually is.
 ‘Mug’s game’
 Suresh Venkatasubramanian of Brown University, who co- authored the AI Bill of Rights, said trying to define AI was “a mug’s game”.
 Any technology that affects people’s rights should be within the scope of the bill, he tweeted.
 The 27-nation EU is taking the more tortuous route of attempting to define the sprawling field.
 Its draft law lists the kinds of approaches defined as AI, and it includes pretty much any computer system that involves automation.
 The problem stems from the changing use of the term AI.
 For decades, it described attempts to create machines that simulated human thinking.
 But funding largely dried up for this research – known as symbolic AI – in the early 2000s.
 The rise of the Silicon Valley titans saw AI reborn as a catch-all label for their number- crunching programs and the algorithms they generated.
 This automation allowed them to target users with advertising and content, helping them to make hundreds of billions of dollars.
 “AI was a way for them to make more use of this surveillance data and to mystify what was happening,” Meredith Whittaker, a former Google worker who co-founded New York University’s AI Now Institute, said.
 So, the EU and US have both concluded that any definition of AI needs to be as broad as possible.
 ‘Too challenging’
 But from that point, the two Western powerhouses have largely gone their separate ways.
 The EU’s draft AI Act runs to more than 100 pages.
 Among its most eye-catching proposals are the complete prohibition of certain “high-risk” technologies – the kind of biometric surveillance tools used in some countries.
 It also drastically limits the use of AI tools by migration officials, police and judges.
 Hasselbalch said some technologies were “simply too challenging to fundamental rights”.
 The AI Bill of Rights, on the other hand, is a brief set of principles framed in aspirational language, with exhortations like “you should be protected from unsafe or ineffective systems”.
 The bill was issued by the White House and relies on existing law.
 Because Congress is deadlocked, experts believe no dedicated AI legislation will be enacted in the United States until at least 2024.
 ‘Flesh wound’
 Opinions differ on the merits of each approach.
 “We desperately need regulation,” said Gary Marcus of New York University.
 He points out that “large language models” – the AI behind chatbots, translation tools, predictive text software and much else – can be used to generate harmful disinformation.
 Whittaker questioned the value of laws aimed at tackling AI rather than the “surveillance business models” that underpin it.“If you’re not addressing that at a fundamental level, I think you’re putting a band-aid over a flesh wound,” she said.
 But other experts have broadly welcomed the US approach.
 AI was a better target for regulators than the more abstract concept of privacy, said Sean McGregor, a researcher who chronicles tech failures for the AI Incident Database.
 But he said there could be a risk of over-regulation.
 “The authorities that exist can regulate AI,” he said, pointing to the likes of the US Federal Trade Commission and the housing regulator HUD.
 But where experts broadly agree is on the need to remove the hype and mysticism that surrounds AI technology.
 “It’s not magical,” McGregor said, likening AI to a highly sophisticated Excel spreadsheet. – AFP",intelligent vacuum cleaner driverless car technique disease artificial intelligence arena modern life promoter human experience critic stress technology risk machine charge life decision regulator worried european union pas legislation age algorithm blueprint bill right legislation china biometric data facial recognition technology powerful control system debate gry hasselbalch danish academic advises controversial technology west danger totalitarian infrastructure huge threat matter benefit regulator task game suresh venkatasubramanian brown university bill right game technology people right bill nation tortuous route define sprawling field draft law kind approach computer system automation term decade attempt machine human funding symbolic rise silicon valley titan reborn catch label program automation target user content hundred billion dollar surveillance data meredith whittaker google worker york university institute definition broad western powerhouse draft eye proposal complete prohibition risk technology biometric surveillance tool country limit tool migration official judge technology fundamental right bill right hand principle aspirational language exhortation unsafe ineffective system bill white house law congress expert legislation united flesh wound opinion merit regulation gary marcus york university language model chatbots translation tool predictive text software generate harmful disinformation whittaker law surveillance business model fundamental level band aid flesh wound expert approach target regulator concept privacy sean mcgregor researcher chronicle tech failure incident database risk regulation authority regulate federal trade commission housing regulator hud expert hype mysticism technology magical mcgregor sophisticated excel spreadsheet afp,"[(0, 0.07984611), (3, 0.9171938)]",3
